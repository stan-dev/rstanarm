[{"path":"https://mc-stan.org/rstanarm/ISSUE_TEMPLATE.html","id":"summary","dir":"","previous_headings":"","what":"Summary:","title":"NA","text":"short summary (sentence two).","code":""},{"path":"https://mc-stan.org/rstanarm/ISSUE_TEMPLATE.html","id":"description","dir":"","previous_headings":"","what":"Description:","title":"NA","text":"full description problem (question).","code":""},{"path":"https://mc-stan.org/rstanarm/ISSUE_TEMPLATE.html","id":"reproducible-steps","dir":"","previous_headings":"","what":"Reproducible Steps:","title":"NA","text":"applicable, steps required reproduce issue. reproducible example, please include .","code":""},{"path":"https://mc-stan.org/rstanarm/ISSUE_TEMPLATE.html","id":"rstanarm-version","dir":"","previous_headings":"","what":"RStanARM Version:","title":"NA","text":"version rstanarm package running (e.g., packageVersion(\"rstanarm\"))","code":""},{"path":"https://mc-stan.org/rstanarm/ISSUE_TEMPLATE.html","id":"r-version","dir":"","previous_headings":"","what":"R Version:","title":"NA","text":"version R running (e.g., getRversion())","code":""},{"path":"https://mc-stan.org/rstanarm/ISSUE_TEMPLATE.html","id":"operating-system","dir":"","previous_headings":"","what":"Operating System:","title":"NA","text":"operating system (e.g., OS X 10.11.3)","code":""},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"abstract","dir":"Articles","previous_headings":"","what":"Abstract","title":"Probabilistic A/B Testing with rstanarm","text":"case study shows basic /B testing using Stan Bayesian methods can used facilitate business decisions. practice, find approach useful given ability quantify domain-specific business knowledge hypotheses use prior distributions. Instead using p-values confidence intervals, able perform inference probability intervals estimated posterior predictions. addition results highly interpretable, approach allows us quantify business risk.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Probabilistic A/B Testing with rstanarm","text":"/B testing experiment. essentially randomized controlled trial industry setting. test experiment conducted subset users order determine change service (e.g. user experience) positive impact business, rolling change users. (consider static /B testing inference performed experiment. /B testing users dynamically allocated outperforming group experiment consider multi-arm bandits.) stylized scenarios /B testing provide useful insight: change order information displayed service users spend time service? personalize cover art streaming content users likely stream content? users responsive revised recommendation system? noticeable difference three point accuracy two basketball players? drug trial, evidence treatment better placebo? Typically, /B testing involves one group people served existing content (control group, group ) another group served different content (treatment group, group B) , measurable indicator, business wants determine difference reaction two groups. compare two groups find difference indicator large (relative uncertainty) can argue different content drove change. Conversely, change minimal may hesitant conclude different content resulted change behavior . situation perhaps content needs redesigned retested. /B testing approaches used practice typically rely frequentist hypothesis testing methods. results methods difficult interpret, can also misleading. Terms “p-values” “confidence intervals” often misinterpreted probabilities directly related quantity interest (e.g. difference means two groups). P-values also often used cutoffs business decisions. words, reaching statistically significant result often sufficient convince business move forward particular decision. argue decisions reductively derived arbitrary cutoffs (e.g. p-value less 0.05). Instead determined domain-specific experts understand industry, statisticians providing interpretable results can help experts make informed decisions. case study provides way domain-specific experts apply knowledge statistical inference process /B testing prior distributions. Additionally, experts can quantify risk willing take probabilistically incorporate inference. key benefits Bayesian approach outlined case study include, Allowing domain-specific experts apply knowledge appetite risk statistical inference. Modeling data rather defining/computing test statistic data. (allows us perform inference (predicted) data instead parameters.) ability describe differences groups probabilistically rather using traditional hypothesis testing methods. Quantifying null hypotheses priors. use simple examples show apply Bayesian inference /B testing using continuous count data. examples used analogous t-test Fisher’s exact test, methodology discussed can applied data follow distributions. first section considers continuous data (assumed generated normal distribution) second section considers count data (assumed generated binomial distribution). (need referesher convoluted hypothesis testing , Appendix goes interpretation p-values using two-sample t-test example.) high-level, stress frequentist methods focus distribution test statistic opposed quantity interest (.e. predictions parameters). methods inference done understanding observed test statistic compares distribution test statistic null hypothesis. Alternatively, Bayesian approach proposed allows statistician perform inference directly quantity interest (case predicted data), transparent informative context /B testing.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"continuous-data","dir":"Articles","previous_headings":"","what":"Continuous Data","title":"Probabilistic A/B Testing with rstanarm","text":"example analogous two sample t-test (specifically Welch’s t-test) statistician interested testing noticeable difference means two different samples. Suppose online streaming company interested testing whether ads affect consumption service. hypothesis reducing ads increase hourly streaming consumption. Since decision can costly significant amount revenue derived ads, useful conduct test evaluate impact ad reduction. One way test draw two random samples user base, serve different levels ad content, see substantial difference streaming consumption (say hours per day). Suppose treat two groups following way, Group (control): streaming service contains ads. Group B (treatment): streaming service contains ads. data collected might look something like following . observation user’s average daily streaming consumption hours. Suppose also additional (binary) variable hc defines whether user predisposed high consumer streaming content (value 1 represents high consumer value -1 represents low consumer). order determine difference groups need define model predicts outcome group. data generated normal distribution appropriate specify normal likelihood. (Often know data generated make assumption distribution used model likelihood.) Since modeling outcome can include variables, high consumer indicator hc. Traditional hypothesis testing methods focused comparing outcome two groups. model outcome comparing groups. allows us include additional information model enable us perform granular inferences. Next need specify prior distributions parameters. domain-specific expert can provide valuable input. example, may believe (due poor sampling) sampled average daily streaming hours low group. situation prior can applied coerce estimated average closer value feel appropriate representative population. Putting pieces together gives us model . \\(y\\) outcome (average streaming hours) \\(sigma\\) residual standard deviation (.e. standard deviation \\(y\\) conditional parameters data). \\(\\mu\\) parameter associated variable \\(group\\) defines group membership, \\(\\beta\\) parameter associated high consumer indicator. One limitation approach \\(\\sigma\\) vary among groups. However, case sufficient assume outcome groups standard deviation. (order allow standard deviation vary among groups model fit rstan, require defining model Stan file.) \\[ \\begin{align*} y_i \\sim &\\mathcal{N}(\\mu_A \\cdot groupA_i + \\mu_B \\cdot groupB_i + \\beta \\cdot high\\_consumer_i, \\sigma) \\\\ \\mu_A \\sim& \\mathcal{N}(3,1) \\\\ \\mu_B \\sim& \\mathcal{N}(3,1) \\\\ \\beta \\sim& \\mathcal{N}(0,1) \\\\ & \\mbox{(default prior specified } \\sigma \\mbox{)} \\end{align*} \\] regard priors, applied \\(\\mathcal{N}(3,1)\\) distributions group effects. reasoning behind twofold: Based prior knowledge (past data /domain specific experts) believe users spend around three hours per day service (regardless random sample says). allow hyperparameters group groups identical quantify belief group B (received treatment) substantially different group . can interpreted incorporating belief underlying null hypothesis prior. importantly, approach allows us conservative inference. end concluding two groups different, can say difference behavior strong overcame prior belief two groups identical. Now established model, need fit model data can estimate parameters. can using rstanarm package can fit Bayesian linear regression model (using stan_glm() function) without intercept, group membership additional variables parameters. fit model . Recall Stan uses sampling algorithm estimate joint posterior distribution parameters means samples instead point estimates parameter values. medians parameter provided . estimates looks like Group average consumption 3 hours Group B average consumption 5 hours. gives us difference consumption approximately 2 hours. Unfortunately, assessment say anything uncertain difference . like able say something like “\\(p\\%\\) sure two groups different enough”. can quantify uncertainty different two estimates computing sample quantiles posterior predictive distribution. often referred credible interval, although preferred term predictive interval describing predictions (posterior interval describing parameters). compute \\(90\\%\\) predictive interval can say \\(90\\%\\) posterior predictions group lie interval. order us evaluate whether two groups different enough can compute overlap coefficient, describes overlap prediction intervals group proportion. example, suppose \\(15\\%\\) overlap \\(90\\%\\) prediction intervals two groups. allows us say, given \\(90\\%\\) certain predictions lie, ’s \\(15\\%\\) chance two groups similar. functions compute proportion overlap two groups. compute \\(0.9\\) prediction interval groups. Note prediction interval choice arbitrary, may vary depending applied context appetite uncertainty. also recommend getting input domain-specific experts. case willing accept \\(10\\%\\) chance wrong predictions lie. closer prediction interval \\(1\\) risk averse business regards inference.  computing \\(90\\%\\) prediction interval groups find overlap proportion approximately \\(0.25\\). Thus, given \\(90\\%\\) sure posterior predictions two groups, \\(75\\%\\) sure two groups fact different. Going back business context, can conclude \\(75\\%\\) sure reducing ads increases daily streaming consumption given acceptable risk \\(10\\%\\) wrong daily streaming consumption. Since modeled outcome using predictor (addition group membership variables) can vary predictor well group membership observation detailed inference. plot prediction intervals group high consumer variable combination. allows us compare difference average streaming hours among two groups individuals categorized high/low consumers.  plot show overlap proportion vary prediction interval varies. put differently, shows probabilistic difference groups varies risk varies. Notice risk take defining prediction interval (.e. closer prediction interval 0) lower overlap proportion, consequentially apparent difference two groups.","code":"set.seed(123) group <- c(rep(1,10), rep(2,12)) group <- factor(c(rep(\"A\",10), rep(\"B\",12))) N <- length(group) hc <- sample(c(-1,1), N, replace = TRUE) effect <- c(3,5)  lp <- effect[group] + 0.7*hc y <- rnorm(N, lp, 0.5)  experiment <- data.frame(y = y,                          group = factor(group),                          hc = hc) experiment ##           y group hc ## 1  2.479907     A -1 ## 2  2.500386     A -1 ## 3  2.355341     A -1 ## 4  3.422079     A  1 ## 5  3.193457     A -1 ## 6  3.948925     A  1 ## 7  2.716691     A  1 ## 8  4.050678     A  1 ## 9  2.063604     A -1 ## 10 1.766088     A -1 ## 11 5.591013     B  1 ## 12 5.186998     B  1 ## 13 5.335554     B  1 ## 14 3.987480     B -1 ## 15 4.856653     B  1 ## 16 4.718894     B -1 ## 17 5.776687     B  1 ## 18 3.730932     B -1 ## 19 4.926907     B -1 ## 20 4.513232     B -1 ## 21 4.152464     B -1 ## 22 6.147563     B  1 fit <- stan_glm(y ~ 0 + group + hc,                 data = experiment,                 family = gaussian(link=\"identity\"),                 prior = normal(c(3,3,0), 1),                 seed = 123) c(coef(fit), sigma = sigma(fit)) ##    groupA    groupB        hc     sigma  ## 2.9614608 4.8750319 0.5630955 0.4960421 #' Quantify Overlapping Proportion #' Compute how much of the smaller distribution overlaps with the larger (i.e. wider) distribution. #' @param large Posterior predictive samples that have larger range than \\code{small}. #' @param small Posterior predictive samples that have smaller range than \\code{large}. #' @param p Probability to compute prediction interval. #' @return A proportion between 0 and 1 indicating how much of \\code{small} is contained in \\code{large} given the credible interval specification. overlap_prop <- function(large, small, p = 1) {   p_lwr <- (1-p)/2   p_upr <- 1 - p_lwr   large_ci <- quantile(large, probs = c(p_lwr, p_upr))   left <- min(large_ci)   right <- max(large_ci)   indxs <- which(small >= left & small <= right)   return(length(indxs)/length(small)) }  #' Quantify Overlapping Posterior Predictive Distributions #' Quantify the overlap between posterior samples from two distributions. #' @param a Group A posterior predictive samples. #' @param b Group B posterior predictive samples. #' @param p Probability to compute credible interval. #' @return A proportion between 0 and 1 indicating how much of the credible intervals for \\code{a} and \\code{b} overlap with one another. overlap <- function(a, b, p = 1) {   length_a <- dist(range(a))   length_b <- dist(range(b))   if (length_a >= length_b) {     out <- overlap_prop(a, b, p)   }   else if (length_a < length_b) {     out <- overlap_prop(b, a, p)   }   return(out) } pp_a <- posterior_predict(fit, newdata = data.frame(group = factor(\"A\"), hc = experiment$hc)) pp_b <- posterior_predict(fit, newdata = data.frame(group = factor(\"B\"), hc = experiment$hc)) pp_a_quant <- quantile(pp_a, probs = c(0.05,0.95)) pp_b_quant <- quantile(pp_b, probs = c(0.05,0.95))  overlap(pp_a, pp_b, p = 0.9) ## [1] 0.2356818  par(mfrow=c(2,1)) # group A hist(pp_a, breaks = 50, col = '#808080', border = '#FFFFFF',      main = \"Group A\",      xlab = \"Avg Streaming (hrs)\",      xlim = c(0,10)) abline(v = pp_a_quant[1], lwd = 2, col = \"red\") abline(v = pp_a_quant[2], lwd = 2, col = \"red\") # group B hist(pp_b, breaks = 50, col = '#808080', border = '#FFFFFF',      main = \"Group B\",      xlab = \"Avg Streaming (hrs)\",      xlim = c(0,10)) abline(v = pp_b_quant[1], lwd = 2, col = \"red\") abline(v = pp_b_quant[2], lwd = 2, col = \"red\") pp_a0 <- posterior_predict(fit, newdata = data.frame(group = factor(\"A\"), hc = -1)) pp_b0 <- posterior_predict(fit, newdata = data.frame(group = factor(\"B\"), hc = -1)) pp_a1 <- posterior_predict(fit, newdata = data.frame(group = factor(\"A\"), hc = 1)) pp_b1 <- posterior_predict(fit, newdata = data.frame(group = factor(\"B\"), hc = 1)) pp_a0_quant <- quantile(pp_a0, probs = c(0.05,0.95)) pp_b0_quant <- quantile(pp_b0, probs = c(0.05,0.95)) pp_a1_quant <- quantile(pp_a1, probs = c(0.05,0.95)) pp_b1_quant <- quantile(pp_b1, probs = c(0.05,0.95))  par(mfrow=c(2,2)) # group A, x = 0 hist(pp_a0, breaks = 50, col = '#808080', border = '#FFFFFF',      main = \"Group A (hc=-1)\",      xlab = \"Avg Streaming (hrs)\",      xlim = c(0,10)) abline(v = pp_a0_quant[1], lwd = 2, col = \"red\") abline(v = pp_a0_quant[2], lwd = 2, col = \"red\") # group B, x = 0 hist(pp_b0, breaks = 50, col = '#808080', border = '#FFFFFF',      main = \"Group B (hc=-1)\",      xlab = \"Avg Streaming (hrs)\",      xlim = c(0,10)) abline(v = pp_b0_quant[1], lwd = 2, col = \"red\") abline(v = pp_b0_quant[2], lwd = 2, col = \"red\") # group A, x = 1 hist(pp_a1, breaks = 50, col = '#808080', border = '#FFFFFF',      main = \"Group A (hc=1)\",      xlab = \"Avg Streaming (hrs)\",      xlim = c(0,10)) abline(v = pp_a1_quant[1], lwd = 2, col = \"red\") abline(v = pp_a1_quant[2], lwd = 2, col = \"red\") # group B, x = 1 hist(pp_b1, breaks = 50, col = '#808080', border = '#FFFFFF',      main = \"Group B (hc=1)\",      xlab = \"Avg Streaming (hrs)\",      xlim = c(0,10)) abline(v = pp_b1_quant[1], lwd = 2, col = \"red\") abline(v = pp_b1_quant[2], lwd = 2, col = \"red\") # prediction interval probabilities ci_p <- seq(0.1,1, by = 0.05) # compute proportions overlap_ab <- sapply(ci_p, function(s){overlap(pp_a, pp_b, s)}) # plot plot(ci_p, overlap_ab, type = \"o\", pch = 20,      xaxt = \"n\", yaxt = \"n\",      main = \"Group A vs Group B\",      xlab = \"Prediction Interval Probability (1-Risk)\",      ylab = \"Overlap Proportion (Group Similarity)\") axis(1, seq(0,1,by=0.1), cex.axis = 0.8) axis(2, seq(0,1,by=0.1), cex.axis = 0.8) abline(v = 0.5, lty = 2)"},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"count-data","dir":"Articles","previous_headings":"","what":"Count Data","title":"Probabilistic A/B Testing with rstanarm","text":"example analogous Fisher’s exact test statistician interested testing differences proportions (particularly form contingency table). Now, suppose business wants know whether product sells better change online user interface (UI) users interact buy product. run experiment two groups obtain following results, Group C (control): 10 users sample 19 purchased product default UI. Group D (treatment): 14 users sample 22 purchased product alternative UI. can assume data binomially distributed, case can define model two groups follows, \\[ y_i \\sim \\mbox{Bin}(\\mbox{logit}^{-1}(\\mu_C \\cdot groupC_i + \\mu_D \\cdot groupD_i), N_i)\\\\ \\] \\(\\mu\\) parameter group, \\(group\\) binary variable indicating group membership, \\(y\\) number users purchased product \\(N\\) total number users group. fit model data. Similar method described previous section compute plot \\(90\\%\\) prediction intervals posterior predictions group. also compute overlap proportion two sets predictions.  Looking histograms ’s clear ’s quite bit overlap two groups. overlap proportion 0.7. \\(90\\%\\) prediction interval, \\(70\\%\\) chance difference behavior UI changes. might suggest don’t strong evidence UI change encouraged change behavior. show overlap proportion varies based amount risk ’re willing take define prediction intervals. Similar continuous example previous section, risk inversely related group similarity.  Note, example involved really small data set (one observation group). model can easily extended many observations within group. Also, just described continuous example, can define comprehensive model outcome additional predictors.","code":"experiment_bin <- data.frame(group = factor(c(\"C\",\"D\")),                              y = c(10,14),                              trials = c(19,22)) fit_group_bin <- stan_glm(cbind(y, trials - y) ~ 0 + group, data = experiment_bin,                           family = binomial(link=\"logit\"), seed = 123) # pp_c <- posterior_linpred(fit_group_bin, newdata = data.frame(group = factor(\"C\")), transform = TRUE) # pp_d <- posterior_linpred(fit_group_bin, newdata = data.frame(group = factor(\"D\")), transform = TRUE) # below doesn't work as expected (predictions are bigger than the number of trials) # pp_c <- posterior_predict(fit_group_bin, newdata = data.frame(group = factor(\"C\"), trials = 19)) # pp_d <- posterior_predict(fit_group_bin, newdata = data.frame(group = factor(\"D\"), trials = 22)) pp <- posterior_predict(fit_group_bin) pp_c <- pp[,1] pp_d <- pp[,2] pp_c_quant <- quantile(pp_c, probs = c(0.05,0.95)) pp_d_quant <- quantile(pp_d, probs = c(0.05,0.95))  # compute overlap overlap(pp_c, pp_d, p = 0.9) ## [1] 0.6885  # plot # group C par(mfrow=c(1,2)) hist(pp_c, breaks = 50, col = '#808080', border = '#FFFFFF',      main = \"Group C\",      xlab = \"Product Consumption\",      xlim = c(0,25)) abline(v = pp_c_quant[1], lwd = 2, col = \"red\") abline(v = pp_c_quant[2], lwd = 2, col = \"red\") # group D hist(pp_d, breaks = 50, col = '#808080', border = '#FFFFFF',      main = \"Group D\",      xlab = \"Product Consumption\",      xlim = c(0,25)) abline(v = pp_d_quant[1], lwd = 2, col = \"red\") abline(v = pp_d_quant[2], lwd = 2, col = \"red\") # prediction interval probabilities ci_p <- rev(seq(0.1,1, by = 0.05)) # compute proportions overlap_cd <- sapply(ci_p, function(s){overlap(pp_c, pp_d, s)}) # plot plot(ci_p, overlap_cd, type = \"o\", pch = 20,      xaxt = \"n\", yaxt = \"n\",      main = \"Group C vs Group D\", xlab = \"Prediction Interval Probability (1-Risk)\", ylab = \"Overlap Proportion (Group Similarity)\") axis(1, seq(0,1,by=0.1), cex.axis = 0.8) axis(2, seq(0,1,by=0.1), cex.axis = 0.8) abline(v = 0.5, lty = 2)"},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"benefits-of-bayesian-methods","dir":"Articles","previous_headings":"","what":"Benefits of Bayesian Methods","title":"Probabilistic A/B Testing with rstanarm","text":"key benefits discussed include ability probabilistically interpret results inference, ability incorporate prior beliefs (.e. business knowledge hypotheses) models. Interpretation probability regards interpretation, advantages taking Bayesian inference approach /B testing using Stan: ability communicate results using intuitive concept probability. ability quantify business risk using probability inference. Quantifying uncertainty probabilistically enables us make statements like “based data collected, model specified, risk willing take; 80% certain two groups different.” much interpretable statements like ‘p-value less 0.2 can reject null hypothesis two groups identical’. exclusively Bayesian benefit (.e. completely excluded priors models, estimating parameters solely likelihood data), took advantage fact appropriately implemented Bayesian computational methods rely robust sampling methods. samples can transformed used make probabilistic statements posterior predictive distribution, consequentially question asked. Incorporating prior beliefs ability define prior distribution parameters useful feature Bayesian methods. Prior information can incorporated model two choices: type distribution distribution parametrized. type distribution relates distribution choose define parameters. continuous data example chose normal distribution. , since underlying data (hours streamed per day) negative, might sensible define truncated normal distribution prior (straightforward implement rstan). gives us opportunity model data generation process appropriately. prior distribution parameterized reflects belief value parameter takes. gives us opportunity quantify business knowledge prior distributions. continuous data example showed parameterized prior distribution group’s parameter capture prior belief two groups similar. similar approach can taken treatment group count data example. types priors, concluded two groups fact different really sure treatment actually changed treatment group’s behavior. words, treatment group’s observed behavior overcame prior belief. also tune belief less strong adjusting density/mass prior distribution sits. Applying type prior help mitigate false-positive conclusions type analysis.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Probabilistic A/B Testing with rstanarm","text":"abstracted summary inference process ’ve gone compare groups involved /B testing. Model indicator measured track difference two groups. Compute prediction interval \\(p\\) posterior predictions two groups. \\(1-p\\) quantifies much risk business willing take regards predicted indicator. value \\(p\\) driven domain-specific experts. Compute proportion \\(o\\) much interval overlaps one another. \\(o\\) defines similarity two groups. implementing steps , can construct following conclusion: given \\((1-p) \\cdot 100\\) percent chance wrong predictions model, \\((1-o) \\cdot 100\\) percent chance two groups different. Bayesian methods outlined case study focused modeling data generation process performing inference posterior predictive distribution two groups. need worry computing test statistics determining distribution statistics null hypothesis. need calculate p-values figure whether groups involved /B test different. Instead performed inference directly posterior predictions. constructing prediction intervals computing overlap intervals able probabilistically convey sure difference two groups. Bayesian inference gives statisticians ability quantify business information/risk enables communicate uncertainty unambiguously decision makers, allowing informed decisions made.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"acknowlegements","dir":"Articles","previous_headings":"","what":"Acknowlegements","title":"Probabilistic A/B Testing with rstanarm","text":"Thanks Jonah Gabry Charles Zhou feedback initial drafts.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Probabilistic A/B Testing with rstanarm","text":"Fisher’s exact test. Wikipedia. Available https://en.wikipedia.org/wiki/Fisher%27s_exact_test. Gallo, . (2017) Refresher /B Testing. Harvard Business Review. https://hbr.org/2017/06/-refresher--ab-testing. Goodrich, B., Gabry, J., Ali, . & Brilleman, S. (2019). rstanarm: Bayesian applied regression modeling via Stan. R package version 2.17.4. https://mc-stan.org/. Krushke, J.K. (2015). Bayesian Data Analysis - Tutorial R, JAGS, Stan. Elsevier, New York, 2nd edition. Overlap coefficient. Wikipedia. Available https://en.wikipedia.org/wiki/Overlap_coefficient Stan Development Team (2019). RStan: R interface Stan. R package version 2.19.2. https://mc-stan.org/. Student’s t-test. Wikipedia. Available https://en.wikipedia.org/wiki/Student's_t-test.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"appendix-a-refresher-on-p-values","dir":"Articles","previous_headings":"","what":"Appendix A: Refresher on p-values","title":"Probabilistic A/B Testing with rstanarm","text":"Recall frequentist methods hypothesis testing involve constructing test statistic available data. , using distribution test statistic null hypothesis, can determine probability observing statistics extreme one calculated. known p-value. small p-value suggests small probability observing extreme test statistic, turn means unlikely statistic generated null hypothesis. Since statistic computed data suggests data unlikely generated null hypothesis. value small p-value arrive conclusion statistician. example consider data associated Group Group B continuous data section. null hypothesis whether two groups equal means. compute Welch’s test statistic p-value given data. p-value case really small, approximately zero. can visualize result. Since know test statistic t-distributed can plot distribution test statistic null, along test statistic calculated observed data. illustrated . red lines (two-tailed) test statistics calculated data.  Given small p-value can make following sequence conclusions: computed test statistic unlikely occur null hypothesis. data used compute statistic unlikely generated null hypothesis. Therefore null hypothesis must invalid can rejected, allowing us conclude two groups different. Notice far removed data observed data generation process. calculate test statistic step away distribution data start dealing distribution test statistic null. also unable encode prior belief business knowledge inference.","code":"group_a <- experiment$y[experiment$group == \"A\"] group_b <- experiment$y[experiment$group == \"B\"] # Relevant dplyr code # group_a <- experiment %>% filter(group == \"A\") %>% select(y) %>% unlist %>% unname # group_b <- experiment %>% filter(group == \"B\") %>% select(y) %>% unlist %>% unname  t_test <- t.test(x=group_a, y=group_b) t_stat <- abs(t_test$statistic) p_value <- t_test$p.value print(p_value) ## [1] 4.492529e-06 # You can manually compute the p-value with the following code # p_value <- pt(-t_stat, t_test$parameter)*2  # you can manually compute the confidence intervals with the following code # group_a_mean <- mean(group_a) # group_b_mean <- mean(group_b) # v <- sqrt((var(group_a)/length(group_a)) + (var(group_b)/length(group_b))) # ci_lwr <- (group_a_mean - group_b_new_mean) - abs(qt(0.025, t_test$parameter[['df']])*v) # ci_upr <- (group_a_mean - group_b_new_mean) + abs(qt(0.025, t_test$parameter[['df']])*v) dof <- t_test$parameter[[\"df\"]] x <- seq(-10,10,length.out = 1e3) plot(x, dt(x, dof), type = \"l\",      main = \"Distribution of Test Statistics Under Null Hypothesis\",      xlab = \"t-statistic value\",      ylab = \"t-distribution density\") abline(v=-t_stat, col=\"red\", lwd=2) abline(v=t_stat, col=\"red\", lwd=2)"},{"path":"https://mc-stan.org/rstanarm/articles/ab-testing.html","id":"appendix-b-hierarchical-example","dir":"Articles","previous_headings":"","what":"Appendix B: Hierarchical Example","title":"Probabilistic A/B Testing with rstanarm","text":"show use hierarchical (multilevel) models alternative modeling approach performing /B tests. Using data continuous example want build model account group-level intercepts allowing information shared among groups. \\[ \\begin{align*} y_{=} \\sim &\\mathcal{N}(\\mu_A + \\beta \\cdot high\\_consumer_{=}, \\sigma) \\\\ y_{=B} \\sim &\\mathcal{N}(\\mu_B + \\beta \\cdot high\\_consumer_{=B}, \\sigma) \\\\ \\beta \\sim& \\mathcal{N}(0,1) \\\\ & \\mbox{(default priors specified covariance matrix } \\sigma \\mbox{)} \\end{align*} \\] fit model. modeling approach can perform inferences shown accounting hierarchical nature data.","code":"fit_hier <- stan_glmer(y ~ 0 + (1 | group) + hc,                        prior = normal(0, 1),                        data = experiment,                        family = gaussian(link=\"identity\"),                        seed = 123) coef(fit_hier) ## $group ##   (Intercept)        hc ## A    2.952043 0.5609544 ## B    4.884713 0.5609544 ##  ## attr(,\"class\") ## [1] \"coef.mer\" fixef(fit_hier) ##        hc  ## 0.5609544 ranef(fit_hier) ## $group ##   (Intercept) ## A    2.952043 ## B    4.884713 ##  ## with conditional variances for \"group\""},{"path":"https://mc-stan.org/rstanarm/articles/aov.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating ANOVA Models with rstanarm","text":"vignette explains estimate ANalysis VAriance (ANOVA) models using stan_aov function rstanarm package four steps Bayesian analysis Specify joint distribution outcome(s) unknowns, typically takes form marginal prior distribution unknowns multiplied likelihood outcome(s) conditional unknowns. joint distribution proportional posterior distribution unknowns conditional observed data Draw posterior distribution using Markov Chain Monte Carlo (MCMC). Evaluate well model fits data possibly revise model. Draw posterior predictive distribution outcome(s) given interesting values predictors order visualize manipulation predictor affects (function ) outcome(s). Steps 3 4 covered depth vignette entitled “Use rstanarm Package”. vignette focuses Step 1 likelihood product independent normal distributions. also demonstrate Step 2 entirely automatic sometimes necessary specify additional tuning parameters order obtain optimally efficient results.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/aov.html","id":"likelihood","dir":"Articles","previous_headings":"","what":"Likelihood","title":"Estimating ANOVA Models with rstanarm","text":"likelihood one observation linear model can written conditionally normal PDF \\[\\frac{1}{\\sigma_{\\epsilon} \\sqrt{2 \\pi}}   e^{-\\frac{1}{2} \\left(\\frac{y - \\mu}{\\sigma_{\\epsilon}}\\right)^2},\\] \\(\\mu = \\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta}\\) linear predictor \\(\\sigma_{\\epsilon}\\) standard deviation error predicting outcome, \\(y\\). likelihood entire sample product \\(N\\) individual likelihood contributions. ANOVA model can considered special case linear regression model \\(K\\) predictors \\(\\mathbf{x}\\) dummy variable indicating membership group. equivalent linear predictor can written \\(\\mu_j = \\alpha + \\alpha_j\\), expresses conditional expectation outcome \\(j\\)-th group sum common mean, \\(\\alpha\\), group-specific deviation common mean, \\(\\alpha_j\\).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/aov.html","id":"priors","dir":"Articles","previous_headings":"","what":"Priors","title":"Estimating ANOVA Models with rstanarm","text":"view ANOVA model special case linear regression model dummy variables predictors, model estimated using prior specification stan_lm function. fact, exactly stan_aov function coded. functions require user specify value prior location (default mode) \\(R^2\\), proportion variance outcome attributable predictors linear model. prior specification appealing ANOVA context fundamental identity \\[SS_{\\mbox{total}} = SS_{\\mbox{model}} + SS_{\\mbox{error}},\\] \\(SS\\) stands sum--squares. normalize identity, obtain tautology \\(1 = R^2 + \\left(1 - R^2\\right)\\) reasonable expect researcher plausible guess \\(R^2\\) conducting ANOVA. See vignette stan_lm function (regularized linear models) information approach. view ANOVA model difference means, model estimated using prior specification stan_lmer function. syntax popularized lme4 package, y ~ 1 + (1|group) represents likelihood \\(\\mu_j = \\alpha + \\alpha_j\\) \\(\\alpha_j\\) normally distributed across \\(J\\) groups mean zero unknown standard deviation. stan_lmer function specifies standard deviation Gamma prior , default, shape scale parameters equal \\(1\\), just standard exponential distribution. However, shape scale parameters can specified positive values. approach also requires specifying prior distribution standard deviation errors independent prior distribution \\(\\alpha_j\\). See vignette stan_glmer function (lme4-style models using rstanarm) information approach.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/aov.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Estimating ANOVA Models with rstanarm","text":"utilize example HSAUR3 package Brian S. Everitt Torsten Hothorn, used 2014 book Handbook Statistical Analyses Using R (3rd Edition) (Chapman & Hall / CRC). book frequentist nature show obtain corresponding Bayesian results. model section 4.3.1 analyzes experiment rats subjected different diets order see much weight gained. experimental factors whether diet low high protein whether protein derived beef cereal. seeing data, one might expect moderate proportion variance weight gain might attributed protein (source) diet. frequentist ANOVA estimates can obtained: obtain Bayesian estimates can prepend stan_ aov specify prior location \\(R^2\\) well optionally number cores computer allowed utilize: specified adapt_delta = 0.999 decrease stepsize largely prevent divergent transitions. See Troubleshooting section main rstanarm vignette details adapt_delta. Also, prior guess \\(R^2 = 0.5\\) overly optimistic. However, frequentist estimates presumably overfit data even . Alternatively, prepend stan_ lmer specify corresponding priors Comparing two models using loo function loo package reveals negligible preference first approach almost entirely due smaller number effective parameters result regularizing priors. However, difference small may seem advantageous present second results line mainstream Bayesian approach ANOVA model.","code":"data(\"weightgain\", package = \"HSAUR3\") coef(aov(weightgain ~ source * type, data = weightgain)) (Intercept)         sourceCereal              typeLow                 100.0                -14.1                -20.8  sourceCereal:typeLow                  18.8 library(rstanarm) post1 <- stan_aov(weightgain ~ source * type, data = weightgain,                    prior = R2(location = 0.5), adapt_delta = 0.999,                   seed = 12345) post1 stan_aov  family:       gaussian [identity]  formula:      weightgain ~ source * type  observations: 40  predictors:   4 ------                      Median MAD_SD (Intercept)           98.7    4.6  sourceCereal         -12.8    6.2  typeLow              -18.6    6.4  sourceCereal:typeLow  16.8    8.8   Auxiliary parameter(s):               Median MAD_SD R2             0.2    0.1   log-fit_ratio  0.0    0.1   sigma         14.7    1.6    ANOVA-like table:                     Median MAD_SD Mean Sq source      546.9  421.7  Mean Sq type        961.6  583.8  Mean Sq source:type 707.1  701.6   ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg post2 <- stan_lmer(weightgain ~ 1 + (1|source) + (1|type) + (1|source:type),                    data = weightgain, prior_intercept = cauchy(),                    prior_covariance = decov(shape = 2, scale = 2),                    adapt_delta = 0.999, seed = 12345)"},{"path":"https://mc-stan.org/rstanarm/articles/aov.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Estimating ANOVA Models with rstanarm","text":"vignette compared contrasted two approaches estimating ANOVA model Bayesian techniques using rstanarm package. likelihood, (small case) differences results attributable differences priors. stan_aov approach just calls stan_lm thus requires prior location \\(R^2\\) linear model. seems rather easy context ANOVA decomposition total sum--squares outcome model sum--squares residual sum--squares. stan_lmer approach just calls stan_glm specifies normal prior mean zero deviations \\(\\alpha\\) across groups. line Bayesians naturally — particularly factors considered “random” — also requires prior \\(\\alpha\\), \\(\\sigma\\), standard deviation normal prior group-level intercepts. stan_lmer approach flexible might appropriate complicated experimental designs.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/betareg.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Modeling Rates/Proportions using Beta Regression with rstanarm","text":"vignette explains model continuous outcomes open unit interval using stan_betareg function rstanarm package. four steps Bayesian analysis Specify joint distribution outcome(s) unknowns, typically takes form marginal prior distribution unknowns multiplied likelihood outcome(s) conditional unknowns. joint distribution proportional posterior distribution unknowns conditional observed data Draw posterior distribution using Markov Chain Monte Carlo (MCMC). Evaluate well model fits data possibly revise model. Draw posterior predictive distribution outcome(s) given interesting values predictors order visualize manipulation predictor affects (function ) outcome(s). Steps 3 4 covered depth vignette entitled “Use rstanarm Package”. vignette focuses Step 1 likelihood product beta distributions.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/betareg.html","id":"likelihood","dir":"Articles","previous_headings":"","what":"Likelihood","title":"Modeling Rates/Proportions using Beta Regression with rstanarm","text":"Beta regression uses beta distribution likelihood data, \\[ f(y_i | , b) = \\frac{y_i^{(-1)}(1-y_i)^{(b-1)}}{B(,b)} \\] \\(B(\\cdot)\\) beta function. shape parameters distribution \\(\\) \\(b\\) enter model according following transformations, \\[ = \\mu\\cdot\\phi \\\\ b = (1-\\mu)\\cdot\\phi \\] Let \\(g_1(\\cdot)\\) link function. , specification shape parameters , \\(\\mu = g_1^{-1}(\\mathbf{X}\\boldsymbol{\\beta})\\), \\(\\boldsymbol{X}\\) \\(N\\times K\\) dimensional matrix predictors, \\(\\boldsymbol{\\beta}\\) \\(K\\) dimensional vector parameters associated predictor. simplest case (one set regressors), \\(\\phi\\) scalar parameter. Alternatively, possible model \\(\\phi\\) using second set regressors \\(\\mathbf{Z}\\). context let \\(g_2(\\cdot)\\) link function necessarily identical \\(g_1(\\cdot)\\). \\(\\phi = g_2^{-1}(\\mathbf{Z}\\boldsymbol{\\gamma})\\), \\(\\boldsymbol{\\gamma}\\) \\(J\\) dimensional vector parameters associated \\(N\\times J\\) dimensional matrix predictors \\(\\mathbf{Z}\\). substituting shape parameter values , likelihood used beta regression takes following form, \\[ f(y_i | \\mu, \\phi) = \\frac{y_i^{(\\mu\\phi-1)}(1-y_i)^{((1-\\mu)\\phi-1)}}{B(\\mu\\phi,(1-\\mu)\\phi)} \\]","code":""},{"path":"https://mc-stan.org/rstanarm/articles/betareg.html","id":"priors","dir":"Articles","previous_headings":"","what":"Priors","title":"Modeling Rates/Proportions using Beta Regression with rstanarm","text":"full Bayesian analysis requires specifying prior distributions \\(f(\\boldsymbol{\\beta})\\) \\(f(\\phi)\\) vector regression coefficients \\(\\phi\\). using stan_betareg, distributions can set using prior_intercept, prior, prior_phi arguments. stan_betareg function supports variety prior distributions, explained rstanarm documentation (help(priors, package = 'rstanarm')). modeling \\(\\phi\\) linear predictor full Bayesian analysis requires specifying prior distributions \\(f(\\boldsymbol{\\beta})\\) \\(f(\\boldsymbol{\\gamma})\\). stan_betareg prior distributions \\(\\boldsymbol{\\gamma}\\) can set using prior_intercept_z prior_z arguments. example, suppose \\(K\\) predictors believe — prior seeing data — \\(\\beta_1, \\dots, \\beta_K\\) \\(\\phi\\) likely positive negative, highly unlikely far zero. beliefs can represented normal distributions mean zero small scale (standard deviation). give \\(\\phi\\) \\(\\beta\\)s prior (scale 1, say), call stan_betareg include arguments prior_intercept = normal(0,1), prior = normal(0,1), prior_phi = normal(0,1). , hand, less priori confidence parameters close zero use larger scale normal distribution /distribution heavier tails normal like Student t distribution. Step 1 “Use rstanarm Package” vignette discusses one example. fitting model can use prior_summary function print information prior distributions used fitting model.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/betareg.html","id":"posterior","dir":"Articles","previous_headings":"","what":"Posterior","title":"Modeling Rates/Proportions using Beta Regression with rstanarm","text":"using single set regressors, posterior distribution \\(\\boldsymbol{\\beta}\\) \\(\\phi\\) proportional product likelihood contributions, \\(K\\) priors \\(\\beta_k\\) parameters, \\(\\phi\\), \\[ f(\\boldsymbol{\\beta},\\phi|\\mathbf{y},\\mathbf{X}) \\propto \\prod_{=1}^N f(y_i | , b) \\times \\prod_{k=1}^K f(\\beta_k) \\times f(\\phi) \\] using two sets regressors, posterior distribution \\(\\boldsymbol{\\beta}\\) \\(\\boldsymbol{\\gamma}\\) proportional product likelihood contribution, \\(K\\) priors \\(\\beta_k\\) parameters, \\(J\\) priors \\(\\gamma_j\\) parameters, \\[ f(\\boldsymbol{\\beta},\\boldsymbol{\\gamma}|\\mathbf{y},\\mathbf{X}) \\propto \\prod_{=1}^N f(y_i | , b) \\times \\prod_{k=1}^K f(\\beta_k) \\times \\prod_{j=1}^J f(\\gamma_j) \\]","code":""},{"path":"https://mc-stan.org/rstanarm/articles/betareg.html","id":"an-example-using-simulated-data","dir":"Articles","previous_headings":"","what":"An Example Using Simulated Data","title":"Modeling Rates/Proportions using Beta Regression with rstanarm","text":"example outcome variable \\(\\mathbf{y}\\) simulated way warrants use beta regression. worth mentioning data generation process quite convoluted, apparent identification likelihood . data simulated uses logistic link function first set regressors log link function second set regressors.  model can fit calling stan_betareg, using appropriate link functions. clarity can use prior_summary print information prior distributions used fit models. priors used fit1 provided . usual posterior analyses available rstanarm. plots illustrate simulated values outcome variable. incorrect model noticeably fails capture top distribution consistently comparison true model.  can also compare models evaluating expected log pointwise predictive density (elpd), can calculated using loo method, provides interface rstanarm models functionality loo package. difference elpd negative indicating expected predictive accuracy first model higher.","code":"SEED <- 1234 set.seed(SEED) eta <- c(1, -0.2) gamma <- c(1.8, 0.4) N <- 200 x <- rnorm(N, 2, 2) z <- rnorm(N, 0, 2) mu <- binomial(link = logit)$linkinv(eta[1] + eta[2]*x) phi <- binomial(link = log)$linkinv(gamma[1] + gamma[2]*z) y <- rbeta(N, mu * phi, (1 - mu) * phi) dat <- data.frame(cbind(y, x, z)) hist(dat$y, col = \"darkgrey\", border = F, main = \"Distribution of Outcome Variable\", xlab = \"y\", breaks = 20, freq = F) library(rstanarm) fit1 <- stan_betareg(y ~ x | z, data = dat, link = \"logit\", link.phi = \"log\",                      cores = 2, seed = 12345) fit2 <- stan_betareg(y ~ -1 + x , data = dat, link = \"logit\", link.phi = \"log\",                      cores = 2, seed = 12345) round(coef(fit1), 2) round(coef(fit2), 2) (Intercept)                 x (phi)_(Intercept)           (phi)_z               0.93             -0.20              1.84              0.31 x (phi)_(Intercept)               0.00              1.08 prior_summary(fit1) Priors for model 'fit1'  ------ Intercept (after predictors centered)  ~ normal(location = 0, scale = 2.5)  Coefficients   Specified prior:     ~ normal(location = 0, scale = 2.5)   Adjusted prior:     ~ normal(location = 0, scale = 1.2)  Intercept_z (after predictors centered)  ~ normal(location = 0, scale = 2.5)  Coefficients_z   Specified prior:     ~ normal(location = 0, scale = 2.5)   Adjusted prior:     ~ normal(location = 0, scale = 1.2) ------ See help('prior_summary.stanreg') for more details library(ggplot2) library(bayesplot) bayesplot_grid(   pp_check(fit1), pp_check(fit2),    xlim = c(0,1),     ylim = c(0,4),    titles = c(\"True Model: y ~ x | z\", \"False Model: y ~ x - 1\"),   grid_args = list(ncol = 2) ) loo1 <- loo(fit1) loo2 <- loo(fit2) loo_compare(loo1, loo2) elpd_diff se_diff fit1   0.0       0.0   fit2 -79.9      11.8"},{"path":"https://mc-stan.org/rstanarm/articles/betareg.html","id":"an-example-using-gasoline-data","dir":"Articles","previous_headings":"","what":"An Example Using Gasoline Data","title":"Modeling Rates/Proportions using Beta Regression with rstanarm","text":"applied contexts may necessary work outcome variable proportion. proportion bound open unit interval beta regression can considered reasonable estimation method. betareg package provides dataset proportion crude oil converted gasoline distillation fractionation. variable defined yield. stan_betareg used model yield function temperature, pressure, batch conditions. plots illustrate simulated values gasoline yield. first model accounts variation batch conditions predictions looks somewhat uniform rather resembling peaked right-skewed behavior true data. second model somewhat better job capturing shape distribution, however location centered around 0.50 rather 0.20.  Evaluating expected log predictive distribution using loo reveals second two models preferred.","code":"library(rstanarm) data(\"GasolineYield\", package = \"betareg\") gas_fit1 <- stan_betareg(yield ~ temp + batch, data = GasolineYield, link = \"logit\",                          seed = 12345) gas_fit2 <- stan_betareg(yield ~ temp + batch | pressure,                          data = GasolineYield, link = \"logit\",                          seed = 12345) round(coef(gas_fit1), 2) round(coef(gas_fit2), 2) (Intercept)        temp      batch1      batch2      batch3      batch4        -5.16        0.01        1.35        0.95        1.15        0.77       batch5      batch6      batch7      batch8      batch9       (phi)         0.80        0.72        0.33        0.26        0.15       12.04 (Intercept)              temp            batch1            batch2              -6.06              0.01              1.69              1.29             batch3            batch4            batch5            batch6               1.53              1.03              1.10              1.01             batch7            batch8            batch9 (phi)_(Intercept)               0.52              0.47              0.37              5.34     (phi)_pressure               0.04 library(ggplot2) bayesplot_grid(   pp_check(gas_fit1), pp_check(gas_fit2),    xlim = c(0,1),     ylim = c(0,5),    titles = c(\"gas_fit1\", \"gas_fit2\"),   grid_args = list(ncol = 2) ) gas_loo1 <- loo(gas_fit1) gas_loo2 <- loo(gas_fit2) loo_compare(gas_loo1, gas_loo2) elpd_diff se_diff gas_fit2   0.0       0.0   gas_fit1 -33.9       3.3"},{"path":"https://mc-stan.org/rstanarm/articles/betareg.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Modeling Rates/Proportions using Beta Regression with rstanarm","text":"Ferrari, SLP Cribari-Neto, F (2004) “Beta Regression Modeling Rates Proportions”. Journal Applied Statistics. Vol. 31, . 07, p799-815.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/binomial.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating Generalized Linear Models for Binary and Binomial Data with rstanarm","text":"vignette explains estimate generalized linear models (GLMs) binary (Bernoulli) Binomial response variables using stan_glm function rstanarm package. four steps Bayesian analysis Specify joint distribution outcome(s) unknowns, typically takes form marginal prior distribution unknowns multiplied likelihood outcome(s) conditional unknowns. joint distribution proportional posterior distribution unknowns conditional observed data Draw posterior distribution using Markov Chain Monte Carlo (MCMC). Evaluate well model fits data possibly revise model. Draw posterior predictive distribution outcome(s) given interesting values predictors order visualize manipulation predictor affects (function ) outcome(s). Steps 3 4 covered depth vignette entitled “Use rstanarm Package”. vignette focuses Step 1 likelihood product conditionally independent binomial distributions (possibly one trial per observation).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/binomial.html","id":"likelihood","dir":"Articles","previous_headings":"","what":"Likelihood","title":"Estimating Generalized Linear Models for Binary and Binomial Data with rstanarm","text":"binomial GLM likelihood one observation \\(y\\) can written conditionally binomial PMF \\[\\binom{n}{y} \\pi^{y} (1 - \\pi)^{n - y},\\] \\(n\\) known number trials, \\(\\pi = g^{-1}(\\eta)\\) probability success \\(\\eta = \\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta}\\) linear predictor. sample size \\(N\\), likelihood entire sample product \\(N\\) individual likelihood contributions. \\(\\pi\\) probability, binomial model link function \\(g\\) maps unit interval (support \\(\\pi\\)) set real numbers \\(\\mathbb{R}\\). applied linear predictor \\(\\eta\\) values \\(\\mathbb{R}\\), inverse link function \\(g^{-1}(\\eta)\\) therefore returns valid probability 0 1. two common link functions used binomial GLMs logit probit functions. logit (log-odds) link function \\(g(x) = \\ln{\\left(\\frac{x}{1-x}\\right)}\\), likelihood single observation becomes \\[\\binom{n}{y}\\left(\\text{logit}^{-1}(\\eta)\\right)^y \\left(1 - \\text{logit}^{-1}(\\eta)\\right)^{n-y} = \\binom{n}{y} \\left(\\frac{e^{\\eta}}{1 + e^{\\eta}}\\right)^{y} \\left(\\frac{1}{1 + e^{\\eta}}\\right)^{n - y}\\] probit link function \\(g(x) = \\Phi^{-1}(x)\\) yields likelihood \\[\\binom{n}{y} \\left(\\Phi(\\eta)\\right)^{y} \\left(1 - \\Phi(\\eta)\\right)^{n - y},\\] \\(\\Phi\\) CDF standard normal distribution. differences logit probit functions minor – , rstanarm default, probit scaled slope origin matches logit’s – two link functions yield similar results. stan_glm, binomial models logit link function can typically fit slightly faster identical model probit link two models implemented Stan. Unless user specific reason prefer probit link, recommend logit simply slightly faster numerically stable. theory, infinitely many possible link functions, although practice typically used. common choices cauchit cloglog functions, can also used stan_glm (every link function compatible withglm work stan_glm).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/binomial.html","id":"priors","dir":"Articles","previous_headings":"","what":"Priors","title":"Estimating Generalized Linear Models for Binary and Binomial Data with rstanarm","text":"full Bayesian analysis requires specifying prior distributions \\(f(\\alpha)\\) \\(f(\\boldsymbol{\\beta})\\) intercept vector regression coefficients. using stan_glm, distributions can set using prior_intercept prior arguments. stan_glm function supports variety prior distributions, explained rstanarm documentation (help(priors, package = 'rstanarm')). example, suppose \\(K\\) predictors believe — prior seeing data — \\(\\alpha, \\beta_1, \\dots, \\beta_K\\) likely positive negative, highly unlikely far zero. beliefs can represented normal distributions mean zero small scale (standard deviation). give \\(\\alpha\\) \\(\\beta\\)s prior (scale 1, say), call stan_glm include arguments prior_intercept = normal(0,1) prior = normal(0,1). , hand, less priori confidence parameters close zero use larger scale normal distribution /distribution heavier tails normal like Student t distribution. Step 1 “Use rstanarm Package” vignette discusses one example.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/binomial.html","id":"posterior","dir":"Articles","previous_headings":"","what":"Posterior","title":"Estimating Generalized Linear Models for Binary and Binomial Data with rstanarm","text":"independent prior distributions, joint posterior distribution \\(\\alpha\\) \\(\\boldsymbol{\\beta}\\) proportional product priors \\(N\\) likelihood contributions: \\[f\\left(\\alpha,\\boldsymbol{\\beta} | \\mathbf{y},\\mathbf{X}\\right) \\propto   f\\left(\\alpha\\right) \\times \\prod_{k=1}^K f\\left(\\beta_k\\right) \\times   \\prod_{=1}^N {   g^{-1}\\left(\\eta_i\\right)^{y_i}   \\left(1 - g^{-1}\\left(\\eta_i\\right)\\right)^{n_i-y_i}}.\\] posterior distribution stan_glm draw using MCMC.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/binomial.html","id":"logistic-regression-example","dir":"Articles","previous_headings":"","what":"Logistic Regression Example","title":"Estimating Generalized Linear Models for Binary and Binomial Data with rstanarm","text":"logit link function used model often referred logistic regression model (inverse logit function CDF standard logistic distribution). example, show carry parts analysis Chapter 5.4 Gelman Hill (2007) using stan_glm. Gelman Hill describe survey 3200 residents small area Bangladesh suffering arsenic contamination groundwater. Respondents elevated arsenic levels wells encouraged switch water source safe public private well nearby area survey conducted several years later learn affected residents switched wells. goal analysis presented Gelman Hill learn factors associated switching wells. start, ’ll use dist (distance respondent’s house nearest well safe drinking water) predictor switch (1 switched, 0 ). ’ll expand model adding arsenic level water resident’s well predictor compare larger model original. loading wells data, first rescale dist variable (measured meters) measured units 100 meters. leave dist original units corresponding regression coefficient represent effect marginal meter, small useful interpretation. estimating models can visualize distribution dist100 data:  plot blue bars correspond 1737 residents said switched wells darker bars show distribution dist100 1283 residents didn’t switch. expect, residents switched wells, distribution dist100 concentrated smaller distances. Bayesian version Gelman Hill’s initial logistic regression model can estimated using stan_glm function. ’ll use Student t prior 7 degrees freedom scale 2.5, , discussed , reasonable default prior coefficients close zero chance large. formula, data family arguments stan_glm specified exactly way glm. ’ve also added optional additional arguments chains (many chains want execute), cores (many cores want computer utilize) seed (reproducibility). can read possible arguments stan_glm documentation (help(stan_glm, package = 'rstanarm')). get sense uncertainty estimates can use posterior_interval function get Bayesian uncertainty intervals. uncertainty intervals computed finding relevant quantiles draws posterior distribution. example, compute 50% intervals use: posterior_interval interpreting parameter estimates Bayesian model see Step 2 “Use rstanarm Package” vignette. Using coefficient estimates can plot predicted probability switch = 1 (function dist100) together observed outcomes:  plot shows model predicted probability switching decent bit 50% residents living close wells safe drinking water. expected, larger values dist100 associated lower predicted probabilities switching. extreme (\\(\\approx 300\\) meters), probability 25%. Next, incorporate additional predictor model: arsenic level water respondent’s well. According Gelman Hill, “levels present Bangladesh drinking water, health risks arsenic roughly proportional exposure, expect switching likely wells high arsenic levels” (pg. 90). need change formula, can use update function: expected coefficient arsenic positive. plot shows distance x-axis arsenic level y-axis predicted probability well-switching mapped color background tiles (lighter color higher probability). observed value switch indicated color points.  can see black points (switch=1) predominantly clustered upper-left region plot predicted probability switching highest. Another way can visualize data model follow Gelman Hill create separate plots varying arsenic level distance. ’ll plot curves representing predicted probability switching minimum, maximum quartile values variables.  can compare two models (without arsenic) using approximation Leave-One-(LOO) cross-validation, method estimating sample predictive performance implemented loo function loo package: results favor fit2 fit1, estimated difference elpd (expected log pointwise predictive density new dataset) much larger standard error. LOO penalizes models adding additional predictors (helps counter overfitting), case fit2 represents enough improvement fit1 penalty including arsenic negligible (arsenic important predictor). vignette stan_lm function also example using loo function results quite bit different see important additional considerations discussed.","code":"library(rstanarm) data(wells) wells$dist100 <- wells$dist / 100 ggplot(wells, aes(x = dist100, y = ..density.., fill = switch == 1)) +   geom_histogram() +    scale_fill_manual(values = c(\"gray30\", \"skyblue\")) t_prior <- student_t(df = 7, location = 0, scale = 2.5) fit1 <- stan_glm(switch ~ dist100, data = wells,                   family = binomial(link = \"logit\"),                   prior = t_prior, prior_intercept = t_prior,                    cores = 2, seed = 12345) (Intercept)     dist100        0.605      -0.621 round(posterior_interval(fit1, prob = 0.5), 2) 25%   75% (Intercept)  0.57  0.65 dist100     -0.69 -0.56 # Predicted probability as a function of x pr_switch <- function(x, ests) plogis(ests[1] + ests[2] * x) # A function to slightly jitter the binary data jitt <- function(...) {   geom_point(aes_string(...), position = position_jitter(height = 0.05, width = 0.1),               size = 2, shape = 21, stroke = 0.2) } ggplot(wells, aes(x = dist100, y = switch, color = switch)) +    scale_y_continuous(breaks = c(0, 0.5, 1)) +   jitt(x=\"dist100\") +    stat_function(fun = pr_switch, args = list(ests = coef(fit1)),                  size = 2, color = \"gray35\") fit2 <- update(fit1, formula = switch ~ dist100 + arsenic) (coef_fit2 <- round(coef(fit2), 3)) (Intercept)     dist100     arsenic        0.002      -0.896       0.462 pr_switch2 <- function(x, y, ests) plogis(ests[1] + ests[2] * x + ests[3] * y) grid <- expand.grid(dist100 = seq(0, 4, length.out = 100),                      arsenic = seq(0, 10, length.out = 100)) grid$prob <- with(grid, pr_switch2(dist100, arsenic, coef(fit2))) ggplot(grid, aes(x = dist100, y = arsenic)) +    geom_tile(aes(fill = prob)) +    geom_point(data = wells, aes(color = factor(switch)), size = 2, alpha = 0.85) +    scale_fill_gradient() +   scale_color_manual(\"switch\", values = c(\"white\", \"black\"), labels = c(\"No\", \"Yes\")) # Quantiles q_ars <- quantile(wells$dist100, seq(0, 1, 0.25)) q_dist <- quantile(wells$arsenic, seq(0, 1, 0.25))   base <- ggplot(wells) + xlim(c(0, NA)) +   scale_y_continuous(breaks = c(0, 0.5, 1)) vary_arsenic <- base + jitt(x=\"arsenic\", y=\"switch\", color=\"switch\") vary_dist <- base + jitt(x=\"dist100\", y=\"switch\", color=\"switch\") for (i in 1:5) {   vary_dist <-      vary_dist + stat_function(fun = pr_switch2, color = \"gray35\",                                args = list(ests = coef(fit2), y = q_dist[i]))   vary_arsenic <-     vary_arsenic + stat_function(fun = pr_switch2, color = \"gray35\",                                   args = list(ests = coef(fit2), x = q_ars[i])) } bayesplot_grid(vary_dist, vary_arsenic,                 grid_args = list(ncol = 2)) (loo1 <- loo(fit1)) Computed from 4000 by 3020 log-likelihood matrix.           Estimate   SE elpd_loo  -2040.1 10.4 p_loo         2.0  0.0 looic      4080.2 20.8 ------ MCSE of elpd_loo is 0.0. MCSE and ESS estimates assume independent draws (r_eff=1).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details. (loo2 <- loo(fit2)) Computed from 4000 by 3020 log-likelihood matrix.           Estimate   SE elpd_loo  -1968.4 15.7 p_loo         3.2  0.1 looic      3936.9 31.3 ------ MCSE of elpd_loo is 0.0. MCSE and ESS estimates assume independent draws (r_eff=1).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details. loo_compare(loo1, loo2) elpd_diff se_diff fit2   0.0       0.0   fit1 -71.7      12.2"},{"path":"https://mc-stan.org/rstanarm/articles/binomial.html","id":"conditional-logit-models","dir":"Articles","previous_headings":"","what":"Conditional Logit Models","title":"Estimating Generalized Linear Models for Binary and Binomial Data with rstanarm","text":"previous example relies fact observations plausibly conditionally independent. contrast, -called “case-control studies” require fixed number successes failures within stratum, question members stratum succeed fail? stan_clogit function estimates model similar clogit function survival package. main syntactical difference clogit function requires user call strata function model formula, whereas stan_clogit function required strata argument. addition, stan_clogit case data must sorted variable passed strata. advantage changes stan_clogit can optionally utilize multilevel syntax lme4 package specify group-specific terms, rather limited multilevel structure supported frailty function survival package. vignette stan_glmer function discusses lme4-style syntax detail. example, posterior predictions also constrained exactly one success (case) strata thus posterior distribution probabilities also constrained:","code":"post <- stan_clogit(case ~ spontaneous + induced + (1 | parity),                      data = infert[order(infert$stratum), ], # order necessary                     strata = stratum, QR = TRUE,                      cores = 2, seed = 12345) post stan_clogit  family:       binomial [clogit]  formula:      case ~ spontaneous + induced + (1 | parity)  observations: 248 ------             Median MAD_SD spontaneous 2.0    0.3    induced     1.4    0.3     Error terms:  Groups Name        Std.Dev.  parity (Intercept) 1.4      Num. levels: parity 6   ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg PPD <- posterior_predict(post) stopifnot(rowSums(PPD) == max(infert$stratum)) PLP <- posterior_linpred(post, transform = TRUE) stopifnot(round(rowSums(PLP)) == max(infert$stratum))"},{"path":"https://mc-stan.org/rstanarm/articles/binomial.html","id":"binomial-models","dir":"Articles","previous_headings":"","what":"Binomial Models","title":"Estimating Generalized Linear Models for Binary and Binomial Data with rstanarm","text":"Although example vignette focused binary response variable, can use nearly identical code sum multiple binary variables. example, image hypothetical dataset similar well-switching data spanning multiple villages. observation (row) data.frame corresponds entire village: switch[] number ‘yes’ responses well-switching question village , dist100[] average distance closest well clean water village , etc. also now variable n n[] number respondents village . data can estimate similar model one used binary case changing formula cbind(switch, n - switch) ~ dist100 + arsenic left-hand side now 2-column matrix first column number ‘yes’ responses second column number ‘’ responses (generally, number successes number failures). model can also specified using proportion ‘yes’ responses total number responses village. corresponds formula prop_switch ~ dist100 + arsenic prop_switch = switch / n proportion ‘yes’ responses. total number responses provided using weights argument. case add weights = n call stan_glm. example similar model can also found Step 1 “Use rstanarm Package” vignette.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/binomial.html","id":"going-further","dir":"Articles","previous_headings":"","what":"Going Further","title":"Estimating Generalized Linear Models for Binary and Binomial Data with rstanarm","text":"hypothetical scenario , also access observations individual villages (just aggregate data), natural extension consider multilevel model takes advantage inherent multilevel structure data (individuals nested within villages). vignette stan_glmer function discusses models.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/binomial.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Estimating Generalized Linear Models for Binary and Binomial Data with rstanarm","text":"Gelman, . Hill, J. (2007). Data Analysis Using Regression Multilevel/Hierarchical Models. Cambridge University Press, Cambridge, UK.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"vignette explains estimate linear generalized linear models (GLMs) continuous response variables using stan_glm function rstanarm package. GLMs discrete outcomes see vignettes binary/binomial count outcomes. four steps Bayesian analysis Specify joint distribution outcome(s) unknowns, typically takes form marginal prior distribution unknowns multiplied likelihood outcome(s) conditional unknowns. joint distribution proportional posterior distribution unknowns conditional observed data Draw posterior distribution using Markov Chain Monte Carlo (MCMC). Evaluate well model fits data possibly revise model. Draw posterior predictive distribution outcome(s) given interesting values predictors order visualize manipulation predictor affects (function ) outcome(s). vignette primarily focuses Steps 1 2 likelihood product conditionally independent continuous distributions. Steps 3 4 covered depth vignette entitled “Use rstanarm Package”, although vignette also give examples model checking generating predictions.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"likelihood","dir":"Articles","previous_headings":"","what":"Likelihood","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"simplest case GLM continuous outcome simply linear model likelihood one observation conditionally normal PDF \\[\\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{1}{2} \\left(\\frac{y - \\mu}{\\sigma}\\right)^2},\\] \\(\\mu = \\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta}\\) linear predictor \\(\\sigma\\) standard deviation error predicting outcome, \\(y\\). generally, linear predictor \\(\\eta = \\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta}\\) can related conditional mean outcome via link function \\(g\\) serves map range values outcome defined space linear predictor defined. linear model described transformation needed link function taken identity function. However, cases link function used Gaussian models; log link, example, can used log transform (conditional) expected value outcome constrained positive. Like glm function, stan_glm function uses R’s family objects. family objects continuous outcomes compatible stan_glm gaussian, Gamma, inverse.gaussian distributions. link functions provided family objects also compatible stan_glm. example, Gamma GLM, assume observations conditionally independent Gamma random variables, common link functions log inverse links. Regardless distribution link function, likelihood entire sample product likelihood contributions individual observations.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"priors","dir":"Articles","previous_headings":"","what":"Priors","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"full Bayesian analysis requires specifying prior distributions \\(f(\\alpha)\\) \\(f(\\boldsymbol{\\beta})\\) intercept vector regression coefficients. using stan_glm, distributions can set using prior_intercept prior arguments. stan_glm function supports variety prior distributions, explained rstanarm documentation (help(priors, package = 'rstanarm')). example, suppose \\(K\\) predictors believe — prior seeing data — \\(\\alpha, \\beta_1, \\dots, \\beta_K\\) likely positive negative, highly unlikely far zero. beliefs can represented normal distributions mean zero small scale (standard deviation). give \\(\\alpha\\) \\(\\beta\\)s prior (scale 1, say), call stan_glm include arguments prior_intercept = normal(0,1) prior = normal(0,1). , hand, less priori confidence parameters close zero use larger scale normal distribution /distribution heavier tails normal like Student t distribution. Step 1 “Use rstanarm Package” vignette discusses one example.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"posterior","dir":"Articles","previous_headings":"","what":"Posterior","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"independent prior distributions, joint posterior distribution \\(\\alpha\\) \\(\\boldsymbol{\\beta}\\) proportional product priors \\(N\\) likelihood contributions: \\[f\\left(\\boldsymbol{\\beta} | \\mathbf{y},\\mathbf{X}\\right) \\propto   f\\left(\\alpha\\right) \\times \\prod_{k=1}^K f\\left(\\beta_k\\right) \\times   \\prod_{=1}^N {f(y_i|\\eta_i)},\\] \\(\\mathbf{X}\\) matrix predictors \\(\\eta\\) linear predictor. posterior distribution stan_glm draw using MCMC.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"linear-regression-example","dir":"Articles","previous_headings":"","what":"Linear Regression Example","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"stan_lm function, vignette, fits regularized linear models using novel means specifying priors regression coefficients. focus using stan_glm function, can used estimate linear models independent priors regression coefficients. illustrate usage stan_glm post-processing functions rstanarm package ’ll use simple example Chapter 3 Gelman Hill (2007): shall fit series regressions predicting cognitive test scores three- four-year-old children given characteristics mothers, using data survey adult American women children (subsample National Longitudinal Survey Youth). Using two predictors – binary indicator whether mother high-school degree (mom_hs) mother’s score IQ test (mom_iq) – fit four contending models. first two models use just one predictors, third use , fourth also include term interaction two predictors. models ’ll use default weakly informative priors stan_glm, currently set normal(0,10) intercept normal(0,5) regression coefficients. overview many available prior distributions see help(\"prior\", package = \"rstanarm\"). Following Gelman Hill’s example, make plots overlaying estimated regression lines data.  several ways add uncertainty estimates plot. One way also plot estimated regression line draw posterior distribution. can extract posterior draws fitted model object using .matrix .data.frame methods:  second model can make plot x-axis show continuous predictor mom_iq:  third fourth models, uses predictors, can plot continuous mom_iq x-axis use color indicate points correspond different subpopulations defined mom_hs. also now plot two regression lines, one subpopulation:","code":"library(rstanarm) data(kidiq) post1 <- stan_glm(kid_score ~ mom_hs, data = kidiq,                    family = gaussian(link = \"identity\"),                    seed = 12345) post2 <- update(post1, formula = . ~ mom_iq) post3 <- update(post1, formula = . ~ mom_hs + mom_iq) (post4 <- update(post1, formula = . ~ mom_hs * mom_iq)) stan_glm  family:       gaussian [identity]  formula:      kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq  observations: 434  predictors:   4 ------               Median MAD_SD (Intercept)   -10.1   13.7  mom_hs         49.5   15.3  mom_iq          1.0    0.1  mom_hs:mom_iq  -0.5    0.2   Auxiliary parameter(s):       Median MAD_SD sigma 18.0    0.6    ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg base <- ggplot(kidiq, aes(x = mom_hs, y = kid_score)) +    geom_point(size = 1, position = position_jitter(height = 0.05, width = 0.1)) +    scale_x_continuous(breaks = c(0,1), labels = c(\"No HS\", \"HS\"))    base + geom_abline(intercept = coef(post1)[1], slope = coef(post1)[2],                     color = \"skyblue4\", size = 1) draws <- as.data.frame(post1) colnames(draws)[1:2] <- c(\"a\", \"b\")  base +    geom_abline(data = draws, aes(intercept = a, slope = b),                color = \"skyblue\", size = 0.2, alpha = 0.25) +    geom_abline(intercept = coef(post1)[1], slope = coef(post1)[2],                color = \"skyblue4\", size = 1) draws <- as.data.frame(as.matrix(post2)) colnames(draws)[1:2] <- c(\"a\", \"b\") ggplot(kidiq, aes(x = mom_iq, y = kid_score)) +    geom_point(size = 1) +   geom_abline(data = draws, aes(intercept = a, slope = b),                color = \"skyblue\", size = 0.2, alpha = 0.25) +    geom_abline(intercept = coef(post2)[1], slope = coef(post2)[2],                color = \"skyblue4\", size = 1) reg0 <- function(x, ests) cbind(1, 0, x) %*% ests  reg1 <- function(x, ests) cbind(1, 1, x) %*% ests  args <- list(ests = coef(post3)) kidiq$clr <- factor(kidiq$mom_hs, labels = c(\"No HS\", \"HS\")) lgnd <- guide_legend(title = NULL) base2 <- ggplot(kidiq, aes(x = mom_iq, fill = relevel(clr, ref = \"HS\"))) +    geom_point(aes(y = kid_score), shape = 21, stroke = .2, size = 1) +    guides(color = lgnd, fill = lgnd) +    theme(legend.position = \"right\") base2 +    stat_function(fun = reg0, args = args, aes(color = \"No HS\"), size = 1.5) +   stat_function(fun = reg1, args = args, aes(color = \"HS\"), size = 1.5) reg0 <- function(x, ests) cbind(1, 0, x, 0 * x) %*% ests  reg1 <- function(x, ests) cbind(1, 1, x, 1 * x) %*% ests args <- list(ests = coef(post4)) base2 +   stat_function(fun = reg0, args = args, aes(color = \"No HS\"), size = 1.5) +    stat_function(fun = reg1, args = args, aes(color = \"HS\"), size = 1.5)"},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"model-comparison","dir":"Articles","previous_headings":"Linear Regression Example","what":"Model comparison","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"One way can compare four contending models use approximation Leave-One-(LOO) cross-validation, implemented loo function loo package: case fourth model preferred highest expected log predicted density (elpd_loo) , equivalently, lowest value LOO Information Criterion (looic). fourth model preferred lot first model difference elpd much larger standard error. However, preference fourth model others isn’t strong:","code":"# Compare them with loo loo1 <- loo(post1, cores = 1) loo2 <- loo(post2, cores = 1) loo3 <- loo(post3, cores = 1) loo4 <- loo(post4, cores = 1) (comp <- loo_compare(loo1, loo2, loo3, loo4)) elpd_diff se_diff post4   0.0       0.0   post3  -3.5       2.7   post2  -6.2       4.1   post1 -42.4       8.7 loo_compare(loo1, loo4) elpd_diff se_diff post4   0.0       0.0   post1 -42.4       8.7 loo_compare(loo3, loo4) elpd_diff se_diff post4  0.0       0.0    post3 -3.5       2.7 loo_compare(loo2, loo4) elpd_diff se_diff post4  0.0       0.0    post2 -6.2       4.1"},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"the-posterior-predictive-distribution","dir":"Articles","previous_headings":"Linear Regression Example","what":"The posterior predictive distribution","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"posterior predictive distribution distribution outcome implied model using observed data update beliefs unknown parameters. simulating observations posterior predictive distribution use notation \\(y^{\\rm rep}\\) (replicate) use observations \\(X\\) used estimate model parameters. \\(X\\) contains new observations use notation \\(\\tilde{y}\\) refer posterior predictive simulations. Simulating data posterior predictive distribution using observed predictors useful checking fit model. Drawing posterior predictive distribution interesting values predictors also lets us visualize manipulation predictor affects (function ) outcome(s).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"graphical-posterior-predictive-checks","dir":"Articles","previous_headings":"Linear Regression Example > The posterior predictive distribution","what":"Graphical posterior predictive checks","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"pp_check function generates variety plots comparing observed outcome \\(y\\) simulated datasets \\(y^{\\rm rep}\\) posterior predictive distribution using observations predictors \\(X\\) used fit model. show possible displays. documentation help(\"pp_check.stanreg\", package = \"rstanarm\") details pp_check options. First ’ll look plot directly comparing distributions \\(y\\) \\(y^{\\rm rep}\\). following call pp_check create plot juxtaposing histogram \\(y\\) histograms five \\(y^{\\rm rep}\\) datasets:  idea model good fit data able generate data \\(y^{\\rm rep}\\) posterior predictive distribution looks lot like observed data \\(y\\). , given \\(y\\), \\(y^{\\rm rep}\\) generate plausible. Another useful plot can make using pp_check shows distribution test quantity \\(T(y^{\\rm rep})\\) compared \\(T(y)\\), value quantity observed data. argument plotfun = \"stat\" specified, pp_check simulate \\(S\\) datasets \\(y_1^{\\rm rep}, \\dots, y_S^{\\rm rep}\\), containing \\(N\\) observations. \\(S\\) size posterior sample (number MCMC draws posterior distribution model parameters) \\(N\\) length \\(y\\). can check \\(T(y)\\) consistent distribution \\(\\left(T(y_1^{\\rm yep}), \\dots, T(y_S^{\\rm yep})\\right)\\). plot see mean observations plausible compared distribution means \\(S\\) \\(y^{\\rm rep}\\) datasets:  Using plotfun=\"stat_2d\" can also specify two test quantities look scatterplot:","code":"pp_check(post4, plotfun = \"hist\", nreps = 5) pp_check(post4, plotfun = \"stat\", stat = \"mean\") pp_check(post4, plotfun = \"stat_2d\", stat = c(\"mean\", \"sd\"))"},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"generating-predictions","dir":"Articles","previous_headings":"Linear Regression Example > The posterior predictive distribution","what":"Generating predictions","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"posterior_predict function used generate replicated data \\(y^{\\rm rep}\\) predictions future observations \\(\\tilde{y}\\). show use posterior_predict generate predictions outcome kid_score range different values mom_iq subpopulations defined mom_hs. now two matrices, y_nohs y_hs. matrix many columns values IQ_SEQ many rows size posterior sample. One way show predictors plot predictions two groups kids side side:","code":"IQ_SEQ <- seq(from = 75, to = 135, by = 5) y_nohs <- posterior_predict(post4, newdata = data.frame(mom_hs = 0, mom_iq = IQ_SEQ)) y_hs <- posterior_predict(post4, newdata = data.frame(mom_hs = 1, mom_iq = IQ_SEQ)) dim(y_hs) [1] 4000   13 par(mfrow = c(1:2), mar = c(5,4,2,1)) boxplot(y_hs, axes = FALSE, outline = FALSE, ylim = c(10,170),         xlab = \"Mom IQ\", ylab = \"Predicted Kid IQ\", main = \"Mom HS\") axis(1, at = 1:ncol(y_hs), labels = IQ_SEQ, las = 3) axis(2, las = 1) boxplot(y_nohs, outline = FALSE, col = \"red\", axes = FALSE, ylim = c(10,170),         xlab = \"Mom IQ\", ylab = NULL, main = \"Mom No HS\") axis(1, at = 1:ncol(y_hs), labels = IQ_SEQ, las = 3)"},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"gamma-regression-example","dir":"Articles","previous_headings":"","what":"Gamma Regression Example","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"Gamma regression often used response variable continuous positive, coefficient variation (rather variance) constant. ’ll use one standard examples Gamma regression, taken McCullagh & Nelder (1989). example also given documentation R’s glm function. outcome interest clotting time blood (seconds) “normal plasma diluted nine different percentage concentrations prothrombin-free plasma; clotting induced two lots thromboplastin” (p. 300). help page R’s glm function presents example follows: fit analogous Bayesian models can simply substitute stan_glm glm . However, instead fitting separate models can also reshape data slightly fit model interacting lot plasma concentration: output , estimate reported shape shape parameter Gamma distribution. reciprocal shape parameter can interpreted similarly summary.glm refers dispersion parameter.","code":"clotting <- data.frame(     u = c(5,10,15,20,30,40,60,80,100),     lot1 = c(118,58,42,35,27,25,21,19,18),     lot2 = c(69,35,26,21,18,16,13,12,12)) summary(glm(lot1 ~ log(u), data = clotting, family = Gamma)) summary(glm(lot2 ~ log(u), data = clotting, family = Gamma)) clotting2 <- with(clotting, data.frame(   log_plasma = rep(log(u), 2),   clot_time = c(lot1, lot2),   lot_id = factor(rep(c(1,2), each = length(u))) ))  fit <- stan_glm(clot_time ~ log_plasma * lot_id, data = clotting2, family = Gamma,                  prior_intercept = normal(0, 1, autoscale = TRUE),                  prior = normal(0, 1, autoscale = TRUE),                 seed = 12345) print(fit, digits = 3) stan_glm  family:       Gamma [inverse]  formula:      clot_time ~ log_plasma * lot_id  observations: 18  predictors:   4 ------                    Median MAD_SD (Intercept)        -0.016  0.007 log_plasma          0.015  0.003 lot_id2            -0.007  0.014 log_plasma:lot_id2  0.008  0.006  Auxiliary parameter(s):       Median MAD_SD shape 7.982  2.756   ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg"},{"path":"https://mc-stan.org/rstanarm/articles/continuous.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Estimating Generalized Linear Models for Continuous Data with rstanarm","text":"Gelman, . Hill, J. (2007). Data Analysis Using Regression Multilevel/Hierarchical Models. Cambridge University Press, Cambridge, UK. McCullagh, P. Nelder, J. . (1989). Generalized Linear Models. Chapman Hall/CRC Press, New York.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/count.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating Generalized Linear Models for Count Data with rstanarm","text":"vignette explains estimate generalized linear models (GLMs) count data using stan_glm function rstanarm package. four steps Bayesian analysis Specify joint distribution outcome(s) unknowns, typically takes form marginal prior distribution unknowns multiplied likelihood outcome(s) conditional unknowns. joint distribution proportional posterior distribution unknowns conditional observed data Draw posterior distribution using Markov Chain Monte Carlo (MCMC). Evaluate well model fits data possibly revise model. Draw posterior predictive distribution outcome(s) given interesting values predictors order visualize manipulation predictor affects (function ) outcome(s). Steps 3 4 covered depth vignette entitled “Use rstanarm Package”. vignette focuses Step 1 Poisson negative binomial regression models using stan_glm function.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/count.html","id":"likelihood","dir":"Articles","previous_headings":"","what":"Likelihood","title":"Estimating Generalized Linear Models for Count Data with rstanarm","text":"outcome single observation \\(y\\) assumed follow Poisson distribution, likelihood one observation can written conditionally Poisson PMF \\[\\tfrac{1}{y!} \\lambda^y e^{-\\lambda},\\] \\(\\lambda = E(y | \\mathbf{x}) = g^{-1}(\\eta)\\) \\(\\eta = \\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta}\\) linear predictor. Poisson distribution also true \\(\\lambda = Var(y | \\mathbf{x})\\), .e. mean variance \\(\\lambda\\). Later vignette also show estimate negative binomial regression, relaxes assumption equal conditional mean variance \\(y\\). rate parameter \\(\\lambda\\) must positive, Poisson GLM link function \\(g\\) maps positive real numbers \\(\\mathbb{R}^+\\) (support \\(\\lambda\\)) set real numbers \\(\\mathbb{R}\\). applied linear predictor \\(\\eta\\) values \\(\\mathbb{R}\\), inverse link function \\(g^{-1}(\\eta)\\) therefore returns positive real number. Although link functions possible, canonical link function Poisson GLM log link \\(g(x) = \\ln{(x)}\\). log link, inverse link function simply exponential function likelihood single observation becomes \\[\\frac{g^{-1}(\\eta)^y}{y!} e^{-g^{-1}(\\eta)} = \\frac{e^{\\eta y}}{y!} e^{-e^\\eta}.\\]","code":""},{"path":"https://mc-stan.org/rstanarm/articles/count.html","id":"priors","dir":"Articles","previous_headings":"","what":"Priors","title":"Estimating Generalized Linear Models for Count Data with rstanarm","text":"full Bayesian analysis requires specifying prior distributions \\(f(\\alpha)\\) \\(f(\\boldsymbol{\\beta})\\) intercept vector regression coefficients. using stan_glm, distributions can set using prior_intercept prior arguments. stan_glm function supports variety prior distributions, explained rstanarm documentation (help(priors, package = 'rstanarm')). example, suppose \\(K\\) predictors believe — prior seeing data — \\(\\alpha, \\beta_1, \\dots, \\beta_K\\) likely positive negative, highly unlikely far zero. beliefs can represented normal distributions mean zero small scale (standard deviation). give \\(\\alpha\\) \\(\\beta\\)s prior (scale 1, say), call stan_glm include arguments prior_intercept = normal(0,1) prior = normal(0,1). , hand, less priori confidence parameters close zero use larger scale normal distribution /distribution heavier tails normal like Student t distribution. Step 1 “Use rstanarm Package” vignette discusses one example.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/count.html","id":"posterior","dir":"Articles","previous_headings":"","what":"Posterior","title":"Estimating Generalized Linear Models for Count Data with rstanarm","text":"independent prior distributions, joint posterior distribution \\(\\alpha\\) \\(\\boldsymbol{\\beta}\\) Poisson model proportional product priors \\(N\\) likelihood contributions: \\[f\\left(\\alpha,\\boldsymbol{\\beta} | \\mathbf{y},\\mathbf{X}\\right) \\propto   f\\left(\\alpha\\right) \\times \\prod_{k=1}^K f\\left(\\beta_k\\right) \\times   \\prod_{=1}^N {   \\frac{g^{-1}(\\eta_i)^{y_i}}{y_i!} e^{-g^{-1}(\\eta_i)}}.\\] posterior distribution stan_glm draw using MCMC.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/count.html","id":"poisson-and-negative-binomial-regression-example","dir":"Articles","previous_headings":"","what":"Poisson and Negative Binomial Regression Example","title":"Estimating Generalized Linear Models for Count Data with rstanarm","text":"example comes Chapter 8.3 Gelman Hill (2007). want make inferences efficacy certain pest management system reducing number roaches urban apartments. Gelman Hill describe experiment (pg. 161): […] treatment control applied 160 104 apartments, respectively, outcome measurement \\(y_i\\) apartment \\(\\) number roaches caught set traps. Different apartments traps different numbers days […] addition intercept, regression predictors model pre-treatment number roaches roach1, treatment indicator treatment, variable indicating whether apartment building restricted elderly residents senior. number days roach traps used apartments sample, include exposure, slightly changes model described Likelihood section rate parameter \\(\\lambda_i = exp(\\eta_i)\\) multiplied exposure \\(u_i\\) giving us \\(y_i \\sim Poisson(u_i \\lambda_i)\\). equivalent adding \\(\\ln{(u_i)}\\) linear predictor \\(\\eta_i\\) can specified using offset argument stan_glm. formula, data, family, offset arguments stan_glm can specified exactly way glm. poisson family function defaults using log link, write code readable someone familiar defaults explicit use family = poisson(link = \"log\"). ’ve also specified optional arguments. chains argument controls many Markov chains executed, cores argument controls number cores utilized computer fitting model. also provided seed option deterministically reproduce results time. stan_glm function many optional arguments allow user control way estimation performed. documentation stan_glm information controls well topics related GLM estimation. point estimates uncertainties glm fit stan_glm fit, see nearly identical: (Note: dataset slightly different one used Gelman Hill (2007), leads slightly different parameter estimates shown book even copying glm call verbatim. Also, rescaled roach1 predictor. purposes example, actual estimates less important process.) Gelman Hill next show compare observed data replicated datasets model check quality fit. don’t show original code used Gelman Hill ’s many lines, requiring several loops care get matrix multiplications right (see pg. 161-162). hand, rstanarm package makes easy. can generate replicated datasets single line code using posterior_predict function: default posterior_predict generate dataset set parameter draws posterior distribution. , yrep \\(S \\times N\\) matrix, \\(S\\) size posterior sample \\(N\\) number data points. row yrep represents full dataset generated posterior predictive distribution. importance posterior_predict function, see “Use rstanarm Package” vignette. Gelman Hill take simulated datasets compute proportion zeros compare observed proportion original data. can easily using pp_check function, generates graphical comparisons data y replicated datasets yrep.  value test statistic (case proportion zeros) computed sample y dark blue vertical line. 30% observations zeros, whereas replicated datasets contain less 1% zeros (light blue histogram). sign consider model accurately accounts large proportion zeros data. Gelman Hill show can using overdispersed Poisson regression. illustrate use different stan_glm model, instead try negative binomial regression, also used overdispersed zero-inflated count data. negative binomial distribution allows (conditional) mean variance \\(y\\) differ unlike Poisson distribution. fit negative binomial model can either use stan_glm.nb function , equivalently, change family specify call stan_glm neg_binomial_2 instead poisson. latter can just use update: now use pp_check , time check proportion zeros replicated datasets negative binomial model:  much better fit, proportion zeros data falls nicely near center distribution proportion zeros among replicated datasets. observed proportion zeros quite plausible model. also made plots manually without using pp_check function yrep datasets created posterior_predict. pp_check function takes care us, yrep can used directly carry posterior predictive checks aren’t automated pp_check. comparing models using loo package also see clear preference negative binomial model surprising given better fit ’ve already observed posterior predictive checks.","code":"library(rstanarm) data(roaches)  # Rescale roaches$roach1 <- roaches$roach1 / 100 # Estimate original model glm1 <- glm(y ~ roach1 + treatment + senior, offset = log(exposure2),              data = roaches, family = poisson) # Estimate Bayesian version with stan_glm stan_glm1 <- stan_glm(y ~ roach1 + treatment + senior, offset = log(exposure2),                       data = roaches, family = poisson,                        prior = normal(0, 2.5),                        prior_intercept = normal(0, 5),                       seed = 12345) round(rbind(glm = coef(glm1), stan_glm = coef(stan_glm1)), digits = 2) (Intercept) roach1 treatment senior glm             3.09    0.7     -0.52  -0.38 stan_glm        3.09    0.7     -0.52  -0.38 round(rbind(glm = summary(glm1)$coefficients[, \"Std. Error\"],              stan_glm = se(stan_glm1)), digits = 3) (Intercept) roach1 treatment senior glm            0.021  0.009     0.025  0.033 stan_glm       0.021  0.009     0.024  0.034 yrep <- posterior_predict(stan_glm1) prop_zero <- function(y) mean(y == 0) (prop_zero_test1 <- pp_check(stan_glm1, plotfun = \"stat\", stat = \"prop_zero\", binwidth = .005)) stan_glm2 <- update(stan_glm1, family = neg_binomial_2) prop_zero_test2 <- pp_check(stan_glm2, plotfun = \"stat\", stat = \"prop_zero\",                              binwidth = 0.01) # Show graphs for Poisson and negative binomial side by side bayesplot_grid(prop_zero_test1 + ggtitle(\"Poisson\"),                 prop_zero_test2 + ggtitle(\"Negative Binomial\"),                 grid_args = list(ncol = 2)) loo1 <- loo(stan_glm1, cores = 1) loo2 <- loo(stan_glm2, cores = 1) loo_compare(loo1, loo2) elpd_diff se_diff stan_glm2     0.0       0.0 stan_glm1 -5345.4     706.7"},{"path":"https://mc-stan.org/rstanarm/articles/count.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Estimating Generalized Linear Models for Count Data with rstanarm","text":"Gelman, . Hill, J. (2007). Data Analysis Using Regression Multilevel/Hierarchical Models. Cambridge University Press, Cambridge, UK.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"vignette explains use stan_lmer, stan_glmer, stan_nlmer, stan_gamm4 functions rstanarm package estimate linear generalized (non-)linear models parameters may vary across groups. continuing, recommend reading vignettes (navigate one level) various ways use stan_glm function. Hierarchical Partial Pooling vignette also examples stan_glm stan_glmer.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"glms-with-group-specific-terms","dir":"Articles","previous_headings":"","what":"GLMs with group-specific terms","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"Models structure refered many names: multilevel models, (generalized) linear mixed (effects) models (GLMM), hierarchical (generalized) linear models, etc. simplest case, model outcome can written \\[\\mathbf{y} = \\alpha + \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{Z} \\mathbf{b} + \\boldsymbol{\\epsilon},\\] \\(\\mathbf{X}\\) matrix predictors analogous Generalized Linear Models \\(\\mathbf{Z}\\) matrix encodes deviations predictors across specified groups. terminology unknowns model diverse. frequentists, error term consists \\(\\mathbf{Z}\\mathbf{b} + \\boldsymbol{\\epsilon}\\) observations within group independent conditional \\(\\mathbf{X}\\) alone. Since, \\(\\mathbf{b}\\) considered part random error term, frequentists allow make distributional assumptions \\(\\mathbf{b}\\), invariably distributed multivariate normal mean vector zero structured covariance matrix \\(\\boldsymbol{\\Sigma}\\). \\(\\epsilon_i\\) also distributed (univariate) normal mean zero standard deviation \\(\\sigma\\), \\(\\mathbf{b}\\) can integrated , implies \\[\\mathbf{y} \\thicksim \\mathcal{N}\\left(\\alpha + \\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2 \\mathbf{}+\\mathbf{Z}^\\top \\boldsymbol{\\Sigma} \\mathbf{Z} \\right),\\] possible maximize likelihood function choosing proposals parameters \\(\\alpha\\), \\(\\boldsymbol{\\beta}\\), (free elements ) \\(\\boldsymbol{\\Sigma}\\). Consequently, frequentists refer \\(\\mathbf{b}\\) random effects capture random deviation effects predictors one group next. contradistinction, \\(\\alpha\\) \\(\\boldsymbol{\\beta}\\) referred fixed effects groups. Moreover, \\(\\alpha\\) \\(\\boldsymbol{\\beta}\\) persist model hypothetical replications analysis draw members groups afresh every time, whereas \\(\\mathbf{b}\\) differ one replication next. Consequently, \\(\\mathbf{b}\\) “parameter” estimated parameters unknown constants fixed repeated sampling. Bayesians condition data -hand without reference repeated sampling describe beliefs unknowns prior distributions observing data. Thus, likelihood simple hierarchical model rstarnarm \\[\\mathbf{y} \\thicksim \\mathcal{N}\\left(\\alpha + \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{Z}\\mathbf{b}, \\sigma^2 \\mathbf{}\\right)\\] observations independent conditional \\(\\mathbf{X}\\) \\(\\mathbf{Z}\\). formulation, intercept(s) coefficients common across groups deviations intercept(s) / coefficients vary across groups Bayesians compelled state prior beliefs unknowns usual assumption (maintained rstanarm) \\(\\mathbf{b} \\thicksim \\mathcal{N}\\left(\\mathbf{0},\\boldsymbol{\\Sigma}\\right),\\) necessary state prior beliefs \\(\\boldsymbol{\\Sigma}\\), addition \\(\\alpha\\), \\(\\boldsymbol{\\beta}\\), \\(\\sigma\\). One many challenges fitting models data comprising multiple groupings confronting tradeoff validity precision. analysis disregards -group heterogeneity can yield parameter estimates wrong -group heterogeneity relatively precise actually -group heterogeneity. Group--group analyses, hand, valid produces estimates relatively imprecise. complete pooling pooling data across groups sometimes called , models ignore grouping structures data tend underfit overfit (Gelman et al.,2013). Hierarchical modeling provides compromise allowing parameters vary group lower levels hierarchy estimating common parameters higher levels. Inference group-level parameter informed group-specific information contained data also data groups well. commonly referred borrowing strength shrinkage. rstanarm, models can estimated using stan_lmer stan_glmer functions, similar syntax lmer glmer functions lme4 package. However, rather performing (restricted) maximum likelihood (RE)ML estimation, Bayesian estimation performed via MCMC. Bayesian model adds independent prior distributions regression coefficients (way stan_glm) well priors terms decomposition covariance matrices group-specific parameters. priors discussed greater detail .","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"priors-on-covariance-matrices","dir":"Articles","previous_headings":"","what":"Priors on covariance matrices","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"section discuss flexible family prior distributions unknown covariance matrices group-specific coefficients.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"overview","dir":"Articles","previous_headings":"Priors on covariance matrices","what":"Overview","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"group, assume vector varying slopes intercepts zero-mean random vector following multivariate Gaussian distribution unknown covariance matrix estimated. Unfortunately, expressing prior information covariance matrix intuitive can also computationally challenging. covariance matrix \\(1\\times 1\\), often much intuitive efficient work instead correlation matrix variances. covariance matrix \\(1\\times 1\\), still denote \\(\\boldsymbol{\\Sigma}\\) details section apply. variances turn decomposed product simplex vector (probability vector) trace implied covariance matrix, defined sum diagonal elements. Finally, trace set equal product order matrix square scale parameter. implied prior covariance matrix represented decov (short decomposition covariance) function rstanarm.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"details","dir":"Articles","previous_headings":"Priors on covariance matrices","what":"Details","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"Using decomposition described , prior used correlation matrix \\(\\Omega\\) called LKJ distribution probability density function proportional determinant correlation matrix raised power \\(\\zeta\\) minus one: \\[ f(\\Omega | \\zeta) \\propto \\text{det}(\\Omega)^{\\zeta - 1}, \\quad \\zeta > 0. \\] shape prior depends value regularization parameter, \\(\\zeta\\) following ways: \\(\\zeta = 1\\) (default), LKJ prior jointly uniform correlation matrices dimension \\(\\Omega\\). \\(\\zeta > 1\\), mode distribution identity matrix. larger value \\(\\zeta\\) sharply peaked density identity matrix. \\(0 < \\zeta < 1\\), density trough identity matrix. \\(J \\times J\\) covariance matrix \\(\\Sigma\\) random vector \\(\\boldsymbol{\\theta} = (\\theta_1, \\dots, \\theta_J)\\) diagonal entries \\({\\Sigma}_{jj} = \\sigma^2_j = \\text{var}(\\theta_j)\\). Therefore, trace covariance matrix equal sum variances. set trace equal product order covariance matrix square positive scale parameter \\(\\tau\\): \\[\\text{tr}(\\Sigma) = \\sum_{j=1}^{J} \\Sigma_{jj} = J\\tau^2.\\] vector variances set equal product simplex vector \\(\\boldsymbol{\\pi}\\) — non-negative sums 1 — scalar trace: \\(J \\tau^2 \\boldsymbol{\\pi}\\). element \\(\\pi_j\\) \\(\\boldsymbol{\\pi}\\) represents proportion trace (total variance) attributable corresponding variable \\(\\theta_j\\). simplex vector \\(\\boldsymbol{\\pi}\\) use symmetric Dirichlet prior, single concentration parameter \\(\\gamma > 0\\): \\(\\gamma = 1\\) (default), prior jointly uniform space simplex vectors \\(J\\) elements. \\(\\gamma > 1\\), prior mode corresponds variables (proportion total) variance, can used ensure posterior variances zero. concentration parameter approaches infinity, mode becomes pronounced. \\(0 < \\gamma < 1\\), variances polarized. elements \\(\\boldsymbol{\\theta}\\) multiplied number \\(k\\), trace covariance matrix increase factor \\(k^2\\). reason, sensible use scale-invariant prior \\(\\tau\\). choose Gamma distribution, shape scale parameters set \\(1\\) default, implying unit-exponential distribution. Users can set shape hyperparameter value greater one ensure posterior trace zero. case \\(\\boldsymbol{\\Sigma}\\) \\(1\\times 1\\), \\(\\tau\\) cross-group standard deviation parameters square variance (Gamma prior shape scale directly applies cross-group standard deviation parameters).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"comparison-with-lme4","dir":"Articles","previous_headings":"","what":"Comparison with lme4","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"several advantages estimating models using rstanarm rather lme4 package. also drawbacks. section briefly discuss find two important advantages well important disadvantage.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"advantage-better-uncertainty-estimates","dir":"Articles","previous_headings":"Comparison with lme4","what":"Advantage: better uncertainty estimates","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"lme4 uses (restricted) maximum likelihood (RE)ML estimation, rstanarm enables full Bayesian inference via MCMC performed. well known (RE)ML tends underestimate uncertainties relies point estimates hyperparameters. Full Bayes, hand, propagates uncertainty hyperparameters throughout levels model provides appropriate estimates uncertainty models consist mix common group-specific parameters.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"advantage-incorporate-prior-information","dir":"Articles","previous_headings":"Comparison with lme4","what":"Advantage: incorporate prior information","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"stan_glmer stan_lmer functions allow user specify prior distributions regression coefficients well unknown covariance matrices. various reasons specify priors, helping stabilize computation incorporating important information analysis enter data.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"disadvantage-speed","dir":"Articles","previous_headings":"Comparison with lme4","what":"Disadvantage: speed","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"benefits full Bayesian inference (via MCMC) come cost. Fitting models (RE)ML tend much faster fitting similar model using MCMC. Speed comparable lme4 can obtained rstanarm using approximate Bayesian inference via mean-field full-rank variational algorithms (see help(\"rstanarm-package\", \"rstanarm\") details). algorithms can useful narrow set candidate models large problems, MCMC always used final statistical inference.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"relationship-to-glmer","dir":"Articles","previous_headings":"","what":"Relationship to glmer","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"lme4 package, fundamental distinction way Linear Mixed Models Generalized Linear Mixed Models estimated. Linear Mixed Models, \\(\\mathbf{b}\\) can integrated analytically, leaving likelihood function can maximized proposals parameters. estimate Linear Mixed Model, one can call lmer function. Generalized Linear Mixed Models appropriate conditional mean outcome determined inverse link function, \\(\\boldsymbol{\\mu} = g\\left(\\alpha + \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{Z}\\mathbf{b}\\right)\\). \\(g\\left(\\cdot\\right)\\) identity function, possible integrate \\(\\mathbf{b}\\) analytically numerical integration must used. estimate Generalized Linear Mixed Model, one can call glmer function specify family argument. rstanarm package, fundamental distinction; fact stan_lmer simply calls stan_glmer family = gaussian(link = \"identity\"). Bayesians () integrate \\(\\mathbf{b}\\) likelihood \\(\\mathbf{b}\\) interest, margins posterior distribution can simply ignored.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"relationship-to-gamm4","dir":"Articles","previous_headings":"","what":"Relationship to gamm4","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"rstanarm package includes stan_gamm4 function similar gamm4 function gamm4 package, turn similar gamm function mgcv package. substring gamm stands Generalized Additive Mixed Models, differ Generalized Additive Models (GAMs) due presence group-specific terms can specified syntax lme4. GAMs GAMMs include nonlinear functions (non-categorical) predictors called “smooths”. example , -called “thin-plate splines” used model counts roaches might fear number roaches current period exponentially increasing function number roaches previous period. Unlike stan_glmer, stan_gamm4 necessary specify group-specific terms one-sided formula passed random argument lme function nlme package.  see relationship past present roaches estimated nonlinear. small number past roaches, function steep appears flatten , although become highly uncertain function rare cases number past roaches large.","code":"library(rstanarm) data(roaches) roaches$roach1 <- roaches$roach1 / 100 roaches$log_exposure2 <- log(roaches$exposure2) post <- stan_gamm4(   y ~ s(roach1) + treatment + log_exposure2,   random = ~(1 | senior),   data = roaches,    family = neg_binomial_2,    QR = TRUE,   cores = 2,   chains = 2,    adapt_delta = 0.99,   seed = 12345 ) plot_nonlinear(post)"},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"relationship-to-nlmer","dir":"Articles","previous_headings":"","what":"Relationship to nlmer","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"stan_gamm4 function allows designated predictors nonlinear effect otherwise called “linear” predictor Generalized Linear Models. stan_nlmer function similar nlmer function lme4 package, essentially allows wider range nonlinear functions relate linear predictor conditional expectation Gaussian outcome. estimate example model nlmer function lme4 package, start rescaling outcome main predictor(s) constant Although substantive effect inferences obtained, numerically much easier Stan lme4 work variables whose units estimated parameters tend single-digit numbers close zero. nlmer function requires user pass starting values ironically-named self-starting non-linear function: Note warning messages indicating difficulty estimating variance-covariance matrix. Although lme4 fallback mechanism, need utilize suggests sample small sustain asymptotic assumptions underlying maximum likelihood estimator. example, use SSlogis function, lot like logistic CDF, additional Asym argument need one indicates value function approaches large values first argument. case, can interpret asymptote maximum possible circumference orange. However, asymptote allowed vary tree tree using Asym | Tree syntax, reflects assumption asymptote randomly-selected tree deviates asymptote population orange trees Gaussian fashion mean zero unknown standard deviation. nlmer function supports user-defined non-linear functions, whereas stan_nlmer function supports pre-defined non-linear functions starting SS stats package, fit essentially model using Stan’s implementation MCMC, add stan_ prefix stan_nlmer, necessary supply starting values; however, case necessary specify init_r argument randomly-chosen starting values \\(0.5\\) away zero (unconstrained parameter space). default value \\(2.0\\) produced suboptimal results. can seen, posterior medians estimated standard deviations MCMC case quite similar maximum likelihood estimates estimated standard errors. However, stan_nlmer produces uncertainty estimates tree-specific deviations asymptote, considerable.  can seen, age tree non-linear effect predicted circumference tree (--sample tree):  pharmacological, evaluate drug concentration using first-order compartment model, However, case posterior distribution bimodal Thus, always running many chains using Stan, especially stan_nlmer.","code":"data(\"Orange\", package = \"datasets\") Orange$age <- Orange$age / 100 Orange$circumference <- Orange$circumference / 100 startvec <- c(Asym = 2, xmid = 7.25, scal = 3.5) library(lme4) nm1 <- nlmer(circumference ~ SSlogis(age, Asym, xmid, scal) ~ Asym|Tree,              data = Orange, start = startvec) summary(nm1) Warning in vcov.merMod(object, use.hessian = use.hessian): variance-covariance matrix computed from finite-difference Hessian is not positive definite or contains NA values: falling back to var-cov estimated from RX Warning in vcov.merMod(object, correlation = correlation, sigm = sig): variance-covariance matrix computed from finite-difference Hessian is not positive definite or contains NA values: falling back to var-cov estimated from RX Nonlinear mixed model fit by maximum likelihood  ['nlmerMod'] Formula: circumference ~ SSlogis(age, Asym, xmid, scal) ~ Asym | Tree    Data: Orange        AIC       BIC    logLik -2*log(L)  df.resid      -49.2     -41.4      29.6     -59.2        30   Scaled residuals:      Min      1Q  Median      3Q     Max  -1.9170 -0.5421  0.1754  0.7116  1.6820   Random effects:  Groups   Name Variance Std.Dev.  Tree     Asym 0.100149 0.31646   Residual      0.006151 0.07843  Number of obs: 35, groups:  Tree, 5  Fixed effects:      Estimate Std. Error t value Asym   1.9205     0.1558   12.32 xmid   7.2791     0.3444   21.14 scal   3.4807     0.2631   13.23  Correlation of Fixed Effects:      Asym  xmid  xmid 0.384       scal 0.362 0.762 [1] \"SSasymp\"     \"SSasympOff\"  \"SSasympOrig\" \"SSbiexp\"     \"SSfol\"        [6] \"SSfpl\"       \"SSgompertz\"  \"SSlogis\"     \"SSmicmen\"    \"SSweibull\" post1 <- stan_nlmer(circumference ~ SSlogis(age, Asym, xmid, scal) ~ Asym|Tree,                     data = Orange, cores = 2, seed = 12345, init_r = 0.5) post1 stan_nlmer  family:       gaussian [inv_SSlogis]  formula:      circumference ~ SSlogis(age, Asym, xmid, scal) ~ Asym | Tree  observations: 35 ------      Median MAD_SD Asym 1.9    0.1    xmid 7.2    0.4    scal 3.4    0.3     Auxiliary parameter(s):       Median MAD_SD sigma 0.1    0.0     Error terms:  Groups   Name Std.Dev.  Tree     Asym 0.31      Residual      0.09     Num. levels: Tree 5   ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg plot(post1, regex_pars = \"^[b]\") nd <- data.frame(age = 1:20, Tree = factor(\"6\", levels = 1:6)) PPD <- posterior_predict(post1, newdata = nd) PPD_df <- data.frame(age = as.factor(rep(1:20, each = nrow(PPD))),                      circumference = c(PPD)) ggplot(PPD_df, aes(age, circumference)) + geom_boxplot() post3 <- stan_nlmer(conc ~ SSfol(Dose, Time, lKe, lKa, lCl) ~                      (0 + lKe + lKa + lCl | Subject), data = Theoph,                     cores = 2, seed = 12345,                      QR = TRUE, init_r = 0.25, adapt_delta = 0.999) pairs(post3, regex_pars = \"^l\") pairs(post3, regex_pars = \"igma\")"},{"path":"https://mc-stan.org/rstanarm/articles/glmer.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Estimating Generalized (Non-)Linear Models with Group-Specific Terms with rstanarm","text":"model fitting functions rstanarm package can essentially can done lme4 gamm4 packages — sense can fit models multilevel structure / nonlinear relationships — propagate uncertainty parameter estimates predictions functions interest. documentation lme4 gamm4 various warnings acknowledge estimated standard errors, confidence intervals, etc. entirely correct, even frequentist perspective. frequentist point estimate also completely miss second mode last example stan_nlmer. Thus, considerable reason prefer rstanarm variants functions regression modeling. disadvantage execution time required produce answer properly captures uncertainty estimates complicated models .","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"preamble","dir":"Articles","previous_headings":"","what":"Preamble","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"vignette provides introduction stan_jm modelling function rstanarm package. stan_jm function allows user estimate shared parameter joint model longitudinal time--event data Bayesian framework.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"Joint modelling can broadly defined simultaneous estimation two statistical models traditionally separately estimated. refer shared parameter joint model longitudinal time--event data, generally mean joint estimation : 1) longitudinal mixed effects model analyses patterns change outcome variable measured repeatedly time (example, clinical biomarker) 2) survival time--event model analyses time event interest occurs (example, death disease progression). Joint estimation -called “submodels” achieved assuming correlated via individual-specific parameters (.e. individual-level random effects). last two decades joint modelling longitudinal time--event data received significant amount attention [1-5]. Methodological developments area motivated growing awareness benefits joint modelling approach can provide. clinical epidemiological research common clinical biomarker repeatedly measured time given patient. addition, common time--event data, patient-specific time defined origin (e.g. time diagnosis disease) terminating clinical event death disease progression also collected. figure shows observed longitudinal measurements (.e. observed “trajectories”) log serum bilirubin small sample patients primary biliary cirrhosis. Solid lines used patients still alive end follow , dashed lines used patients died. plots, can observe -patient variation longitudinal trajectories log serum bilirubin, patients showing increase biomarker time, others decreasing, remaining stable. Moreover, variation patients terms frequency timing longitudinal measurements. perspective clinical risk prediction, may interested asking whether -patient variation log serum bilirubin trajectories provides meaningful prognostic information can help us differentiate patients regard clinical event interest, death. Alternatively, epidemiological perspective may wish explore potential etiological associations changes log serum bilirubin mortality. Joint modelling approaches provide us framework can begin answer types clinical epidemiological questions. formally, motivations undertaking joint modelling analysis longitudinal time--event data might include one following: One may interested underlying changes biomarker influence occurrence event. However, including observed biomarker measurements directly time--event model time-varying covariates poses several problems. example, widely used Cox proportional hazards model assumed time--event model biomarker measurements need available patients failure times, unlikely case [3]. simple methods imputation used, “last observation carried forward” method, likely induce bias [6]. Furthermore, observed biomarker measurements may subject measurement error therefore inclusion time-varying covariates may result biased inefficient estimates. cases, measurement error result parameter estimates shrunk towards null [7]. hand, joint modelling approaches allow us estimate association biomarker (function biomarker trajectory, rate change biomarker) risk event, whilst allowing discrete time measurement-error aspects observed biomarker. One may interested primarily evolution clinical biomarker may wish account known informative dropout. value future (unobserved) biomarker measurements related occurrence terminating event, unobserved biomarker measurements “missing random” [8,9]. words, biomarker measurements patients event differ event. circumstances, inference based solely observed measurements biomarker subject bias. joint modelling approach can help adjust informative dropout shown reduce bias estimated parameters associated longitudinal changes biomarker [1,9,10]. Joint models naturally suited task dynamic risk prediction. example, joint modelling approaches used develop prognostic models predictions event risk can updated new longitudinal biomarker measurements become available. Taylor et al. [11] jointly modelled longitudinal measurements prostate specific antigen (PSA) time clinical recurrence prostate cancer. joint model used develop web-based calculator provide real-time predictions probability recurrence based patient’s date PSA measurements. vignette, describe rstanarm package’s stan_jm modelling function. modelling function allows users fit shared parameter joint model longitudinal time--event data Bayesian framework, backend estimation carried using Stan. Section 2 describe formulation joint model used stan_jm. Section 3 present variety examples showing usage stan_jm. Note aspects estimation covered vignettes, priors vignette contains details prior distributions available regression coefficients.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"model-formulation","dir":"Articles","previous_headings":"Technical details","what":"Model formulation","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"shared parameter joint model consists related submodels specified separately longitudinal time--event outcomes. therefore commonly referred longitudinal submodel(s) event submodel. longitudinal event submodels linked using shared individual-specific parameters, can parameterised number ways. describe submodels .","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"longitudinal-submodels","dir":"Articles","previous_headings":"Technical details > Model formulation","what":"Longitudinal submodel(s)","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"assume \\(y_{ijm}(t) = y_{im}(t_{ij})\\) corresponds observed value \\(m^{th}\\) \\((m = 1,...,M)\\) biomarker individual \\(\\) \\((= 1,...,N)\\) taken time point \\(t_{ij}\\), \\(j =  1,...,n_{im}\\). specify (multivariate) generalised linear mixed model assumes \\(y_{ijm}(t)\\) follows distribution exponential family mean \\(\\mu_{ijm}(t)\\) linear predictor \\[ \\eta_{ijm}(t) = g_m(\\mu_{ijm}(t)) =   \\boldsymbol{x}^T_{ijm}(t) \\boldsymbol{\\beta}_m +   \\boldsymbol{z}^T_{ijm}(t) \\boldsymbol{b}_{im} \\] \\(\\boldsymbol{x}^T_{ijm}(t)\\) \\(\\boldsymbol{z}^T_{ijm}(t)\\) row-vectors covariates (likely include function time, example linear slope, cubic splines, polynomial terms) associated vectors fixed individual-specific parameters \\(\\boldsymbol{\\beta}_m\\) \\(\\boldsymbol{b}_{im}\\), respectively, \\(g_m\\) known link function. distribution link function allowed differ \\(M\\) longitudinal submodels. let vector \\(\\boldsymbol{\\beta} = \\{ \\boldsymbol{\\beta}_m ; m = 1,...,M\\}\\) denote collection population-level parameters across \\(M\\) longitudinal submodels. assume dependence across different longitudinal submodels (.e. correlation different longitudinal biomarkers) captured shared multivariate normal distribution individual-specific parameters; , assume \\[ \\begin{pmatrix} \\boldsymbol{b}_{i1} \\\\ \\vdots \\\\ \\boldsymbol{b}_{iM} \\end{pmatrix} =   \\boldsymbol{b}_i \\sim   \\mathsf{Normal} \\left( 0 , \\boldsymbol{\\Sigma} \\right) \\] unstructured variance-covariance matrix \\(\\boldsymbol{\\Sigma}\\).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"event-submodel","dir":"Articles","previous_headings":"Technical details > Model formulation","what":"Event submodel","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"assume also observe event time \\(T_i = \\mathsf{min} \\left( T^*_i , C_i \\right)\\) \\(T^*_i\\) denotes -called “true” event time individual \\(\\) (potentially unobserved) \\(C_i\\) denotes censoring time. define event indicator \\(d_i = (T^*_i \\leq C_i)\\). model hazard event using parametric proportional hazards regression model form \\[ h_i(t) = h_0(t; \\boldsymbol{\\omega}) \\mathsf{exp}   \\left(     \\boldsymbol{w}^T_i(t) \\boldsymbol{\\gamma} +     \\sum_{m=1}^M \\sum_{q=1}^{Q_m}       f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t)   \\right) \\] \\(h_i(t)\\) hazard event individual \\(\\) time \\(t\\), \\(h_0(t; \\boldsymbol{\\omega})\\) baseline hazard time \\(t\\) given parameters \\(\\boldsymbol{\\omega}\\), \\(\\boldsymbol{w}^T_i(t)\\) row-vector individual-specific covariates (possibly time-dependent) associated vector regression coefficients \\(\\boldsymbol{\\gamma}\\) (log hazard ratios), \\(f_{mq}(.)\\) set known functions \\(m=1,...,M\\) \\(q=1,...,Q_m\\), \\(\\alpha_{mq}\\) regression coefficients (log hazard ratios). longitudinal event submodels assumed related via “association structure”, set functions \\(\\{ f_{mq} ; m = 1,...,M, q = 1,...,Q_m \\}\\) may conditional population-level parameters longitudinal submodel \\(\\boldsymbol{\\beta}\\), individual-specific parameters \\(\\boldsymbol{b}_{}\\), population-level parameters \\(\\alpha_{mq}\\) \\(m=1,...,M\\) \\(q=1,...,Q_m\\). , association structure joint model captured via \\(\\sum_{m=1}^M \\sum_{q=1}^{Q_m} f_{mq}(\\boldsymbol{\\beta}_m, \\boldsymbol{b}_{im}, \\alpha_{mq}; t)\\) term linear predictor event submodel. \\(\\alpha_{mq}\\) referred “association parameters” since quantify strength association longitudinal event processes. various ways association structure can described next section. probability individual \\(\\) still event-free time \\(t\\), often referred “survival probability”, defined \\[ S_i(t) =   \\text{Prob} \\Big( T_i^* \\geq t \\Big) =   \\exp \\Big( -H_i(t) \\Big) \\] \\(H_i(t) = \\int_{s=0}^t h_i(s) ds\\) cumulative hazard individual \\(\\). assume baseline hazard \\(h_0(t; \\boldsymbol{\\omega})\\) modelled parametrically. stan_jm modelling function baseline hazard specified either: approximation using B-splines log hazard scale (default); Weibull distribution; approximation using piecewise constant function log hazard scale (sometimes referred piecewise exponential). choice baseline hazard can made via basehaz argument. case B-splines piecewise constant baseline hazard, user can control flexibility specifying knots degrees freedom via basehaz_ops argument. (Note currently slightly limited post-estimation functionality available models estimated piecewise constant baseline hazard, perhaps least preferable choice).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"association-structures","dir":"Articles","previous_headings":"Technical details > Model formulation","what":"Association structures","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"mentioned previous section, dependence longitudinal event submodels captured association structure, can specified number ways. simplest association structure likely \\[ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{im}, \\alpha_{mq}; t) = \\alpha_{mq} \\eta_{im}(t) \\] often referred current value association structure since assumes log hazard event time \\(t\\) linearly associated value longitudinal submodel’s linear predictor also evaluated time \\(t\\). common association structure used joint modelling literature date. situation longitudinal submodel based identity link function normal error distribution (.e. linear mixed model) current value association structure can viewed method including underlying “true” value biomarker time-varying covariate event submodel.1 However, association structures also possible. example, assume log hazard event linearly associated current slope (.e. rate change) longitudinal submodel’s linear predictor, \\[ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\frac{d\\eta_{im}(t)}{dt} \\] fact whole range possible association structures, many discussed literature [14-16]. stan_jm modelling function rstanarm package allows following association structures, specified via assoc argument: Current value (linear predictor expected value) \\[ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\eta_{im}(t) \\\\ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\mu_{im}(t) \\] Current slope (linear predictor expected value) \\[ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\frac{d\\eta_{im}(t)}{dt} \\\\ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\frac{d\\mu_{im}(t)}{dt} \\] Area curve (linear predictor expected value) \\[ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\int_0^t \\eta_{im}(u) du \\\\ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\int_0^t \\mu_{im}(u) du \\] Interactions different biomarkers \\[ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\eta_{im}(t) \\eta_{im'}(t)   \\text{ } m = m' \\text{ } m \\neq m' \\\\ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\eta_{im}(t) \\mu_{im'}(t)   \\text{ } m = m' \\text{ } m \\neq m' \\\\ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\mu_{im}(t) \\mu_{im'}(t)   \\text{ } m = m' \\text{ } m \\neq m' \\] Interactions biomarker (’s slope) observed data \\[ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} c_{}(t)  \\eta_{im}(t)   \\text{  covariate value } c_{}(t) \\\\ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} c_{}(t)  \\mu_{im}(t)   \\text{  covariate value } c_{}(t) \\\\ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} c_{}(t)  \\frac{d\\eta_{im}(t)}{dt}   \\text{  covariate value } c_{}(t) \\\\ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} c_{}(t)  \\frac{d\\mu_{im}(t)}{dt}   \\text{  covariate value } c_{}(t) \\] well using lagged values . , replacing \\(t\\) \\(t-u\\) \\(u\\) lag time, hazard event time \\(t\\) assumed associated function longitudinal submodel parameters time \\(t-u\\). Lastly, can specify time-independent function random effects, possibly including fixed effect component. example, \\[ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) = \\alpha_{mq} \\boldsymbol{b}_{im0} \\] \\[ f_{mq}(\\boldsymbol{\\beta}, \\boldsymbol{b}_{}, \\alpha_{mq}; t) =   \\alpha_{mq} \\Big( \\boldsymbol{\\beta}_{m0} + \\boldsymbol{b}_{im0} \\Big) \\] \\(\\boldsymbol{\\beta}_{m0}\\) population-level intercept \\(m^{th}\\) longitudinal submodel \\(\\boldsymbol{b}_{im0}\\) \\(^{th}\\) individual’s random deviation population-level intercept \\(m^{th}\\) longitudinal submodel. Note one association structure can specified, however, possible combinations allowed. Moreover, fitting multivariate joint model (.e. one longitudinal outcome) can optionally choose use different association structure(s) linking longitudinal submodel event submodel. can pass list length \\(M\\) assoc argument.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"assumptions","dir":"Articles","previous_headings":"Technical details > Model formulation","what":"Assumptions","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"define set assumptions multivariate shared parameter joint model. -called conditional independence assumption shared parameter joint model postulates \\[   y_{im}(t) \\perp y_{im'}(t) \\mid \\boldsymbol{b}_i, \\boldsymbol{\\theta}  \\\\   y_{im}(t) \\perp y_{im}(t') \\mid \\boldsymbol{b}_i, \\boldsymbol{\\theta} \\\\   y_{im}(t) \\perp T_i^*      \\mid \\boldsymbol{b}_i, \\boldsymbol{\\theta} \\] \\(m \\neq m'\\) \\(t \\neq t'\\), \\(\\boldsymbol{\\theta}\\) denotes combined vector remaining population-level parameters model. , conditional individual-specific parameters \\(\\boldsymbol{b}_i\\) population-level parameters \\(\\boldsymbol{\\theta}\\), following assumed: () biomarker measurement individual \\(\\) independent individual’s true event time \\(T_i^*\\); (ii) two measurements \\(m^{th}\\) biomarker taken \\(^{th}\\) individual two distinct time points \\(t\\) \\(t'\\) (.e. longitudinal repeated measurements) independent one another; (iii) two measurements two different biomarkers, taken \\(^{th}\\) individual time point \\(t\\) independent one another. conditional independence assumptions allow convenient factorisation full likelihood joint model likelihoods component parts (.e. likelihood longitudinal submodel, likelihood event submodel, likelihood distribution individual-specific parameters), facilitates estimation model. Moreover, require two additional assumptions: () censoring process event outcome independent true event time, \\(C_i \\perp T_i^* \\mid \\boldsymbol{\\theta}\\) (.e. uninformative censoring); (ii) visiting process observation times \\(t_{ijm}\\) determined independent true event time \\(T_i^*\\) missing future unobserved longitudinal biomarker measurements.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"log-posterior-distribution","dir":"Articles","previous_headings":"Technical details > Model formulation","what":"Log posterior distribution","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"conditional independence assumption, log posterior \\(^{th}\\) individual can specified \\[ \\log p(\\boldsymbol{\\theta}, \\boldsymbol{b}_{} \\mid \\boldsymbol{y}_{}, T_i, d_i)   \\propto     \\log \\Bigg[       \\Bigg(         \\prod_{m=1}^M           \\prod_{j=1}^{n_i}             p(y_{ijm}(t) \\mid \\boldsymbol{b}_{}, \\boldsymbol{\\theta})       \\Bigg)       p(T_i, d_i \\mid \\boldsymbol{b}_{}, \\boldsymbol{\\theta})       p(\\boldsymbol{b}_{} \\mid \\boldsymbol{\\theta})       p(\\boldsymbol{\\theta})     \\Bigg]     \\] \\(\\boldsymbol{y}_i = \\{ y_{ijm}(t); j = 1,...,n_i, m = 1,...,M \\}\\) denotes collection longitudinal biomarker data individual \\(\\) \\(\\boldsymbol{\\theta}\\) denotes remaining population-level parameters model. can rewrite log posterior \\[ \\log p(\\boldsymbol{\\theta}, \\boldsymbol{b}_{} \\mid \\boldsymbol{y}_{}, T_i, d_i)   \\propto     \\Bigg(       \\sum_{m=1}^M         \\sum_{j=1}^{n_i}           \\log p(y_{ijm}(t) \\mid \\boldsymbol{b}_{}, \\boldsymbol{\\theta})     \\Bigg) +     \\log p(T_i, d_i \\mid \\boldsymbol{b}_{}, \\boldsymbol{\\theta}) +     \\log p(\\boldsymbol{b}_{} \\mid \\boldsymbol{\\theta}) +     \\log p(\\boldsymbol{\\theta}) \\] \\(\\sum_{j=1}^{n_{im}} \\log p(y_{ijm} \\mid \\boldsymbol{b}_{}, \\boldsymbol{\\theta})\\) log likelihood \\(m^{th}\\) longitudinal submodel, \\(\\log p(T_i, d_i \\mid \\boldsymbol{b}_{}, \\boldsymbol{\\theta})\\) log likelihood event submodel, \\(\\log p(\\boldsymbol{b}_{} \\mid \\boldsymbol{\\theta})\\) log likelihood distribution group-specific parameters (.e. random effects), \\(\\log p(\\boldsymbol{\\theta})\\) represents log likelihood joint prior distribution across remaining unknown parameters.2 can rewrite log likelihood event submodel \\[ \\log p(T_i, d_i \\mid \\boldsymbol{b}_{}, \\boldsymbol{\\theta}) =   d_i * \\log h_i(T_i) - \\int_0^{T_i} h_i(s) ds \\] use Gauss-Kronrod quadrature \\(Q\\) nodes approximate \\(\\int_0^{T_i} h_i(s) ds\\), \\[ \\int_0^{T_i} h_i(s) ds \\approx \\frac{T_i}{2} \\sum_{q=1}^{Q} w_q h_i \\bigg( \\frac{T_i(1+s_q)}{2} \\bigg) \\] \\(w_q\\) \\(s_q\\), respectively, standardised weights locations (“abscissa”) quadrature node \\(q\\) \\((q=1,...,Q)\\) [17]. default stan_jm modelling function use \\(Q=15\\) quadrature nodes, however user wishes, can choose \\(Q=15\\), \\(11\\), \\(7\\) quadrature nodes (specified via qnodes argument). Therefore, individual’s event time \\(T_i\\) can evaluate design matrices event submodel longitudinal submodels \\(Q+1\\) necessary time points (event time \\(T_i\\) quadrature points \\(\\frac{T_i(1+s_q)}{2}\\) \\(q=1,...,Q\\)) pass Stan’s data block. can evaluate log likelihood event submodel simply calculating hazard \\(h_i(t)\\) \\(Q+1\\) time points summing quantities appropriately. calculation need performed time iterate Stan’s model block. simplified example underlying Stan code used fit joint model can found Brilleman et al. (2018) [12].","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"model-predictions","dir":"Articles","previous_headings":"Technical details","what":"Model predictions","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"discussing methods can generate posterior predictions, first let us define additional relevant quantities. Let \\(\\mathcal{D} = \\{ \\boldsymbol{y}_i, T_i, d_i; = 1,...,N \\}\\) entire collection outcome data sample. refer sample “training data”. Let \\(T_{max} = \\max \\{ T_i; = 1,...,N \\}\\) denote maximum event censoring time across \\(= 1,...,N\\) individuals training data.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"individual-specific-predictions-for-in-sample-individuals-for-0-leq-t-leq-t_i","dir":"Articles","previous_headings":"Technical details > Model predictions","what":"Individual-specific predictions for in-sample individuals (for \\(0 \\leq t \\leq T_i\\))","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"can generate posterior predictions longitudinal time--event outcomes following manner. \\(^{th}\\) individual training data, predicted value \\(m^{th}\\) longitudinal biomarker time \\(t\\), denoted \\(y^*_{im}(t)\\), can generated posterior predictive distribution \\[ p \\Big( y^{*}_{im}(t) \\mid \\mathcal{D} \\Big) =   \\int     \\int       p \\Big( y^{*}_{im}(t) \\mid \\boldsymbol{\\theta}, \\boldsymbol{b}_i \\Big)       p \\Big( \\boldsymbol{\\theta}, \\boldsymbol{b}_i \\mid \\mathcal{D} \\Big)     \\space d \\boldsymbol{b}_i   \\space d \\boldsymbol{\\theta} \\] , similarly, predicted probability \\(^{th}\\) individual event-free time \\(t\\), denoted \\(S^*_i(t)\\), can generated posterior predictive distribution \\[ p \\Big( S^{*}_{}(t) \\mid \\mathcal{D} \\Big) =   \\int     \\int       p \\Big( S^{*}_i(t) \\mid \\boldsymbol{\\theta}, \\boldsymbol{b}_i \\Big)       p \\Big( \\boldsymbol{\\theta}, \\boldsymbol{b}_i \\mid \\mathcal{D} \\Big)     d \\boldsymbol{b}_i \\space d \\boldsymbol{\\theta}       \\] Note simplicity ignored implicit conditioning covariates; \\(\\boldsymbol{x}_{im}(t)\\) \\(\\boldsymbol{z}_{im}(t)\\), \\(m = 1,...,M\\), \\(\\boldsymbol{w}_{}(t)\\). Since individual \\(\\) included training data, easy us approximate posterior predictive distributions drawing \\(p(y^{*}_{im}(t) \\mid \\boldsymbol{\\theta}^{(l)}, \\boldsymbol{b}_i^{(l)})\\) \\(p(S^{*}_i(t) \\mid \\boldsymbol{\\theta}^{(l)}, \\boldsymbol{b}_i^{(l)})\\) \\(\\boldsymbol{\\theta}^{(l)}\\) \\(\\boldsymbol{b}_i^{(l)}\\) \\(l^{th}\\) \\((l = 1,...,L)\\) MCMC draws joint posterior distribution \\(p(\\boldsymbol{\\theta}, \\boldsymbol{b}_i \\mid \\mathcal{D})\\). draws posterior predictive distributions can used assessing fit model. example, draws \\(p(y^{*}_{im}(t) \\mid \\mathcal{D})\\) \\(0 \\leq t \\leq T_i\\) can used evaluate fit longitudinal trajectory \\(m^{th}\\) biomarker \\(^{th}\\) individual, draws \\(p(S^{*}_{}(t) \\mid \\mathcal{D})\\) \\(0 \\leq t \\leq T_{max}\\) can averaged across \\(N\\) individuals obtain standardised survival curve (discussed greater detail later sections) can compared observed survival curve, example, Kaplan-Meier curve.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"individual-specific-predictions-for-in-sample-individuals-for-t-c_i","dir":"Articles","previous_headings":"Technical details > Model predictions","what":"Individual-specific predictions for in-sample individuals (for \\(t > C_i\\))","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"However, given know event censoring time individual training data, may make sense consider happen censored individuals study look beyond last known survival time (.e. extrapolation). individual \\(\\), training data, known event-free censoring time \\(C_i\\), wish draw conditional posterior predictive distribution longitudinal outcome time \\(t > C_i\\), \\[ p \\Big( y^{*}_{im}(t) \\mid \\mathcal{D}, t > C_i \\Big) =   \\int     \\int       p \\Big( y^{*}_{im}(t) \\mid \\boldsymbol{\\theta}, \\boldsymbol{b}_i, t > C_i \\Big)       p \\Big( \\boldsymbol{\\theta}, \\boldsymbol{b}_i \\mid \\mathcal{D} \\Big)     d \\boldsymbol{b}_i \\space d \\boldsymbol{\\theta} \\] conditional posterior predictive distribution survival probability time \\(t > C_i\\), \\[ \\begin{aligned} p \\Big( S^{*}_{}(t) \\mid \\mathcal{D}, t > C_i, T_i^* > C_i \\Big) & =   \\frac     {p \\Big( S^{*}_{}(t)   \\mid \\mathcal{D} \\Big)}     {p \\Big( S^{*}_{}(C_i) \\mid \\mathcal{D} \\Big)} \\\\ & =   \\int     \\int       \\frac         {p \\Big( S^{*}_i(t)   \\mid \\boldsymbol{\\theta}, \\boldsymbol{b}_i \\Big)}         {p \\Big( S^{*}_i(C_i) \\mid \\boldsymbol{\\theta}, \\boldsymbol{b}_i \\Big)}       \\space p \\Big( \\boldsymbol{\\theta}, \\boldsymbol{b}_i \\mid \\mathcal{D} \\Big)     d \\boldsymbol{b}_i \\space d \\boldsymbol{\\theta} \\end{aligned} \\] draws conditional posterior predictive distributions can used extrapolate future individual \\(\\), conditional longitudinal biomarker data collected baseline censoring time \\(C_i\\). example, draws \\(p(y^{*}_{im}(t) \\mid \\mathcal{D}, t > C_i)\\) \\(C_i \\leq t \\leq T_{max}\\) can used show forecasted longitudinal trajectory \\(m^{th}\\) biomarker \\(^{th}\\) individual, draws \\(p(S^{*}_{}(t) \\mid \\mathcal{D}, t > C_i, T_i^* > C_i))\\) \\(C_i \\leq t \\leq T_{max}\\) can used show estimated conditional probability individual \\(\\) remaining event-free future.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"individual-specific-predictions-for-out-of-sample-individuals-i-e--dynamic-predictions","dir":"Articles","previous_headings":"Technical details > Model predictions","what":"Individual-specific predictions for out-of-sample individuals (i.e. dynamic predictions)","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"TBC. Describe dynamic predictions framework Rizopoulos (2011) [18]. types individual-specific predictions can obtained using posterior_traj posterior_survfit functions providing prediction data specifying dynamic = TRUE (default); see examples provided .","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"population-level-i-e--marginal-predictions","dir":"Articles","previous_headings":"Technical details > Model predictions","what":"Population-level (i.e. marginal) predictions","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"can also generate posterior predictions longitudinal time--event outcomes require conditioning observed outcome data specific individual. , discuss two ways can done. first way “marginalise” distribution individual-specific parameters. wish generate predicted value \\(m^{th}\\) longitudinal biomarker time \\(t\\) new individual \\(k\\) observed data. denote prediction \\(y^*_{km}(t)\\) note can generated posterior predictive distribution longitudinal outcome \\[ \\begin{aligned} p \\Big( y^{*}_{km}(t) \\mid \\mathcal{D} \\Big) & =   \\int     \\int       p \\Big( y^{*}_{km}(t) \\mid \\boldsymbol{\\theta}, \\boldsymbol{\\tilde{b}}_k \\Big)       p \\Big( \\boldsymbol{\\theta}, \\boldsymbol{\\tilde{b}}_k \\mid \\mathcal{D} \\Big)     \\space d \\boldsymbol{\\tilde{b}}_{k}   \\space d \\boldsymbol{\\theta} \\\\ & =   \\int     \\int       p \\Big( y^{*}_{km}(t) \\mid \\boldsymbol{\\theta}, \\boldsymbol{\\tilde{b}}_k \\Big)       p \\Big( \\boldsymbol{\\tilde{b}}_k \\mid \\boldsymbol{\\theta} \\Big)       p \\Big( \\boldsymbol{\\theta} \\mid \\mathcal{D} \\Big)     \\space d \\boldsymbol{\\tilde{b}}_{k}   \\space d \\boldsymbol{\\theta} \\end{aligned} \\] similarly survival probability \\[ \\begin{aligned} p \\Big( S^{*}_{k}(t) \\mid \\mathcal{D} \\Big) & =   \\int     \\int       p \\Big( S^{*}_k(t) \\mid \\boldsymbol{\\theta}, \\boldsymbol{\\tilde{b}}_k \\Big)       p \\Big( \\boldsymbol{\\theta}, \\boldsymbol{\\tilde{b}}_k \\mid \\mathcal{D} \\Big)     d \\boldsymbol{b}_k \\space d \\boldsymbol{\\theta} \\\\ & = \\int     \\int       p \\Big( S^{*}_k(t) \\mid \\boldsymbol{\\theta}, \\boldsymbol{\\tilde{b}}_k \\Big)       p \\Big( \\boldsymbol{\\tilde{b}}_k \\mid \\boldsymbol{\\theta} \\Big)       p \\Big( \\boldsymbol{\\theta} \\mid \\mathcal{D} \\Big)     d \\boldsymbol{b}_k \\space d \\boldsymbol{\\theta} \\\\ \\end{aligned} \\] can obtain draws \\(\\boldsymbol{\\tilde{b}}_k\\) manner individual-specific parameters \\(\\boldsymbol{b}_i\\). , \\(l^{th}\\) iteration MCMC sampler draw \\(\\boldsymbol{\\tilde{b}}_k^{(l)}\\) store it3. However, individual \\(k\\) provide contribution training data effectively taking random draws posterior distribution individual-specific parameters. therefore effectively marginalising distribution group-specific coefficients obtain predictions using draws \\(\\boldsymbol{\\tilde{b}}_k^{(l)}\\) fro \\(l = 1,\\dots,L\\). words, predicting new individual information except drawn population \\(= 1,...,N\\) individuals training data. predictions incorporate uncertainty associated -individual variation 95% credible intervals likely wide. types marginal predictions can obtained using posterior_traj posterior_survfit functions providing prediction data specifying dynamic = FALSE; see examples provided . second way effectively ignore group-level structure model. , predict population-level parameters contributing model. example, identity link function normal error distribution (.e. linear mixed effect longitudinal submodel), obtain draws distribution \\(y^{(l)}_{km}(t) \\sim N \\Big( \\boldsymbol{x}^T_{km}(t) \\boldsymbol{\\beta}_m^{(l)}, \\sigma_m^{(l)} \\Big)\\) \\(\\boldsymbol{\\beta}_m^{(l)}\\) \\(\\sigma_m^{(l)}\\) population-level parameters residual error standard deviation, respectively, \\(l^{th}\\) draw MCMC samples. However, referring “marginal” prediction somewhat misleading since explicitly conditioning individual-specific parameters implicitly assuming know equal zero absolute certainty. , actually drawing posterior predictive distribution longitudinal outcome \\[ \\begin{aligned} p \\Big( y^{*}_{km}(t) \\mid \\mathcal{D} \\Big) & =   \\int       p \\Big( y^{*}_{km}(t) \\mid \\boldsymbol{\\theta}, \\boldsymbol{b}_k = 0 \\Big)       p \\Big( \\boldsymbol{\\theta} \\mid \\mathcal{D} \\Big)   d \\boldsymbol{\\theta} \\\\ \\end{aligned} \\] similarly survival probability \\[ p \\Big( S^{*}_{k}(t) \\mid \\mathcal{D} \\Big) =   \\int     p \\Big( S^{*}_k(t) \\mid \\boldsymbol{\\theta}, \\boldsymbol{b}_k = 0 \\Big)     p \\Big( \\boldsymbol{\\theta} \\mid \\mathcal{D} \\Big)   d \\boldsymbol{\\theta} \\\\ \\] types -called “marginal” predictions can currently obtained using posterior_traj posterior_survfit functions.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"standardised-survival-probabilities","dir":"Articles","previous_headings":"Technical details > Model predictions","what":"Standardised survival probabilities","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"previously discussed population-level (.e. marginal) predictions assumed implicit conditioning covariate values longitudinal submodel, \\(\\boldsymbol{x}_{im}(t)\\) \\(\\boldsymbol{z}_{im}(t)\\) \\(m = 1,...,M\\), event submodel, \\(\\boldsymbol{w}_{}(t)\\). Even though marginalise distribution individual-specific parameters still assuming obtained predictions known values covariates. However, sometimes wish marginalise (.e. average) observed distribution covariates well. discuss method can predicted survival probabilities. time \\(t\\), possible obtain standardised survival probability averaging individual-specific survival probabilities. , can obtain \\[ S^*(t) = \\frac{\\sum_{=1}^{N^{pred}} S_i^*(t)}{N^{pred}} \\] \\(S_i^*(t)\\) predicted survival probability individual \\(\\) (\\(= 1,\\dots,N^{pred}\\) time \\(t\\), \\(N^{pred}\\) number individuals included prediction dataset. refer predictions standardised survival probabilities. Note however, \\(N_{pred}\\) sufficiently large (e.g. pass new data just 2 individuals, say) marginalising covariate distribution may meaningful , similarly, joint random effects distribution may poor representation random effects distribution entire population. better calculate standardised survival probabilities using , say, \\(N^{pred}\\) equal total number individuals training data.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"delayed-entry-left-truncation","dir":"Articles","previous_headings":"Technical details > Model extensions","what":"Delayed entry (left-truncation)","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"TBC.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"multilevel-clustering","dir":"Articles","previous_headings":"Technical details > Model extensions","what":"Multilevel clustering","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"TBC.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"loowaic-in-the-context-of-joint-models","dir":"Articles","previous_headings":"Technical details > Model comparison","what":"LOO/WAIC in the context of joint models","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"TBC.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"dataset-used-in-the-examples","dir":"Articles","previous_headings":"Usage examples","what":"Dataset used in the examples","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"use Mayo Clinic’s primary biliary cirrhosis (PBC) dataset examples . dataset contains 312 individuals primary biliary cirrhosis participated randomised placebo controlled trial D-penicillamine conducted Mayo Clinic 1974 1984 [19]. However, ensure examples run quickly, use small random subset just 40 patients full data. example data contained two separate data frames. first data frame contains multiple-row per patient longitudinal biomarker information, shown second data frame contains single-row per patient survival information, shown variables included across two datasets can defined follows: age years albumin serum albumin (g/dl) logBili logarithm serum bilirubin death indicator death endpoint futimeYears time (years) baseline earliest death, transplantion censoring id numeric ID unique individual platelet platelet count sex gender (m = male, f = female) status status endpoint (0 = censored, 1 = transplant, 2 = dead) trt binary treatment code (0 = placebo, 1 = D-penicillamine) year time (years) longitudinal measurements, taken time since baseline) description example datasets can found accessing following help documentation:","code":"head(pbcLong) id      age sex trt      year     logBili albumin platelet 1  1 58.76523   f   1 0.0000000  2.67414865    2.60      190 2  1 58.76523   f   1 0.5256674  3.05870707    2.94      183 3  2 56.44627   f   1 0.0000000  0.09531018    4.14      221 4  2 56.44627   f   1 0.4982888 -0.22314355    3.60      188 5  2 56.44627   f   1 0.9993155  0.00000000    3.55      161 6  2 56.44627   f   1 2.1026694  0.64185389    3.92      122 head(pbcSurv) id      age sex trt futimeYears status death 1   1 58.76523   f   1    1.095140      2     1 3   2 56.44627   f   1   14.151951      0     0 12  3 70.07255   m   1    2.770705      2     1 16  4 54.74059   f   1    5.270363      2     1 23  5 38.10541   f   0    4.120465      1     0 29  6 66.25873   f   0    6.852841      2     1 help(\"datasets\", package = \"rstanarm\")"},{"path":[]},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"univariate-joint-model-current-value-association-structure","dir":"Articles","previous_headings":"Usage examples > Fitting the models","what":"Univariate joint model (current value association structure)","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"example fit simple univariate joint model, one normally distributed longitudinal marker, association structure based current value linear predictor, B-splines baseline hazard. fit model use joint (longitudinal time--event) modelling function rstanarm package: stan_jm. calling stan_jm must, minimum, specify formula object longitudinal event submodels (arguments formulaLong formulaEvent), data frames contain variables longitudinal event submodels (arguments dataLong dataEvent), name variable representing time longitudinal submodel (argument time_var). formula longitudinal submodel specified using lme4 package formula style. y ~ x + (random_effects | grouping_factor). example specify log serum bilirubin (logBili) follows subject-specific linear trajectory. include fixed intercept fixed slope (year), well random intercept random slope subject id ((year | id)). formula event submodel specified using survival package formula style. , outcome left ~ needs format Surv(event_time, event_indicator) single row per individual data, Surv(start_time, stop_time, event_indicator) multiple row per individual data. latter allows exogenous time-varying covariates included event submodel. example assume log hazard death linearly related gender (sex) indicator treatment D-penicillamine (trt). argument refresh = 2000 specified Stan didn’t provide us excessive progress updates whilst fitting model. However, fitting model take several minutes hours fit, may wish request progress updates quite regularly, example setting refresh = 20 every 20 iterations (default refresh argument set 1/10th total number iterations). fitted model returned object S3 class stanjm. variety methods post-estimation functions available class, including: print, summary, plot, fixef, ranef, coef, VarCorr, posterior_interval, update, . , examine basic output fitted joint model typing print(mod1): “Long1|etavalue” row “Event submodel” \\(\\alpha_{mq}\\) parameter (\\(m = 1\\), \\(q = 1\\)). estimated median tells us one unit increase individual’s underlying level log serum bilirubin, estimated log hazard death increases amount. mean absolute deviation (MAD) provided robust estimate standard deviation posterior distribution. case MAD_SD association parameter indicates quite large uncertainty around estimated association log serum bilirubin risk death (recall small dataset). wanted slightly detailed output model parameters, well details regarding model estimation (example computation time, number longitudinal observations, number individuals, type baseline hazard, etc) can instead use summary method: easiest way extract correlation matrix random effects (aside viewing print output) use VarCorr function (modelled VarCorr function lme4 package). wish extract variances covariances (instead standard deviations correlations) can type following return data frame relevant information:","code":"library(rstanarm) mod1 <- stan_jm(formulaLong = logBili ~ sex + trt + year + (year | id),                  dataLong = pbcLong,                 formulaEvent = survival::Surv(futimeYears, death) ~ sex + trt,                  dataEvent = pbcSurv,                 time_var = \"year\",                 chains = 1, refresh = 2000, seed = 12345) Fitting a univariate joint model.  Please note the warmup may be much slower than later iterations!  SAMPLING FOR MODEL 'jm' NOW (CHAIN 1). Chain 1:  Chain 1: Gradient evaluation took 0.000222 seconds Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.22 seconds. Chain 1: Adjust your expectations accordingly! Chain 1:  Chain 1:  Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) Chain 1:  Chain 1:  Elapsed Time: 19.218 seconds (Warm-up) Chain 1:                19.832 seconds (Sampling) Chain 1:                39.05 seconds (Total) Chain 1: stan_jm  formula (Long1): logBili ~ sex + trt + year + (year | id)  family  (Long1): gaussian [identity]  formula (Event): survival::Surv(futimeYears, death) ~ sex + trt  baseline hazard: bs  assoc:           etavalue (Long1) ------  Longitudinal submodel: logBili             Median MAD_SD (Intercept)  0.304  0.558 sexf         0.477  0.523 trt         -0.127  0.370 year         0.212  0.043 sigma        0.354  0.016  Event submodel:                 Median MAD_SD exp(Median) (Intercept)     -3.179  0.621  0.042      sexf            -0.336  0.620  0.715      trt             -0.720  0.415  0.487      Long1|etavalue   1.341  0.238  3.821      b-splines-coef1 -0.836  1.035     NA      b-splines-coef2  0.518  0.881     NA      b-splines-coef3 -1.797  1.196     NA      b-splines-coef4  0.299  1.652     NA      b-splines-coef5 -0.061  1.665     NA      b-splines-coef6 -0.820  1.665     NA       Group-level error terms:  Groups Name              Std.Dev. Corr  id     Long1|(Intercept) 1.2954                Long1|year        0.1921   0.52 Num. levels: id 40   Sample avg. posterior predictive distribution  of longitudinal outcomes:                Median MAD_SD Long1|mean_PPD 0.585  0.032   ------ For info on the priors used see help('prior_summary.stanreg'). summary(mod1, probs = c(.025,.975)) Model Info:   function:        stan_jm  formula (Long1): logBili ~ sex + trt + year + (year | id)  family  (Long1): gaussian [identity]  formula (Event): survival::Surv(futimeYears, death) ~ sex + trt  baseline hazard: bs  assoc:           etavalue (Long1)  algorithm:       sampling  priors:          see help('prior_summary')  sample:          1000 (posterior sample size)  num obs:         304 (Long1)  num subjects:    40  num events:      29 (72.5%)  groups:          id (40)  runtime:         0.6 mins  Estimates:                                                 mean     sd       2.5%   Long1|(Intercept)                                0.294    0.586   -0.926 Long1|sexf                                       0.499    0.560   -0.529 Long1|trt                                       -0.144    0.386   -0.973 Long1|year                                       0.214    0.042    0.136 Long1|sigma                                      0.354    0.017    0.324 Long1|mean_PPD                                   0.586    0.030    0.527 Event|(Intercept)                               -3.191    0.622   -4.477 Event|sexf                                      -0.299    0.620   -1.407 Event|trt                                       -0.740    0.445   -1.663 Event|b-splines-coef1                           -0.949    1.065   -3.263 Event|b-splines-coef2                            0.462    0.908   -1.410 Event|b-splines-coef3                           -1.807    1.186   -4.100 Event|b-splines-coef4                            0.388    1.567   -2.682 Event|b-splines-coef5                           -0.077    1.647   -3.410 Event|b-splines-coef6                           -1.014    1.692   -4.884 Assoc|Long1|etavalue                             1.347    0.237    0.915 Sigma[id:Long1|(Intercept),Long1|(Intercept)]    1.678    0.438    1.012 Sigma[id:Long1|year,Long1|(Intercept)]           0.129    0.076    0.018 Sigma[id:Long1|year,Long1|year]                  0.037    0.020    0.014 log-posterior                                 -329.512    9.997 -349.426                                                 97.5%  Long1|(Intercept)                                1.367 Long1|sexf                                       1.627 Long1|trt                                        0.582 Long1|year                                       0.299 Long1|sigma                                      0.387 Long1|mean_PPD                                   0.647 Event|(Intercept)                               -2.068 Event|sexf                                       1.036 Event|trt                                        0.128 Event|b-splines-coef1                            0.882 Event|b-splines-coef2                            2.114 Event|b-splines-coef3                            0.370 Event|b-splines-coef4                            3.494 Event|b-splines-coef5                            2.989 Event|b-splines-coef6                            1.810 Assoc|Long1|etavalue                             1.829 Sigma[id:Long1|(Intercept),Long1|(Intercept)]    2.703 Sigma[id:Long1|year,Long1|(Intercept)]           0.300 Sigma[id:Long1|year,Long1|year]                  0.085 log-posterior                                 -311.470  Diagnostics:                                               mcse  Rhat  n_eff Long1|(Intercept)                             0.029 0.999  411  Long1|sexf                                    0.028 0.999  407  Long1|trt                                     0.023 1.001  281  Long1|year                                    0.002 0.999  288  Long1|sigma                                   0.001 1.002  953  Long1|mean_PPD                                0.001 1.001 1165  Event|(Intercept)                             0.019 1.001 1131  Event|sexf                                    0.018 1.002 1156  Event|trt                                     0.013 0.999 1149  Event|b-splines-coef1                         0.040 0.999  703  Event|b-splines-coef2                         0.029 1.000 1008  Event|b-splines-coef3                         0.046 0.999  660  Event|b-splines-coef4                         0.065 0.999  589  Event|b-splines-coef5                         0.064 0.999  654  Event|b-splines-coef6                         0.061 0.999  767  Assoc|Long1|etavalue                          0.007 0.999 1074  Sigma[id:Long1|(Intercept),Long1|(Intercept)] 0.025 0.999  306  Sigma[id:Long1|year,Long1|(Intercept)]        0.006 1.001  182  Sigma[id:Long1|year,Long1|year]               0.001 1.003  214  log-posterior                                 0.708 1.002  199   For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). as.data.frame(VarCorr(mod1)) grp              var1       var2       vcov     sdcor 1  id Long1|(Intercept)       <NA> 1.67802152 1.2953847 2  id        Long1|year       <NA> 0.03691896 0.1921431 3  id Long1|(Intercept) Long1|year 0.12937327 0.5197818"},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"univariate-joint-model-current-value-and-current-slope-association-structure","dir":"Articles","previous_headings":"Usage examples > Fitting the models","what":"Univariate joint model (current value and current slope association structure)","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"previous example fitting shared parameter joint model assumed log hazard event (case log hazard death) time t linearly related subject-specific expected value longitudinal marker (case expected value log serum bilirubin) also time t. default association structure, although explicitly specified setting assoc = \"etavalue\" argument. However, let’s suppose believe log hazard death actually related current value log serum bilirubin current rate change log serum bilirubin. estimate joint model need indicate want also include subject-specific slope (time t) longitudinal submodel part association structure. setting assoc argument equal character vector c(\"etavalue\", \"etaslope\") indicates desired association structure: example subject-specific slope actually constant across time t since linear trajectory. Note however still use \"etaslope\" association structure even non-linear subject specific trajectory (example modelled using cubic splines polynomials).","code":"mod2 <- stan_jm(formulaLong = logBili ~ sex + trt + year + (year | id),                  dataLong = pbcLong,                 formulaEvent = survival::Surv(futimeYears, death) ~ sex + trt,                  dataEvent = pbcSurv,                 assoc = c(\"etavalue\", \"etaslope\"),                 time_var = \"year\",                  chains = 1, refresh = 2000, seed = 12345)"},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"multivariate-joint-model-current-value-association-structures","dir":"Articles","previous_headings":"Usage examples > Fitting the models","what":"Multivariate joint model (current value association structures)","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"Suppose instead interested two repeatedly measured clinical biomarkers, log serum bilirubin serum albumin, association risk death. may wish model two biomarkers, allowing correlation , estimating respective associations log hazard death. fit linear mixed effects submodel (identity link, normal distribution) biomarker patient-specific intercept linear slope covariates. event submodel include gender (sex) treatment (trt) baseline covariates. biomarker assumed associated log hazard death time \\(t\\) via ’s expected value time \\(t\\) (.e. current value association structure). model going fit can therefore specified : \\[ y_{im}(t_{ijm}) \\sim N(\\mu_{im}(t_{ijm}), \\sigma_m) \\] \\[ \\eta_{im}(t) = \\mu_{im}(t) = \\beta_{0m} + \\beta_{1m} t + b_{0mi} + b_{1mi} t \\] \\[ h_i(t) = h_0(t; \\boldsymbol{\\omega}) \\exp(\\gamma_1 w_{1i} + \\gamma_2 w_{2i} + \\alpha_{1i} \\mu_{i1}(t) + \\alpha_{2i} \\mu_{i2}(t)) \\] \\(t\\) time years, \\(w_{1i}\\) \\(w_{2i}\\) , respectively, gender treatment indicators individual \\(\\). (Note due small sample size, clinical findings analysis overinterpreted!). can now examine output fitted model, example can examine summary output association parameters alone:","code":"mod3 <- stan_jm(     formulaLong = list(         logBili ~ sex + trt + year + (year | id),          albumin ~ sex + trt + year + (year | id)),     formulaEvent = survival::Surv(futimeYears, death) ~ sex + trt,      dataLong = pbcLong, dataEvent = pbcSurv,     time_var = \"year\",     chains = 1, refresh = 2000, seed = 12345) Fitting a multivariate joint model.  Please note the warmup may be much slower than later iterations!  SAMPLING FOR MODEL 'jm' NOW (CHAIN 1). Chain 1:  Chain 1: Gradient evaluation took 0.00032 seconds Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 3.2 seconds. Chain 1: Adjust your expectations accordingly! Chain 1:  Chain 1:  Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) Chain 1:  Chain 1:  Elapsed Time: 35.291 seconds (Warm-up) Chain 1:                36.241 seconds (Sampling) Chain 1:                71.532 seconds (Total) Chain 1: print(mod3) stan_jm  formula (Long1): logBili ~ sex + trt + year + (year | id)  family  (Long1): gaussian [identity]  formula (Long2): albumin ~ sex + trt + year + (year | id)  family  (Long2): gaussian [identity]  formula (Event): survival::Surv(futimeYears, death) ~ sex + trt  baseline hazard: bs  assoc:           etavalue (Long1), etavalue (Long2) ------  Longitudinal submodel 1: logBili             Median MAD_SD (Intercept)  0.263  0.508 sexf         0.475  0.487 trt         -0.063  0.374 year         0.222  0.043 sigma        0.354  0.017  Longitudinal submodel 2: albumin             Median MAD_SD (Intercept)  3.471  0.224 sexf         0.066  0.240 trt          0.000  0.168 year        -0.156  0.023 sigma        0.291  0.013  Event submodel:                 Median  MAD_SD  exp(Median) (Intercept)       6.854   2.660 947.312     sexf             -0.101   0.652   0.904     trt              -0.501   0.500   0.606     Long1|etavalue    0.805   0.312   2.236     Long2|etavalue   -3.075   0.834   0.046     b-splines-coef1  -0.973   1.138      NA     b-splines-coef2   0.546   0.849      NA     b-splines-coef3  -2.571   1.352      NA     b-splines-coef4  -0.645   1.807      NA     b-splines-coef5  -1.276   1.887      NA     b-splines-coef6  -2.704   1.864      NA      Group-level error terms:  Groups Name              Std.Dev. Corr               id     Long1|(Intercept) 1.24123                            Long1|year        0.18822   0.49                     Long2|(Intercept) 0.51395  -0.65 -0.49               Long2|year        0.09606  -0.57 -0.81  0.45 Num. levels: id 40   Sample avg. posterior predictive distribution  of longitudinal outcomes:                Median MAD_SD Long1|mean_PPD 0.588  0.030  Long2|mean_PPD 3.343  0.025   ------ For info on the priors used see help('prior_summary.stanreg'). summary(mod3, pars = \"assoc\") Model Info:   function:        stan_jm  formula (Long1): logBili ~ sex + trt + year + (year | id)  family  (Long1): gaussian [identity]  formula (Long2): albumin ~ sex + trt + year + (year | id)  family  (Long2): gaussian [identity]  formula (Event): survival::Surv(futimeYears, death) ~ sex + trt  baseline hazard: bs  assoc:           etavalue (Long1), etavalue (Long2)  algorithm:       sampling  priors:          see help('prior_summary')  sample:          1000 (posterior sample size)  num obs:         304 (Long1), 304 (Long2)  num subjects:    40  num events:      29 (72.5%)  groups:          id (40)  runtime:         1.2 mins  Estimates:                        mean   sd     2.5%   25%    50%    75%    97.5% Assoc|Long1|etavalue  0.806  0.301  0.236  0.593  0.805  1.014  1.397  Assoc|Long2|etavalue -3.142  0.872 -4.946 -3.657 -3.075 -2.532 -1.603   Diagnostics:                      mcse  Rhat  n_eff Assoc|Long1|etavalue 0.009 0.999 1189  Assoc|Long2|etavalue 0.032 1.000  763   For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1)."},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"posterior-predictions","dir":"Articles","previous_headings":"Usage examples","what":"Posterior predictions","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"can also access range post-estimation functions (described stan_jm related help documentation; see example help(posterior_traj) help(posterior_survfit)).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"predicted-individual-specific-longitudinal-trajectory-for-in-sample-individuals","dir":"Articles","previous_headings":"Usage examples > Posterior predictions","what":"Predicted individual-specific longitudinal trajectory for in-sample individuals","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"Predicted individual-specific biomarker values can obtained using either posterior_traj posterior_predict function. posterior_traj preferable, can used obtain biomarker values series evenly spaced time points baseline individual’s event censoring time using default interpolate = TRUE option. Whereas, posterior_predict function provides predicted biomarker values observed time points, time points new data. Predicting biomarker values series evenly spaced time points can convenient can easily used plotting longitudinal trajectory. Moreover, default posterior_traj returns data frame variables corresponding individual ID, time, predicted mean biomarker value, limits 95% credible interval (.e. uncertainty interval predicted mean biomarker value), limits 95% prediction interval (.e. uncertainty interval predicted biomarker data point), level uncertainty intervals can changed via prob argument. Conversely, posterior_predict function returns \\(S\\) \\(N\\) matrix predictions \\(S\\) number posterior draws \\(N\\) number prediction time points (note return type can also obtained posterior_traj specifying argument return_matrix = TRUE). example, let’s plot predicted individual-specific longitudinal trajectories two biomarkers (log serum bilirubin serum albumin) multivariate joint model estimated . three individuals (IDs 6, 7 8) included model estimation. plots log serum bilirubin:  plots serum albumin:  m argument specifies biomarker want predict (relevant multivariate joint model). ids argument optional, specifies subset individuals want predict. plotting method, plot_observed = TRUE specifies want include observed biomarker values plot longitudinal trajectory. wanted extrapolate trajectory forward event censoring time individual, can easily achieved specifying extrapolate = TRUE posterior_traj call. example, plot log serum bilirubin extrapolation:  serum albumin extrapolation:  , included vline = TRUE adds vertical dashed line timing individual’s event censoring time. interpolation extrapolation biomarker trajectory can controlled control argument posterior_traj function; example, specify number time points predict, distance extrapolate, . customize plots , example, using ggplot2 functionality using additional arguments described help(plot.predict.stanjm).","code":"p1 <- posterior_traj(mod3, m = 1, ids = 6:8) pp1 <- plot(p1, plot_observed = TRUE) pp1 p2 <- posterior_traj(mod3, m = 2, ids = 6:8) pp2 <- plot(p2, plot_observed = TRUE) pp2 p3 <- posterior_traj(mod3, m = 1, ids = 6:8, extrapolate = TRUE) pp3 <- plot(p3, plot_observed = TRUE, vline = TRUE) pp3 p4 <- posterior_traj(mod3, m = 2, ids = 6:8, extrapolate = TRUE) pp4 <- plot(p4, plot_observed = TRUE, vline = TRUE) pp4"},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"predicted-individual-specific-survival-curves-for-in-sample-individuals","dir":"Articles","previous_headings":"Usage examples > Posterior predictions","what":"Predicted individual-specific survival curves for in-sample individuals","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"Predicted individual-specific survival probabilities /survival curves can obtained using posterior_survfit function. function default returns data frame individual ID, time, predicted survival probability (posterior mean limits 95% credible interval). uncertainty level credible interval can changed via prob argument. default, individual-specific survival probabilities calculated conditional individual’s last known survival time. predicting survival probabilities individuals used estimation model (.e. -sample individuals, new covariate data provided), individual’s “last known survival time” event censoring time. (Note wanted didn’t want condition individual’s last known survival time, specify condition = FALSE, probably wouldn’t want unless calculating marginal standardised survival probabilities, discussed later). default argument extrapolate = TRUE specifies individual-specific conditional survival probabilities calculated evenly spaced time points individual’s last known survival time maximum follow time observed estimation sample. behaviour extrapolation can controlled via control argument. specify extrapolate = FALSE survival probabilities calculated one time point, specified times argument (otherwise default individual’s last known survival time). example, let plot predicted individual-specific conditional survival curve three individual’s used previous example. predicted survival curve obtained multivariate joint model estimated .  customize plot , example, using ggplot2 functionality using additional arguments described help(plot.survfit.stanjm).","code":"p5 <- posterior_survfit(mod3, ids = 6:8) pp5 <- plot(p5) pp5"},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"combined-plot-of-longitudinal-trajectories-and-survival-curves","dir":"Articles","previous_headings":"Usage examples > Posterior predictions","what":"Combined plot of longitudinal trajectories and survival curves","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"package also provides convenience plotting function, combines plots individual-specific longitudinal trajectories, individual-specific survival function. can demonstrate replotting predictions three individuals previous example:  can see strong relationship underlying values biomarkers mortality. Patient 8 , relative patients 6 7, higher underlying value log serum bilirubin lower underlying value serum albumin end follow far worse predicted probability survival.","code":"plot_stack_jm(yplot = list(pp3, pp4), survplot = pp5)"},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"predicted-individual-specific-longitudinal-trajectory-and-survival-curve-for-out-of-sample-individuals-i-e--dynamic-predictions","dir":"Articles","previous_headings":"Usage examples > Posterior predictions","what":"Predicted individual-specific longitudinal trajectory and survival curve for out-of-sample individuals (i.e. dynamic predictions)","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"Let us take individual training data, case individual subject ID value 8. However, pretend individual member training data rather new individual obtained new biomarker measurements. goal obtain predictions longitudinal trajectory individual, conditional survival curve, given know conditional biomarker measurements currently available. First, let’s extract data subject 8 rename subject ID value appear individual included training dataset: Note longitudinal data event data new individual. require data submodels going generate dynamic predictions require drawing new individual-specific parameters (.e. random effects) individual conditional observed data. means need evaluate likelihood full joint model requires longitudinal event data (note however status indicator death ignored, since assumed individual predicting still alive time wish generate predictions). Now can pass data posterior_traj function way -sample individuals, except now specify newdataLong newdataEvent arguments. also specify last_time argument function knows variable event data specifies individual’s last known survival time (default behaviour use time last biomarker measurement). predictions new individual log serum bilirubin trajectory can obtained using:  serum albumin trajectory:  conditional survival probabilities use similar information, provided posterior_survfit function:  can use plot_stack_jm function, saw previous example, stack plots longitudinal trajectory conditional survival curve:  see predicted longitudinal trajectories conditional survival curve individual, obtained using dynamic predictions approach, similar predictions obtained used individual-specific parameters original model estimation. situations conditioning outcome data. Side note: can even compare estimated individual specific parameters obtained two approaches. example, posterior mean estimated individual-specific parameters individual 8 fitted model: mean draws individual-specific parameters individual 8 dynamic predictions approach:","code":"ndL <- pbcLong[pbcLong$id == 8, , drop = FALSE] ndE <- pbcSurv[pbcSurv$id == 8, , drop = FALSE] ndL$id <- paste0(\"new_patient\") ndE$id <- paste0(\"new_patient\") p6 <- posterior_traj(mod3, m = 1,                       newdataLong = ndL,                       newdataEvent = ndE,                      last_time = \"futimeYears\") Drawing new random effects for 1 individuals. Monitoring progress:   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100% pp6 <- plot(p6, plot_observed = TRUE, vline = TRUE) pp6 p7 <- posterior_traj(mod3, m = 2,                       newdataLong = ndL,                       newdataEvent = ndE,                      last_time = \"futimeYears\") Drawing new random effects for 1 individuals. Monitoring progress:   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100% pp7 <- plot(p7, plot_observed = TRUE, vline = TRUE) pp7 p8 <- posterior_survfit(mod3,                         newdataLong = ndL,                          newdataEvent = ndE,                         last_time = \"futimeYears\") Drawing new random effects for 1 individuals. Monitoring progress:   |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100% pp8 <- plot(p8) pp8 plot_stack_jm(yplot = list(pp6, pp7), survplot = pp8) c(ranef(mod3)[[\"Long1\"]][[\"id\"]][8,],    ranef(mod3)[[\"Long2\"]][[\"id\"]][8,]) $`(Intercept)` [1] -1.636025  $year [1] 0.1106856  $`(Intercept)` [1] 0.4636367  $year [1] -0.04915748 colMeans(attr(p6, \"b_new\")) b[Long1|(Intercept) id:new_patient]        b[Long1|year id:new_patient]                          -1.65217893                          0.10504485  b[Long2|(Intercept) id:new_patient]        b[Long2|year id:new_patient]                           0.45330164                         -0.03059108"},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"predicted-population-level-longitudinal-trajectory","dir":"Articles","previous_headings":"Usage examples > Posterior predictions","what":"Predicted population-level longitudinal trajectory","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"Suppose wanted predict longitudinal trajectory biomarkers, marginalising distribution individual-specific parameters. , can pass new data frame covariate values want use predictions. , demonstrate obtaining predicted trajectory log serum bilirubin, multivariate joint model estimated previously. prediction data require variables year, sex trt, since covariates used longitudinal submodel. predict value log serum bilirubin years 0 10, combination sex trt. also need include id variable prediction data relevant longitudinal submodel. Since want marginalise individual-specific parameters (.e. individual-level random effects) need note two things: First, values id variable must match individual used model estimation. , use following id values: \"male_notrt\", \"female_notrt\", \"male_trt\", \"female_trt\", since individual prediction data represents different combination sex trt. However, given individuals id value just long didn’t match individual used model estimation Second, need specify argument dynamic = FALSE calling posterior_traj. specifies want draw new individual-specific parameters conditional outcome data observed time \\(t\\). Instead, want predictions marginalise distribution individual-specific parameters therefore conditional covariates conditional outcome data new individuals. prediction data: predict marginal longitudinal trajectory log serum bilirubin covariate profile plot can type:  marginalising distribution individual-specific parameters, incorporating variation related -individual differences, therefore prediction interval wide (shown shaded area around marginal longitudinal trajectory). magnitude effects sex trt relatively small compared population-level effect year -individual variation intercept slope. example, point estimates population-level effects sex, trt, year: standard deviations individual-level random effects: shows us point estimates population-level effects sex trt 0.57 -0.10, respectively, whereas standard deviation individual-specific intercept slope parameters 1.24 0.19; hence, differences due population-level effects gender treatment (.e. differences black line across four panels plot) swamped width uncertainty intervals (.e. grey shaded areas).","code":"ndL <- expand.grid(year = seq(0, 10, 1),                    sex = c(\"m\", \"f\"),                     trt = 0:1) ndL$id <- rep(c(\"male_notrt\", \"female_notrt\",                 \"male_trt\", \"female_trt\"), each = 11) ndL <- ndL[, c(4,1,2,3)] str(ndL) 'data.frame':   44 obs. of  4 variables:  $ id  : chr  \"male_notrt\" \"male_notrt\" \"male_notrt\" \"male_notrt\" ...  $ year: num  0 1 2 3 4 5 6 7 8 9 ...  $ sex : Factor w/ 2 levels \"m\",\"f\": 1 1 1 1 1 1 1 1 1 1 ...  $ trt : int  0 0 0 0 0 0 0 0 0 0 ... p1 <- posterior_traj(mod3, m = 1, newdataLong = ndL, dynamic = FALSE) plot(p1) + ggplot2::coord_cartesian(ylim = c(-10,15)) fixef(mod3)$Long1 (Intercept)        sexf         trt        year   0.26316891  0.47545756 -0.06287211  0.22199841 VarCorr(mod3) Groups Name              Std.Dev. Corr                  id     Long1|(Intercept) 1.241233                              Long1|year        0.188221  0.490                       Long2|(Intercept) 0.513955 -0.652 -0.494                Long2|year        0.096057 -0.567 -0.810  0.454"},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"standardised-survival-curves","dir":"Articles","previous_headings":"Usage examples > Posterior predictions","what":"Standardised survival curves","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"example show standardised survival curve can obtained, \\(= 1,...,N^{pred}\\) individuals used generating standardised survival curve individuals used estimating model. obtain survival curve multivariate joint model estimated earlier example (mod3). standardise = TRUE argument posterior_survfit specifies want obtain individual-specific predictions survival curve average . , practical terms, need obtain survival probabilities time \\(t\\) individual average want explicitly specify values \\(t\\) want use (values \\(t\\) used individuals). specify values \\(t\\) use via times argument; predict standardised survival curve time 0 convenience can just specify extrapolate = TRUE (default anyway) mean automatically predict 10 evenly spaced time points 0 maximum event censoring time.","code":"p1 <- posterior_survfit(mod3, standardise = TRUE, times = 0) head(p1) # data frame with standardised survival probabilities year survpred  ci_lb  ci_ub 1 0.0000   1.0000 1.0000 1.0000 2 1.0154   0.8243 0.7659 0.8943 3 2.0307   0.7309 0.6606 0.7805 4 3.0461   0.6789 0.6133 0.7221 5 4.0614   0.6351 0.5746 0.6877 6 5.0768   0.5934 0.5386 0.6456 plot(p1) # plot the standardised survival curve"},{"path":"https://mc-stan.org/rstanarm/articles/jm.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Estimating Joint Models for Longitudinal and Time-to-Event Data with rstanarm","text":"Henderson R, Diggle P, Dobson . Joint modelling longitudinal measurements event time data. Biostatistics 2000;1(4):465-80. Wulfsohn MS, Tsiatis AA. joint model survival longitudinal data measured error. Biometrics 1997;53(1):330-9. Tsiatis AA, Davidian M. Joint modeling longitudinal time--event data: overview. Stat Sinica 2004;14(3):809-34. Gould AL, Boye , Crowther MJ, Ibrahim JG, Quartey G, Micallef S, et al. Joint modeling survival longitudinal non-survival data: current methods issues. Report DIA Bayesian joint modeling working group. Stat Med. 2015;34(14):2181-95. Rizopoulos D. Joint Models Longitudinal Time--Event Data: Applications R CRC Press; 2012. Liu G, Gould AL. Comparison alternative strategies analysis longitudinal trials dropouts. J Biopharm Stat 2002;12(2):207-26. Prentice RL. Covariate Measurement Errors Parameter-Estimation Failure Time Regression-Model. Biometrika 1982;69(2):331-42. Baraldi , Enders CK. introduction modern missing data analyses. J Sch Psychol 2010;48(1):5-37. Philipson PM, Ho WK, Henderson R. Comparative review methods handling drop-longitudinal studies. Stat Med 2008;27(30):6276-98. Pantazis N, Touloumi G. Bivariate modelling longitudinal measurements two human immunodeficiency type 1 disease progression markers presence informative drop-outs. Applied Statistics 2005;54:405-23. Taylor JM, Park Y, Ankerst DP, et al. Real-time individual predictions prostate cancer recurrence using joint models. Biometrics 2013;69(1):206-13. Brilleman SL, Crowther MJ, Moreno-Betancur M, Buros Novik J, Wolfe R. Joint longitudinal time--event models via Stan. : Proceedings StanCon 2018. https://github.com/stan-dev/stancon_talks Stan Development Team. rstanarm: Bayesian applied regression modeling via Stan. R package version 2.14.1. https://mc-stan.org/. 2016. R Core Team. R: language environment statistical computing. Vienna, Austria: R Foundation Statistical Computing; 2015. Crowther MJ, Lambert PC, Abrams KR. Adjusting measurement error baseline prognostic biomarkers included time--event analysis: joint modelling approach. BMC Med Res Methodol 2013;13. Hickey GL, Philipson P, Jorgensen , Kolamunnage-Dona R. Joint modelling time--event multivariate longitudinal outcomes: recent developments issues. BMC Med Res Methodol 2016;16(1):117. Rizopoulos D, Ghosh P. Bayesian semiparametric multivariate joint model multiple longitudinal outcomes time--event. Stat Med. 2011;30(12):1366-80. Laurie DP. Calculation Gauss-Kronrod quadrature rules. Math Comput 1997;66(219):1133-45. Rizopoulos D. Dynamic Predictions Prospective Accuracy Joint Models Longitudinal Time--Event Data. Biometrics 2011;67(3):819-829. Therneau T, Grambsch P. Modeling Survival Data: Extending Cox Model Springer-Verlag, New York; 2000. ISBN: 0-387-98784-3","code":""},{"path":"https://mc-stan.org/rstanarm/articles/lm.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating Regularized Linear Models with rstanarm","text":"vignette explains estimate linear models using stan_lm function rstanarm package. four steps Bayesian analysis Specify joint distribution outcome(s) unknowns, typically takes form marginal prior distribution unknowns multiplied likelihood outcome(s) conditional unknowns. joint distribution proportional posterior distribution unknowns conditional observed data Draw posterior distribution using Markov Chain Monte Carlo (MCMC). Evaluate well model fits data possibly revise model. Draw posterior predictive distribution outcome(s) given interesting values predictors order visualize manipulation predictor affects (function ) outcome(s). Steps 3 4 covered depth vignette entitled “Use rstanarm Package”. vignette focuses Step 1 likelihood product independent normal distributions. goal rstanarm package make Bayesian estimation common regression models routine. goal can partially accomplished providing interfaces similar popular formula-based interfaces frequentist estimators regression models. fully accomplishing goal sometimes entails utilizing priors applied researchers unaware prefer. priors intended work well data user might pass interface generated according assumptions likelihood function. important distinguish priors easy applied researchers specify priors easy applied researchers conceptualize. prior described emphasizes former outline derivation applied researchers may feel comfortable utilizing .","code":""},{"path":"https://mc-stan.org/rstanarm/articles/lm.html","id":"likelihood","dir":"Articles","previous_headings":"","what":"Likelihood","title":"Estimating Regularized Linear Models with rstanarm","text":"likelihood one observation linear model can written conditionally normal PDF \\[\\frac{1}{\\sigma_{\\epsilon} \\sqrt{2 \\pi}}   e^{-\\frac{1}{2} \\left(\\frac{y - \\mu}{\\sigma_{\\epsilon}}\\right)^2},\\] \\(\\mu = \\alpha + \\mathbf{x}^\\top \\boldsymbol{\\beta}\\) linear predictor \\(\\sigma_{\\epsilon}\\) standard deviation error predicting outcome, \\(y\\). likelihood entire sample product \\(N\\) individual likelihood contributions. well-known likelihood sample maximized sum--squared residuals minimized, occurs \\[ \\widehat{\\boldsymbol{\\beta}} = \\left(\\mathbf{X}^\\top \\mathbf{X}\\right)^{-1}                                    \\mathbf{X}^\\top \\mathbf{y}, \\] \\[ \\widehat{\\alpha} = \\overline{y} - \\overline{\\mathbf{x}}^\\top                                      \\widehat{\\boldsymbol{\\beta}}, \\] \\[ \\widehat{\\sigma}_{\\epsilon}^2 =   \\frac{\\left(\\mathbf{y} - \\widehat{\\alpha} - \\mathbf{X} \\widehat{                                               \\boldsymbol{\\beta}}\\right)^\\top         \\left(\\mathbf{y} - \\widehat{\\alpha} - \\mathbf{X} \\widehat{                                               \\boldsymbol{\\beta}}\\right)}{N},\\] \\(\\overline{\\mathbf{x}}\\) vector contains sample means \\(K\\) predictors, \\(\\mathbf{X}\\) \\(N \\times K\\) matrix centered predictors, \\(\\mathbf{y}\\) \\(N\\)-vector outcomes \\(\\overline{y}\\) sample mean outcome.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/lm.html","id":"qr-decomposition","dir":"Articles","previous_headings":"","what":"QR Decomposition","title":"Estimating Regularized Linear Models with rstanarm","text":"lm function R actually performs QR decomposition design matrix, \\(\\mathbf{X} = \\mathbf{Q}\\mathbf{R}\\), \\(\\mathbf{Q}^\\top \\mathbf{Q} = \\mathbf{}\\) \\(\\mathbf{R}\\) upper triangular. Thus, OLS solution coefficients can written \\(\\left(\\mathbf{X}^\\top \\mathbf{X}\\right)^{-1} \\mathbf{X}^\\top \\mathbf{y} =   \\mathbf{R}^{-1} \\mathbf{Q}^\\top \\mathbf{y}\\). lm function utilizes QR decomposition numeric stability reasons, QR decomposition also useful thinking priors Bayesian version linear model. addition, writing likelihood terms \\(\\mathbf{Q}\\) allows evaluated efficient manner Stan.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/lm.html","id":"priors","dir":"Articles","previous_headings":"","what":"Priors","title":"Estimating Regularized Linear Models with rstanarm","text":"key innovation stan_lm function rstanarm package prior parameters QR-reparameterized model. understand prior, think equations characterize maximum likelihood solutions observing data \\(\\mathbf{X}\\) especially \\(\\mathbf{y}\\). prior distribution \\(\\boldsymbol{\\theta} = \\mathbf{Q}^\\top \\mathbf{y}\\) ? can write \\(k\\)-th element \\(\\theta_k = \\rho_k \\sigma_Y \\sqrt{N - 1}\\) \\(\\rho_k\\) correlation \\(k\\)th column \\(\\mathbf{Q}\\) outcome, \\(\\sigma_Y\\) standard deviation outcome, \\(\\frac{1}{\\sqrt{N-1}}\\) standard deviation \\(k\\) column \\(\\mathbf{Q}\\). let \\(\\boldsymbol{\\rho} = \\sqrt{R^2}\\mathbf{u}\\) \\(\\mathbf{u}\\) unit vector uniformly distributed surface hypersphere. Consequently, \\(R^2 = \\boldsymbol{\\rho}^\\top \\boldsymbol{\\rho}\\) familiar coefficient determination linear model. uninformative prior \\(R^2\\) standard uniform, special case Beta distribution shape parameters equal \\(1\\). non-uniform prior \\(R^2\\) somewhat analogous ridge regression, popular data mining produces better --sample predictions least squares penalizes \\(\\boldsymbol{\\beta}^\\top \\boldsymbol{\\beta}\\), usually standardizing predictors. informative prior \\(R^2\\) effectively penalizes \\(\\boldsymbol{\\rho}\\top \\boldsymbol{\\rho}\\), encourages \\(\\boldsymbol{\\beta} = \\mathbf{R}^{-1} \\boldsymbol{\\theta}\\) closer origin. Lewandowski, Kurowicka, Joe (2009) derives distribution correlation matrix depends single shape parameter \\(\\eta > 0\\), implies variance one variable given remaining \\(K\\) variables \\(\\mathrm{Beta}\\left(\\eta,\\frac{K}{2}\\right)\\). Thus, \\(R^2\\) distributed \\(\\mathrm{Beta}\\left(\\frac{K}{2},\\eta\\right)\\) prior information location \\(R^2\\) can used choose value hyperparameter \\(\\eta\\). R2(location, ) function rstanarm package supports four ways choosing \\(\\eta\\): = \"mode\" location prior mode \\(\\left(0,1\\right)\\) interval. default since mode \\(\\mathrm{Beta}\\left(\\frac{K}{2},\\eta\\right)\\) distribution \\(\\frac{\\frac{K}{2} - 1}{\\frac{K}{2} + \\eta - 2}\\) mode exists \\(K > 2\\). \\(K \\leq 2\\), user must specify something else . = \"mean\" location prior mean \\(\\left(0,1\\right)\\) interval, mean \\(\\mathrm{Beta}\\left(\\frac{K}{2},\\eta\\right)\\) distribution \\(\\frac{\\frac{K}{2}}{\\frac{K}{2} + \\eta}\\). = \"median\" location prior median \\(\\left(0,1\\right)\\) interval. median \\(\\mathrm{Beta}\\left(\\frac{K}{2},\\eta\\right)\\) distribution available closed form \\(K > 2\\) approximately equal \\(\\frac{\\frac{K}{2} - \\frac{1}{3}}{\\frac{K}{2} + \\eta - \\frac{2}{3}}\\). Regardless whether \\(K > 2\\), R2 function can numerically solve value \\(\\eta\\) consistent given prior median utilizing quantile function. = \"log\" location (negative) prior value \\(\\mathbb{E} \\ln R^2 = \\psi\\left(\\frac{K}{2}\\right)-   \\psi\\left(\\frac{K}{2}+\\eta\\right)\\), \\(\\psi\\left(\\cdot\\right)\\) digamma function. , given prior value left-hand side easy numerically solve corresponding value \\(\\eta\\). default value location argument R2 function. informative prior \\(R^2\\), must chosen user light research project. However, specifying location = 0.5 often safe, case \\(\\eta = \\frac{K}{2}\\) regardless whether \"mode\", \"mean\", \"median\". addition, possible specify NULL, case standard uniform \\(R^2\\) utilized. set \\(\\sigma_y = \\omega s_y\\) \\(s_y\\) sample standard deviation outcome \\(\\omega > 0\\) unknown scale parameter estimated. prior \\(\\omega\\) contravene Bayes’ theorem situation Jeffreys prior, \\(f\\left(\\omega\\right) \\propto \\frac{1}{\\omega}\\), proportional Jeffreys prior unknown \\(\\sigma_y\\), \\(f\\left(\\sigma_y\\right) \\propto \\frac{1}{\\sigma_y} = \\frac{1}{\\omega \\widehat{\\sigma}_y} \\propto \\frac{1}{\\omega}\\). parameterization prior makes easy Stan work continuous outcome variable, matter units measurement . seem need prior \\(\\sigma_{\\epsilon}\\), prior beliefs \\(\\sigma_{\\epsilon} = \\omega s_y \\sqrt{1 - R^2}\\) already implied prior beliefs \\(\\omega\\) \\(R^2\\). leaves prior \\(\\alpha = \\overline{y} - \\overline{\\mathbf{x}}^\\top \\mathbf{R}^{-1} \\boldsymbol{\\theta}\\). default choice improper uniform prior, normal prior can also specified one mean zero standard deviation \\(\\frac{\\sigma_y}{\\sqrt{N}}\\).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/lm.html","id":"posterior","dir":"Articles","previous_headings":"","what":"Posterior","title":"Estimating Regularized Linear Models with rstanarm","text":"previous sections imply posterior distribution \\(\\omega\\), \\(\\alpha\\), \\(\\mathbf{u}\\), \\(R^2\\). parameters interest can recovered generated quantities: \\(\\sigma_y = \\omega s_y\\) \\(\\sigma_{\\epsilon} = \\sigma_y \\sqrt{1 - R^2}\\) \\(\\boldsymbol{\\beta} = \\mathbf{R}^{-1} \\mathbf{u} \\sigma_y \\sqrt{R^2 \\left(N-1\\right)}\\) implementation actually utilizes improper uniform prior \\(\\ln \\omega\\). Consequently, \\(\\ln \\omega = 0\\), marginal standard deviation outcome implied model sample standard deviation outcome. \\(\\ln \\omega > 0\\), marginal standard deviation outcome implied model exceeds sample standard deviation, model overfits data. \\(\\ln \\omega < 0\\), marginal standard deviation outcome implied model less sample standard deviation, model underfits data data-generating process nonlinear. Given regularizing nature prior \\(R^2\\), minor underfit considered ideal goal obtain good --sample predictions. model badly underfits overfits data, may want reconsider model.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/lm.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Estimating Regularized Linear Models with rstanarm","text":"utilize example HSAUR3 package Brian S. Everitt Torsten Hothorn, used 2014 book Handbook Statistical Analyses Using R (3rd Edition) (Chapman & Hall / CRC). book frequentist nature show obtain corresponding Bayesian results. model section 5.3.1 analyzes experiment clouds seeded different amounts silver iodide see increased rainfall. effect vary according covariates, (except time) interacted treatment variable. people probably skeptical cloud hacking explain much variation rainfall thus prior mode \\(R^2\\) probably fairly small. frequentist estimator model can replicated executing Note looked estimated \\(R^2\\) \\(\\sigma\\) ordinary least squares model. can estimate Bayesian version model prepending stan_ lm call, specifying prior mode \\(R^2\\), optionally specifying many cores computer may utilize: case, “Bayesian point estimates”, represented posterior medians, appear quite different ordinary least squares estimates. However, log-fit_ratio (.e. \\(\\ln \\omega\\)) quite small, indicating model slightly overfits data prior derived utilized. Thus, safe conclude ordinary least squares estimator considerably overfits data since \\(24\\) observations estimate \\(12\\) parameters prior information parameters. Also, obvious estimated average treatment effect since treatment variable, seeding, interacted four correlated predictors. However, easy estimate visualize average treatment effect (ATE) using rstanarm’s posterior_predict function.  can seen, treatment effect estimated precisely almost likely negative positive.","code":"data(\"clouds\", package = \"HSAUR3\") ols <- lm(rainfall ~ seeding * (sne + cloudcover + prewetness + echomotion) +             time, data = clouds) round(coef(ols), 3) (Intercept)                      seedingyes                           -0.346                          15.683                              sne                      cloudcover                            0.420                           0.388                       prewetness            echomotionstationary                            4.108                           3.153                             time                  seedingyes:sne                           -0.045                          -3.197            seedingyes:cloudcover           seedingyes:prewetness                           -0.486                          -2.557  seedingyes:echomotionstationary                           -0.562 library(rstanarm) post <-   stan_lm(     rainfall ~ seeding * (sne + cloudcover + prewetness + echomotion) + time,     data = clouds,     prior = R2(location = 0.2),     seed = 12345   ) post stan_lm  family:       gaussian [identity]  formula:      rainfall ~ seeding * (sne + cloudcover + prewetness + echomotion) +         time  observations: 24  predictors:   11 ------                                 Median MAD_SD (Intercept)                      2.4    2.3   seedingyes                       6.8    3.8   sne                              0.2    0.7   cloudcover                       0.2    0.2   prewetness                       1.7    2.8   echomotionstationary             1.4    1.5   time                             0.0    0.0   seedingyes:sne                  -1.4    1.0   seedingyes:cloudcover           -0.2    0.2   seedingyes:prewetness           -1.1    3.5   seedingyes:echomotionstationary -0.2    2.0    Auxiliary parameter(s):               Median MAD_SD R2            0.3    0.1    log-fit_ratio 0.0    0.1    sigma         2.6    0.4     ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg clouds_cf <- clouds clouds_cf$seeding[] <- \"yes\" y1_rep <- posterior_predict(post, newdata = clouds_cf) clouds_cf$seeding[] <- \"no\" y0_rep <- posterior_predict(post, newdata = clouds_cf) qplot(x = c(y1_rep - y0_rep), geom = \"histogram\", xlab = \"Estimated ATE\")"},{"path":"https://mc-stan.org/rstanarm/articles/lm.html","id":"alternative-approach","dir":"Articles","previous_headings":"","what":"Alternative Approach","title":"Estimating Regularized Linear Models with rstanarm","text":"prior derived works well many situations quite simple use since requires user specify prior location \\(R^2\\). Nevertheless, implications prior somewhat difficult conceptualize. Thus, perhaps worthwhile compare another estimator linear model simply puts independent Cauchy priors regression coefficients. simpler approach can executed calling stan_glm function family = gaussian() specifying priors: can compare two approaches using approximation Leave-One-(LOO) cross-validation, implemented loo function loo package. results indicate first approach expected produce better --sample predictions Warning messages least important. Many estimated shape parameters Generalized Pareto distribution \\(0.5\\) model Cauchy priors, indicates estimates going converge slowly true --sample deviance measures. Thus, \\(24\\) observations, considered reliable. complicated prior derived stronger — evidenced fact effective number parameters half simpler approach \\(12\\) maximum likelihood estimator — \\(24\\) Pareto shape estimates “danger zone”. might want reexamine observations  posterior sensitive , overall, results seem tolerable. general, expect joint prior derived work better many predictors relative number observations. Placing independent, heavy-tailed priors coefficients neither reflects beliefs researcher conveys enough information stabilize computations.","code":"simple <-   stan_glm(     rainfall ~ seeding * (sne + cloudcover + prewetness + echomotion) + time,     data = clouds,     family = gaussian(),     prior = cauchy(),     prior_intercept = cauchy(),     seed = 12345   ) (loo_post <- loo(post)) Computed from 4000 by 24 log-likelihood matrix.           Estimate   SE elpd_loo    -60.3  5.3 p_loo         5.9  2.4 looic       120.5 10.6 ------ MCSE of elpd_loo is 0.1. MCSE and ESS estimates assume independent draws (r_eff=1).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details. loo_compare(loo_post, loo(simple)) Warning: Found 3 observation(s) with a pareto_k > 0.7. We recommend calling 'loo' again with argument 'k_threshold = 0.7' in order to calculate the ELPD without the assumption that these observations are negligible. This will refit the model 3 times to compute the ELPDs for the problematic observations directly. elpd_diff se_diff post    0.0       0.0    simple -0.9       3.0 plot(loo_post, label_points = TRUE)"},{"path":"https://mc-stan.org/rstanarm/articles/lm.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Estimating Regularized Linear Models with rstanarm","text":"vignette discussed prior distribution utilized stan_lm function, likelihood similar syntax lm function R adds ability expression prior beliefs location \\(R^2\\), familiar proportion variance outcome variable attributable predictors linear model. Since \\(R^2\\) well-understood bounded scalar, easy specify prior information , whereas Bayesian approaches require researcher specify joint prior distribution regression coefficients (intercept error variance). However, researchers little inclination specify prior distributions thoughtfully take short-cut specifying one prior distribution taken apply regression coefficients independent (intercept error variance). short-cut available stan_glm function described detail rstanarm vignettes Generalized Linear Models (GLMs), can found navigating one level. optimistic prior \\(R^2\\) greatly help accomplishing goal rstanarm making Bayesian estimation regression models routine. approach used specify prior ANOVA models (see stan_aov) proportional-odds models ordinal outcomes (see stan_polr). Finally, stan_biglm function can used design matrix large qr function process. stan_biglm function inputs output biglm function biglm package, utilizes incremental QR decomposition require entire dataset loaded memory simultaneously. However, biglm function needs called particular way order work stan_biglm. particular, means columns design matrix, sample mean outcome, sample standard deviation outcome need passed stan_biglm function, well flag indicating whether model really include intercept. Also, number columns design matrix currently exceed number rows. Although stan_biglm run fairly quickly without much memory, resulting object fairly plain stanfit object rather enhanced stanreg object like produced stan_lm. Many enhanced capabilities stanreg object depend able access full design matrix, posterior predictions, posterior checks, etc. output stan_biglm require custom R code.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/lm.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Estimating Regularized Linear Models with rstanarm","text":"Lewandowski, D., Kurowicka D., Joe, H. (2009). Generating random correlation matrices based vines extended onion method. Journal Multivariate Analysis. 100(9), 1989–2001.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The Data","title":"MRP with rstanarm","text":"Three data sets simulated function simulate_mrp_data(), defined source code R markdown document (printed appendix). first, sample, contains \\(n\\) observations individuals form sample (.e., \\(n\\) rows). individual age (recorded membership within specific age bracket), ethnicity, income level (recorded membership within specific bracket), gender. Participants randomly sampled state. MRP often used dichotomous fixed choice questions (e.g., McCain’s share two party vote (Ghitza Gelman 2013); support George W Bush, (Park, Gelman, Bafumi 2004); support death penalty (Shirley Gelman 2015)), use binary variable outcome vignette. However, MRP can also used two categories outcome continuous. simple toy example, describe proportion population choose adopt cat dog, given opportunity. simulate data using function included appendix document. simulate_mrp_data() function simulates sample much larger population. returns list including sample, population poststratification matrix true population preference cats. variables describing individual (age, ethnicity, income level gender) used match sample population interest. need form post-stratification table, contains number people possible combination post-stratification variables. 4 variables 2 (male), 7 (age), 3 (ethnicity) 3 (income) levels, 2x7x3x3 different levels. Participants also selected state (50), increasing number possible levels \\(6300\\). make inference population, also need proportion individuals post stratification cell population level. use information update estimate outcome variable sample representative population. particularly helpful belief sample bias (e.g., greater proportion females responded males), bias impacts outcome variable (e.g., maybe women likely pick cat men). possible combination factors, post-stratification table shows proportion/number population cell (rather proportion/number sample cell). read poststrat data simulated data list. One benefits using simulated data set example actual population level probability cat preference known post-stratification cell. real world data analysis, don’t luxury, use later case study check predictions model. Details regarding simulation data available appendix.","code":"mrp_sim <- simulate_mrp_data(n=1200) str(mrp_sim) List of 3  $ sample   :'data.frame':  1200 obs. of  7 variables:   ..$ cat_pref: num [1:1200] 1 1 1 1 0 0 1 1 1 1 ...   ..$ male    : num [1:1200] 0 0 0 0 0 0 0 1 0 0 ...   ..$ age     : num [1:1200] 5 6 3 6 1 5 7 6 5 7 ...   ..$ eth     : num [1:1200] 3 1 2 1 1 1 3 3 2 3 ...   ..$ income  : num [1:1200] 3 1 2 1 3 1 2 1 1 1 ...   ..$ state   : num [1:1200] 19 45 21 47 12 38 2 20 11 34 ...   ..$ id      : num [1:1200] 1 2 3 4 5 6 7 8 9 10 ...  $ poststrat:'data.frame':  6300 obs. of  6 variables:   ..$ male  : num [1:6300] 0 0 0 0 0 0 0 0 0 0 ...   ..$ eth   : num [1:6300] 1 1 1 1 1 1 1 1 1 1 ...   ..$ age   : num [1:6300] 1 1 1 1 1 1 1 1 1 1 ...   ..$ income: num [1:6300] 1 1 1 1 1 1 1 1 1 1 ...   ..$ state : num [1:6300] 1 2 3 4 5 6 7 8 9 10 ...   ..$ N     : num [1:6300] 103741 104862 164704 133049 167578 ...  $ true_popn:'data.frame':  6300 obs. of  6 variables:   ..$ male    : num [1:6300] 0 0 0 0 0 0 0 0 0 0 ...   ..$ eth     : num [1:6300] 1 1 1 1 1 1 1 1 1 1 ...   ..$ age     : num [1:6300] 1 1 1 1 1 1 1 1 1 1 ...   ..$ income  : num [1:6300] 1 1 1 1 1 1 1 1 1 1 ...   ..$ state   : num [1:6300] 1 2 3 4 5 6 7 8 9 10 ...   ..$ cat_pref: num [1:6300] 0.5 0.426 0.269 0.574 0.332 ... sample <- mrp_sim[[\"sample\"]] rbind(head(sample), tail(sample)) cat_pref male age eth income state   id 1           1    0   5   3      3    19    1 2           1    0   6   1      1    45    2 3           1    0   3   2      2    21    3 4           1    0   6   1      1    47    4 5           0    0   1   1      3    12    5 6           0    0   5   1      1    38    6 1195        0    0   6   3      2    21 1195 1196        1    0   3   3      1    46 1196 1197        1    0   5   1      2    48 1197 1198        0    1   1   1      1    14 1198 1199        0    0   1   3      1    12 1199 1200        0    1   3   2      2    12 1200 poststrat <- mrp_sim[[\"poststrat\"]] rbind(head(poststrat), tail(poststrat)) male eth age income state      N 1       0   1   1      1     1 103741 2       0   1   1      1     2 104862 3       0   1   1      1     3 164704 4       0   1   1      1     4 133049 5       0   1   1      1     5 167578 6       0   1   1      1     6 109814 6295    1   3   7      3    45  10061 6296    1   3   7      3    46  13055 6297    1   3   7      3    47  12578 6298    1   3   7      3    48  13754 6299    1   3   7      3    49   9937 6300    1   3   7      3    50   9646 true_popn <- mrp_sim[[\"true_popn\"]] rbind(head(true_popn), tail(true_popn)) male eth age income state  cat_pref 1       0   1   1      1     1 0.5000000 2       0   1   1      1     2 0.4255575 3       0   1   1      1     3 0.2689414 4       0   1   1      1     4 0.5744425 5       0   1   1      1     5 0.3318122 6       0   1   1      1     6 0.6224593 6295    1   3   7      3    45 0.7502601 6296    1   3   7      3    46 0.8581489 6297    1   3   7      3    47 0.9241418 6298    1   3   7      3    48 0.6456563 6299    1   3   7      3    49 0.4255575 6300    1   3   7      3    50 0.9308616"},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"exploring-graphically","dir":"Articles","previous_headings":"","what":"Exploring Graphically","title":"MRP with rstanarm","text":"begin MRP analysis, first explore data set basic visualizations.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"comparing-sample-to-population","dir":"Articles","previous_headings":"Exploring Graphically","what":"Comparing sample to population","title":"MRP with rstanarm","text":"aim analysis obtain population estimation cat preference given sample \\(4626\\). can see following plot difference proportions sample population. Horizontal panels represent variable. Bars represent proportion sample (solid) population (dashed) category (represented colour x-axis). ease viewing, ordered states terms proportion sample state observed. continue formatting choice thoughout vignette.","code":"sample$state <- factor(sample$state, levels=1:50) sample$state <- with(sample, factor(state, levels=order(table(state)))) true_popn$state <- factor(true_popn$state,levels = levels(sample$state)) poststrat$state <- factor(poststrat$state,levels = levels(sample$state))"},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"effect-of-the-post-stratification-variable-on-preference-for-cats","dir":"Articles","previous_headings":"","what":"Effect of the post-stratification variable on preference for cats","title":"MRP with rstanarm","text":"Secondly; consider evidence different proportions across different levels post-stratification variable; consider post-stratification variables. break proportion individuals prefer cat (y-axis) different levels (x-axis) post-stratification variable (horizontal panels). can see figure appears differences cat preference different levels post-stratification variables. Given previous figure, suggested sample different population share different levels theses variables, suggest using sample estimate cat preference may give accurate estimates cat preference population.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"interaction-effect","dir":"Articles","previous_headings":"Effect of the post-stratification variable on preference for cats","what":"Interaction effect","title":"MRP with rstanarm","text":"Thirdly, demonstrate visually interaction age gender compare case interaction. simulated interaction effect age (x-axis) gender (color), right panel, contrasted interaction effect (left panel). panels demonstrate difference genders outcome variable (y-axis), second panel shows difference changing variable x-axis.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"design-effect","dir":"Articles","previous_headings":"Effect of the post-stratification variable on preference for cats","what":"Design effect","title":"MRP with rstanarm","text":"Lastly look difference cat preference states, form basis multi-level component analysis. Participants randomly selected particular states. Plotting state (x-axis) overall proportion participants prefer cats (y-axis) demonstrates state differences. downward slope ordered x-axis proportion cat preference ease viewing. also include second plot horizontal line represent overall preference cats total population, according sample.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"mrp-with-rstanarm","dir":"Articles","previous_headings":"","what":"MRP with rstanarm","title":"MRP with rstanarm","text":"visual inspection, appears different levels post-stratification variable different preferences cats. survey also appears sampling bias; indicating groups /sampled relative population. net effect make good population level estimates cat preference straight sample. aim infer preference cats population using post-stratification variables account systematic differences sample population. Using rstanarm, becomes simple procedure. first step use multi-level logistic regression model predict preference cats sample given variables use post-stratify. Note actually rows post-stratification matrix observed units, cells poststrat matrix don’t observe. can use multi-level model partially pool information across different levels within variable assist . model described , use fixed intercept gender, hierarchically modeled varying intercepts factors. Let \\(\\theta_{j}\\) denote preference cats \\(j\\)th poststratification cell. non-hierarchical part model can written \\[\\theta_j= logit^{-1}(X_{j}\\beta),\\] \\(X\\) contains indicator male female interaction term age. Adding varying intercepts variables model becomes \\[ \\theta_j = logit^{-1}( X_{j}\\beta + \\alpha_{\\rm state[j]}^{\\rm state} + \\alpha_{\\rm age[j]}^{\\rm age} + \\alpha_{\\rm eth[j]}^{\\rm eth} + \\alpha_{\\rm inc[j]}^{\\rm inc} ) \\] $$ \\[\\begin{align*} \\alpha_{\\rm state[j]}^{\\rm state} & \\sim N(0,\\sigma^{\\rm state}) \\\\ \\alpha_{\\rm age[j]}^{\\rm age} & \\sim N(0,\\sigma^{\\rm age})\\\\ \\alpha_{\\rm eth[j]}^{\\rm eth} & \\sim N(0,\\sigma^{\\rm eth})\\\\ \\alpha_{\\rm inc[j]}^{\\rm inc} &\\sim N(0,\\sigma^{\\rm inc}) \\\\ \\end{align*}\\] $$ \\(\\sigma^{\\rm state}\\), \\(\\sigma^{\\rm age}\\), \\(\\sigma^{\\rm eth}\\), \\(\\sigma^{\\rm inc}\\) estimated data (case using rstanarm’s default priors), beneficial means share information levels variable can prevent levels less data sensitive observed values. also helps levels don’t observe use information levels observe. benefits type model, see Gelman et al. (2005), see Ghitza Gelman (2013) Si et al. (2017) complicated extensions involve deep interactions structured prior distributions. model specified using stan_glmer() function rstanarm, uses formula syntax glmer() function lme4 package: first pass check whether model performing well, note warnings divergences, failure converge tree depth. errors occur, information alleviate provided .","code":"fit <- stan_glmer(   cat_pref ~ factor(male) + factor(male) * factor(age) +      (1 | state) + (1 | age) + (1 | eth) + (1 | income),   family = binomial(link = \"logit\"),   data = sample ) print(fit) stan_glmer  family:       binomial [logit]  formula:      cat_pref ~ factor(male) + factor(male) * factor(age) + (1 | state) +         (1 | age) + (1 | eth) + (1 | income)  observations: 1200 ------                            Median MAD_SD (Intercept)                 0.8    0.9   factor(male)1              -0.3    0.6   factor(age)2               -0.2    1.0   factor(age)3               -0.5    0.8   factor(age)4                0.6    0.8   factor(age)5                0.3    0.8   factor(age)6                1.1    0.9   factor(age)7                0.8    0.8   factor(male)1:factor(age)2  0.3    1.7   factor(male)1:factor(age)3 -0.8    0.8   factor(male)1:factor(age)4 -1.3    0.7   factor(male)1:factor(age)5 -1.0    0.7   factor(male)1:factor(age)6 -0.6    0.7   factor(male)1:factor(age)7 -1.1    0.6    Error terms:  Groups Name        Std.Dev.  state  (Intercept) 1.13      age    (Intercept) 1.21      eth    (Intercept) 0.91      income (Intercept) 0.73     Num. levels: state 50, age 7, eth 3, income 3   ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg"},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"population-estimate","dir":"Articles","previous_headings":"MRP with rstanarm","what":"Population Estimate","title":"MRP with rstanarm","text":"get summary baseline log odds cat preference first element factor (.e., male = 0, age = 1) state, plus estimates variability intercept state, ethnicity, age income. interesting, currently achieved model predicts cat preference given number factor-type predictors sample. like estimate cat preference population accounting differences sample population. use posterior_linpred() function obtain posterior estimates cat preference given proportion people population level factors included model. can compare estimate made just used sample: can also add last figure graphically represent difference sample population estimate.  simulated data, can look directly preference cats simulated consider good estimate . also add figure. MRP estimate barely , sample estimate 10 percentage points. indicates using MRP helps make estimates population sample accurate.","code":"posterior_prob <- posterior_linpred(fit, transform = TRUE, newdata = poststrat) poststrat_prob <- posterior_prob %*% poststrat$N / sum(poststrat$N) model_popn_pref <- c(mean = mean(poststrat_prob), sd = sd(poststrat_prob)) round(model_popn_pref, 3) mean    sd  0.568 0.024 sample_popn_pref <- mean(sample$cat_pref) round(sample_popn_pref, 3) [1] 0.681 compare2 <- compare2 +   geom_hline(yintercept = model_popn_pref[1], colour = '#2ca25f', size = 1) +   geom_text(aes(x = 5.2, y = model_popn_pref[1] + .025), label = \"MRP\", colour = '#2ca25f') bayesplot_grid(compare, compare2,                 grid_args = list(nrow = 1, widths = c(8, 1))) true_popn_pref <- sum(true_popn$cat_pref * poststrat$N) / sum(poststrat$N) round(true_popn_pref, 3) [1] 0.561"},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"estimates-for-states","dir":"Articles","previous_headings":"MRP with rstanarm","what":"Estimates for states","title":"MRP with rstanarm","text":"One nice benefits using MRP make inference population can change population interest. previous paragraph inferred preference cats whole population. can also infer preference cats single state. following code post-stratify state turn. Note can reuse predictive model previous step update different population demographics. particularly useful complicated cases large data sets model takes time fit. , first use proportion population combination post-stratification groups estimate proportion people preferred cats population, case population interest state. similar findings considered population whole. estimates cat preference (percent) using sample MRP based estimates much closer actual percentage, especially sample size population relatively small. easier see graphically, continue add additional layers previous figure. add model estimates,represented triangles, true population cat preference, represented transparent circles.","code":"state_df <- data.frame(   State = 1:50,   model_state_sd = rep(-1, 50),   model_state_pref = rep(-1, 50),   sample_state_pref = rep(-1, 50),   true_state_pref = rep(-1, 50),   N = rep(-1, 50) )  for(i in 1:length(levels(as.factor(poststrat$state)))) {   poststrat_state <- poststrat[poststrat$state == i, ]     posterior_prob_state <- posterior_linpred(     fit,     transform = TRUE,     draws = 1000,     newdata = as.data.frame(poststrat_state)   )   poststrat_prob_state <- (posterior_prob_state %*% poststrat_state$N) / sum(poststrat_state$N)   #This is the estimate for popn in state:   state_df$model_state_pref[i] <- round(mean(poststrat_prob_state), 4)   state_df$model_state_sd[i] <- round(sd(poststrat_prob_state), 4)   #This is the estimate for sample   state_df$sample_state_pref[i] <- round(mean(sample$cat_pref[sample$state == i]), 4)   #And what is the actual popn?   state_df$true_state_pref[i] <-     round(sum(true_popn$cat_pref[true_popn$state == i] * poststrat_state$N) /             sum(poststrat_state$N), digits = 4)   state_df$N[i] <- length(sample$cat_pref[sample$state == i]) }  state_df[c(1,3:6)] State model_state_pref sample_state_pref true_state_pref  N 1      1           0.5068            0.5000          0.5966  2 2      2           0.6573            0.8571          0.5315  7 3      3           0.4462            0.5385          0.3803 13 4      4           0.7616            0.8846          0.6590 26 5      5           0.4232            0.5200          0.4439 50 6      6           0.6853            0.8947          0.6982 19 7      7           0.7119            0.8250          0.6386 40 8      8           0.6987            0.9167          0.7850 12 9      9           0.7203            0.8571          0.6788 14 10    10           0.6153            0.7727          0.5966 44 11    11           0.7272            0.8824          0.7850 17 12    12           0.3860            0.4737          0.4012 57 13    13           0.7191            1.0000          0.7690  5 14    14           0.6128            0.6818          0.5966 22 15    15           0.2034            0.2000          0.1181 15 16    16           0.3838            0.4706          0.3599 34 17    17           0.2181            0.1538          0.2169 13 18    18           0.3444            0.0000          0.2169  2 19    19           0.4733            0.6000          0.4656  5 20    20           0.7992            0.8974          0.7850 39 21    21           0.3825            0.5250          0.3599 40 22    22           0.7661            0.9167          0.8755 12 23    23           0.6042            0.7333          0.5751 30 24    24           0.6389            1.0000          0.7690  2 25    25           0.7445            0.8261          0.8002 23 26    26           0.7605            0.8704          0.7524 54 27    27           0.2621            0.3500          0.2657 20 28    28           0.5807            0.6667          0.4656  3 29    29           0.5356            0.6757          0.5095 37 30    30           0.5152            0.5946          0.5315 37 31    31           0.6151            0.7143          0.7350  7 32    32           0.4203            0.5000          0.3399 42 33    33           0.6095            0.7353          0.6178 68 34    34           0.5805            0.7200          0.4656 25 35    35           0.5904            0.7200          0.6590 25 36    36           0.5317            0.6250          0.5751  8 37    37           0.6940            0.8571          0.8855  7 38    38           0.2926            0.3750          0.3205 48 39    39           0.7196            0.8824          0.8533 17 40    40           0.3245            0.3684          0.2657 19 41    41           0.7710            0.9286          0.6982 14 42    42           0.6794            0.8235          0.5751 34 43    43           0.5300            0.6667          0.5315  6 44    44           0.6567            0.8000          0.4439 15 45    45           0.6612            0.8077          0.5315 26 46    46           0.6541            0.7750          0.6788 40 47    47           0.7236            0.8621          0.8002 29 48    48           0.5144            0.6545          0.4224 55 49    49           0.2334            0.2500          0.2487  8 50    50           0.8228            1.0000          0.8146 13 state_df$State <- factor(state_df$State, levels = levels(sample$state)) round(100 * c(   mean = mean(abs(state_df$sample_state_pref-state_df$true_state_pref), na.rm = TRUE),   max = max(abs(state_df$sample_state_pref-state_df$true_state_pref), na.rm = TRUE) )) mean  max    14   36 round(100 * c(   mean = mean(abs(state_df$model_state_pref-state_df$true_state_pref)),   max = max(abs(state_df$model_state_pref-state_df$true_state_pref)) )) mean  max     6   21"},{"path":[]},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"alternate-methods-of-modelling","dir":"Articles","previous_headings":"Other formats","what":"Alternate methods of modelling","title":"MRP with rstanarm","text":"Previously used binary outcome variable. alternative form model aggregate data poststrat cell level model number successes (endorsement cat preference case) total number people cell. need create two n x 1 outcome variables, N_cat_pref (number cell prefer cats) N (number poststrat cell). can use two outcome variables model data using binomial distribution. Like , can use posterior_linpred() function obtain estimate preference cats population. , get answer fit model using binary outcome. two ways equivalent, can use whichever form convenient data hand. details two forms binomial models available .","code":"# not evaluated to avoid dependency on tidyverse sample_alt <- sample %>%   group_by(male, age, income, state, eth) %>%   summarise(N_cat_pref = sum(cat_pref), N = n()) %>%   ungroup() fit2 <- stan_glmer(   cbind(N_cat_pref, N - N_cat_pref) ~ factor(male) + factor(male) * factor(age) +      (1 | state) + (1 | age) + (1 | eth) + (1 | income),   family = binomial(\"logit\"),   data = sample_alt,   refresh = 0 ) print(fit2) stan_glmer  family:       binomial [logit]  formula:      cbind(N_cat_pref, N - N_cat_pref) ~ factor(male) + factor(male) *         factor(age) + (1 | state) + (1 | age) + (1 | eth) + (1 |         income)  observations: 940 ------                            Median MAD_SD (Intercept)                 0.8    1.0   factor(male)1              -0.4    0.6   factor(age)2               -0.3    1.1   factor(age)3               -0.5    0.9   factor(age)4                0.6    0.9   factor(age)5                0.3    0.8   factor(age)6                1.0    0.9   factor(age)7                0.8    0.9   factor(male)1:factor(age)2  0.3    1.8   factor(male)1:factor(age)3 -0.8    0.8   factor(male)1:factor(age)4 -1.3    0.7   factor(male)1:factor(age)5 -1.0    0.7   factor(male)1:factor(age)6 -0.5    0.7   factor(male)1:factor(age)7 -1.1    0.6    Error terms:  Groups Name        Std.Dev.  state  (Intercept) 1.11      age    (Intercept) 1.22      eth    (Intercept) 0.92      income (Intercept) 0.73     Num. levels: state 50, age 7, eth 3, income 3   ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg posterior_prob_alt <- posterior_linpred(fit2, transform = TRUE, newdata = poststrat) poststrat_prob_alt <- posterior_prob_alt %*% poststrat$N / sum(poststrat$N) model_popn_pref_alt <- c(mean = mean(poststrat_prob_alt), sd = sd(poststrat_prob_alt)) round(model_popn_pref_alt, 3) mean    sd  0.568 0.024"},{"path":[]},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"examples-of-other-formulas","dir":"Articles","previous_headings":"Appendix","what":"Examples of other formulas","title":"MRP with rstanarm","text":"formulas fitting -called “mixed-effects” models rstanarm lme4 package. table examples can found Table 2 vignette lme4 package, available .","code":""},{"path":"https://mc-stan.org/rstanarm/articles/mrp.html","id":"code-to-simulate-the-data","dir":"Articles","previous_headings":"Appendix","what":"Code to simulate the data","title":"MRP with rstanarm","text":"source code simulate_mrp_function(), based code provided Aki Vehtari.","code":"print(simulate_mrp_data) function (n)  {     J <- c(2, 3, 7, 3, 50)     poststrat <- as.data.frame(array(NA, c(prod(J), length(J) +          1)))     colnames(poststrat) <- c(\"male\", \"eth\", \"age\", \"income\",          \"state\", \"N\")     count <- 0     for (i1 in 1:J[1]) {         for (i2 in 1:J[2]) {             for (i3 in 1:J[3]) {                 for (i4 in 1:J[4]) {                   for (i5 in 1:J[5]) {                     count <- count + 1                     poststrat[count, 1:5] <- c(i1 - 1, i2, i3,                        i4, i5)                   }                 }             }         }     }     p_male <- c(0.52, 0.48)     p_eth <- c(0.5, 0.2, 0.3)     p_age <- c(0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.1)     p_income <- c(0.5, 0.35, 0.15)     p_state_tmp <- runif(50, 10, 20)     p_state <- p_state_tmp/sum(p_state_tmp)     poststrat$N <- 0     for (j in 1:prod(J)) {         poststrat$N[j] <- round(2.5e+08 * p_male[poststrat[j,              1] + 1] * p_eth[poststrat[j, 2]] * p_age[poststrat[j,              3]] * p_income[poststrat[j, 4]] * p_state[poststrat[j,              5]])     }     p_response_baseline <- 0.01     p_response_male <- c(2, 0.8)/2.8     p_response_eth <- c(1, 1.2, 2.5)/4.7     p_response_age <- c(1, 0.4, 1, 1.5, 3, 5, 7)/18.9     p_response_inc <- c(1, 0.9, 0.8)/2.7     p_response_state <- rbeta(50, 1, 1)     p_response_state <- p_response_state/sum(p_response_state)     p_response <- rep(NA, prod(J))     for (j in 1:prod(J)) {         p_response[j] <- p_response_baseline * p_response_male[poststrat[j,              1] + 1] * p_response_eth[poststrat[j, 2]] * p_response_age[poststrat[j,              3]] * p_response_inc[poststrat[j, 4]] * p_response_state[poststrat[j,              5]]     }     people <- sample(prod(J), n, replace = TRUE, prob = poststrat$N *          p_response)     n_cell <- rep(NA, prod(J))     for (j in 1:prod(J)) {         n_cell[j] <- sum(people == j)     }     coef_male <- c(0, -0.3)     coef_eth <- c(0, 0.6, 0.9)     coef_age <- c(0, -0.2, -0.3, 0.4, 0.5, 0.7, 0.8, 0.9)     coef_income <- c(0, -0.2, 0.6)     coef_state <- c(0, round(rnorm(49, 0, 1), 1))     coef_age_male <- t(cbind(c(0, 0.1, 0.23, 0.3, 0.43, 0.5,          0.6), c(0, -0.1, -0.23, -0.5, -0.43, -0.5, -0.6)))     true_popn <- data.frame(poststrat[, 1:5], cat_pref = rep(NA,          prod(J)))     for (j in 1:prod(J)) {         true_popn$cat_pref[j] <- plogis(coef_male[poststrat[j,              1] + 1] + coef_eth[poststrat[j, 2]] + coef_age[poststrat[j,              3]] + coef_income[poststrat[j, 4]] + coef_state[poststrat[j,              5]] + coef_age_male[poststrat[j, 1] + 1, poststrat[j,              3]])     }     y <- rbinom(n, 1, true_popn$cat_pref[people])     male <- poststrat[people, 1]     eth <- poststrat[people, 2]     age <- poststrat[people, 3]     income <- poststrat[people, 4]     state <- poststrat[people, 5]     sample <- data.frame(cat_pref = y, male, age, eth, income,          state, id = 1:length(people))     for (i in 1:ncol(poststrat)) {         poststrat[, i] <- as.numeric(poststrat[, i])     }     for (i in 1:ncol(true_popn)) {         true_popn[, i] <- as.numeric(true_popn[, i])     }     for (i in 1:ncol(sample)) {         sample[, i] <- as.numeric(sample[, i])     }     list(sample = sample, poststrat = poststrat, true_popn = true_popn) }"},{"path":[]},{"path":"https://mc-stan.org/rstanarm/articles/polr.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Estimating Ordinal Regression Models with rstanarm","text":"vignette explains estimate models ordinal outcomes using stan_polr function rstanarm package. four steps Bayesian analysis Specify joint distribution outcome(s) unknowns, typically takes form marginal prior distribution unknowns multiplied likelihood outcome(s) conditional unknowns. joint distribution proportional posterior distribution unknowns conditional observed data Draw posterior distribution using Markov Chain Monte Carlo (MCMC). Evaluate well model fits data possibly revise model. Draw posterior predictive distribution outcome(s) given interesting values predictors order visualize manipulation predictor affects (function ) outcome(s). Steps 3 4 covered depth vignette entitled “Use rstanarm Package”. vignette focuses Step 1. One strengths MCMC Stan — opposed Gibbs sampler — reparameterizations essentially costless, allows user specify priors parameters either intuitive, numerically stable, computationally efficient without changing posterior distribution parameters enter likelihood. Advantageous parameterizations already built Stan programs used rstanarm package, just matter using vignettes explain priors work context reparameterizations.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/polr.html","id":"likelihood","dir":"Articles","previous_headings":"","what":"Likelihood","title":"Estimating Ordinal Regression Models with rstanarm","text":"Ordinal outcomes fall one \\(J\\) categories. One way motivate ordinal model introduce latent variable, \\(y^\\ast\\), related observed outcomes via observation mechanism: \\[y=\\begin{cases} 1 & \\mbox{}y^{\\ast}<\\zeta_{1}\\\\ 2 & \\mbox{}\\zeta_{1}\\leq y^{\\ast}<\\zeta_{2}\\\\ \\vdots\\\\ J & \\mbox{}\\zeta_{J-1}\\leq y^{\\ast} \\end{cases},\\] \\(\\boldsymbol{\\zeta}\\) vector cutpoints length \\(J-1\\). \\(y^\\ast\\) modeled linear function \\(K\\) predictors \\[y^\\ast = \\mu + \\epsilon = \\mathbf{x}^\\top \\boldsymbol{\\beta} + \\epsilon,\\] \\(\\epsilon\\) mean zero unit scale can specified drawn one several distributions. Note “intercept” model since data distinguish intercept cutpoints. However, \\(J = 2\\), \\(\\zeta_1\\) can referred either cutpoint intercept. Bayesian can treat \\(y^\\ast\\) another unknown parameter, although computational efficiency Stan code essentially integrates \\(y^\\ast\\) posterior distribution, leaving posterior distribution \\(\\boldsymbol{\\beta}\\) \\(\\boldsymbol{\\zeta}\\). Nevertheless, useful motivate model theoretically \\(y^\\ast\\) just unknown parameter distribution truncated relevant element(s) \\(\\boldsymbol{\\zeta}\\).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/polr.html","id":"priors","dir":"Articles","previous_headings":"","what":"Priors","title":"Estimating Ordinal Regression Models with rstanarm","text":"\\(y^\\ast\\) observed simply linear regression model , description priors vignette entitled “Estimating Linear Models rstanarm Package” apply directly. Another way say thing conditional realization \\(y^\\ast\\), linear regression model description priors vignette apply (read continuing subsection). stan_lm function essentially specifies prior \\(\\boldsymbol{\\theta} = \\mathbf{R}^{-1} \\boldsymbol{\\beta}\\), \\(\\mathbf{R}\\) upper triangular matrix QR decomposition design matrix, \\(\\mathbf{X} = \\mathbf{Q} \\mathbf{R}\\). Furthermore, stan_lm, \\(\\sigma_{\\epsilon} = \\sigma_y \\sqrt{1 - R^2}\\) \\(R^2\\) proportion variance outcome attributable coefficients linear model. main difference context model ordinal outcome scale \\(y^\\ast\\) identified data. Thus, ordinal model specifies \\(\\sigma_{\\epsilon} = 1\\), implies \\(\\sigma_{y^\\ast} = 1 / \\sqrt{1 - R^2}\\) intermediate parameter rather primitive parameter. somewhat difficult specify prior value \\(R^2\\) ordinal model \\(R^2\\) refers proportion variance \\(y^\\ast\\) attributable predictors linear model. general, \\(R^2\\) tends lower ordinal model linear model continuous outcome observed. difference ordinal model global intercept rather vector \\(J-1\\) cutpoints. implied prior cutpoints used rstanarm package somewhat novel. user instead specifies Dirichlet prior \\(\\Pr\\left(y=j \\, \\left.\\right| \\, \\overline{\\mathbf{x}} \\right)\\), say prior probability outcome falling \\(J\\) categories given predictors sample means. Dirichlet prior simplex random variable, whose elements non-negative sum \\(1\\). Dirichlet PDF can written \\[f\\left(\\boldsymbol{\\pi}|\\boldsymbol{\\alpha}\\right) \\propto \\prod_{j=1}^J{\\pi_j^{\\alpha_j - 1}}, \\] \\(\\boldsymbol{\\pi}\\) simplex vector \\(\\pi_j = \\Pr\\left(y=j \\, \\left.\\right| \\, \\overline{\\mathbf{x}} \\right)\\). Dirichlet prior one easiest specify -called “concentration” hyperparameters \\(\\boldsymbol{\\alpha}\\) can interpreted prior counts, .e., prior observations J categories (although need integers). \\(\\alpha_j = 1\\) every \\(j\\) (default used rstanarm) Dirichlet prior jointly uniform space simplexes. corresponds prior count one observation falling \\(J\\) ordinal categories predictors sample means conveys reasonable weak prior information category probability zero. , \\(j\\), \\(\\alpha_j = \\alpha > 1\\) prior mode \\(J\\) categories equiprobable, prior probability \\(1/J\\) outcome falling \\(J\\) categories. larger value \\(\\alpha\\) sharply peaked distribution mode. \\(j\\)-th cutpoint \\(\\zeta_j\\) given \\[\\zeta_j = F_{y^\\ast}^{-1}\\left(\\sum_{=1}^j{\\pi_i}\\right),\\] \\(F_{y^\\ast}^{-1}\\) inverse CDF function, depends assumed distribution \\(y^\\ast\\). Common choices include normal logistic distributions. scale parameter distribution \\(\\sigma_{y^\\ast} = 1/\\sqrt{1 - R^2}\\). short, making \\(\\zeta_j\\) function \\(\\boldsymbol{\\pi}\\), allows us specify Dirichlet prior \\(\\boldsymbol{\\pi}\\), simpler specifying prior \\(\\boldsymbol{\\zeta}\\) directly.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/polr.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Estimating Ordinal Regression Models with rstanarm","text":"section, start ordinal model tobacco consumption function age alcohol consumption. Frequentist estimates can obtained using polr function MASS package: obtain Bayesian estimates, prepend stan_ specify priors: point estimates, represented posterior medians, qualitatively similar maximum-likelihood estimates somewhat shrunk toward zero due regularizing prior coefficients. Since cutpoints actually known, appropriate model take account, stan_polr currently support . Next, utilize example MASS package low birthweight binary outcome interest. First, recode variables: usually good idea rescale variables constants numbers single double digits. start estimating linear model birthweight kilograms, flipping sign positive coefficients associated lower birthweights. Next, estimate “ordinal” model incidence low birthweight, defined birth weight less \\(2.5\\) kilograms. Even though outcome binary, binary variable special case ordinal variable \\(J=2\\) categories acceptable stan_polr. can think bwt something proportional \\(y^\\ast\\) pretend observed, forcing us estimate ordinal model.  prior seems worked well case none points plot \\(0.5\\), indicated posterior sensitive observations. compare estimated coefficients, signs similar magnitudes, exception “Intercept”. ordinal model outcome \\(J=2\\) categories, “Intercept” actually \\(\\zeta_1\\), conventional call “Intercept” agrees stan_glm family = binomial(link = 'probit'). Recall \\(\\sigma_{\\epsilon} = 1\\) ordinal model, rescale coefficients linear model dividing posterior median \\(\\sigma\\), resulting coefficients even closer ordinal model. illustrates fundamental similarity linear model continuous observed outcome linear model latent \\(y^\\ast\\) generates ordinal observed outcome. main difference outcome continuous observed, can estimate scale errors meaningfully. outcome ordinal, can fix scale latent errors \\(1\\) arbitrarily. Finally, \\(J = 2\\), stan_polr function allows specify non-NULL values shape rate arguments, implies “scobit” likelihood probability success given \\(F\\left(y^\\ast \\right)^\\alpha\\), \\(F\\left(\\right)\\) logistic CDF \\(\\alpha > 0\\) skewing parameter gamma prior given shape rate. \\(\\alpha \\neq 1\\), relationship \\(y^\\ast\\) probability success asymmetric. principle, seems appropriate estimate \\(\\alpha\\) practice, lot data needed estimate \\(\\alpha\\) adequate precision. previous example, specify shape = 2 rate = 2 reflect prior beliefs \\(\\alpha\\) expected \\(1\\) variance \\(\\frac{1}{2}\\), loo calculation yields many Pareto shape parameters excessively large. However, \\(189\\) observations, model may fruitful.","code":"library(MASS) print(polr(tobgp ~ agegp + alcgp, data = esoph), digits = 1) Call: polr(formula = tobgp ~ agegp + alcgp, data = esoph)  Coefficients: agegp.L agegp.Q agegp.C agegp^4 agegp^5 alcgp.L alcgp.Q alcgp.C    -0.37   -0.38   -0.24    0.04   -0.04   -0.19   -0.02    0.03   Intercepts: 0-9g/day|10-19    10-19|20-29      20-29|30+            -1.0            0.2            1.3   Residual Deviance: 241.8195  AIC: 263.8195 library(rstanarm) post0 <- stan_polr(tobgp ~ agegp + alcgp, data = esoph,                     prior = R2(0.25), prior_counts = dirichlet(1),                    seed = 12345) print(post0, digits = 1) stan_polr  family:       ordered [logistic]  formula:      tobgp ~ agegp + alcgp  observations: 88 ------         Median MAD_SD agegp.L -0.2    0.4   agegp.Q -0.2    0.4   agegp.C -0.1    0.3   agegp^4  0.0    0.3   agegp^5  0.0    0.3   alcgp.L -0.1    0.3   alcgp.Q  0.0    0.3   alcgp.C  0.0    0.3    Cutpoints:                Median MAD_SD 0-9g/day|10-19 -1.0    0.2   10-19|20-29     0.2    0.2   20-29|30+       1.3    0.2    ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg data(\"birthwt\", package = \"MASS\") birthwt$race <- factor(birthwt$race, levels = 1:3,                         labels = c(\"white\", \"black\", \"other\")) birthwt$bwt <- birthwt$bwt / 1000 # convert from grams to kilograms birthwt$low <- factor(birthwt$low, levels = 0:1, labels = c(\"no\", \"yes\")) post1 <- stan_lm(-bwt ~ smoke + age + race + ptl + ht + ftv,                  data = birthwt, prior = R2(0.5),                   seed = 12345) print(post1) stan_lm  family:       gaussian [identity]  formula:      -bwt ~ smoke + age + race + ptl + ht + ftv  observations: 189  predictors:   8 ------             Median MAD_SD (Intercept) -3.3    0.2   smoke        0.4    0.1   age          0.0    0.0   raceblack    0.4    0.2   raceother    0.4    0.1   ptl          0.2    0.1   ht           0.4    0.2   ftv          0.0    0.0    Auxiliary parameter(s):               Median MAD_SD R2            0.2    0.0    log-fit_ratio 0.0    0.1    sigma         0.7    0.0     ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg post2 <- stan_polr(low ~ smoke + age + race + ptl + ht + ftv, data = birthwt,                    prior = R2(0.5), prior_counts = dirichlet(c(1,1)),                     method = \"probit\", seed = 12345) plot(loo(post2)) round(cbind(Linear = coef(post1), Ordinal = coef(post2),              Rescaled = coef(post1) / sigma(post1)), 3) Linear Ordinal Rescaled (Intercept) -3.254  -0.535   -4.812 smoke        0.361   0.514    0.534 age         -0.003  -0.025   -0.005 raceblack    0.394   0.514    0.582 raceother    0.400   0.530    0.592 ptl          0.154   0.400    0.228 ht           0.368   0.696    0.544 ftv         -0.004  -0.005   -0.006"},{"path":"https://mc-stan.org/rstanarm/articles/polr.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Estimating Ordinal Regression Models with rstanarm","text":"posterior distribution ordinal model requires priors coefficients cutpoints. priors used stan_polr function unconventional work well variety problems. prior coefficients essentially used stan_lm function omits scale parameter standard deviation latent \\(y^\\ast\\) identified data. cutpoints conditionally deterministic given simplex vector probability falling \\(J\\) ordinal categories given predictors sample means. Thus, Dirichlet prior — relatively easy specify good default jointly uniform — simplex completes posterior distribution. approach provides alternative stan_glm family = binomial() even outcome variable two categories. stan_glm function options prior coefficients prior intercept (can interpreted first cutpoint \\(J = 2\\)). However, may difficult obtain efficient sampling priors.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"vignette illustrates effects posterior inference pooling data (.k.sharing strength) across units repeated binary trial data. provides R code fit check predictive models three situations: () complete pooling, assumes unit , (b) pooling, assumes units unrelated, (c) partial pooling, similarity among units estimated. note explains working examples () fit models using rstanarm plot results, (ii) estimate event probabilities, (iii) evaluate posterior predictive densities evaluate model predictions held-data, (iv) rank units chance success, (v) perform multiple comparisons several settings, (vi) replicate new data posterior \\(p\\)-values, (vii) perform graphical posterior predictive checks. content vignette based Bob Carpenter’s Stan tutorial Hierarchical Partial Pooling Repeated Binary Trials, show fit models carry predictions model checking comparison using rstanarm. text taken original, additions subtractions make content useful rstanarm users. Stan code original tutorial also entirely removed, rstanarm fit models Stan without user write underlying Stan programs. Stan code original document good reference anyone interested models estimated “--hood”, though parameterizations used internally rstanarm differ somewhat original.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"repeated-binary-trials","dir":"Articles","previous_headings":"","what":"Repeated Binary Trials","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Suppose \\(N\\) units \\(n \\1{:}N\\), observe \\(y_n\\) successes \\(K_n\\) trials. example, data may consist rat tumor development, \\(y_n\\) rats developing tumors \\(K_n\\) total rats experimental control group \\(n \\1{:}N\\) (Tarone 1982) surgical mortality, \\(y_n\\) surgical patients dying \\(K_n\\) surgeries hospitals \\(n \\1{:}N\\) (Spiegelhalter et al. 1996) baseball batting ability, \\(y_n\\) hits \\(K_n\\) bats baseball players \\(n \\1{:}N\\) (Efron Morris 1975; Carpenter 2009) machine learning system accuracy, \\(y_n\\) correct classifications \\(K_n\\) examples systems \\(n \\1{:}N\\) (ML conference proceedings; Kaggle competitions) vignette use small baseball data set Efron Morris (1975), also provide rat control data Tarone (1982), surgical mortality data Spiegelhalter et al. (1996) extended baseball data set Carpenter (2009).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"baseball-hits-efron-and-morris-1975","dir":"Articles","previous_headings":"Repeated Binary Trials","what":"Baseball Hits (Efron and Morris 1975)","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"running example, use data Table 1 (Efron Morris 1975), included rstanarm name bball1970 (downloaded 24 Dec 2015 ). drawn 1970 Major League Baseball season (leagues). data separates outcome initial 45 -bats rest season. running code, N number units (players). unit n, K[n] number initial trials (-bats), y[n] number initial successes (hits), K_new[n] remaining number trials (remaining -bats), y_new[n] number successes remaining trials (remaining hits). remaining data can used evaluate predictive performance models conditioned observed data. , “train” first 45 bats see well various models predicting rest season.","code":"library(rstanarm) data(bball1970) bball <- bball1970 print(bball) Player AB Hits RemainingAB RemainingHits 1    Clemente 45   18         367           127 2    Robinson 45   17         426           127 3      Howard 45   16         521           144 4   Johnstone 45   15         275            61 5       Berry 45   14         418           114 6     Spencer 45   14         466           126 7   Kessinger 45   13         586           155 8    Alvarado 45   12         138            29 9       Santo 45   11         510           137 10    Swaboda 45   11         200            46 11 Petrocelli 45   10         538           142 12  Rodriguez 45   10         186            42 13      Scott 45   10         435           132 14      Unser 45   10         277            73 15   Williams 45   10         591           195 16 Campaneris 45    9         558           159 17     Munson 45    8         408           129 18      Alvis 45    7          70            14 # A few quantities we'll use throughout N <- nrow(bball) K <- bball$AB y <- bball$Hits K_new <- bball$RemainingAB y_new <- bball$RemainingHits"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"pooling","dir":"Articles","previous_headings":"","what":"Pooling","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"complete pooling, unit assumed chance success. pooling, unit assumed completely unrelated chance success. partial pooling, unit assumed different chance success, data observed units informs estimates unit. Partial pooling typically accomplished hierarchical models. Hierarchical models directly model population units. population model perspective, pooling corresponds infinite population variance, whereas complete pooling corresponds zero population variance. following sections, three types pooling models fit baseball data.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"fitting-the-models","dir":"Articles","previous_headings":"","what":"Fitting the Models","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"First ’ll create useful objects use throughout rest vignette. One function batting_avg, just formats number include three decimal places right zero printing, customary batting averages.","code":"batting_avg <- function(x) print(format(round(x, digits = 3), nsmall = 3), quote = FALSE) player_avgs <- y / K # player avgs through 45 AB tot_avg <- sum(y) / sum(K) # overall avg through 45 AB  cat(\"Player averages through 45 at-bats:\\n\") batting_avg(player_avgs) cat(\"Overall average through 45 at-bats:\\n\") batting_avg(tot_avg) Player averages through 45 at-bats:  [1] 0.400 0.378 0.356 0.333 0.311 0.311 0.289 0.267 0.244 0.244 0.222 0.222 [13] 0.222 0.222 0.222 0.200 0.178 0.156 Overall average through 45 at-bats: [1] 0.265"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"complete-pooling","dir":"Articles","previous_headings":"Fitting the Models","what":"Complete Pooling","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"complete pooling model assumes single parameter \\(\\theta\\) representing chance success units (case players). Assuming player’s -bats independent Bernoulli trials, probability distribution player’s number hits \\(y_n\\) modeled \\[ p(y_n \\, | \\, \\theta) \\ = \\ \\mathsf{Binomial}(y_n \\, | \\, K_n, \\theta). \\] viewed function \\(\\theta\\) fixed \\(y_n\\), called likelihood function. Assuming player independent leads complete data likelihood \\[ p(y \\, | \\, \\theta) = \\prod_{n=1}^N \\mathsf{Binomial}(y_n \\, | \\, K_n, \\theta). \\] Using family=binomial(\"logit\"), stan_glm function rstanarm parameterize model terms log-odds \\(\\alpha\\), defined logit transform \\[ \\alpha = \\mathrm{logit}(\\theta) = \\log \\, \\frac{\\theta}{1 - \\theta}. \\] example, \\(\\theta = 0.25\\) corresponds odds \\(.25\\) \\(.75\\) (equivalently, \\(1\\) \\(3\\)), log-odds \\(\\log .25 / .75 = -1.1\\). model therefore \\[ p(y_n \\, | \\, K_n, \\alpha) \\ = \\ \\mathsf{Binomial}(y_n \\, | \\, K_n, \\ \\mathrm{logit}^{-1}(\\alpha)) \\] inverse logit function logistic sigmoid logistic regression gets name inverse logit function also standard logistic Cumulative Distribution Function (CDF), \\[ \\mathrm{logit}^{-1}(\\alpha) = \\frac{1}{1 + \\exp(-\\alpha)} = \\theta. \\] construction, \\(\\alpha \\(-\\infty, \\infty)\\), \\(\\mathrm{logit}^{-1}(\\alpha) \\(0, 1)\\); sigmoid converts arbitrary log odds back probability scale. use normal distribution mean \\(-1\\) standard deviation \\(1\\) prior log-odds \\(\\alpha\\). weakly informative prior places 95% prior probability interval \\((-3, 1)\\), inverse-logit transforms interval \\((0.05, 0.73)\\). prior median \\(-1\\) corresponds \\(0.27\\) chance success. fact, even narrower prior actually motivated substantial baseball knowledge. figure shows prior \\(\\alpha\\) well prior implies probability \\(\\theta\\).  fit model call stan_glm formula cbind(Hits, AB - Hits) ~ 1. left-hand side formula specifies binomial outcome providing number successes (hits) failures (-bats) player, right-hand side indicates want intercept-model. summary function compute sorts summary statistics fitted model, ’ll create small function compute just posterior summary statistics ’ll want models estimate. summary_stats function, defined , take matrix posterior draws input, apply inverse-logit transformation (convert log-odds probabilities) compute median 80% interval. data, players rest season, posterior approaches delta function around maximum likelihood estimate posterior interval around central posterior intervals shrink. Nevertheless, even know player’s chance success exactly, large amount uncertainty running \\(K\\) binary trials chance success; using binomial model fundamentally bounds prediction accuracy. Although model good baseline comparison, good reason believe large amount prior data (players many 10,000 trials) unlikely baseball players chance success.","code":"SEED <- 101 wi_prior <- normal(-1, 1)  # weakly informative prior on log-odds fit_pool <- stan_glm(cbind(Hits, AB - Hits) ~ 1, data = bball, family = binomial(\"logit\"),                      prior_intercept = wi_prior, seed = SEED) invlogit <- plogis  # function(x) 1/(1 + exp(-x)) summary_stats <- function(posterior) {   x <- invlogit(posterior)  # log-odds -> probabilities   t(apply(x, 2, quantile, probs = c(0.1, 0.5, 0.9)))  }  pool <- summary_stats(as.matrix(fit_pool))  # as.matrix extracts the posterior draws pool <- matrix(pool,  # replicate to give each player the same estimates                nrow(bball), ncol(pool), byrow = TRUE,                 dimnames = list(bball$Player, c(\"10%\", \"50%\", \"90%\"))) batting_avg(pool) 10%   50%   90%   Clemente   0.245 0.265 0.285 Robinson   0.245 0.265 0.285 Howard     0.245 0.265 0.285 Johnstone  0.245 0.265 0.285 Berry      0.245 0.265 0.285 Spencer    0.245 0.265 0.285 Kessinger  0.245 0.265 0.285 Alvarado   0.245 0.265 0.285 Santo      0.245 0.265 0.285 Swaboda    0.245 0.265 0.285 Petrocelli 0.245 0.265 0.285 Rodriguez  0.245 0.265 0.285 Scott      0.245 0.265 0.285 Unser      0.245 0.265 0.285 Williams   0.245 0.265 0.285 Campaneris 0.245 0.265 0.285 Munson     0.245 0.265 0.285 Alvis      0.245 0.265 0.285"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"no-pooling","dir":"Articles","previous_headings":"Fitting the Models","what":"No Pooling","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"model pooling involves separate chance--success parameter \\(\\theta_n \\[0,1]\\) player \\(n\\), \\(\\theta_n\\) assumed independent. rstanarm parameterize model terms log-odds, \\(\\alpha_n = \\mathrm{logit}(\\theta_n)\\), likelihood uses log-odds success \\(\\alpha_n\\) unit \\(n\\) modeling number successes \\(y_n\\) \\[ p(y_n \\, | \\, \\alpha_n) = \\mathsf{Binomial}(y_n \\, | \\, K_n, \\mathrm{logit}^{-1}(\\alpha_n)). \\] Assuming \\(y_n\\) independent (conditional \\(\\theta\\)), leads total data likelihood \\[ p(y \\, | \\, \\alpha) = \\prod_{n=1}^N \\mathsf{Binomial}(y_n \\, | \\, K_n, \\mathrm{logit}^{-1}(\\alpha_n)). \\] fit model need tweak model formula used full pooling model drop intercept instead include predictor factor variable Player. equivalent estimating separate intercept log-odds scale player. ’ll also use prior (rather prior_intercept) argument since Player considered predictor rather intercept R’s perspective. Using weakly informative prior now means \\(\\alpha_n\\) gets \\(\\mathsf{Normal}(-1, 1)\\) prior, independent others. 80% interval much wider estimated interval population complete pooling model; expected—45 data units parameter opposed 810 complete pooling case. units different numbers trials, intervals also vary based size. estimated chance success goes toward 0.5, 80% intervals gets wider. expected chance success parameters, variance maximized \\(\\theta = 0.5\\). Based existing knowledge baseball, -pooling model almost certainly overestimating high abilities underestimating lower abilities (Ted Williams, 30 years prior year data collected, last player 40% observed success rate season, whereas 20% less low rare defensive specialists).","code":"fit_nopool <- update(fit_pool, formula = . ~ 0 + Player, prior = wi_prior) nopool <- summary_stats(as.matrix(fit_nopool)) rownames(nopool) <- as.character(bball$Player) batting_avg(nopool) parameters   10%   50%   90%     Clemente   0.300 0.386 0.473   Robinson   0.279 0.366 0.458   Howard     0.263 0.344 0.435   Johnstone  0.244 0.326 0.414   Berry      0.227 0.305 0.393   Spencer    0.226 0.306 0.389   Kessinger  0.209 0.284 0.370   Alvarado   0.190 0.266 0.352   Santo      0.172 0.244 0.330   Swaboda    0.172 0.243 0.328   Petrocelli 0.154 0.223 0.305   Rodriguez  0.157 0.226 0.305   Scott      0.156 0.224 0.306   Unser      0.156 0.225 0.303   Williams   0.156 0.225 0.305   Campaneris 0.138 0.204 0.282   Munson     0.124 0.185 0.258   Alvis      0.108 0.166 0.241"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"partial-pooling","dir":"Articles","previous_headings":"Fitting the Models","what":"Partial Pooling","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Complete pooling provides estimated abilities narrowly distributed units removes chance modeling population variation. Estimating chance success separately without pooling provides estimated abilities broadly distributed units hence variable. Clearly amount pooling two extremes called . much? hierarchical model treats players belonging population players. properties population estimated along player abilities, implicitly controlling amount pooling applied. variable (estimate ) population, less pooling applied. Mathematically, hierarchical model places prior abilities parameters estimated. model can estimated using stan_glmer function. stan_glmer (like glmer) estimates varying intercepts Player estimating single global intercept \\(\\alpha_0\\) individual deviations intercept player \\(\\delta_n = \\alpha_n - \\alpha_0\\), get posterior distribution \\(\\alpha_n\\) need shift posterior draws corresponding draw intercept. can easily using sweep function. estimates less extreme -pooling case, expect due partial pooling. also clear wide posteriors \\(\\theta_n\\) considerable uncertainty estimates chance--success unit--unit (player--player) basis.","code":"fit_partialpool <-    stan_glmer(cbind(Hits, AB - Hits) ~ (1 | Player), data = bball,               family = binomial(\"logit\"),              prior_intercept = wi_prior, seed = SEED) # shift each player's estimate by intercept (and then drop intercept) shift_draws <- function(draws) {   sweep(draws[, -1], MARGIN = 1, STATS = draws[, 1], FUN = \"+\") } alphas <- shift_draws(as.matrix(fit_partialpool)) partialpool <- summary_stats(alphas) partialpool <- partialpool[-nrow(partialpool),] rownames(partialpool) <- as.character(bball$Player) batting_avg(partialpool) parameters   10%   50%   90%     Clemente   0.249 0.283 0.349   Robinson   0.245 0.281 0.341   Howard     0.243 0.277 0.331   Johnstone  0.240 0.274 0.323   Berry      0.238 0.271 0.317   Spencer    0.235 0.271 0.316   Kessinger  0.233 0.268 0.310   Alvarado   0.229 0.265 0.303   Santo      0.222 0.262 0.299   Swaboda    0.223 0.262 0.298   Petrocelli 0.216 0.258 0.294   Rodriguez  0.218 0.259 0.293   Scott      0.217 0.259 0.294   Unser      0.217 0.258 0.293   Williams   0.215 0.258 0.296   Campaneris 0.211 0.255 0.290   Munson     0.205 0.253 0.287   Alvis      0.198 0.250 0.285"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"observed-vs--estimated-chance-of-success","dir":"Articles","previous_headings":"Fitting the Models","what":"Observed vs. Estimated Chance of Success","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Figure 5.4 (Gelman et al. 2013) plots observed number successes \\(y_n\\) first \\(K_n\\) trials versus median 80% intervals estimated chance--success parameters \\(\\theta_n\\) posterior. following R code reproduces similar plot data.  horizontal axis observed rate success, broken player (overplotting players number successes—number trials data). dots posterior medians bars extending cover central 80% posterior interval. Players observed rates indistinguishable, differences estimates due MCMC error. horizontal red line intercept equal overall success rate, overall success rate also posterior mode (.e., maximum likelihood estimate) complete pooling model. diagonal blue line intercept 0 slope 1. Estimates falling line make maximum likelihood estimates -pooling model. Overall, plot makes amount pooling toward prior evident.","code":"library(ggplot2) models <- c(\"complete pooling\", \"no pooling\", \"partial pooling\") estimates <- rbind(pool, nopool, partialpool) colnames(estimates) <- c(\"lb\", \"median\", \"ub\") plotdata <- data.frame(estimates,                         observed = rep(player_avgs, times = length(models)),                         model = rep(models, each = N),                         row.names = NULL)  ggplot(plotdata, aes(x = observed, y = median, ymin = lb, ymax = ub)) +   geom_hline(yintercept = tot_avg, color = \"lightpink\", size = 0.75) +   geom_abline(intercept = 0, slope = 1, color = \"skyblue\") +    geom_linerange(color = \"gray60\", size = 0.75) +    geom_point(size = 2.5, shape = 21, fill = \"gray30\", color = \"white\", stroke = 0.2) +    facet_grid(. ~ model) +   coord_fixed() +   scale_x_continuous(breaks = c(0.2, 0.3, 0.4)) +   labs(x = \"Observed Hits / AB\", y = \"Predicted chance of hit\") +   ggtitle(\"Posterior Medians and 80% Intervals\")"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"posterior-predictive-distribution","dir":"Articles","previous_headings":"","what":"Posterior Predictive Distribution","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"fit model using “training” data, usually interested predictions fitted model new data, can use make predictions new data points; e.g., predict many hits Roberto Clemente get rest season, evaluate predictions observed future data; e.g., well predict many hits Roberto Clemente actually got rest season, generate new simulated data validate model fits. full Bayesian inference, make point estimate parameters use prediction—instead use average predictions weighted posterior. Given data \\(y\\) model parameters \\(\\theta\\), posterior predictive distribution new data \\(\\tilde{y}\\) defined \\[ p(\\tilde{y} \\, | \\, y) \\ = \\ \\int_{\\Theta} p(\\tilde{y} \\, | \\, \\theta) \\ p(\\theta \\, | \\, y) \\ \\mathrm{d}\\theta, \\] \\(\\Theta\\) support parameters \\(\\theta\\). integral form says \\(p(\\tilde{y} \\, | \\, y)\\) defined weighted average legal parameter values \\(\\theta \\\\Theta\\) likelihood function \\(p(\\tilde{y} \\, | \\, \\theta)\\), weights given posterior, \\(p(\\theta \\, | \\, y)\\). want get sidetracked notational mathematical subtleties expectations , posterior predictive density reduces expectation \\(p(\\tilde{y} \\, | \\, \\theta)\\) conditioned \\(y\\).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"evaluating-held-out-data-predictions","dir":"Articles","previous_headings":"Posterior Predictive Distribution","what":"Evaluating Held-Out Data Predictions","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"posterior predictive density formulated expectation posterior, possible compute via MCMC. \\(M\\) draws \\(\\theta^{(m)}\\) posterior \\(p(\\theta \\, | \\, y)\\), posterior predictive log density new data \\(y^{\\mathrm{new}}\\) given MCMC approximation \\[ \\log \\frac{1}{M} \\, \\sum_{m=1}^M \\ p\\left( y^{\\mathrm{new}} \\, | \\, \\theta^{(m)} \\right). \\] practice, requires care prevent underflow floating point calculations; robust calculation log scale provided .","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"simulating-replicated-data","dir":"Articles","previous_headings":"Posterior Predictive Distribution","what":"Simulating Replicated Data","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"also straightforward use forward simulation probability distribution data \\(p(y \\, | \\, \\theta)\\) generate replicated data \\(y^{\\mathrm{rep}}\\) according posterior predictive distribution. (Recall \\(p(y \\, | \\, \\theta)\\) called probability distribution \\(\\theta\\) fixed likelihood \\(y\\) fixed.) \\(M\\) draws \\(\\theta^{(m)}\\) posterior \\(p(\\theta \\, | \\, y)\\), replicated data can simulated drawing sequence \\(M\\) simulations according \\(y^{\\mathrm{rep} \\ (m)}\\) drawn according distribution \\(p(y \\, | \\, \\theta^{(m)})\\). latter random variate generation can usually done efficiently (computationally statistically) means forward simulation probability distribution data; provide example .","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"prediction-for-new-trials","dir":"Articles","previous_headings":"Posterior Predictive Distribution","what":"Prediction for New Trials","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Efron Morris’s (1975) baseball data includes observed hit rate initial 45 bats, also includes data player rest season. question arises well models predict player’s performance rest season based initial 45 bats.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"calibration","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Prediction for New Trials","what":"Calibration","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"well calibrated statistical model one uncertainty predictions matches uncertainty data. , estimate posterior 50% intervals predictions new data (, number hits rest season player), roughly 50% new data fall predicted 50% interval. model true sense correctly describing generative process data, Bayesian inference guaranteed well calibrated. Given models rarely correct deep sense, practice concerned testing calibration quantities interest.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"sharpness","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Prediction for New Trials","what":"Sharpness","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Given two well calibrated models, one makes precise predictions sense narrower intervals better predictively (Gneiting et al. 2007). see example, rather well-calibrated prediction ’s 90% chance number hits player rest season fall \\((120, 130)\\) 90% prediction number hits fall \\((100, 150)\\). models introduced , posterior delta function provides sharpest predictions. Even , residual uncertainty due repeated trials; \\(K^{\\mathrm{new}}\\) trials fixed \\(\\theta_n\\) chance success, random variable \\(Y^{\\mathrm{new}}_n\\) denoting number successes unit \\(n\\) standard deviation repeated binary trials \\[ \\mathrm{sd}[Y^{\\mathrm{new}}_n] \\ = \\ \\sqrt{K \\ \\theta \\, (1 - \\theta)}. \\]","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"why-evaluate-with-the-predictive-posterior","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Prediction for New Trials","what":"Why Evaluate with the Predictive Posterior?","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"predictive posterior density directly measures probability seeing new data. higher probability assigned new data, better job model done predicting outcome. limit, ideal model perfectly predict new outcome uncertainty (probability 1 discrete outcome delta function true value density continuous outcome). notion related notion sharpness discussed previous section, new observations higher predictive densities, ’re probably within narrower posterior intervals (Gneiting et al. 2007).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"log-eptildey-theta-vs-elog-ptildey-theta","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Prediction for New Trials","what":"\\(\\log E[p(\\tilde{y} \\, | \\, \\theta)]\\) vs \\(E[\\log p(\\tilde{y} \\, | \\, \\theta)]\\)","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"log posterior predictive density defined obvious way \\[ \\log p(\\tilde{y} \\, | \\, y) = \\log \\int_{\\Theta} p(\\tilde{y} \\, | \\, \\theta)                      \\ p(\\theta \\, | \\, y)                      \\ \\mathrm{d}\\theta. \\] posterior expectation, rather log posterior expectation. particular, confused posterior expectation log predictive density, given \\[ \\int_{\\Theta} \\left( \\log p(\\tilde{y} \\, | \\, \\theta) \\right)                \\ p(\\theta \\, | \\, y)                  \\ \\mathrm{d}\\theta. \\] Although easy compute Stan stable fashion, produce answer (show ). \\(-\\log(u)\\) convex, little wrangling Jensen’s inequality shows expectation log less equal log expectation, \\[ \\int_{\\Theta} \\left( \\, \\log p(\\tilde{y} \\, | \\, \\theta) \\, \\right) \\ p(\\theta \\, | \\, y) \\ \\mathrm{d}\\theta \\ \\leq \\ \\log \\int_{\\Theta} p(\\tilde{y} \\, | \\, \\theta) \\ p(\\theta \\, | \\, y) \\ \\mathrm{d}\\theta \\] ’ll compute expectations demonstrate Jensen’s inequality running example. variables K_new[n] y_new[n] hold number bats (trials) number hits (successes) player (unit) n. held data can compute log density data point using log_lik function, , like posterior_predict, accepts newdata argument. log_lik function return \\(M \\times N\\) matrix, \\(M\\) size posterior sample (number draws obtained posterior distribution) \\(N\\) number data points newdata. can take row sums matrix sum data points. now distributions log_p_new matrix column model. model, posterior mean log_p_new give us \\[ \\int_{\\Theta} \\left( \\log p(\\tilde{y} \\, | \\, \\theta) \\right)                \\ p(\\theta \\, | \\, y)                  \\ \\mathrm{d}\\theta \\ \\approx \\ \\frac{1}{M} \\, \\sum_{m=1}^M \\log p(y^{\\mathrm{new}} \\, | \\, \\theta^{(m)}). \\] compute models need take mean corresponding column log_p_new. predictive standpoint, models ranked amount pooling , complete pooling best, pooling worst predictively. models predictions averaging posteriors, amount posterior uncertainty also ranked reverse order amount pooling . now see, ranking models can change compute posterior expectation log predictive density.","code":"newdata <- data.frame(Hits = y_new, AB = K_new, Player = bball$Player) fits <- list(Pooling = fit_pool,               NoPooling = fit_nopool,               PartialPooling = fit_partialpool)  # compute log_p_new matrix with each of the models in 'fits' log_p_new_mats <- lapply(fits, log_lik, newdata = newdata)  # for each matrix in the list take the row sums log_p_new <- sapply(log_p_new_mats, rowSums) M <- nrow(log_p_new) head(log_p_new) Pooling NoPooling PartialPooling [1,] -87.50510 -270.1454      -98.24389 [2,] -73.97575 -310.3988     -116.16486 [3,] -80.95743 -250.4451      -93.64268 [4,] -77.54662 -281.8998     -101.46736 [5,] -74.39093 -172.3741     -115.82690 [6,] -88.18157 -171.3092      -74.83273 mean_log_p_new <- colMeans(log_p_new) round(sort(mean_log_p_new, decreasing = TRUE), digits = 1) Pooling PartialPooling      NoPooling           -81.8          -99.6         -207.8"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"posterior-expectation-of-the-log-predictive-density","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Prediction for New Trials > \\(\\log E[p(\\tilde{y} \\, | \\, \\theta)]\\) vs \\(E[\\log p(\\tilde{y} \\, | \\, \\theta)]\\)","what":"Posterior expectation of the log predictive density","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"straight path calculate define generated quantity \\(p(y^{\\mathrm{new}} \\, | y)\\), look posterior mean computed Stan, takes log. , \\[ \\log p(y^{\\mathrm{new}} \\, | \\, y) \\ \\approx \\ \\log \\frac{1}{M} \\, \\sum_{m=1}^M p(y^{\\mathrm{new}} \\, | \\, \\theta^{(m)}). \\] Unfortunately, won’t work cases try compute \\(p(y^{\\mathrm{new}} \\, | \\, \\theta^{(m)})\\) directly, prone underflow. example, 2000 outcomes \\(y^{\\mathrm{new}}_n\\), likelihood 0.5 \\(\\theta^{(m)}\\), underflow, \\(0.5^{2000}\\) smaller smallest positive number computer can represent using standard double-precision floating point (used Stan, R, etc.). contrast, work log scale, \\(\\log p(y^{\\mathrm{new}} \\, | \\, y)\\) underflow. ’s sum bunch terms order 1. already saw can’t just average log get log average. avoid underflow, ’re going use log-sum--exponentials trick, begins noting obvious, \\[ \\log \\frac{1}{M} \\, \\sum_{m=1}^M \\ p(y^{\\mathrm{new}} \\, | \\, \\theta^{(m)}). \\ = \\ \\log \\frac{1}{M} \\, \\sum_{m=1}^M                      \\ \\exp \\left( \\log p(y^{\\mathrm{new}} \\, | \\, \\theta^{(m)}) \\right). \\] ’ll write last expression \\[ -\\log M +  \\mathrm{log\\_sum\\_exp \\, }         \\ \\log p(y^{\\mathrm{new}} \\, | \\, \\theta^{(m)}) \\] can compute \\(\\mathrm{log\\_sum\\_exp}\\) stably subtracting max value. Suppose \\(u = u_1, \\ldots, u_M\\), \\(\\max(u)\\) largest \\(u_m\\). can calculate \\[ \\mathrm{log\\_sum\\_exp \\, } \\ u_m \\ = \\ \\log \\sum_{m=1}^M \\exp(u_m) \\ = \\ \\max(u) + \\log \\sum_{m=1}^M \\exp(u_m - \\max(u)). \\] \\(u_m - \\max(u) \\leq 0\\), exponentiations overflow. may underflow zero, lose precision leading \\(\\max(u)\\) term; way underflow can arise \\(u_m - \\max(u)\\) small, meaning won’t add significant digits \\(\\max(u)\\) underflowed. can implement \\(\\mathrm{log\\_sum\\_exp}\\) R follows: include \\(-\\log M\\) term make log_mean_exp: can use compute log posterior predictive densities models: Now ranking different! expected, values greater expectation log density due Jensen’s inequality. partial pooling model appears making slightly better predictions full pooling model, turn making slightly better predictions pooling model.","code":"log_sum_exp <- function(u) {   max_u <- max(u)   a <- 0   for (n in 1:length(u)) {     a <- a + exp(u[n] - max_u)   }   max_u + log(a) }  # Or equivalently using vectorization log_sum_exp <- function(u) {   max_u <- max(u)   max_u + log(sum(exp(u - max_u))) } log_mean_exp <- function(u) {   M <- length(u)   -log(M) + log_sum_exp(u) } new_lps <- lapply(log_p_new_mats, function(x) apply(x, 2, log_mean_exp))  # sum over the data points new_lps_sums <- sapply(new_lps, sum)  round(sort(new_lps_sums, decreasing = TRUE), digits = 1) PartialPooling        Pooling      NoPooling           -71.8          -73.1          -81.5"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"approximating-the-expected-log-predictive-density","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Prediction for New Trials > \\(\\log E[p(\\tilde{y} \\, | \\, \\theta)]\\) vs \\(E[\\log p(\\tilde{y} \\, | \\, \\theta)]\\)","what":"Approximating the expected log predictive density","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Vehtari, Gelman, Gabry (2016) shows expected log predictive density can approximated using loo function model compared across models: third column leave-one-(loo) approximation expected log predictive density. approximation asymptotically valid 18 observations case, substantially underestimates expected log predictive densities found previous subsection. Nevertheless, relative ranking models essentially pooled partially pooled models virtually indistinguishable much better pooling model.","code":"loo_compare(loo(fit_partialpool), loo(fit_pool), loo(fit_nopool)) elpd_diff se_diff fit_pool         0.0       0.0    fit_partialpool -0.1       0.5    fit_nopool      -6.0       2.6"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"predicting-new-observations","dir":"Articles","previous_headings":"Posterior Predictive Distribution","what":"Predicting New Observations","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"rstanarm straightforward generate draws posterior predictive distribution using posterior_predict function. capability, can either generate predictions new data can apply predictors already . two sources uncertainty predictions, first uncertainty \\(\\theta\\) posterior \\(p(\\theta \\, | \\, y)\\) second uncertainty due likelihood \\(p(\\tilde{y} \\, | \\, \\theta)\\). let \\(z_n\\) number successes unit \\(n\\) \\(K^{\\mathrm{new}}_n\\) trials. might seem tempting eliminate second source uncertainty set \\(z_n^{(m)}\\) expectation, \\(\\theta_n^{(m)} \\, K^{\\mathrm{new}}\\), draw \\(m\\) posterior rather simulating new value. might seem tempting remove first source uncertainty use posterior mean (median mode …) rather draws posterior. Either way, resulting values suffice estimating posterior mean, capture uncertainty prediction \\(y^{\\mathrm{new}}_n\\) thus useful estimating predictive standard deviations quantiles basis decision making uncertainty. words, predictions properly calibrated (sense define ). predict \\(z\\) player can use following code: Translating posterior number hits season batting average, \\(\\frac{y_n + z_n}{K_n + K^{\\mathrm{new}}_n}\\), get 80% posterior interval Roberto Clemente partial pooling model. Part uncertainty due uncertainty Clemente’s underlying chance success, part uncertainty due 367 remaining trials (bats) modeled binomial. remaining bats season, Clemente’s success rate (batting average) \\(127 / 367 = 0.346\\). model, following plot shows player’s posterior predictive 50% interval predicted batting average (success rate) remaining bats (trials); observed success rate remainder season shown blue dot.  choose plot 50% posterior intervals good single point checking calibration. Rather plotting number hits vertical axis, standardized predictions outcomes success rate. unit (player) different number subsequent trials (bats), posterior intervals relatively wider narrower within plots model (trials imply narrower intervals average). unit number initial observed trials, variation primarily due uncertainty binomial model outcomes.","code":"newdata <- data.frame(Hits = y_new, AB = K_new, Player = bball$Player) ppd_pool <- posterior_predict(fit_pool, newdata) ppd_nopool <- posterior_predict(fit_nopool, newdata) ppd_partialpool <- posterior_predict(fit_partialpool, newdata) colnames(ppd_pool) <- colnames(ppd_nopool) <- colnames(ppd_partialpool) <- as.character(bball$Player) colMeans(ppd_partialpool) Clemente   Robinson     Howard  Johnstone      Berry    Spencer  Kessinger   107.11175  122.81375  147.09175   76.57650  114.83275  127.77175  158.14625    Alvarado      Santo    Swaboda Petrocelli  Rodriguez      Scott      Unser    36.78775  133.26850   52.09350  137.74925   47.83100  111.74450   71.23400    Williams Campaneris     Munson      Alvis   151.40900  141.09625  101.63950   17.27250 z_1 <- ppd_partialpool[, 1] clemente_80pct <- (y[1] + quantile(z_1, prob = c(0.1, 0.9))) / (K[1] + K_new[1]) batting_avg(clemente_80pct) 10%   90%  0.255 0.359 ppd_intervals <- function(x) t(apply(x, 2, quantile, probs = c(0.25, 0.75))) ppd_summaries <- (1 / K_new) * rbind(ppd_intervals(ppd_pool),                                      ppd_intervals(ppd_nopool),                                      ppd_intervals(ppd_partialpool)) df_ppd <- data.frame(player = rep(1:length(y_new), 3),                      y = rep(y_new / K_new, 3),                      lb = ppd_summaries[, \"25%\"],                      ub = ppd_summaries[, \"75%\"],                      model = rep(models, each = length(y_new))) ggplot(df_ppd, aes(x=player, y=y, ymin=lb, ymax=ub)) +    geom_linerange(color = \"gray60\", size = 2) +    geom_point(size = 2.5, color = \"skyblue4\") +   facet_grid(. ~ model) +   labs(x = NULL, y = \"batting average\") +    scale_x_continuous(breaks = NULL) +   ggtitle(expression(     atop(\"Posterior Predictions for Batting Average in Remainder of Season\",          atop(\"50% posterior predictive intervals (gray bars); observed (blue dots)\", \"\"))))"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"calibration-1","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Predicting New Observations","what":"Calibration","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"50% intervals, expect half estimates lie outside intervals well-calibrated model. fewer expected number outcomes lie estimated posterior intervals, reason believe model well calibrated—posterior intervals narrow. also true many outcomes lie estimated posterior intervals—case intervals broad. course, variation tests number units lying intervals random variable (see exercises), practice looking extreme values indicators miscalibration. models complete pooling model appears reasonably well calibrated, even calibration complete pooling model bad (variation chance--success among players low enough variance complete pooling model rejected possibility amount data used ).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"sharpness-1","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Predicting New Observations","what":"Sharpness","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Consider width posterior predictive intervals units across models. model pooling broadest posterior predictive intervals complete pooling model narrowest. expected given number observations used fit model; 45 pooling case 810 complete pooling case, relatively something partial pooling models. log odds model pooling, intervals slightly narrower direct hierarchical model. two well calibrated models, one narrower posterior intervals preferable predictions tighter. term introduced Gneiting et al. (2007) “sharpness.” limit, perfect model provide delta function true answer vanishing posterior interval.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"estimating-event-probabilities","dir":"Articles","previous_headings":"Posterior Predictive Distribution","what":"Estimating Event Probabilities","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"80% interval partial pooling model coincidentally shows us model estimates roughly 10% chance Roberto Clemente batting 0.400 better season based batting 0.400 first 45 bats. great, non-trivial. Rather fishing right quantile hoping get lucky, can write model directly estimate event probabilities, Robert Clemente’s batting average 0.400 better season. Event probabilities defined expectations indicator functions parameters data. example, probability player \\(n\\)’s batting average 0.400 better conditioned data \\(y\\) defined conditional event probability \\[ \\mathrm{Pr}\\left[ \\frac{(y_n + z_n)}{(45 + K^{\\mathrm{new}}_n)} \\geq 0.400 \\, \\Big| \\, y \\right] \\ = \\ \\int_{\\Theta} \\mathrm{}\\left[\\frac{(y_n + z_n)}{(45 + K^{\\mathrm{new}}_n)} \\geq 0.400\\right]        \\ p(z_n \\, | \\, \\theta_n, K^{\\mathrm{new}}_n)        \\ p(\\theta \\, | \\, y, K)        \\ \\mathrm{d}\\theta. \\] indicator function \\(\\mathrm{}[c]\\) evaluates 1 condition \\(c\\) true 0 false. just another expectation respect posterior, can calculate event probability using MCMC \\[ \\mathrm{Pr}\\left[\\frac{(y_n + z_n)}{(45 + K^{\\mathrm{new}}_n)} \\geq 0.400 \\, \\Big| \\, y \\right] \\ \\approx \\ \\frac{1}{M} \\, \\sum_{m=1}^M \\mathrm{}\\left[\\frac{(y_n + z_n^{(m)})}{(45 + K^{\\mathrm{new}}_n)} \\geq 0.400\\right]. \\] event season batting average greater 0.400. care ability (chance success), batting average (success rate) rest season? ask question whether \\(\\mathrm{Pr}[\\theta_n > 0.4]\\). defined weighted average prior computed via MCMC previous case. \\[ \\mathrm{Pr}\\left[\\theta_n \\geq 0.400 \\, | \\, y \\right] \\ = \\ \\int_{\\Theta} \\mathrm{}\\left[\\theta_n \\geq 0.400\\right]        \\ p(\\theta \\, | \\, y, K)        \\ \\mathrm{d}\\theta \\ \\approx \\ \\frac{1}{M} \\, \\sum_{m=1}^M \\mathrm{}[\\theta_n^{(m)} \\geq 0.400]. \\]","code":"draws_partialpool <- shift_draws(as.matrix(fit_partialpool)) thetas_partialpool <- plogis(draws_partialpool) thetas_partialpool <- thetas_partialpool[,-ncol(thetas_partialpool)] colnames(thetas_partialpool) <- as.character(bball$Player) ability_gt_400 <- thetas_partialpool > 0.4 cat(\"Pr(theta_n >= 0.400 | y)\\n\") colMeans(ability_gt_400)[c(1, 5, 10)]  some_gt_350 <- apply(thetas_partialpool, 1, function(x) max(x) > 0.35) cat(\"Pr(at least one theta_n >= 0.350 | y)\\n\") mean(some_gt_350) Pr(theta_n >= 0.400 | y) Clemente    Berry  Swaboda   0.02175  0.00325  0.00050  Pr(at least one theta_n >= 0.350 | y) [1] 0.22875"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"multiple-comparisons","dir":"Articles","previous_headings":"Posterior Predictive Distribution","what":"Multiple Comparisons","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"snuck “multiple comparison” event last section, namely whether player chance success hits .350 greater. traditional significance testing multiple trials, common adjust falsely rejecting null hypothesis (-called Type error) inflating conventional (arguably far low) 5% target reporting “significance.” example, suppose 18 players ability parameters \\(\\theta_n\\) \\(N\\) null hypotheses form \\(H_0^n: \\theta_n < 0.350\\). Now suppose evaluate 18 hypotheses independently conventional \\(p = 0.05\\) significance level, giving 5% chance rejecting null hypothesis error. run 18 hypothesis tests, overall chance falsely rejecting least one null hypotheses whopping \\(1 - (1 - 0.05)^{18} = 0.60\\). traditional solution problem apply Bonferroni adjustment control false rejection rate; typical adjustment divide \\(p\\)-value number hypothesis tests “family” (, collective test done). sets rate \\(p = 0.05/18\\), approximately \\(p = 0.003\\), results slightly less 5% chance falsely rejecting null hypothesis error. Although Bonferroni correction reduce overall chance falsely rejecting null hypothesis, also reduces statistical power test degree. means many null hypotheses fail rejected error. Rather classical multiple comparison adjustments adjust false-discovery rate, Bonferroni correction, Gelman et al. (2012) suggest using hierarchical model perform partial pooling instead. already shown, hierarchical models partially pool data, pulls estimates toward population mean strength determined amount observed variation population (see also Figure 2 (Gelman et al. 2012)). automatically reduces false-discovery rate, though way intrinsically calibrated false discovery, good, reducing overall false discovery rate reduces true discovery rate time. generated quantity some_ability_gt_350 set 1 maximum ability estimate \\(\\theta\\) greater 0.35. thus posterior mean generated quantity event probability \\[ \\mathrm{Pr}[\\mathrm{max}(\\theta) > 0.350] \\ = \\ \\int_{\\Theta} \\mathrm{}[\\mathrm{max}(\\theta) > 0.35] \\ p(\\theta \\, | \\, y, K) \\ \\mathrm{d}\\theta \\ \\approx \\ \\frac{1}{M} \\, \\sum_{m=1}^M \\ \\mathrm{}[\\mathrm{max}(\\theta^{(m)}) > 0.35] \\] \\(\\theta^{(m)}\\) sequence posterior draws ability parameter vector. Stan reports value posterior mean generated quantity some_ability_gt_350, takes value \\(\\mathrm{}[\\mathrm{max}(\\theta^{(m)}) > 0.35]\\) iteration. probability estimate player ability (chance success) greater 0.350 essentially zero complete essentially guaranteed pooling model. partially pooled estimates considered significant conventional p=0.05 thresholds. One way get handle ’s going inspect posterior 80% intervals chance--success estimates first graph .","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"ranking","dir":"Articles","previous_headings":"Posterior Predictive Distribution","what":"Ranking","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"addition multiple comparisons, can use simultaneous estimation ability parameters rank units. section, rank ballplayers (estimated) chance success (.e., batting ability). course, ranking players ability makes sense complete pooling model, every player assumed ability. abundantly clear posterior intervals uncertainty great 45 bats. original Volume BUGS example surgical mortality, posterior distribution ranks plotted hospital. now straightforward reproduce figure baseball data.","code":"reverse_rank <- function(x) 1 + length(x) - rank(x) # so lower rank is better rank <- apply(thetas_partialpool, 1, reverse_rank) t(apply(rank, 1, quantile, prob = c(0.1, 0.5, 0.9))) parameters   10% 50% 90%   Clemente     1   5  14   Robinson     1   5  14   Howard       1   6  14   Johnstone    2   7  15   Berry        2   8  15   Spencer      2   8  15   Kessinger    2   9  16   Alvarado     3   9  16   Santo        3  10  17   Swaboda      3  10  17   Petrocelli   4  11  17   Rodriguez    4  11  17   Scott        4  11  17   Unser        4  11  17   Williams     3  11  17   Campaneris   4  12  17   Munson       4  13  18   Alvis        5  14  18 df_rank <- data.frame(name = rep(bball$Player, each = M),                        rank = c(t(rank)))  ggplot(df_rank, aes(rank)) +   stat_count(width = 0.8) +   facet_wrap(~ name) +   scale_x_discrete(\"Rank\", limits = c(1, 5, 10, 15)) +   scale_y_discrete(\"Probability\", limits = c(0, 0.1 * M, 0.2 * M),                    labels = c(\"0.0\", \"0.1\", \"0.2\")) +    ggtitle(\"Rankings for Partial Pooling Model\")"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"who-has-the-highest-chance-of-success","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Ranking","what":"Who has the Highest Chance of Success?","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"can use ranking statistic calculate event probability unit \\(n\\) unit highest chance success using MCMC \\[ \\mathrm{Pr}[\\theta_n = \\max(\\theta)] \\ = \\ \\int_{\\Theta} \\mathrm{}[\\theta_n = \\mathrm{max}(\\theta)]               \\ p(\\theta \\, | \\, y, K)               \\ \\mathrm{d}\\theta \\ \\approx \\ \\frac{1}{M} \\, \\sum_{m=1}^M \\mathrm{}[\\theta^{(m)}_n = \\mathrm{max}(\\theta^{(m)})]. \\] Like models, partial pooling mitigates implicit multiple comparisons done calculate probabilities rankings. Contrast approach pairwise significance test applies false-discovery correction. can compute straightforwardly using rank data already computed compute directly . \\(\\mathrm{Pr}[\\theta_n = \\theta_{n'}] = 0\\) \\(n \\neq n'\\), don’t worry ties.  question player highest chance success (batting ability) doesn’t even make sense complete pooling model, chance success parameters definition. models, amount pooling directly determines probabilities best player. , probability best goes high performing players pooling, whereas goes -average players.","code":"thetas_nopool <- plogis(as.matrix(fit_nopool)) colnames(thetas_nopool) <- as.character(bball$Player) rank_nopool <- apply(thetas_nopool, 1, reverse_rank) is_best_nopool <- rowMeans(rank_nopool == 1) is_best_partialpool <- rowMeans(rank == 1)  df_is_best <- data.frame(unit = rep(bball$Player, 2),                           is_best = c(is_best_partialpool, is_best_nopool),                           model = rep(c(\"partial pooling\", \"no pooling\"), each = N))  ggplot(df_is_best, aes(x=unit, y=is_best)) +   geom_bar(stat = \"identity\") +   facet_wrap(~ model) +   scale_y_continuous(name = \"Pr[player is best]\") +   ggtitle(\"Who is the Best Player?\") +    theme(axis.text.x = element_text(angle = -45, vjust = 1, hjust = 0))"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"graphical-posterior-predictive-checks","dir":"Articles","previous_headings":"Posterior Predictive Distribution","what":"Graphical Posterior Predictive Checks","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"can simulate data predictive distribution compare original data used fitting model. consistent, either model capturing aspects data probing test statistics measurement made highly unlikely. , extreme \\(p\\)-values lead us suspect something wrong model deserves exploration. cases, willing work models wrong measurable aspects, accurately capture quantities interest application. , ’s possible model capture , , aspects data set, still useful.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"test-statistics-and-bayesian-p-values","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Graphical Posterior Predictive Checks","what":"Test Statistics and Bayesian \\(p\\)-Values","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"test statistic \\(T\\) function data real value. Following (Gelman et al. 2013), concentrate four specific test statistics repeated binary trial data (though choices fairly general): minimum value, maximum value, sample mean, sample standard deviation. Given test statistic \\(T\\) data \\(y\\), Bayesian \\(p\\)-value direct definition probability, \\[ p_B = \\mathrm{Pr}[T(y^{\\mathrm{rep}}) \\geq T(y) \\, | \\, y]. \\] Bayesian \\(p\\)-values, like traditional counterparts, probabilities, probabilities model true. simply measure discrepancies observed data expect model true. Values Bayesian \\(p\\)-values near 0 1 indicate data \\(y\\) used estimate model unlikely generated estimated model. forms full Bayesian inference, estimate full posterior, just point estimate. Bayesain inferences, average posterior rather working point estimate parameters. Expanding expectation indicator function, \\[ p_B \\ = \\   \\int_{\\Theta, Y^{\\mathrm{rep}}}     \\mathrm{}[T(y^{\\mathrm{rep}}) \\geq T(y)]       \\ p(y^{\\mathrm{rep}} \\, | \\, \\theta)     \\ p(\\theta \\, | \\, y)     \\ \\mathrm{d}\\theta, \\] treat \\(y^{\\mathrm{rep}}\\) parameter parallel \\(\\theta\\), integrating possible values \\(y^{\\mathrm{rep}} \\Y^{\\mathrm{rep}}\\). usual, use integration sign general way intended include summation, discrete variable \\(y^{\\mathrm{rep}}\\). formulation expectation leads obvious MCMC calculation based posterior draws \\(y^{\\mathrm{rep} (m)}\\) \\(m \\1{:}M\\), \\[ p_B \\approx \\frac{1}{M} \\, \\sum_{m=1}^M \\mathrm{}[T(y^{\\mathrm{rep} \\ (m)}) \\geq T(y)]. \\] Using pp_check rstanarm, can easily reproduce Figure 6.12 (Gelman et al. 2013), shows posterior predictive distribution test statistic, observed value vertical line, \\(p\\)-value tests. First, just plot pooling model using mean test statistic:  stat argument can name R function (including functions defined Global Environment) takes vector input returns scalar. make plots models several test statistics can use following code, create list ggplot objects model arrange everything single plot.  worrisomely extreme value visible plots \\(p\\)-value standard deviation -pooling model, vast majority simulated data sets model standard deviations greater actual data. didn’t actually compute \\(p\\)-value extreme \\(p\\)-values easy detect visually whether \\(p\\)-value less \\(0.05\\) arbitrary value little use us beyond can already see plot. However, want actually compute \\(p\\)-value can easily:","code":"pp_check(fit_nopool, plotfun = \"stat\", stat = \"mean\") tstat_plots <- function(model, stats) {   lapply(stats, function(stat) {     graph <- pp_check(model, plotfun = \"stat\", stat = stat,                        seed = SEED) # optional arguments     graph + xlab(stat) + theme(legend.position = \"none\")   }) } Tstats <- c(\"mean\", \"sd\", \"min\", \"max\") ppcs_pool <- tstat_plots(fit_pool, Tstats) ppcs_nopool <- tstat_plots(fit_nopool, Tstats) ppcs_partialpool <- tstat_plots(fit_partialpool, Tstats)  if (require(gridExtra)) {   grid.arrange(     arrangeGrob(grobs = ppcs_pool, nrow = 1, left = \"Pooling\"),      arrangeGrob(grobs = ppcs_nopool, nrow = 1, left = \"No Pooling\"),     arrangeGrob(grobs = ppcs_partialpool, nrow = 1, left = \"Partial Pooling\")   ) } yrep <- posterior_predict(fit_nopool, seed = SEED) # seed is optional Ty <- sd(y) Tyrep <- apply(yrep, 1, sd)  # tail-area probability p <- 1 - mean(Tyrep > Ty) print(p) [1] 0.01325"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"comparing-observed-and-replicated-data","dir":"Articles","previous_headings":"Posterior Predictive Distribution > Graphical Posterior Predictive Checks","what":"Comparing Observed and Replicated Data","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Following advice Gelman et al. (2013), take fitted parameters data set generate replicated data sets, compare replicated data sets visually observed data used fit model. section ’ll create plots model using partial pooling, plots can made models . using rstanarm’s pp_check function, can plot simulated data sets along original data set visual inspection suggested Gelman et al. (2013). type posterior predictive check set check argument \"distributions\" use nreps specify many replicated sets data generate posterior predictive distribution. models binomial outcome, instead plotting number successes (hits case) x-axis, pp_check plot proportion successes.  simulations unreasonable binomial likelihood, spread actual data. case, may actually data selected major league baseball players actual data distribution. Efron Morris (1975, p 312) write sample chosen wanted 30 50 bats assure satisfactory approximation binomial normal distribution leaving bulk bats estimated. also wanted include unusually good hitter (Clemente) test method least one extreme parameter, situation expected less favorable Stein’s estimator. Stein’s estimator requires equal variances, situation, equal bats, remaining 17 players either April 26 May 3 New York Times reported 45 bats.","code":"pp_check(fit_partialpool, plotfun = \"hist\", nreps = 15, binwidth = 0.025) +   ggtitle(\"Model: Partial Pooling\")"},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"discussion","dir":"Articles","previous_headings":"","what":"Discussion","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"hierarchical model introduces estimation bias toward population mean stronger bias, less variance estimates units. Exactly much bias variance warranted can estimated calibrating model testing predictions bear . little data, little can gain sharp inferences provide informative priors, well worth prior information available. hand, data, models provide similar results (see exercises), limit, models (complete pooling) converge posteriors delta functions around empirical chance success (.e., maximum likelihood estimate). Meanwhile, Bayesian inference allowing us make accurate predictions data available hit asymptotic regime.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"exercises","dir":"Articles","previous_headings":"","what":"Exercises","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Generate fake data according pooling, -pooling, partial pooling models. Fit model consider coverage posterior 80% intervals. Try generating data player different number -bats (trials) fitting models. effect number initial trials posterior? way quantify effect? section fit complete pooling model show plot prior distribution probability success \\(\\theta\\) implied \\(\\mathsf{Normal}(-1,1)\\) prior log-odds \\(\\alpha\\). \\(\\theta = \\mathrm{logit}^{-1}(\\alpha)\\) \\(p(\\alpha) = \\mathsf{Normal}(\\alpha \\,|\\, -1, 1)\\), \\(p(\\theta)\\)? hint, see . sensitive basic -pooling model choice prior? used somewhat informative prior due knowledge baseball, prior made less informative. , , affect posterior inference? test statistics might used evaluate model fit data? Try using pp_check(model, plotfun=\"stat\", stat = \"my_test\"), my_test function computes test statistic. example, check 25% quantile first define function q25 <- function(x) quantile(x, 0.25) call pp_check(model, plotfun = \"stat\", stat = \"q25\"). Discuss difference batting average -base percentage random variables. Consider particularly denominator (-bat versus plate appearance). denominator kinds problems always random variable ? might important inference?","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Betancourt, M. Girolami, M. (2015) Hamiltonian Monte Carlo hierarchical models. Current Trends Bayesian Methodology Applications 79. Efron, B. Morris, C. (1975) Data analysis using Stein’s estimator generalizations. Journal American Statistical Association 70(350), 311–319. [ pdf] Gelman, ., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, ., Rubin, D. B. (2013) Bayesian Data Analysis, 3rd Edition. Chapman & Hall/CRC Press, London. Gelman, . Hill, J. (2007) Data Analysis Using Regression Multilevel-Hierarchical Models. Cambridge University Press, Cambridge, United Kingdom. Gelman, ., Hill, J., Yajima, M. (2012) (usually) don’t worry multiple comparisons. Journal Research Educational Effectiveness 5, 189–211. [ preprint] Gneiting, T., Balabdaoui, F., Raftery, . E. (2007) Probabilistic forecasts, calibration sharpness. Journal Royal Statistical Society: Series B (Statistical Methodology), 69(2), 243–268. Lunn, D., Jackson, C., Best, N., Thomas, ., Spiegelhalter, D. (2013) BUGS Book: Practical Introduction Bayesian Analysis. Chapman & Hall/CRC Press. Neal, R. M. (2003) Slice sampling. Annals Statistics 31(3):705–767. Papaspiliopoulos, O., Roberts, G. O., Skold, M. (2003) Non-centered parameterisations hierarchical models data augmentation. Bayesian Statistics 7: Proceedings Seventh Valencia International Meeting, edited Bernardo, J. M., Bayarri, M. J., Berger, J. O., Dawid, . P., Heckerman, D., Smith, . F. M., West, M. Oxford University Press, Chicago. Plummer, M., Best, N., Cowles, K., & Vines, K. (2006). CODA: Convergence diagnosis output analysis MCMC. R News, 6(1), 7–11. Spiegelhalter, D., Thomas, ., Best, N., & Gilks, W. (1996) BUGS 0.5 Examples. MRC Biostatistics Unit, Institute Public health, Cambridge, UK. Stan Development Team (2015) Stan Modeling Language User’s Guide Reference Manual. [web page] Tarone, R. E. (1982) use historical control information testing trend proportions. Biometrics 38(1):215–220. Vehtari, , Gelman, ., & Gabry, J. (2016) Practical Bayesian model evaluation using leave-one-cross-validation WAIC. [ pdf]","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"additional-data-sets","dir":"Articles","previous_headings":"","what":"Additional Data Sets","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"following additional data sets similar structure baseball data used vignette included rstanarm.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"rat-tumors-n-71","dir":"Articles","previous_headings":"Additional Data Sets","what":"Rat tumors (N = 71)","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Tarone (1982) provides data set tumor incidence historical control groups rats; specifically endometrial stromal polyps female lab rats type F344. data set taken book site (Gelman et al. 2013): load: data(tumors, package = \"rstanarm\") Data source: https://www.stat.columbia.edu/~gelman/book/data/rats.asc","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"surgical-mortality-n-12","dir":"Articles","previous_headings":"Additional Data Sets","what":"Surgical mortality (N = 12)","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Spiegelhalter et al. (1996) provide data set mortality rates 12 hospitals performing cardiac surgery babies. just manually entered data paper; also available Stan example models repository R format. load: data(mortality, package = \"rstanarm\") Data source: Unknown","code":""},{"path":"https://mc-stan.org/rstanarm/articles/pooling.html","id":"baseball-hits-1996-al-n-308","dir":"Articles","previous_headings":"Additional Data Sets","what":"Baseball hits 1996 AL (N = 308)","title":"Hierarchical Partial Pooling for Repeated Binary Trials","text":"Carpenter (2009) updates Efron Morris’s (1975) data set entire set players entire 2006 American League season Major League Baseball. data originally downloaded seanlahman.com, currently working. load: data(bball2006, package = \"rstanarm\") Data Source: https://web.archive.org/web/20220618114439/https://lingpipe-blog.com/2009/09/23/","code":""},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"july-2020-update","dir":"Articles","previous_headings":"","what":"July 2020 Update","title":"Prior Distributions for rstanarm Models","text":"July 2020 changes prior distributions: Except default priors, autoscale now defaults FALSE. means specifying custom priors longer need manually set autoscale=FALSE every time use distribution. minor changes default priors intercept (non-hierarchical) regression coefficients. See Default priors scale adjustments . recommend new book Regression Stories, discusses background behind default priors rstanarm also provides examples specifying non-default priors.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Prior Distributions for rstanarm Models","text":"vignette provides overview specification prior distributions works rstanarm package. still work progress content added future versions rstanarm. reading vignette important first read Use rstanarm Package vignette, provides general overview package. Every modeling function rstanarm offers subset arguments table used specifying prior distributions model parameters.  * stan_glm also implies stan_glm.nb. stan_glmer implies stan_lmer stan_glmer.nb.  stan_polr, stan_betareg, stan_gamm4 functions also provide additional arguments specific models:  specify arguments user provides call one various available functions specifying priors (e.g., prior = normal(0, 1), prior = cauchy(c(0, 1), c(1, 2.5))). documentation functions can found help(\"priors\"). rstanarm documentation vignettes provide many examples using arguments specify priors documentation arguments help pages various rstanarm modeling functions (e.g., help(\"stan_glm\")) also explains distributions can used specifying prior-related arguments.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"default-weakly-informative-prior-distributions","dir":"Articles","previous_headings":"","what":"Default (Weakly Informative) Prior Distributions","title":"Prior Distributions for rstanarm Models","text":"exceptions, default priors rstanarm —priors used arguments tables untouched— flat priors. Rather, defaults intended weakly informative. , designed provide moderate regularization help stabilize computation. many () applications defaults perform well, guaranteed (default priors make sense every possible model specification). way rstanarm attempts make priors weakly informative default internally adjust scales priors. works (, importantly, turn ) explained , first can look default priors action fitting basic linear regression model stan_glm function. specifying priors, stan_glm function accepts arguments prior_intercept, prior, prior_aux. use default priors just leave arguments defaults (.e., don’t specify ): prior_summary function provides concise summary priors used: Starting bottom , can see : Auxiliary: sigma, error standard deviation, default prior \\(\\mathsf{exponential}(1)\\). However, result automatic rescaling, actual scale used 6.03. Coefficients: default regression coefficients (case coefficients wt variables) treated priori independent normal priors centered 0 scale (standard deviation) \\(2.5\\). Like sigma, order default weakly informative rstanarm adjust scales priors coefficients. result, prior scales actually used 15.40 30.20. Intercept: intercept, default prior normal mean \\(0\\) standard deviation \\(2.5\\), case standard deviation adjusted 15.07. also note parentheses informing prior applies intercept predictors centered (similar note can found documentation prior_intercept argument). many cases value \\(y\\) \\(x=0\\) meaningful easier think value \\(x = \\bar{x}\\). Therefore placing prior intercept centering predictors typically makes easier specify reasonable prior intercept. (Note: user need manually center predictors.) disable centering predictors, need omit intercept model formula include column ones predictor (named \"(Intercept)\" data.frame). can specify prior “coefficient” column ones. next two subsections describe rescaling works easily disable desired.","code":"library(\"rstanarm\") default_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1) prior_summary(default_prior_test) Priors for model 'default_prior_test'  ------ Intercept (after predictors centered)   Specified prior:     ~ normal(location = 20, scale = 2.5)   Adjusted prior:     ~ normal(location = 20, scale = 15)  Coefficients   Specified prior:     ~ normal(location = [0,0], scale = [2.5,2.5])   Adjusted prior:     ~ normal(location = [0,0], scale = [15.40,30.20])  Auxiliary (sigma)   Specified prior:     ~ exponential(rate = 1)   Adjusted prior:     ~ exponential(rate = 0.17) ------ See help('prior_summary.stanreg') for more details"},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"default-priors-and-scale-adjustments","dir":"Articles","previous_headings":"Default (Weakly Informative) Prior Distributions","what":"Default priors and scale adjustments","title":"Prior Distributions for rstanarm Models","text":"Automatic scale adjustments happen two cases: default priors used. user sets autoscale=TRUE specifying prior (e.g., normal(0, 3, autoscale=TRUE)). See help(\"priors\") list distributions see autoscale argument. describe default priors work intercept, regression coefficients, (applicable) auxiliary parameters. Autoscaling using default priors works analogously (autoscale=TRUE). Assume outcome \\(y\\) predictors \\(x_1,\\ldots,x_k\\) model linear predictor \\[ \\alpha + \\beta_1 x_1 + \\dots + \\beta_K x_K. \\]","code":""},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"regression-coefficients","dir":"Articles","previous_headings":"Default (Weakly Informative) Prior Distributions > Default priors and scale adjustments","what":"Regression coefficients","title":"Prior Distributions for rstanarm Models","text":"default prior regression coefficients \\(\\beta_k\\) \\[ \\beta_k \\sim \\mathsf{Normal}(0, \\, 2.5 \\cdot s_y/s_x) \\] \\(s_x = \\text{sd}(x)\\) \\[ s_y = \\begin{cases} \\text{sd}(y) & \\text{} \\:\\: {\\tt family=gaussian(link)}, \\\\ 1 & \\text{otherwise}. \\end{cases} \\] corresponds prior = normal(0, 2.5, autoscale = TRUE) rstanarm code.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"intercept","dir":"Articles","previous_headings":"Default (Weakly Informative) Prior Distributions > Default priors and scale adjustments","what":"Intercept","title":"Prior Distributions for rstanarm Models","text":"intercept assigned prior indirectly. prior_intercept argument refers intercept predictors centered (internally rstanarm). , instead placing prior expected value \\(y\\) \\(x=0\\), place prior expected value \\(y\\) \\(x = \\bar{x}\\). default prior centered intercept, say \\(\\alpha_c\\), \\[ \\alpha_c \\sim \\mathsf{Normal}(m_y, \\, 2.5 \\cdot s_y) \\] \\[ m_y = \\begin{cases} \\bar{y} & \\text{} \\:\\: {\\tt family=gaussian(link=\"identity\")}, \\\\ 0 & \\text{otherwise} \\end{cases} \\] \\(s_y\\) (either 1 \\(\\text{sd(y)}\\)).","code":""},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"auxiliary-parameters","dir":"Articles","previous_headings":"Default (Weakly Informative) Prior Distributions > Default priors and scale adjustments","what":"Auxiliary parameters","title":"Prior Distributions for rstanarm Models","text":"default prior auxiliary parameter (residual standard deviation Gaussian, shape gamma, reciprocal dispersion negative binomial, etc.) exponential distribution rate \\(1/s_y\\) \\[ \\text{aux} \\sim \\mathsf{Exponential}(1/s_y) \\] \\(s_y\\) (either 1 \\(\\text{sd(y)}\\)). corresponds prior_aux = exponential(1, autoscale=TRUE) rstanarm code.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"note-on-data-based-priors","dir":"Articles","previous_headings":"Default (Weakly Informative) Prior Distributions > Default priors and scale adjustments","what":"Note on data-based priors","title":"Prior Distributions for rstanarm Models","text":"scaling based scales predictors (possibly outcome) technically data-dependent priors. However, since priors quite wide (cases rather conservative), amount information used weak mainly takes account order magnitude variables. enables rstanarm offer defaults reasonable many models.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"disabling-prior-scale-adjustments","dir":"Articles","previous_headings":"Default (Weakly Informative) Prior Distributions","what":"Disabling prior scale adjustments","title":"Prior Distributions for rstanarm Models","text":"disable automatic rescaling simply specify prior default. rstanarm versions including version 2.19.3 used require explicitly set autoscale argument FALSE, now autoscaling happens default default priors. use autoscaling manually specified priors set autoscale = TRUE. example, prior specification include autoscaling: can verify prior scales weren’t adjusted checking prior_summary:","code":"test_no_autoscale <-   update(     default_prior_test,     prior = normal(0, 5),     prior_intercept = student_t(4, 0, 10),     prior_aux = cauchy(0, 3)   ) prior_summary(test_no_autoscale) Priors for model 'test_no_autoscale'  ------ Intercept (after predictors centered)  ~ student_t(df = 4, location = 0, scale = 10)  Coefficients  ~ normal(location = [0,0], scale = [5,5])  Auxiliary (sigma)  ~ half-cauchy(location = 0, scale = 3) ------ See help('prior_summary.stanreg') for more details"},{"path":[]},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"uninformative-is-usually-unwarranted-and-unrealistic-flat-is-frequently-frivolous-and-fictional","dir":"Articles","previous_headings":"How to Specify Flat Priors (and why you typically shouldn’t)","what":"Uninformative is usually unwarranted and unrealistic (flat is frequently frivolous and fictional)","title":"Prior Distributions for rstanarm Models","text":"“non-informative” “uninformative” used context prior distributions, typically refers flat (uniform) distribution nearly flat distribution. Sometimes may also used refer parameterization-invariant Jeffreys prior. Although rstanarm prevent using diffuse flat priors, unless data strong wise avoid . Rarely appropriate applied setting use prior gives (nearly ) probability mass values near zero gives values bigger age universe nanoseconds. Even much narrower prior , e.g., normal distribution \\(\\sigma = 500\\), tend put much probability mass unreasonable parameter values reasonable ones. fact, using prior \\(\\theta \\sim \\mathsf{Normal(\\mu = 0, \\sigma = 500)}\\) implies strange prior beliefs. example, believe priori \\(P(|\\theta| < 250) < P(|\\theta| > 250)\\), can easily verified calculation normal CDF via approximation Monte Carlo draws: much probability mass outside interval (-250, 250). almost never correspond prior beliefs researcher parameter well-specified applied regression model yet priors like \\(\\theta \\sim \\mathsf{Normal(\\mu = 0, \\sigma = 500)}\\) (extreme) remain quite popular. Even know little, flat wide prior almost never best approximation beliefs parameters model can express using rstanarm (software). amount prior information available. example, even nothing suggest priori particular coefficient positive negative, almost always enough information suggest different orders magnitude equally likely. Making use information setting prior scale parameter simple —one heuristic set scale order magnitude bigger suspect — added benefit helping stabilize computations. -depth discussion non-informative vs weakly informative priors available case study Shape Weakly Informative Prior Affects Inferences.","code":"p <- 1 - 2 * pnorm(-250, mean = 0, sd = 500) print(paste(\"Pr(-250 < theta < 250) =\", round(p, 2))) [1] \"Pr(-250 < theta < 250) = 0.38\" theta <- rnorm(1e5, mean = 0, sd = 500) p_approx <- mean(abs(theta) < 250) print(paste(\"Pr(-250 < theta < 250) =\", round(p_approx, 2))) [1] \"Pr(-250 < theta < 250) = 0.38\" d <- data.frame(theta, clr = abs(theta) > 250) library(ggplot2) ggplot(d, aes(x = theta, fill = clr)) +    geom_histogram(binwidth = 5, show.legend = FALSE) +    scale_y_continuous(name = \"\", labels = NULL, expand = c(0,0)) +    scale_x_continuous(name = expression(theta), breaks = c(-1000, -250, 250, 1000))"},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"specifying-flat-priors","dir":"Articles","previous_headings":"How to Specify Flat Priors (and why you typically shouldn’t)","what":"Specifying flat priors","title":"Prior Distributions for rstanarm Models","text":"rstanarm use flat priors NULL specified rather distribution. example, use flat prior regression coefficients specify prior=NULL: case let rstanarm use default priors intercept error standard deviation (change wanted), coefficient wt variable flat prior. double check indeed flat prior used coefficient wt can call prior_summary:","code":"flat_prior_test <- stan_glm(mpg ~ wt, data = mtcars, prior = NULL) prior_summary(flat_prior_test) Priors for model 'flat_prior_test'  ------ Intercept (after predictors centered)   Specified prior:     ~ normal(location = 20, scale = 2.5)   Adjusted prior:     ~ normal(location = 20, scale = 15)  Coefficients  ~ flat  Auxiliary (sigma)   Specified prior:     ~ exponential(rate = 1)   Adjusted prior:     ~ exponential(rate = 0.17) ------ See help('prior_summary.stanreg') for more details"},{"path":"https://mc-stan.org/rstanarm/articles/priors.html","id":"informative-prior-distributions","dir":"Articles","previous_headings":"","what":"Informative Prior Distributions","title":"Prior Distributions for rstanarm Models","text":"Although default priors tend work well, prudent use informative priors encouraged. example, suppose linear regression model \\[y_i \\sim \\mathsf{Normal}\\left(\\alpha + \\beta_1 x_{1,} + \\beta_2 x_{2,}, \\, \\sigma\\right)\\] evidence (perhaps previous research topic) approximately \\(\\beta_1 \\(-15, -5)\\) \\(\\beta_2 \\(-1, 1)\\). example informative prior \\(\\boldsymbol{\\beta} = (\\beta_1, \\beta_2)'\\) \\[ \\boldsymbol{\\beta} \\sim \\mathsf{Normal} \\left(   \\begin{pmatrix} -10 \\\\ 0 \\end{pmatrix},   \\begin{pmatrix} 5^2 & 0 \\\\ 0 & 2^2 \\end{pmatrix} \\right), \\] sets prior means midpoints intervals allows wiggle room either side. data highly informative parameter values (enough overwhelm prior) prior yield similar results non-informative prior. amount data /signal--noise ratio decrease, using informative prior becomes increasingly important. variables y, x1, x2 data frame dat model can specified left priors intercept error standard deviation defaults, informative priors can specified parameters analogous manner.","code":"my_prior <- normal(location = c(-10, 0), scale = c(5, 2)) stan_glm(y ~ x1 + x2, data = dat, prior = my_prior)"},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"How to Use the rstanarm Package","text":"vignette provides overview use functions rstanarm package focuses commonalities. rstanarm vignettes go particularities individual model-estimating functions. goal rstanarm package make Bayesian estimation routine common regression models applied researchers use. enable researchers avoid counter-intuitiveness frequentist approach probability statistics minimal changes existing R scripts. four steps Bayesian analysis Specify joint distribution outcome(s) unknowns, typically takes form marginal prior distribution unknowns multiplied likelihood outcome(s) conditional unknowns. joint distribution proportional posterior distribution unknowns conditional observed data Draw posterior distribution using Markov Chain Monte Carlo (MCMC). Evaluate well model fits data possibly revise model. Draw posterior predictive distribution outcome(s) given interesting values predictors order visualize manipulation predictor affects (function ) outcome(s). Step 1 necessarily model-specific covered detail vignettes cover specific forms marginal prior distribution likelihood outcome. somewhat involved corresponding first step frequentist analysis, requires likelihood outcome specified. However, default priors rstanarm package work well majority cases. Steps 2, 3, 4 focus vignette largely specific joint distribution Step 1 specified. key concept Step 3 Step 4 posterior predictive distribution, distribution outcome implied model used observed data update beliefs unknown parameters. Frequentists, definition, posterior predictive distribution frequentist predictions subtly different applied researchers seek. Maximum likelihood estimates condition observed outcome data uncertainty estimates pertains variation sampling distribution estimator, .e. distribution estimates occur repeat process drawing random sample well-defined population apply estimator sample. possible construct distribution predictions frequentist paradigm evokes hypothetical repeating process drawing random sample, applying estimator time, generating point predictions outcome. contrast, posterior predictive distribution conditions observed outcome data hand update beliefs unknowns variation resulting distribution predictions reflects remaining uncertainty beliefs unknowns.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"step-1-specify-a-posterior-distribution","dir":"Articles","previous_headings":"","what":"Step 1: Specify a posterior distribution","title":"How to Use the rstanarm Package","text":"sake discussion, need posterior distribution draw . utilize example HSAUR3 package Brian S. Everitt Torsten Hothorn, used 2014 book Handbook Statistical Analyses Using R (3rd Edition) (Chapman & Hall / CRC). book frequentist nature show obtain corresponding Bayesian results. model section 6.3.2 pertains whether survey respondent agrees disagrees conservative statement role women society, modeled function gender education respondents. posterior distribution — independent priors — can written \\[f\\left(\\alpha,\\beta_1,\\beta_2|\\mathbf{y},\\mathbf{X}\\right) \\propto   f\\left(\\alpha\\right) f\\left(\\beta_1\\right) f\\left(\\beta_2\\right) \\times   \\prod_{=1}^J {   g^{-1}\\left(\\eta_i\\right)^{y_i}   \\left(1 - g^{-1}\\left(\\eta_i\\right)\\right)^{n_i-y_i}},\\] \\(\\eta_i = \\alpha + \\beta_1 \\mbox{education}_i + \\beta_2 \\mbox{Female}_i\\) linear predictor function intercept \\(\\left(\\alpha\\right)\\), coefficient years education \\(\\left(\\beta_1\\right)\\), intercept-shift \\(\\left(\\beta_2\\right)\\) case respondent female. data organized \\(y_i\\) number respondents agree statement level education gender, \\(n_i - y_i\\) number people disagree statement. inverse link function, \\(p = g^{-1}\\left(\\eta_i \\right)\\), binomial likelihood can one several Cumulative Distribution Functions (CDFs) case standard logistic CDF, \\(g^{-1}\\left(\\eta_i \\right)=\\frac{1}{1 + e^{-\\eta_i}}\\). Suppose believe — prior seeing data — \\(\\alpha\\), \\(\\beta_1\\), \\(\\beta_2\\) probably close zero, likely positive negative, small chance quite far zero. beliefs can represented Student t distributions degrees freedom order produce moderately heavy tails. particular, specify seven degrees freedom. Note purported beliefs may well skeptical actual beliefs, probably women people education less conservative societal views.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"note-on-prior-beliefs-and-default-priors","dir":"Articles","previous_headings":"Step 1: Specify a posterior distribution","what":"Note on “prior beliefs” and default priors","title":"How to Use the rstanarm Package","text":"vignette use term “prior beliefs” refer generality information content prior distribution (conditional model). Sometimes previous research topic interest motivates beliefs model parameters, times work may exist several studies may make contradictory claims. Regardless, nearly always knowledge reflected choice prior distributions. example, one believes logistic regression coefficient greater five absolute value predictors scaled reasonably. may also seen examples -called “non-informative” (“vague”, “diffuse”, etc.) priors like normal distribution variance 1000. data reasonably scaled, priors almost always bad idea various reasons (give non-trivial weight extreme values, reduce computational efficiency, etc). default priors rstanarm designed weakly informative, mean avoid placing unwarranted prior weight nonsensical parameter values provide regularization avoid overfitting, also allow extreme values warranted data. additional information available, weakly informative defaults can replaced informative priors.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"step-2-draw-from-the-posterior-distribution","dir":"Articles","previous_headings":"","what":"Step 2: Draw from the posterior distribution","title":"How to Use the rstanarm Package","text":"likelihood sample just product \\(J\\) groups \\[g^{-1}\\left(\\eta_i \\right)^{y_i}   \\left(1 - g^{-1}\\left(\\eta_i \\right)\\right)^{n_i-y_i},\\] can maximized \\(\\alpha\\), \\(\\beta_1\\), \\(\\beta_2\\) obtain frequentist estimates calling p-value null hypothesis \\(\\beta_1 = 0\\) small, p-value null hypothesis \\(\\beta_2 = 0\\) large. However, frequentist p-values awkward pertain probability scientific hypothesis true rather probability observing \\(z\\)-statistic large (magnitude) null hypothesis true. desire make probabilistic statements scientific hypothesis one reason many people drawn Bayesian approach. model likelihood Student t priors seven degrees freedom can specified using rstanarm package similar way prepending stan_ glm call specifying priors (optionally number cores computer utilize): can seen, “Bayesian point estimates” — represented posterior medians — similar maximum likelihood estimates. Frequentists ask whether point estimate greater magnitude double estimated standard deviation sampling distribution. simply estimates standard deviation marginal posterior distributions, based scaling Median Absolute Deviation (MAD) posterior medians obtain robust estimator posterior standard deviation. addition, can use posterior_interval function obtain Bayesian uncertainty interval \\(\\beta_1\\): Unlike frequentist confidence intervals — interpretable terms post-data probabilities — Bayesian uncertainty interval indicates believe seeing data \\(0.95\\) probability \\(\\beta_2\\) ci95[1,1] ci95[1,2]. Alternatively, say essentially zero probability \\(\\beta_2 > 0\\), although frequentists make claim coherently. Many post-estimation methods available model estimated glm also available model estimated stan_glm. example, rstanarm provide confint method, although reserved computing confidence intervals case user elects estimate model (penalized) maximum likelihood. using full Bayesian inference (rstanarm default) approximate Bayesian inference posterior_interval function used obtain Bayesian uncertainty intervals.","code":"data(\"womensrole\", package = \"HSAUR3\") womensrole$total <- womensrole$agree + womensrole$disagree womensrole_glm_1 <- glm(cbind(agree, disagree) ~ education + gender,                         data = womensrole, family = binomial(link = \"logit\")) round(coef(summary(womensrole_glm_1)), 3) Estimate Std. Error z value Pr(>|z|) (Intercept)     2.509      0.184  13.646    0.000 education      -0.271      0.015 -17.560    0.000 genderFemale   -0.011      0.084  -0.136    0.892 library(rstanarm) womensrole_bglm_1 <- stan_glm(cbind(agree, disagree) ~ education + gender,                               data = womensrole,                               family = binomial(link = \"logit\"),                                prior = student_t(df = 7, 0, 5),                                prior_intercept = student_t(df = 7, 0, 5),                               cores = 2, seed = 12345) womensrole_bglm_1 stan_glm  family:       binomial [logit]  formula:      cbind(agree, disagree) ~ education + gender  observations: 42  predictors:   3 ------              Median MAD_SD (Intercept)   2.5    0.2   education    -0.3    0.0   genderFemale  0.0    0.1    ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg ci95 <- posterior_interval(womensrole_bglm_1, prob = 0.95, pars = \"education\") round(ci95, 2) 2.5% 97.5% education -0.3 -0.24 cbind(Median = coef(womensrole_bglm_1), MAD_SD = se(womensrole_bglm_1)) Median     MAD_SD (Intercept)   2.52098276 0.18285768 education    -0.27153061 0.01556542 genderFemale -0.01262136 0.08463091 summary(residuals(womensrole_bglm_1)) # not deviance residuals Min.    1st Qu.     Median       Mean    3rd Qu.       Max.       NA's  -0.3076575 -0.0359870 -0.0041319 -0.0003265  0.0660755  0.2822688          1 cov2cor(vcov(womensrole_bglm_1)) (Intercept)   education genderFemale (Intercept)    1.0000000 -0.93963167  -0.23059559 education     -0.9396317  1.00000000  -0.02463045 genderFemale  -0.2305956 -0.02463045   1.00000000"},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"step-3-criticize-the-model","dir":"Articles","previous_headings":"","what":"Step 3: Criticize the model","title":"How to Use the rstanarm Package","text":"launch_shinystan function shinystan package provides almost tools need visualize posterior distribution diagnose problems Markov chains. case, results fine verify , can call open web browser drives visualizations. rest subsection, focus users can programmatically evaluate whether model adequate. minimal requirement Bayesian estimates model fit data estimates conditioned . key function posterior_predict, can passed new data.frame predict --sample, case omitted obtain -sample posterior predictions: resulting matrix rows equal number posterior simulations, case \\(2000\\) columns equal number observations original dataset, \\(42\\) combinations education gender. element matrix predicted number respondents value education gender agreed survey question thus reasonably close observed proportion agreements data. can create plot check : Posterior predictive boxplots vs. observed datapoints boxplots provide median, interquartile range, hinges posterior predictive distribution given gender level education, red points represent corresponding observed data. can seen, model predicts observed data fairly well six sixteen years education predicts less well low high levels education less data. Consequently, might consider model education quadratic effect agreement, easy specify using R’s formula-based syntax. Frequentists test null hypothesis coefficient squared level education zero. Bayesians might ask whether model expected produce better --sample predictions model level education. latter question can answered using leave-one-cross-validation approximation thereof provided loo function loo package, method provided rstanarm package. First, verify posterior sensitive particular observation dataset.  one two moderate outliers (whose statistics greater \\(0.5\\)), much effect resulting model comparison: case, little difference expected log pointwise deviance two models, essentially indifferent taking account second model estimates additional parameter. “LOO Information Criterion (LOOIC)” purpose Akaike Information Criterion (AIC) used frequentists. intended estimate expected log predicted density (ELPD) new dataset. However, AIC ignores priors assumes posterior distribution multivariate normal, whereas functions loo package used assume posterior distribution multivariate normal integrate uncertainty parameters. assumes one observation can omitted without major effect posterior distribution, can judged using plots .","code":"launch_shinystan(womensrole_bglm_1, ppd = FALSE) y_rep <- posterior_predict(womensrole_bglm_1) dim(y_rep) [1] 4000   42 par(mfrow = 1:2, mar = c(5,3.7,1,0) + 0.1, las = 3) boxplot(sweep(y_rep[,womensrole$gender == \"Male\"], 2, STATS =                 womensrole$total[womensrole$gender == \"Male\"], FUN = \"/\"),          axes = FALSE, main = \"Male\", pch = NA,         xlab = \"Years of Education\", ylab = \"Proportion of Agrees\") with(womensrole, axis(1, at = education[gender == \"Male\"] + 1,                        labels = 0:20)) axis(2, las = 1) with(womensrole[womensrole$gender == \"Male\",],       points(education + 1,  agree / (agree + disagree),              pch = 16, col = \"red\")) boxplot(sweep(y_rep[,womensrole$gender == \"Female\"], 2, STATS =            womensrole$total[womensrole$gender == \"Female\"], FUN = \"/\"),            axes = FALSE, main = \"Female\", pch = NA,         xlab = \"Years of Education\", ylab = \"\") with(womensrole, axis(1, at = education[gender == \"Female\"] + 1,      labels = 0:20)) with(womensrole[womensrole$gender == \"Female\",],       points(education + 1,  agree / (agree + disagree),              pch = 16, col = \"red\")) (womensrole_bglm_2 <- update(womensrole_bglm_1, formula. = . ~ . + I(education^2))) stan_glm  family:       binomial [logit]  formula:      cbind(agree, disagree) ~ education + gender + I(education^2)  observations: 42  predictors:   4 ------                Median MAD_SD (Intercept)     2.1    0.4   education      -0.2    0.1   genderFemale    0.0    0.1   I(education^2)  0.0    0.0    ------ * For help interpreting the printed output see ?print.stanreg * For info on the priors used see ?prior_summary.stanreg loo_bglm_1 <- loo(womensrole_bglm_1) loo_bglm_2 <- loo(womensrole_bglm_2) par(mfrow = 1:2, mar = c(5,3.8,1,0) + 0.1, las = 3) plot(loo_bglm_1, label_points = TRUE) plot(loo_bglm_2, label_points = TRUE) loo_compare(loo_bglm_1, loo_bglm_2) elpd_diff se_diff womensrole_bglm_1  0.0       0.0    womensrole_bglm_2 -0.7       1.7 loo_bglm_1 Computed from 4000 by 42 log-likelihood matrix.           Estimate   SE elpd_loo   -104.8  9.5 p_loo         4.2  1.7 looic       209.7 18.9 ------ MCSE of elpd_loo is NA. MCSE and ESS estimates assume independent draws (r_eff=1).  Pareto k diagnostic values:                          Count Pct.    Min. ESS (-Inf, 0.7]   (good)     41    97.6%   446         (0.7, 1]   (bad)       0     0.0%   <NA>        (1, Inf)   (very bad)  1     2.4%   <NA>     See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"step-4-analyze-manipulations-of-predictors","dir":"Articles","previous_headings":"","what":"Step 4: Analyze manipulations of predictors","title":"How to Use the rstanarm Package","text":"Frequentists attempt interpret estimates model, difficult except model linear, inverse link function, contains interaction terms. Bayesians can avoid difficulty simply inspecting posterior predictive distribution different levels predictors. example, can seen, \\(100\\) women college degree versus \\(100\\) women high school degree, expect \\(20\\) fewer college-educated women agree question. even chance difference \\(24\\) \\(16\\), one--four chance greater, one--four chance less.","code":"# note: in newdata we want agree and disagree to sum to the number of people we # want to predict for. the values of agree and disagree don't matter so long as # their sum is the desired number of trials. we need to explicitly imply the # number of trials like this because our original data are aggregate. if we had # bernoulli data then it would be a given we wanted to predict for single # individuals. newdata <- data.frame(agree = c(0,0), disagree = c(100,100), education = c(12,16),                       gender = factor(\"Female\", levels = c(\"Male\", \"Female\"))) y_rep <- posterior_predict(womensrole_bglm_2, newdata) summary(apply(y_rep, 1, diff)) Min. 1st Qu.  Median    Mean 3rd Qu.    Max.   -41.00  -24.00  -20.00  -19.69  -16.00   -1.00"},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"troubleshooting","dir":"Articles","previous_headings":"","what":"Troubleshooting","title":"How to Use the rstanarm Package","text":"section provides suggestions proceed encounter warning messages generated modeling functions rstanarm package. example models used just purposes concisely demonstrating certain difficulties possible remedies (won’t worry merit models ). references end provide information relevant issues.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"markov-chains-did-not-converge","dir":"Articles","previous_headings":"Troubleshooting","what":"Markov chains did not converge","title":"How to Use the rstanarm Package","text":"Recommendation: run chains iterations (certain cases, see qualification ). default, rstanarm modeling functions run four randomly initialized Markov chains, 2000 iterations (including warmup period 1000 iterations discarded). chains must converge target distribution inferences valid. models, default settings sufficient, see warning message Markov chains converging, first thing try increasing number iterations. can done specifying iter argument. However, parameters proper priors (priors set NULL), used default values iterations (2000) chains (4), Rhats (explained ) greater 2, increasing number iterations alone unlikely solve problem. One way monitor whether chain converged equilibrium distribution compare behavior randomly initialized chains. motivation Gelman Rubin potential scale reduction statistic Rhat. Rhat statistic measures ratio average variance draws within chain variance pooled draws across chains; chains equilibrium, Rhat one. chains converged common distribution, Rhat statistic tend greater one. Gelman Rubin’s recommendation independent Markov chains initialized diffuse starting values parameters sampled values Rhat 1.1. Rhat values 1.1 rstanarm print warning message like : illustrate check Rhat values fitting model using rstanarm ’ll fit two models run different numbers iterations. first model leads warning message convergence second model . Indeed, can see many Rhat values much bigger 1 first model: Since didn’t get warning second model shouldn’t find parameters Rhat far 1: Details computation Rhat limitations can found Stan Modeling Language User’s Guide Reference Manual.","code":"Markov chains did not converge! Do not analyze results! bad_rhat <- stan_glm(mpg ~ ., data = mtcars, iter = 20, chains = 2, seed = 12345) Warning: There were 2 chains where the estimated Bayesian Fraction of Missing Information was low. See https://mc-stan.org/misc/warnings.html#bfmi-low Warning: Examine the pairs() plot to diagnose sampling problems Warning: The largest R-hat is 2.83, indicating chains have not mixed. Running the chains for more iterations may help. See https://mc-stan.org/misc/warnings.html#r-hat Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. Running the chains for more iterations may help. See https://mc-stan.org/misc/warnings.html#bulk-ess Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. Running the chains for more iterations may help. See https://mc-stan.org/misc/warnings.html#tail-ess Warning: Markov chains did not converge! Do not analyze results! good_rhat <- update(bad_rhat, iter = 1000, chains = 2, seed = 12345) rhat <- summary(bad_rhat)[, \"Rhat\"] rhat[rhat > 1.1] (Intercept)           cyl          drat            wt          qsec       2.341370      3.218821      2.270997      1.334041      1.350006             vs          gear          carb      mean_PPD log-posterior       2.335472      1.542550      1.948308      1.715434      1.564986 any(summary(good_rhat)[, \"Rhat\"] > 1.1) [1] FALSE"},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"divergent-transitions","dir":"Articles","previous_headings":"Troubleshooting","what":"Divergent transitions","title":"How to Use the rstanarm Package","text":"Recommendation: increase target acceptance rate adapt_delta. Hamiltonian Monte Carlo (HMC), MCMC algorithm used Stan, works simulating evolution Hamiltonian system. Stan uses symplectic integrator approximate exact solution Hamiltonian dynamics. step size parameter large relative curvature log posterior approximation can diverge threaten validity sampler. rstanarm print warning divergent transitions warmup period, case posterior sample may biased. recommended method increase adapt_delta parameter – target average proposal acceptance probability adaptation – turn reduce step size. modeling functions accepts adapt_delta argument, increase adapt_delta can simply change value default value value closer \\(1\\). reduce frequency users need manually set adapt_delta, default value depends prior distribution used (see help(\"adapt_delta\",  package = \"rstanarm\") details). downside increasing target acceptance rate – , consequence, decreasing step size – sampling tend slower. Intuitively, smaller step size means steps required explore posterior distribution. Since validity estimates guaranteed post-warmup divergent transitions, slower sampling minor cost.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"maximum-treedepth-exceeded","dir":"Articles","previous_headings":"Troubleshooting","what":"Maximum treedepth exceeded","title":"How to Use the rstanarm Package","text":"Recommendation: increase maximum allowed treedepth max_treedepth unless convergence diagnostics ok. Configuring -U-Turn-Sampler (variant HMC used Stan) involves putting cap depth trees evaluates iteration. controlled maximum depth parameter max_treedepth. maximum allowed tree depth reached indicates NUTS terminating prematurely avoid excessively long execution time. rstanarm prints warning transitions exceeding maximum treedepth try increasing max_treedepth parameter using optional control argument. example, increase max_treedepth 16 (default used rstanarm 15) can provide argument control = list(max_treedepth = 16) rstanarm modeling functions. see warning hitting maximum treedepth (rare), need worry. models rstanarm capable fitting, get warning max treedepth typically also get warnings diagnostics. However, see max treedepth warning convergence diagnostics fine, can typically ignore warning. case warning likely indicates efficiency issues results invalid analyze.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"How to Use the rstanarm Package","text":"vignette, gone four steps Bayesian analysis. first step — specifying posterior distribution — varies considerably one analysis next likelihood function employed differs depending nature outcome variable prior beliefs parameters model varies situation situation researcher researcher. However, given posterior distribution given posterior distribution can drawn using rstanarm package, remaining steps conceptually similar across analyses. key draw posterior predictive distribution outcome, model predicts outcome updated beliefs unknown parameters observed data. Posterior predictive distributions can used model checking making inferences manipulations predictors affect outcome. course, assumes obtained draws posterior distribution faithfully. functions rstanarm package throw warnings evidence draws tainted, discussed steps remedy problems. part, model-fitting functions rstanarm package unlikely produce many warnings, may appear complicated models. posterior distribution specify first step sampled using rstanarm package, often possible create hand-written program Stan language posterior distribution can drawn using rstan package. See documentation rstan package https://mc-stan.org details advanced usage Stan. However, many relatively simple models can fit using rstanarm package without writing code Stan language, illustrated estimating function rstanarm package vignettes.","code":""},{"path":"https://mc-stan.org/rstanarm/articles/rstanarm.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"How to Use the rstanarm Package","text":"Betancourt, M. J., & Girolami, M. (2013). Hamiltonian Monte Carlo hierarchical models. arXiv preprint. Stan Development Team. (2015). Stan modeling language user’s guide reference manual, Version 2.9.0. https://mc-stan.org/docs/. See ‘Hamiltonian Monte Carlo Sampling’ chapter. Gelman, ., & Rubin, D. B. (1992). Inference iterative simulation using multiple sequences. Statistical Science, 7(4), 457 – 472. Gelman, ., & Shirley, K. (2011). Inference simulations monitoring convergence. S. Brooks, . Gelman, G. Jones, & X. Meng (Eds.), Handbook Markov chain Monte Carlo. Boca Raton: Chapman & Hall/CRC.","code":""},{"path":"https://mc-stan.org/rstanarm/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jonah Gabry. Author. Imad Ali. Contributor. Sam Brilleman. Contributor. Jacqueline Buros Novik. Contributor.           R/stan_jm.R AstraZeneca. Contributor.           R/stan_jm.R Trustees Columbia University. Copyright holder. Simon Wood. Copyright holder.           R/stan_gamm4.R R Core Deveopment Team. Copyright holder.           R/stan_aov.R Douglas Bates. Copyright holder.           R/pp_data.R Martin Maechler. Copyright holder.           R/pp_data.R Ben Bolker. Copyright holder.           R/pp_data.R Steve Walker. Copyright holder.           R/pp_data.R Brian Ripley. Copyright holder.           R/stan_aov.R, R/stan_polr.R William Venables. Copyright holder.           R/stan_polr.R Paul-Christian Burkner. Copyright holder.           R/misc.R Ben Goodrich. Maintainer, author.","code":""},{"path":"https://mc-stan.org/rstanarm/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Goodrich B, Gabry J, Ali & Brilleman S. (2025). rstanarm: Bayesian applied regression modeling via Stan. R package version 2.32.2 https://mc-stan.org/rstanarm. Brilleman SL, Crowther MJ, Moreno-Betancur M, Buros Novik J & Wolfe R. Joint longitudinal time--event models via Stan. StanCon 2018. 10-12 Jan 2018. Pacific Grove, CA, USA. https://github.com/stan-dev/stancon_talks/","code":"@Misc{,   title = {rstanarm: {Bayesian} applied regression modeling via {Stan}.},   author = {Ben Goodrich and Jonah Gabry and Imad Ali and Sam Brilleman},   note = {R package version 2.32.2},   year = {2025},   url = {https://mc-stan.org/rstanarm/}, } @Misc{,   title = {Joint longitudinal and time-to-event models via {Stan}.},   author = {SL Brilleman and MJ Crowther and M Moreno-Betancur and J {Buros Novik} and R Wolfe},   note = {StanCon 2018. 10-12 Jan 2018. Pacific Grove, CA, USA.},   url = {https://github.com/stan-dev/stancon_talks/},   year = {2018}, }"},{"path":[]},{"path":"https://mc-stan.org/rstanarm/index.html","id":"bayesian-applied-regression-modeling-arm-via-stan","dir":"","previous_headings":"","what":"Bayesian applied regression modeling (arm) via Stan","title":"Bayesian Applied Regression Modeling via Stan","text":"R package emulates R model-fitting functions uses Stan (via rstan package) back-end estimation. primary target audience people open Bayesian inference using Bayesian software easier use frequentist software otherwise. Fitting models rstanarm also useful experienced Bayesian software users want take advantage pre-compiled Stan programs written Stan developers carefully implemented prioritize numerical stability avoidance sampling problems. rstanarm package appendage rstan package, R interface Stan. rstanarm enables many common applied regression models estimated using Markov Chain Monte Carlo, variational approximations posterior distribution, optimization. package allows models specified using customary R modeling syntax (e.g., like glm formula data.frame). Additional arguments provided specifying prior distributions. set models supported rstanarm large (continue grow), also limited enough possible integrate tightly pp_check function graphical posterior predictive checks using bayesplot posterior_predict function easily estimate effect specific manipulations predictor variables predict outcome training set. fitted model objects returned rstanarm modeling functions called stanreg objects. addition traditional methods defined fitted model objects, stanreg objects can also used loo package leave-one-cross-validation, model comparison, model weighting/averaging shinystan package exploring posterior distribution model diagnostics graphical user interface. model estimating functions described greater detail individual help pages vignettes. provide brief overview: stan_lm, stan_aov,stan_biglm Similar lm aov novel regularizing priors model parameters driven prior beliefs R-squared, proportion variance outcome attributable predictors linear model. stan_glm, stan_glm.nb Similar glm various possible prior distributions coefficients , applicable, prior distribution auxiliary parameter Generalized Linear Model (GLM) characterized family object (e.g. shape parameter Gamma models). also possible estimate negative binomial model similar glm.nb function MASS package. stan_glmer, stan_glmer.nb, stan_lmer Similar glmer, glmer.nb, lmer functions (lme4 package) GLMs augmented group-specific terms deviate common coefficients according mean-zero multivariate normal distribution highly-structured unknown covariance matrix (rstanarm introduces innovative prior distribution). MCMC provides appropriate estimates uncertainty models consist mix common group-specific parameters. stan_nlmer Similar nlmer (lme4 package) package nonlinear “mixed-effects” models, flexible priors can specified parameters model, including unknown covariance matrices varying (group-specific) coefficients. stan_gamm4 Similar gamm4 (gamm4 package), augments GLM (possibly group-specific terms) nonlinear smooth functions predictors form Generalized Additive Mixed Model (GAMM). Rather calling lme4::glmer like gamm4 , stan_gamm4 essentially calls stan_glmer, avoids optimization issues often crop GAMMs provides better estimates uncertainty parameter estimates. stan_polr Similar polr (MASS package) models ordinal response, Bayesian model also implies prior distribution unknown cutpoints. Can also used model binary outcomes, possibly estimating unknown exponent governing probability success. stan_betareg Similar betareg (betareg package) models outcome rate (proportion) , rather performing maximum likelihood estimation, full Bayesian estimation performed default, customizable prior distributions parameters. stan_clogit Similar clogit (survival package) models binary outcome number successes failures fixed within stratum research design. minor syntactical differences relative survival::clogit allow stan_clogit accept group-specific terms stan_glmer. stan_mvmer multivariate form stan_glmer, whereby user can specify one submodels consisting GLM group-specific terms. one submodel specified (.e. one outcome variable) dependence induced assuming group-specific terms grouping factor correlated across submodels. stan_jm Estimates shared parameter joint models longitudinal time--event (.e. survival) data. joint model can univariate (.e. one longitudinal outcome) multivariate (.e. one longitudinal outcome). variety parameterisations available linking longitudinal event processes (.e. variety association structures). modeling functions rstanarm package take algorithm argument can one following: Sampling (algorithm=\"sampling\"): Uses Markov Chain Monte Carlo (MCMC) — particular, Stan’s implementation Hamiltonian Monte Carlo (HMC) tuned diagonal mass matrix — draw posterior distribution parameters. slowest reliable available estimation algorithms default recommended algorithm statistical inference. Mean-field (algorithm=\"meanfield\"): Uses mean-field variational inference draw approximation posterior distribution. particular, algorithm finds set independent normal distributions unconstrained space — transformed constrained space — closely approximate posterior distribution. draws repeatedly independent normal distributions transforms constrained space. entire process much faster HMC yields independent draws recommended final statistical inference. can useful narrow set candidate models large problems, particularly specifying QR=TRUE stan_glm, stan_glmer, stan_gamm4, approximation posterior distribution. Full-rank (algorithm=\"fullrank\"): Uses full-rank variational inference draw approximation posterior distribution finding multivariate normal distribution unconstrained space — transformed constrained space — closely approximates posterior distribution. draws repeatedly multivariate normal distribution transforms draws constrained space. process slower meanfield variational inference faster HMC. Although still approximation posterior distribution thus recommended final statistical inference, approximation realistic mean-field variational inference parameters assumed independent unconstrained space. Nevertheless, fullrank variational inference difficult optimization problem algorithm prone non-convergence convergence local optimum. Optimizing (algorithm=\"optimizing\"): Finds posterior mode using C++ implementation LBGFS algorithm. prior information, equivalent maximum likelihood, case great reason use functions rstanarm package emulated functions packages. However, priors specified, estimates penalized maximum likelihood estimates, may redeeming value. Currently, optimization supported stan_glm.","code":""},{"path":"https://mc-stan.org/rstanarm/index.html","id":"resources","dir":"","previous_headings":"","what":"Resources","title":"Bayesian Applied Regression Modeling via Stan","text":"mc-stan.org/rstanarm (online documentation, vignettes) Ask question (Stan Forums Discourse) Open issue (GitHub issues bug reports, feature requests)","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/index.html","id":"latest-release","dir":"","previous_headings":"Installation","what":"Latest Release","title":"Bayesian Applied Regression Modeling via Stan","text":"recent rstanarm release can installed CRAN via","code":"install.packages(\"rstanarm\")"},{"path":"https://mc-stan.org/rstanarm/index.html","id":"development-version","dir":"","previous_headings":"Installation","what":"Development Version","title":"Bayesian Applied Regression Modeling via Stan","text":"install GitHub, first make sure can install rstan package C++ toolchain following instructions. rstan successfully installed, can install rstanarm GitHub using remotes package executing following R: can switch build_vignettes TRUE takes lot longer install vignettes already separately available Stan website CRAN. installation fails, please let us know filing issue.","code":"# Change 2 to however many cores you can/want to use to parallelize install # If you experience crashes or run out RAM during installation, try changing this to 1 Sys.setenv(MAKEFLAGS = \"-j2\") Sys.setenv(\"R_REMOTES_NO_ERRORS_FROM_WARNINGS\" = \"true\") remotes::install_github(\"stan-dev/rstanarm\", INSTALL_opts = \"--no-multiarch\", force = TRUE)"},{"path":"https://mc-stan.org/rstanarm/index.html","id":"survival-analysis-version","dir":"","previous_headings":"Installation","what":"Survival Analysis Version","title":"Bayesian Applied Regression Modeling via Stan","text":"feature/survival branch GitHub contains development version rstanarm includes survival analysis functionality (via stan_surv modelling function). functionality available CRAN release rstanarm, users wish use survival analysis functionality can install binary version survival branch rstanarm Stan R packages repository : Note binary static (.e. automatically updated) hosted users can access (experimental) survival analysis functionality without needing go time consuming (sometimes painful) task installing development version rstanarm source.","code":"install.packages(\"rstanarm\", repos = c('https://stan-dev.r-universe.dev', getOption(\"repos\")))"},{"path":"https://mc-stan.org/rstanarm/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Bayesian Applied Regression Modeling via Stan","text":"interested contributing development rstanarm please see developer notes page.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/QR-argument.html","id":null,"dir":"Reference","previous_headings":"","what":"The QR argument — QR-argument","title":"The QR argument — QR-argument","text":"Details QR argument rstanarm's modeling functions.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/QR-argument.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The QR argument — QR-argument","text":"QR argument logical scalar defaulting   FALSE, TRUE applies scaled qr   decomposition design matrix, \\(X = Q^\\ast R^\\ast\\).   autoscale = TRUE (default)   call function passed prior argument,   \\(Q^\\ast = Q \\sqrt{n-1}\\)   \\(R^\\ast = \\frac{1}{\\sqrt{n-1}} R\\).   autoscale = FALSE, \\(R\\) scaled lower-right   element \\(R^\\ast\\) \\(1\\). coefficients relative \\(Q^\\ast\\) obtained   premultiplied inverse \\(R^{\\ast}\\) obtain coefficients   relative original predictors, \\(X\\). Thus,   autoscale = FALSE, coefficient last column \\(X\\)   coefficient last column \\(Q^\\ast\\). transformations change likelihood data   recommended computational reasons multiple predictors.   Importantly, columns \\(X\\) almost generally correlated,   columns \\(Q^\\ast\\) uncorrelated design, often makes   sampling posterior easier. However, QR   TRUE prior argument applies coefficients relative   \\(Q^\\ast\\) (interpretable), setting QR=TRUE   recommended informative prior regression   coefficients informative prior last regression   coefficient (case set autoscale = FALSE   specifying priors). details see Stan case study   QR Decomposition Regression Models   https://mc-stan.org/users/documentation/case-studies/qr_regression.html.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/QR-argument.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The QR argument — QR-argument","text":"Stan Development Team. Stan Modeling Language Users Guide Reference Manual. https://mc-stan.org/users/documentation/.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/adapt_delta.html","id":null,"dir":"Reference","previous_headings":"","what":"adapt_delta: Target average acceptance probability — adapt_delta","title":"adapt_delta: Target average acceptance probability — adapt_delta","text":"Details adapt_delta argument rstanarm's modeling functions.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/adapt_delta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"adapt_delta: Target average acceptance probability — adapt_delta","text":"-U-Turn Sampler (NUTS), variant Hamiltonian Monte   Carlo used used rstanarm, adapt_delta target average   proposal acceptance probability Stan's adaptation period.   adapt_delta ignored rstanarm algorithm argument   set \"sampling\". default value adapt_delta 0.95, except prior   regression coefficients R2, hs,   hs_plus, case default 0.99. defaults higher (conservative) default   adapt_delta=0.8 used rstan package, may result   slower sampling speeds robust posterior distributions   high curvature. general need change adapt_delta unless see   warning message divergent transitions, case can   increase adapt_delta default value closer 1   (e.g. 0.95 0.99, 0.99 0.999, etc). step size used   numerical integrator function adapt_delta   increasing adapt_delta result smaller step size fewer   divergences. Increasing adapt_delta typically result   slower sampler, always lead robust sampler.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/adapt_delta.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"adapt_delta: Target average acceptance probability — adapt_delta","text":"Stan Development Team. Stan Modeling Language Users Guide Reference Manual. https://mc-stan.org/users/documentation/. Brief Guide Stan's Warnings:   https://mc-stan.org/misc/warnings.html#divergent-transitions--warmup","code":""},{"path":"https://mc-stan.org/rstanarm/reference/as.matrix.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the posterior sample — as.matrix.stanreg","title":"Extract the posterior sample — as.matrix.stanreg","text":"models fit using MCMC (algorithm=\"sampling\"), posterior sample —post-warmup draws posterior distribution— can extracted fitted model object matrix, data frame, array. .matrix .data.frame methods merge chains together, whereas .array method keeps chains separate. models fit using optimization (\"optimizing\") variational inference (\"meanfield\" \"fullrank\"), posterior sample rather matrix (data frame) 1000 draws either asymptotic multivariate Gaussian sampling distribution parameters variational approximation posterior distribution.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/as.matrix.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the posterior sample — as.matrix.stanreg","text":"","code":"# S3 method for class 'stanreg' as.matrix(x, ..., pars = NULL, regex_pars = NULL)  # S3 method for class 'stanreg' as.array(x, ..., pars = NULL, regex_pars = NULL)  # S3 method for class 'stanreg' as.data.frame(x, ..., pars = NULL, regex_pars = NULL)"},{"path":"https://mc-stan.org/rstanarm/reference/as.matrix.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the posterior sample — as.matrix.stanreg","text":"x fitted model object returned one rstanarm modeling functions. See stanreg-objects. ... Ignored. pars optional character vector parameter names. regex_pars optional character vector regular expressions use parameter selection. regex_pars can used place pars addition pars. Currently, functions accept regex_pars argument ignore models fit using optimization.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/as.matrix.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the posterior sample — as.matrix.stanreg","text":"matrix, data.frame, array, dimensions depend   pars regex_pars, well model estimation   algorithm (see Description section ).","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/as.matrix.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the posterior sample — as.matrix.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{ if (!exists(\"example_model\")) example(example_model) # Extract posterior sample after MCMC draws <- as.matrix(example_model) print(dim(draws))  # For example, we can see that the median of the draws for the intercept  # is the same as the point estimate rstanarm uses print(median(draws[, \"(Intercept)\"])) print(example_model$coefficients[[\"(Intercept)\"]])  # The as.array method keeps the chains separate draws_array <- as.array(example_model) print(dim(draws_array)) # iterations x chains x parameters  # Extract draws from asymptotic Gaussian sampling distribution  # after optimization fit <- stan_glm(mpg ~ wt, data = mtcars, algorithm = \"optimizing\") draws <- as.data.frame(fit) print(colnames(draws)) print(nrow(draws)) # 1000 draws are taken  # Extract draws from variational approximation to the posterior distribution fit2 <- update(fit, algorithm = \"meanfield\") draws <- as.data.frame(fit2, pars = \"wt\") print(colnames(draws)) print(nrow(draws)) # 1000 draws are taken # } } #>  #> exmpl_> if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { #> exmpl_+ example_model <-  #> exmpl_+   stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd), #> exmpl_+              data = lme4::cbpp, family = binomial, QR = TRUE, #> exmpl_+              # this next line is only to keep the example small in size! #> exmpl_+              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0) #> exmpl_+ example_model #> exmpl_+ } #> stan_glmer #>  family:       binomial [logit] #>  formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd) #>  observations: 56 #> ------ #>             Median MAD_SD #> (Intercept) -1.5    0.6   #> size         0.0    0.0   #> period2     -1.0    0.3   #> period3     -1.1    0.4   #> period4     -1.6    0.5   #>  #> Error terms: #>  Groups Name        Std.Dev. #>  herd   (Intercept) 0.76     #> Num. levels: herd 15  #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg #> [1] 1000   21 #> [1] -1.515377 #> [1] -1.515377 #> [1] 500   2  21 #> [1] \"(Intercept)\" \"wt\"          \"sigma\"       #> [1] 1000 #> Chain 1: ------------------------------------------------------------ #> Chain 1: EXPERIMENTAL ALGORITHM: #> Chain 1:   This procedure has not been thoroughly tested and may be unstable #> Chain 1:   or buggy. The interface is subject to change. #> Chain 1: ------------------------------------------------------------ #> Chain 1:  #> Chain 1:  #> Chain 1:  #> Chain 1: Gradient evaluation took 2.2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Begin eta adaptation. #> Chain 1: Iteration:   1 / 250 [  0%]  (Adaptation) #> Chain 1: Iteration:  50 / 250 [ 20%]  (Adaptation) #> Chain 1: Iteration: 100 / 250 [ 40%]  (Adaptation) #> Chain 1: Iteration: 150 / 250 [ 60%]  (Adaptation) #> Chain 1: Iteration: 200 / 250 [ 80%]  (Adaptation) #> Chain 1: Success! Found best value [eta = 1] earlier than expected. #> Chain 1:  #> Chain 1: Begin stochastic gradient ascent. #> Chain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  #> Chain 1:    100         -199.711             1.000            1.000 #> Chain 1:    200         -145.781             0.685            1.000 #> Chain 1:    300         -134.939             0.483            0.370 #> Chain 1:    400         -124.247             0.384            0.370 #> Chain 1:    500         -114.013             0.325            0.090 #> Chain 1:    600          -97.593             0.299            0.168 #> Chain 1:    700          -89.716             0.269            0.090 #> Chain 1:    800          -89.115             0.236            0.090 #> Chain 1:    900          -89.614             0.210            0.088 #> Chain 1:   1000          -89.450             0.190            0.088 #> Chain 1:   1100          -89.124             0.090            0.086 #> Chain 1:   1200          -89.136             0.053            0.080 #> Chain 1:   1300          -89.459             0.045            0.007 #> Chain 1:   1400          -89.339             0.037            0.006 #> Chain 1:   1500          -89.409             0.028            0.004 #> Chain 1:   1600          -89.057             0.012            0.004 #> Chain 1:   1700          -89.342             0.003            0.004 #> Chain 1:   1800          -88.968             0.003            0.004 #> Chain 1:   1900          -89.288             0.003            0.004 #> Chain 1:   2000          -89.399             0.003            0.004 #> Chain 1:   2100          -89.904             0.003            0.004 #> Chain 1:   2200          -89.471             0.003            0.004 #> Chain 1:   2300          -89.648             0.003            0.004 #> Chain 1:   2400          -89.044             0.004            0.004 #> Chain 1:   2500          -89.182             0.004            0.004 #> Chain 1:   2600          -89.249             0.003            0.004 #> Chain 1:   2700          -89.307             0.003            0.004 #> Chain 1:   2800          -89.656             0.003            0.004 #> Chain 1:   2900          -89.055             0.003            0.004 #> Chain 1:   3000          -89.374             0.004            0.004 #> Chain 1:   3100          -89.347             0.003            0.004 #> Chain 1:   3200          -89.044             0.003            0.003 #> Chain 1:   3300          -89.282             0.003            0.003 #> Chain 1:   3400          -89.180             0.002            0.003 #> Chain 1:   3500          -89.445             0.003            0.003 #> Chain 1:   3600          -88.930             0.003            0.003 #> Chain 1:   3700          -89.128             0.003            0.003 #> Chain 1:   3800          -89.273             0.003            0.003 #> Chain 1:   3900          -89.221             0.002            0.003 #> Chain 1:   4000          -88.955             0.002            0.003 #> Chain 1:   4100          -89.087             0.002            0.003 #> Chain 1:   4200          -89.442             0.003            0.003 #> Chain 1:   4300          -89.457             0.002            0.002 #> Chain 1:   4400          -89.148             0.003            0.003 #> Chain 1:   4500          -89.370             0.002            0.002 #> Chain 1:   4600          -88.966             0.002            0.002 #> Chain 1:   4700          -89.159             0.002            0.002 #> Chain 1:   4800          -89.471             0.003            0.003 #> Chain 1:   4900          -89.269             0.003            0.003 #> Chain 1:   5000          -89.090             0.003            0.002 #> Chain 1:   5100          -89.190             0.003            0.002 #> Chain 1:   5200          -89.215             0.002            0.002 #> Chain 1:   5300          -89.220             0.002            0.002 #> Chain 1:   5400          -89.496             0.002            0.002 #> Chain 1:   5500          -89.219             0.002            0.002 #> Chain 1:   5600          -89.212             0.002            0.002 #> Chain 1:   5700          -89.269             0.002            0.002 #> Chain 1:   5800          -89.702             0.002            0.002 #> Chain 1:   5900          -89.541             0.002            0.002 #> Chain 1:   6000          -89.517             0.002            0.001 #> Chain 1:   6100          -89.470             0.001            0.001 #> Chain 1:   6200          -89.060             0.002            0.002 #> Chain 1:   6300          -89.467             0.002            0.003 #> Chain 1:   6400          -89.174             0.002            0.003 #> Chain 1:   6500          -89.106             0.002            0.002 #> Chain 1:   6600          -89.083             0.002            0.002 #> Chain 1:   6700          -89.312             0.002            0.003 #> Chain 1:   6800          -89.392             0.002            0.002 #> Chain 1:   6900          -89.270             0.002            0.001 #> Chain 1:   7000          -88.979             0.002            0.003 #> Chain 1:   7100          -89.230             0.002            0.003 #> Chain 1:   7200          -88.998             0.002            0.003 #> Chain 1:   7300          -89.365             0.002            0.003 #> Chain 1:   7400          -89.208             0.002            0.003 #> Chain 1:   7500          -89.108             0.002            0.003 #> Chain 1:   7600          -89.129             0.002            0.003 #> Chain 1:   7700          -88.939             0.002            0.002 #> Chain 1:   7800          -89.534             0.003            0.003 #> Chain 1:   7900          -88.906             0.003            0.003 #> Chain 1:   8000          -89.087             0.003            0.003 #> Chain 1:   8100          -88.991             0.003            0.002 #> Chain 1:   8200          -88.983             0.003            0.002 #> Chain 1:   8300          -89.323             0.003            0.002 #> Chain 1:   8400          -89.016             0.003            0.002 #> Chain 1:   8500          -89.293             0.003            0.003 #> Chain 1:   8600          -89.358             0.003            0.003 #> Chain 1:   8700          -89.161             0.003            0.003 #> Chain 1:   8800          -88.894             0.003            0.003 #> Chain 1:   8900          -89.349             0.002            0.003 #> Chain 1:   9000          -89.346             0.002            0.003 #> Chain 1:   9100          -89.402             0.002            0.003 #> Chain 1:   9200          -89.223             0.002            0.003 #> Chain 1:   9300          -89.061             0.002            0.002 #> Chain 1:   9400          -88.958             0.002            0.002 #> Chain 1:   9500          -89.476             0.002            0.002 #> Chain 1:   9600          -89.143             0.003            0.002 #> Chain 1:   9700          -89.275             0.002            0.002 #> Chain 1:   9800          -88.954             0.003            0.002 #> Chain 1:   9900          -89.765             0.003            0.002 #> Chain 1:   10000          -89.301             0.003            0.004 #> Chain 1: Informational Message: The maximum number of iterations is reached! The algorithm may not have converged. #> Chain 1: This variational approximation is not guaranteed to be meaningful. #> Chain 1:  #> Chain 1: Drawing a sample of size 1000 from the approximate posterior...  #> Chain 1: COMPLETED. #> Warning: Pareto k diagnostic value is 0.9. Resampling is unreliable. Increasing the number of draws or decreasing tol_rel_obj may help. #> [1] \"wt\" #> [1] 1000"},{"path":"https://mc-stan.org/rstanarm/reference/available-algorithms.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation algorithms available for rstanarm models — available-algorithms","title":"Estimation algorithms available for rstanarm models — available-algorithms","text":"Estimation algorithms available rstanarm models","code":""},{"path":"https://mc-stan.org/rstanarm/reference/available-algorithms.html","id":"estimation-algorithms","dir":"Reference","previous_headings":"","what":"Estimation algorithms","title":"Estimation algorithms available for rstanarm models — available-algorithms","text":"modeling functions rstanarm package take algorithm argument can one following: Sampling (algorithm=\"sampling\") Uses Markov Chain Monte Carlo (MCMC) — particular, Hamiltonian Monte  Carlo (HMC) tuned diagonal mass matrix — draw  posterior distribution parameters. See sampling  (rstan) details. slowest reliable  available estimation algorithms default  recommended algorithm statistical inference. Mean-field (algorithm=\"meanfield\") Uses mean-field variational inference draw approximation  posterior distribution. particular, algorithm finds set  independent normal distributions unconstrained space —  transformed constrained space — closely approximate  posterior distribution. draws repeatedly independent  normal distributions transforms constrained space.  entire process much faster HMC yields independent draws  recommended final statistical inference. can  useful narrow set candidate models large problems, particularly  specifying QR=TRUE stan_glm,  stan_glmer, stan_gamm4,  approximation posterior distribution. Full-rank (algorithm=\"fullrank\") Uses full-rank variational inference draw approximation  posterior distribution finding multivariate normal distribution  unconstrained space — transformed constrained space  — closely approximates posterior distribution. draws  repeatedly multivariate normal distribution transforms  draws constrained space. process slower meanfield  variational inference faster HMC. Although still  approximation posterior distribution thus recommended  final statistical inference, approximation realistic  mean-field variational inference parameters  assumed independent unconstrained space. Nevertheless, fullrank  variational inference difficult optimization problem  algorithm prone non-convergence convergence local  optimum. Optimizing (algorithm=\"optimizing\") Finds posterior mode using C++ implementation LBGFS algorithm.  See optimizing details. prior  information, equivalent maximum likelihood, case  great reason use functions rstanarm package  emulated functions packages. However, priors  specified, estimates penalized maximum likelihood estimates,  may redeeming value. Currently, optimization  supported stan_glm.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/available-models.html","id":null,"dir":"Reference","previous_headings":"","what":"Modeling functions available in rstanarm — available-models","title":"Modeling functions available in rstanarm — available-models","text":"Modeling functions available rstanarm","code":""},{"path":"https://mc-stan.org/rstanarm/reference/available-models.html","id":"modeling-functions","dir":"Reference","previous_headings":"","what":"Modeling functions","title":"Modeling functions available in rstanarm — available-models","text":"model estimating functions described greater detail individual help pages vignettes. provide brief overview: stan_lm, stan_aov, stan_biglm Similar lm aov   novel regularizing priors model parameters driven prior   beliefs \\(R^2\\), proportion variance outcome   attributable predictors linear model. stan_glm, stan_glm.nb Similar glm various possible prior  distributions coefficients , applicable, prior distribution  auxiliary parameter Generalized Linear Model (GLM)  characterized family object (e.g. shape  parameter Gamma models). also possible estimate negative  binomial model similar way glm.nb function  MASS package. stan_glmer, stan_glmer.nb, stan_lmer Similar glmer, glmer.nb   lmer functions lme4 package GLMs   augmented group-specific terms deviate common   coefficients according mean-zero multivariate normal distribution   highly-structured unknown covariance matrix (rstanarm   introduces innovative prior distribution). MCMC provides   appropriate estimates uncertainty models consist mix   common group-specific parameters. stan_nlmer Similar nlmer lme4 package   nonlinear \"mixed-effects\" models, group-specific coefficients   flexible priors unknown covariance matrices. stan_gamm4 Similar gamm4 gamm4 package,   augments GLM (possibly group-specific terms) nonlinear smooth   functions predictors form Generalized Additive Mixed Model   (GAMM). Rather calling glmer like   gamm4 , stan_gamm4 essentially calls   stan_glmer, avoids optimization issues often   crop GAMMs provides better estimates uncertainty   parameter estimates. stan_polr Similar polr MASS package   models ordinal response, Bayesian model also implies prior   distribution unknown cutpoints. Can also used model binary   outcomes, possibly estimating unknown exponent governing   probability success. stan_betareg Similar betareg models outcome   rate (proportion) , rather performing maximum likelihood   estimation, full Bayesian estimation performed default,   customizable prior distributions parameters. stan_clogit Similar clogit models binary outcome    number successes failures fixed within stratum    research design. minor syntactical differences relative    clogit allow stan_clogit accept    group-specific terms stan_glmer. stan_mvmer multivariate form stan_glmer, whereby user can    specify one submodels consisting GLM group-specific    terms. one submodel specified (.e. one    outcome variable) dependence induced assuming    group-specific terms grouping factor correlated across submodels. stan_jm Estimates shared parameter joint models longitudinal time--event    (.e. survival) data. joint model can univariate (.e. one longitudinal    outcome) multivariate (.e. one longitudinal outcome). variety    parameterisations available linking longitudinal event    processes (.e. variety association structures).","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/bayes_R2.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a Bayesian version of R-squared or LOO-adjusted R-squared for regression models. — bayes_R2.stanreg","title":"Compute a Bayesian version of R-squared or LOO-adjusted R-squared for regression models. — bayes_R2.stanreg","text":"Compute Bayesian version R-squared LOO-adjusted R-squared regression models.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/bayes_R2.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a Bayesian version of R-squared or LOO-adjusted R-squared for regression models. — bayes_R2.stanreg","text":"","code":"# S3 method for class 'stanreg' bayes_R2(object, ..., re.form = NULL)  # S3 method for class 'stanreg' loo_R2(object, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/bayes_R2.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a Bayesian version of R-squared or LOO-adjusted R-squared for regression models. — bayes_R2.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. ... Currently ignored. re.form models group-level terms, re.form passed posterior_epred specified.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/bayes_R2.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a Bayesian version of R-squared or LOO-adjusted R-squared for regression models. — bayes_R2.stanreg","text":"vector R-squared values length equal posterior   sample size (posterior distribution R-squared).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/bayes_R2.stanreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute a Bayesian version of R-squared or LOO-adjusted R-squared for regression models. — bayes_R2.stanreg","text":"Andrew Gelman, Ben Goodrich, Jonah Gabry, Aki Vehtari (2019). R-squared Bayesian regression models. American Statistician, appear. doi:10.1080/00031305.2018.1549100  (Article, Notebook)","code":""},{"path":"https://mc-stan.org/rstanarm/reference/bayes_R2.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute a Bayesian version of R-squared or LOO-adjusted R-squared for regression models. — bayes_R2.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { fit <- stan_glm(   mpg ~ wt + cyl,    data = mtcars,    QR = TRUE,    chains = 2,    refresh = 0 ) rsq <- bayes_R2(fit) print(median(rsq)) hist(rsq)  loo_rsq <- loo_R2(fit) print(median(loo_rsq))  # multilevel binomial model if (!exists(\"example_model\")) example(example_model) print(example_model) median(bayes_R2(example_model)) median(bayes_R2(example_model, re.form = NA)) # exclude group-level } #> [1] 0.8156549  #> [1] 0.7993705 #> stan_glmer #>  family:       binomial [logit] #>  formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd) #>  observations: 56 #> ------ #>             Median MAD_SD #> (Intercept) -1.5    0.6   #> size         0.0    0.0   #> period2     -1.0    0.3   #> period3     -1.1    0.4   #> period4     -1.6    0.5   #>  #> Error terms: #>  Groups Name        Std.Dev. #>  herd   (Intercept) 0.76     #> Num. levels: herd 15  #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg #> [1] 0.6206511"},{"path":"https://mc-stan.org/rstanarm/reference/example_jm.html","id":null,"dir":"Reference","previous_headings":"","what":"Example joint longitudinal and time-to-event model — example_jm","title":"Example joint longitudinal and time-to-event model — example_jm","text":"model use rstanarm examples related stan_jm.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/example_jm.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example joint longitudinal and time-to-event model — example_jm","text":"Calling example(\"example_jm\") run model   Examples section, , resulting stanmvreg object   available global environment. chains iter   arguments specified make example small size. practice,   recommend left unspecified order use default   values increased convergence problems. cores   argument optional multicore system, user may well want   set equal number chains executed.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/example_jm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example joint longitudinal and time-to-event model — example_jm","text":"","code":"# set.seed(123)   if (.Platform$OS.type != \"windows\" || .Platform$r_arch !=\"i386\")   example_jm <-       stan_jm(formulaLong = logBili ~ year + (1 | id),               dataLong = pbcLong[1:101,],              formulaEvent = survival::Surv(futimeYears, death) ~ sex + trt,               dataEvent = pbcSurv[1:15,],              time_var = \"year\",              # this next line is only to keep the example small in size!              chains = 1, seed = 12345, iter = 100, refresh = 0) #> Loading required namespace: data.table #> Fitting a univariate joint model. #>  #> Please note the warmup may be much slower than later iterations! #> Warning: The largest R-hat is 1.07, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess"},{"path":"https://mc-stan.org/rstanarm/reference/example_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Example model — example_model","title":"Example model — example_model","text":"model use rstanarm examples.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/example_model.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example model — example_model","text":"Calling example(\"example_model\") run model   Examples section, , resulting stanreg object   available global environment. chains iter   arguments specified make example small size. practice,   recommend left unspecified order use default   values (4 2000 respectively) increased convergence   problems. cores argument optional multicore system,   user may well want set equal number chains   executed.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/example_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example model — example_model","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { example_model <-    stan_glmer(cbind(incidence, size - incidence) ~ size + period + (1|herd),              data = lme4::cbpp, family = binomial, QR = TRUE,              # this next line is only to keep the example small in size!              chains = 2, cores = 1, seed = 12345, iter = 1000, refresh = 0) example_model } #> stan_glmer #>  family:       binomial [logit] #>  formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd) #>  observations: 56 #> ------ #>             Median MAD_SD #> (Intercept) -1.5    0.6   #> size         0.0    0.0   #> period2     -1.0    0.3   #> period3     -1.1    0.4   #> period4     -1.6    0.5   #>  #> Error terms: #>  Groups Name        Std.Dev. #>  herd   (Intercept) 0.76     #> Num. levels: herd 15  #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg"},{"path":"https://mc-stan.org/rstanarm/reference/family.stanmvreg.html","id":null,"dir":"Reference","previous_headings":"","what":"family method for stanmvreg objects — family.stanmvreg","title":"family method for stanmvreg objects — family.stanmvreg","text":"family method stanmvreg objects","code":""},{"path":"https://mc-stan.org/rstanarm/reference/family.stanmvreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"family method for stanmvreg objects — family.stanmvreg","text":"","code":"# S3 method for class 'stanmvreg' family(object, m = NULL, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/family.stanmvreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"family method for stanmvreg objects — family.stanmvreg","text":"object, ... See family. m Integer specifying number name submodel","code":""},{"path":"https://mc-stan.org/rstanarm/reference/family.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"family method for stanreg objects — family.stanreg","title":"family method for stanreg objects — family.stanreg","text":"family method stanreg objects","code":""},{"path":"https://mc-stan.org/rstanarm/reference/family.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"family method for stanreg objects — family.stanreg","text":"","code":"# S3 method for class 'stanreg' family(object, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/family.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"family method for stanreg objects — family.stanreg","text":"object, ... See family.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/formula.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"formula method for stanreg objects — formula.stanreg","title":"formula method for stanreg objects — formula.stanreg","text":"formula method stanreg objects","code":""},{"path":"https://mc-stan.org/rstanarm/reference/formula.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"formula method for stanreg objects — formula.stanreg","text":"","code":"# S3 method for class 'stanreg' formula(x, ..., m = NULL)"},{"path":"https://mc-stan.org/rstanarm/reference/formula.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"formula method for stanreg objects — formula.stanreg","text":"x stanreg object. ... Can contain fixed.random.arguments default FALSE.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/get_y.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract X, Y or Z from a stanreg object — get_y","title":"Extract X, Y or Z from a stanreg object — get_y","text":"Extract X, Y Z stanreg object","code":""},{"path":"https://mc-stan.org/rstanarm/reference/get_y.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract X, Y or Z from a stanreg object — get_y","text":"","code":"get_y(object, ...)  get_x(object, ...)  get_z(object, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/get_y.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract X, Y or Z from a stanreg object — get_y","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. ... arguments passed methods. stanmvreg object can integer m specifying submodel.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/get_y.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract X, Y or Z from a stanreg object — get_y","text":"get_x get_z, matrix. get_y, either   vector matrix, depending response variable specified.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/kfold.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"K-fold cross-validation — kfold.stanreg","title":"K-fold cross-validation — kfold.stanreg","text":"kfold method performs exact \\(K\\)-fold cross-validation. First data randomly partitioned \\(K\\) subsets equal size (close equal possible), user can specify folds argument determine partitioning. model refit \\(K\\) times, time leaving one \\(K\\) subsets. \\(K\\) equal total number observations data \\(K\\)-fold cross-validation equivalent exact leave-one-cross-validation (loo efficient approximation).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/kfold.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K-fold cross-validation — kfold.stanreg","text":"","code":"# S3 method for class 'stanreg' kfold(   x,   K = 10,   ...,   folds = NULL,   save_fits = FALSE,   cores = getOption(\"mc.cores\", 1) )"},{"path":"https://mc-stan.org/rstanarm/reference/kfold.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K-fold cross-validation — kfold.stanreg","text":"x fitted model object returned one rstanarm modeling functions. See stanreg-objects. K kfold, number subsets (folds) data partitioned performing \\(K\\)-fold cross-validation. model refit K times, time leaving one K folds. folds argument specified K automatically set length(unique(folds)), otherwise specified value K passed loo::kfold_split_random randomly partition data K subsets equal (close equal possible) size. ... Currently ignored. folds kfold, optional integer vector one element per observation data used fit model. element vector integer 1:K indicating K folds corresponding observation belongs. convenience functions available loo package create integer vectors use purpose (see Examples section also kfold-helpers page). save_fits kfold, TRUE, component 'fits' added returned object store cross-validated stanreg objects indices omitted observations fold. Defaults FALSE. cores number cores use parallelization. Instead fitting separate Markov chains model different cores, default kfold distribute K models fit across cores (using parLapply Windows mclapply otherwise). Markov chains model run sequentially. often efficient option, especially many cores available, cases may preferable fit K models sequentially instead use cores Markov chains. can accomplished setting options(mc.cores) desired number cores use Markov chains also manually specifying cores=1 calling kfold function. See end Examples section demonstration.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/kfold.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"K-fold cross-validation — kfold.stanreg","text":"object classes 'kfold' 'loo' similar structure   objects returned loo waic   methods compatible loo_compare function   comparing models.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/kfold.stanreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"K-fold cross-validation — kfold.stanreg","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical   Bayesian model evaluation using leave-one-cross-validation WAIC.   Statistics Computing. 27(5), 1413–1432.   doi:10.1007/s11222-016-9696-4. arXiv preprint:   https://arxiv.org/abs/1507.04544 Yao, Y., Vehtari, ., Simpson, D., Gelman, . (2018) Using   stacking average Bayesian predictive distributions. Bayesian   Analysis, advance publication,  doi:10.1214/17-BA1091 .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/kfold.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"K-fold cross-validation — kfold.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{ fit1 <- stan_glm(mpg ~ wt, data = mtcars, refresh = 0) fit2 <- stan_glm(mpg ~ wt + cyl, data = mtcars, refresh = 0) fit3 <- stan_glm(mpg ~ disp * as.factor(cyl), data = mtcars, refresh = 0)  # 10-fold cross-validation # (if possible also specify the 'cores' argument to use multiple cores) (kfold1 <- kfold(fit1, K = 10)) kfold2 <- kfold(fit2, K = 10) kfold3 <- kfold(fit3, K = 10)  loo_compare(kfold1, kfold2, kfold3)  # stratifying by a grouping variable # (note: might get some divergences warnings with this model but  # this is just intended as a quick example of how to code this) fit4 <- stan_lmer(mpg ~ disp + (1|cyl), data = mtcars, refresh = 0) table(mtcars$cyl) folds_cyl <- loo::kfold_split_stratified(K = 3, x = mtcars$cyl) table(cyl = mtcars$cyl, fold = folds_cyl) kfold4 <- kfold(fit4, folds = folds_cyl, cores = 2) print(kfold4) # } } #> Fitting model 1 out of 10 #> Fitting model 2 out of 10 #> Fitting model 3 out of 10 #> Fitting model 4 out of 10 #> Fitting model 5 out of 10 #> Fitting model 6 out of 10 #> Fitting model 7 out of 10 #> Fitting model 8 out of 10 #> Fitting model 9 out of 10 #> Fitting model 10 out of 10 #> Fitting model 1 out of 10 #> Fitting model 2 out of 10 #> Fitting model 3 out of 10 #> Fitting model 4 out of 10 #> Fitting model 5 out of 10 #> Fitting model 6 out of 10 #> Fitting model 7 out of 10 #> Fitting model 8 out of 10 #> Fitting model 9 out of 10 #> Fitting model 10 out of 10 #> Fitting model 1 out of 10 #> Fitting model 2 out of 10 #> Fitting model 3 out of 10 #> Fitting model 4 out of 10 #> Fitting model 5 out of 10 #> Fitting model 6 out of 10 #> Fitting model 7 out of 10 #> Fitting model 8 out of 10 #> Fitting model 9 out of 10 #> Fitting model 10 out of 10 #> Fitting K = 3 models distributed over 2 cores #>  #> Based on 3-fold cross-validation. #>  #>            Estimate  SE #> elpd_kfold    -86.5 4.3 #> p_kfold         7.3 1.7 #> kfoldic       172.9 8.5 # Example code demonstrating the different ways to specify the number  # of cores and how the cores are used #  # options(mc.cores = NULL) #  # # spread the K models over N_CORES cores (method 1) # kfold(fit, K, cores = N_CORES) #  # # spread the K models over N_CORES cores (method 2) # options(mc.cores = N_CORES) # kfold(fit, K) #   # # fit K models sequentially using N_CORES cores for the Markov chains each time # options(mc.cores = N_CORES) # kfold(fit, K, cores = 1)"},{"path":"https://mc-stan.org/rstanarm/reference/launch_shinystan.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Using the ShinyStan GUI with rstanarm models — launch_shinystan.stanreg","title":"Using the ShinyStan GUI with rstanarm models — launch_shinystan.stanreg","text":"ShinyStan interface provides visual numerical summaries model parameters convergence diagnostics.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/launch_shinystan.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Using the ShinyStan GUI with rstanarm models — launch_shinystan.stanreg","text":"","code":"# S3 method for class 'stanreg' launch_shinystan(   object,   ppd = TRUE,   seed = 1234,   model_name = NULL,   note = NULL,   rstudio = getOption(\"shinystan.rstudio\"),   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/launch_shinystan.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using the ShinyStan GUI with rstanarm models — launch_shinystan.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. ppd rstanarm draw posterior predictive distribution launching ShinyStan? default TRUE, although large objects can convenient set FALSE drawing posterior predictive distribution can time consuming. ppd TRUE graphical posterior predictive checks available ShinyStan launched. seed Passed pp_check ppd TRUE. model_name, note Optional arguments passed .shinystan. rstudio relevant 'RStudio' users. default (FALSE) launch app user's default web browser rather pop-Viewer provided 'RStudio'. Users can change default TRUE setting global option options(shinystan.rstudio = TRUE). ... Optional arguments passed runApp.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/launch_shinystan.stanreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Using the ShinyStan GUI with rstanarm models — launch_shinystan.stanreg","text":"launch_shinystan function accept   stanreg object input. Currently, almost   model fit using one rstanarm's model-fitting functions can   used ShinyStan. exception ShinyStan   currently support rstanarm models fit using   algorithm='optimizing'. See   shinystan package documentation   information.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/launch_shinystan.stanreg.html","id":"faster-launch-times","dir":"Reference","previous_headings":"","what":"Faster launch times","title":"Using the ShinyStan GUI with rstanarm models — launch_shinystan.stanreg","text":"rstanarm models ShinyStan may take long time launch. case one models may able speed launch_shinystan one several ways: Prevent ShinyStan preparing graphical posterior predictive   checks: used stanreg object   (rstanarm model object) ShinyStan draw posterior   predictive distribution prepare graphical posterior predictive checks   launching. way go PPcheck page plots   immediately available. can time consuming models fit   large datasets can prevent behavior creating shinystan   object calling launch_shinystan. use   .shinystan optional argument ppd set   FALSE (see Examples section ). launch   ShinyStan go PPcheck page plots longer   automatically generated presented standard   interface requiring first specify appropriate \\(y\\)   \\(yrep\\), can done many rstanarm models. Use shinystan object: Even want prevent ShinyStan preparing graphical   posterior predictive checks, first creating shinystan object using   .shinystan can reduce future launch   times. , launch_shinystan(sso) faster   launch_shinystan(fit), sso shinystan object   fit stanreg object. still may take time   .shinystan create sso initially, time   subsequently call launch_shinystan(sso) reuse sso   instead internally creating shinystan object every time. See   Examples section .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/launch_shinystan.stanreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Using the ShinyStan GUI with rstanarm models — launch_shinystan.stanreg","text":"Gabry, J. , Simpson, D. , Vehtari, . , Betancourt, M.   Gelman, . (2019), Visualization Bayesian workflow. J. R. Stat.   Soc. , 182: 389-402. doi:10.1111/rssa.12378,   arXiv preprint,   code GitHub) Muth, C., Oravecz, Z., Gabry, J. (2018) User-friendly Bayesian regression modeling: tutorial rstanarm shinystan. Quantitative Methods Psychology. 14(2), 99–119. https://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf","code":""},{"path":"https://mc-stan.org/rstanarm/reference/launch_shinystan.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Using the ShinyStan GUI with rstanarm models — launch_shinystan.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\dontrun{ if (!exists(\"example_model\")) example(example_model)   # Launch the ShinyStan app without saving the resulting shinystan object if (interactive()) launch_shinystan(example_model)  # Launch the ShinyStan app (saving resulting shinystan object as sso) if (interactive()) sso <- launch_shinystan(example_model)  # First create shinystan object then call launch_shinystan sso <- shinystan::as.shinystan(example_model) if (interactive()) launch_shinystan(sso)  # Prevent ShinyStan from preparing graphical posterior predictive checks that # can be time consuming. example_model is small enough that it won't matter # much here but in general this can help speed up launch_shinystan sso <- shinystan::as.shinystan(example_model, ppd = FALSE) if (interactive()) launch_shinystan(sso) # } } #>  #> Hang on... preparing graphical posterior predictive checks for rstanarm model. #> See help('shinystan', 'rstanarm') for how to disable this feature. #> Note: in most cases the default test statistic 'mean' is too weak to detect anything of interest."},{"path":"https://mc-stan.org/rstanarm/reference/log_lik.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Pointwise log-likelihood matrix — log_lik.stanreg","title":"Pointwise log-likelihood matrix — log_lik.stanreg","text":"models fit using MCMC , log_lik method returns \\(S\\) \\(N\\) pointwise log-likelihood matrix, \\(S\\) size posterior sample \\(N\\) number data points, case stanmvreg method (called stan_jm model objects) \\(S\\) \\(Npat\\) matrix \\(Npat\\) number individuals.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/log_lik.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pointwise log-likelihood matrix — log_lik.stanreg","text":"","code":"# S3 method for class 'stanreg' log_lik(object, newdata = NULL, offset = NULL, ...)  # S3 method for class 'stanmvreg' log_lik(object, m = 1, newdata = NULL, ...)  # S3 method for class 'stanjm' log_lik(object, newdataLong = NULL, newdataEvent = NULL, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/log_lik.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pointwise log-likelihood matrix — log_lik.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. newdata optional data frame new data (e.g. holdout data) use evaluating log-likelihood. See description newdata posterior_predict. offset vector offsets. required newdata specified offset specified fitting model. ... Currently ignored. m Integer specifying number name submodel newdataLong, newdataEvent Optional data frames containing new data (e.g. holdout data) use evaluating log-likelihood model estimated using stan_jm. fitted model multivariate joint model (.e. one longitudinal outcome), newdataLong allowed list data frames. supplying new data, newdataEvent also include variables corresponding event time event indicator required evaluating log likelihood event submodel. details, see description newdataLong newdataEvent posterior_survfit.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/log_lik.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pointwise log-likelihood matrix — log_lik.stanreg","text":"stanreg stanmvreg methods \\(S\\)   \\(N\\) matrix, \\(S\\) size posterior sample   \\(N\\) number data points. stanjm method   \\(S\\) \\(Npat\\) matrix \\(Npat\\) number individuals.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/log_lik.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pointwise log-likelihood matrix — log_lik.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{  roaches$roach100 <- roaches$roach1 / 100  fit <- stan_glm(     y ~ roach100 + treatment + senior,     offset = log(exposure2),     data = roaches,     family = poisson(link = \"log\"),     prior = normal(0, 2.5),     prior_intercept = normal(0, 10),     iter = 500, # just to speed up example,     refresh = 0  )  ll <- log_lik(fit)  dim(ll)  all.equal(ncol(ll), nobs(fit))   # using newdata argument  nd <- roaches[1:2, ]  nd$treatment[1:2] <- c(0, 1)  ll2 <- log_lik(fit, newdata = nd, offset = c(0, 0))  head(ll2)  dim(ll2)  all.equal(ncol(ll2), nrow(nd)) # } } #> [1] TRUE"},{"path":"https://mc-stan.org/rstanarm/reference/logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit and inverse logit — logit","title":"Logit and inverse logit — logit","text":"Logit inverse logit","code":""},{"path":"https://mc-stan.org/rstanarm/reference/logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit and inverse logit — logit","text":"","code":"logit(x)  invlogit(x)"},{"path":"https://mc-stan.org/rstanarm/reference/logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit and inverse logit — logit","text":"x Numeric vector.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/logit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logit and inverse logit — logit","text":"numeric vector length x.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Information criteria and cross-validation — loo.stanreg","title":"Information criteria and cross-validation — loo.stanreg","text":"models fit using MCMC, compute approximate leave-one-  cross-validation (LOO, LOOIC) , less preferably, Widely Applicable   Information Criterion (WAIC) using loo   package. (\\(K\\)-fold cross-validation see kfold.stanreg.)   Functions  model comparison, model weighting/averaging also   provided. Note: functions guaranteed work   properly unless data argument specified model   fit. Also, loo version 2.0.0 default number cores   now 1, recommend using many (close many) cores   possible setting cores argument using   options(mc.cores = VALUE) set entire session.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information criteria and cross-validation — loo.stanreg","text":"","code":"# S3 method for class 'stanreg' loo(   x,   ...,   cores = getOption(\"mc.cores\", 1),   save_psis = FALSE,   k_threshold = NULL,   r_eff = FALSE )  # S3 method for class 'stanreg' waic(x, ...)  # S3 method for class 'stanreg' loo_compare(x, ..., criterion = c(\"loo\", \"kfold\", \"waic\"), detail = FALSE)  # S3 method for class 'stanreg_list' loo_compare(x, ..., criterion = c(\"loo\", \"kfold\", \"waic\"), detail = FALSE)  # S3 method for class 'stanreg_list' loo_model_weights(x, ..., cores = getOption(\"mc.cores\", 1), k_threshold = NULL)  compare_models(..., loos = list(), detail = FALSE)"},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information criteria and cross-validation — loo.stanreg","text":"x loo waic, fitted model object returned   one rstanarm modeling functions. See stanreg-objects. loo_model_weights method, x   \"stanreg_list\" object, list fitted model objects created   stanreg_list. loo_compare also allows x   single stanreg object, remaining objects passed via ...,   single stanreg_list object. ... loo_compare.stanreg, ... can contain objects   returned loo, kfold,   waic method (see Examples section, ). loo_model_weights, ... contain arguments (e.g.   method) pass default loo_model_weights   method loo package. cores, save_psis Passed loo. k_threshold Threshold flagging estimates Pareto shape parameters \\(k\\) estimated loo. See proceed loo gives warnings section, , details. r_eff TRUE FALSE indicating whether compute r_eff argument pass loo package. TRUE, rstanarm call relative_eff compute r_eff argument pass loo package. FALSE (default), avoid computing r_eff, can slow. r_eff measures amount autocorrelation MCMC draws, used compute accurate ESS MCSE estimates pointwise total ELPDs. r_eff=FALSE, reported ESS MCSE estimates may -optimistic posterior draws far independent. criterion loo_compare.stanreg loo_compare.stanreg_list, comparison based LOO-CV (criterion=\"loo\"), K-fold-CV (criterion=\"kfold\"), WAIC (criterion=\"waic\"). default LOO-CV. See Comparing models Examples sections . detail loo_compare.stanreg loo_compare.stanreg_list, TRUE extra information model (currently just model formulas) printed output. loos list objects produced loo function","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information criteria and cross-validation — loo.stanreg","text":"structure objects returned loo waic   methods documented detail Value section   loo waic (loo   package). loo_compare returns matrix class 'compare.loo'. See   Comparing models section details.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":"approximate-loo-cv","dir":"Reference","previous_headings":"","what":"Approximate LOO CV","title":"Information criteria and cross-validation — loo.stanreg","text":"loo method stanreg objects   provides interface loo package   approximate leave-one-cross-validation (LOO). LOO Information   Criterion (LOOIC) purpose Akaike Information Criterion   (AIC) used frequentists. intended estimate   expected log predictive density (ELPD) new dataset. However, AIC   ignores priors assumes posterior distribution multivariate   normal, whereas functions loo package make   distributional assumption integrate uncertainty parameters.   assumes one observation can omitted without   major effect posterior distribution, can judged using   diagnostic plot provided   plot.loo method warnings   provided print.loo method (see   Use rstanarm Package vignette example process).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":"how-to-proceed-when-loo-gives-warnings-k-threshold-","dir":"Reference","previous_headings":"","what":"How to proceed when loo gives warnings (k_threshold)","title":"Information criteria and cross-validation — loo.stanreg","text":"k_threshold argument loo method rstanarm   models provided possible remedy diagnostics reveal   problems stemming posterior's sensitivity particular   observations. Warnings Pareto \\(k\\) estimates indicate observations   approximation LOO problematic (described   detail Vehtari, Gelman, Gabry (2017)   loo package documentation).   k_threshold argument can used set \\(k\\) value   observation flagged. k_threshold NULL   \\(J\\) observations \\(k\\) estimates   k_threshold loo called refit   original model \\(J\\) times, time leaving one \\(J\\)   problematic observations. pointwise contributions observations   total ELPD computed directly substituted   previous estimates \\(J\\) observations stored   object created loo. Another option consider K-fold   cross-validation, documented separate page (see   kfold). Note: warning messages issued loo large   Pareto \\(k\\) estimates recommend setting k_threshold   least \\(0.7\\). theoretical reason, explained Vehtari,   Gelman, Gabry (2017), setting threshold stricter value   \\(0.5\\), practice find errors LOO   approximation start increase non-negligibly \\(k > 0.7\\).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":"comparing-models","dir":"Reference","previous_headings":"","what":"Comparing models","title":"Information criteria and cross-validation — loo.stanreg","text":"\"loo\" (\"waic\" \"kfold\") objects can passed   loo_compare function loo package   perform model comparison. rstanarm also provides   loo_compare.stanreg method can used \"loo\" (\"waic\"   \"kfold\") object added fitted model object (see   Examples section ). second method   allows rstanarm perform extra checks done   loo package (e.g., verifying models   compared fit using outcome variable). loo_compare return matrix one row per model columns   containing ELPD difference standard error difference.   first row matrix model largest ELPD   (smallest LOOIC) contain zeros (difference   model ). remaining models ELPD   difference SE reported relative model best ELPD   (first row). See Details section   loo_compare page loo package   information.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":"model-weights","dir":"Reference","previous_headings":"","what":"Model weights","title":"Information criteria and cross-validation — loo.stanreg","text":"loo_model_weights method can used   compute model weights \"stanreg_list\" object, list   fitted model objects made stanreg_list. end   Examples section demonstration. details see   loo_model_weights documentation loo   package.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Information criteria and cross-validation — loo.stanreg","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical   Bayesian model evaluation using leave-one-cross-validation WAIC.   Statistics Computing. 27(5), 1413–1432.   doi:10.1007/s11222-016-9696-4. arXiv preprint:   https://arxiv.org/abs/1507.04544 Yao, Y., Vehtari, ., Simpson, D., Gelman, . (2018) Using   stacking average Bayesian predictive distributions. Bayesian   Analysis, advance publication,  doi:10.1214/17-BA1091 . Gabry, J. , Simpson, D. , Vehtari, . , Betancourt, M.   Gelman, . (2019), Visualization Bayesian workflow. J. R. Stat.   Soc. , 182: 389-402. doi:10.1111/rssa.12378,   arXiv preprint,   code GitHub)","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/loo.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Information criteria and cross-validation — loo.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{ fit1 <- stan_glm(mpg ~ wt, data = mtcars, refresh = 0) fit2 <- stan_glm(mpg ~ wt + cyl, data = mtcars, refresh = 0)  # (for bigger models use as many cores as possible) loo1 <- loo(fit1, cores = 1) print(loo1) loo2 <- loo(fit2, cores = 1) print(loo2)  # when comparing models the loo objects can be passed to loo_compare # as individual arguments or as a list of loo objects loo_compare(loo1, loo2) loo_compare(list(loo1, loo2))  # if the fitted model objects contain a loo object in the component \"loo\" # then the model objects can be passed directly or as a stanreg_list fit1$loo <- loo1 fit2$loo <- loo2 loo_compare(fit1, fit2)  # if the fitted model objects contain a loo object _and_ a waic or kfold # object, then the criterion argument determines which of them the comparison # is based on  fit1$waic <- waic(fit1) fit2$waic <- waic(fit2) loo_compare(fit1, fit2, criterion = \"waic\")  # the models can also be combined into a stanreg_list object, and more  # informative model names can be provided to use when printing model_list <- stanreg_list(fit1, fit2, model_names = c(\"Fewer predictors\", \"More predictors\")) loo_compare(model_list)  fit3 <- stan_glm(mpg ~ disp * as.factor(cyl), data = mtcars, refresh = 0) loo3 <- loo(fit3, cores = 2, k_threshold = 0.7) loo_compare(loo1, loo2, loo3)  # setting detail=TRUE will also print model formulas if used with # loo_compare.stanreg or loo_compare.stanreg_list fit3$loo <- loo3 model_list <- stanreg_list(fit1, fit2, fit3) loo_compare(model_list, detail=TRUE)  # Computing model weights # # if the objects in model_list already have 'loo' components then those # will be used. otherwise loo will be computed for each model internally # (in which case the 'cores' argument may also be used and is passed to loo()) loo_model_weights(model_list)  # defaults to method=\"stacking\" loo_model_weights(model_list,  method = \"pseudobma\") loo_model_weights(model_list,  method = \"pseudobma\", BB = FALSE)  # you can also pass precomputed loo objects directly to loo_model_weights loo_list <- list(A = loo1, B = loo2, C = loo3) # names optional (affects printing) loo_model_weights(loo_list) # } } #>  #> Computed from 4000 by 32 log-likelihood matrix. #>  #>          Estimate  SE #> elpd_loo    -83.4 4.3 #> p_loo         3.2 1.1 #> looic       166.9 8.5 #> ------ #> MCSE of elpd_loo is 0.0. #> MCSE and ESS estimates assume independent draws (r_eff=1). #>  #> All Pareto k estimates are good (k < 0.7). #> See help('pareto-k-diagnostic') for details. #>  #> Computed from 4000 by 32 log-likelihood matrix. #>  #>          Estimate  SE #> elpd_loo    -78.6 4.6 #> p_loo         4.1 1.3 #> looic       157.1 9.2 #> ------ #> MCSE of elpd_loo is 0.1. #> MCSE and ESS estimates assume independent draws (r_eff=1). #>  #> All Pareto k estimates are good (k < 0.7). #> See help('pareto-k-diagnostic') for details. #> Warning:  #> 3 (9.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. #> Warning:  #> 3 (9.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. #> 1 problematic observation(s) found. #> Model will be refit 1 times. #>  #> Fitting model 1 out of 1 (leaving out observation 4) #> Method: stacking #> ------ #>   weight #> A 0.000  #> B 0.487  #> C 0.513"},{"path":"https://mc-stan.org/rstanarm/reference/loo_predict.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute weighted expectations using LOO — loo_predict.stanreg","title":"Compute weighted expectations using LOO — loo_predict.stanreg","text":"functions wrappers around E_loo function (loo package) provide compatibility rstanarm models.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo_predict.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute weighted expectations using LOO — loo_predict.stanreg","text":"","code":"# S3 method for class 'stanreg' loo_predict(   object,   type = c(\"mean\", \"var\", \"quantile\"),   probs = 0.5,   ...,   psis_object = NULL )  # S3 method for class 'stanreg' loo_linpred(   object,   type = c(\"mean\", \"var\", \"quantile\"),   probs = 0.5,   transform = FALSE,   ...,   psis_object = NULL )  # S3 method for class 'stanreg' loo_predictive_interval(object, prob = 0.9, ..., psis_object = NULL)"},{"path":"https://mc-stan.org/rstanarm/reference/loo_predict.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute weighted expectations using LOO — loo_predict.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. type type expectation compute. options \"mean\", \"variance\", \"sd\", \"quantile\". probs computing quantiles, vector probabilities. ... Currently unused. psis_object object returned psis. missing psis run internally, may time consuming models fit large datasets. transform Passed posterior_linpred. prob loo_predictive_interval, scalar \\((0,1)\\) indicating desired probability mass include intervals. default prob=0.9 (\\(90\\)% intervals).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo_predict.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute weighted expectations using LOO — loo_predict.stanreg","text":"list elements value pareto_k. loo_predict loo_linpred value component   vector one element per observation. loo_predictive_interval value component matrix   one row per observation two columns (like   predictive_interval). loo_predictive_interval(..., prob   = p) equivalent loo_predict(..., type = \"quantile\", probs =   c(, 1-)) = (1 - p)/2, except transposes result   adds informative column names. See E_loo pareto-k-diagnostic   details pareto_k diagnostic.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo_predict.stanreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute weighted expectations using LOO — loo_predict.stanreg","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical   Bayesian model evaluation using leave-one-cross-validation WAIC.   Statistics Computing. 27(5), 1413–1432.   doi:10.1007/s11222-016-9696-4. arXiv preprint:   https://arxiv.org/abs/1507.04544 Yao, Y., Vehtari, ., Simpson, D., Gelman, . (2018) Using   stacking average Bayesian predictive distributions. Bayesian   Analysis, advance publication,  doi:10.1214/17-BA1091 . Gabry, J. , Simpson, D. , Vehtari, . , Betancourt, M.   Gelman, . (2019), Visualization Bayesian workflow. J. R. Stat.   Soc. , 182: 389-402. doi:10.1111/rssa.12378,   arXiv preprint,   code GitHub)","code":""},{"path":"https://mc-stan.org/rstanarm/reference/loo_predict.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute weighted expectations using LOO — loo_predict.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\dontrun{ if (!exists(\"example_model\")) example(example_model)  # optionally, log-weights can be pre-computed and reused psis_result <- loo::psis(log_ratios = -log_lik(example_model))  loo_probs <- loo_linpred(example_model, type = \"mean\", transform = TRUE, psis_object = psis_result) str(loo_probs)  loo_pred_var <- loo_predict(example_model, type = \"var\", psis_object = psis_result) str(loo_pred_var)  loo_pred_ints <- loo_predictive_interval(example_model, prob = 0.8, psis_object = psis_result) str(loo_pred_ints) # } } #> Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details. #> Instead of posterior_linpred(..., transform=TRUE) please call posterior_epred(), which provides equivalent functionality. #> List of 2 #>  $ value   : num [1:56] 0.4294 0.1141 0.0679 0.0993 0.1687 ... #>  $ pareto_k: num [1:56] 0.853 0.344 0.617 0.201 0.504 ... #> List of 2 #>  $ value   : num [1:56] 5.062 1.676 0.597 0.499 6.039 ... #>  $ pareto_k: num [1:56] 0.799 0.344 0.617 0.131 0.829 ... #> List of 2 #>  $ value   : num [1:56, 1:2] 3 0 0 0 1 0 0 1 0 0 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : NULL #>   .. ..$ : chr [1:2] \"10%\" \"90%\" #>  $ pareto_k: num [1:56] 0.791 0.344 0.617 0.131 0.425 ..."},{"path":"https://mc-stan.org/rstanarm/reference/model.frame.stanmvreg.html","id":null,"dir":"Reference","previous_headings":"","what":"model.frame method for stanmvreg objects — model.frame.stanmvreg","title":"model.frame method for stanmvreg objects — model.frame.stanmvreg","text":"model.frame method stanmvreg objects","code":""},{"path":"https://mc-stan.org/rstanarm/reference/model.frame.stanmvreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"model.frame method for stanmvreg objects — model.frame.stanmvreg","text":"","code":"# S3 method for class 'stanmvreg' model.frame(formula, fixed.only = FALSE, m = NULL, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/model.frame.stanmvreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"model.frame method for stanmvreg objects — model.frame.stanmvreg","text":"formula, ... See model.frame. fixed.See model.frame.merMod. m Integer specifying number name submodel","code":""},{"path":"https://mc-stan.org/rstanarm/reference/model.frame.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"model.frame method for stanreg objects — model.frame.stanreg","title":"model.frame method for stanreg objects — model.frame.stanreg","text":"model.frame method stanreg objects","code":""},{"path":"https://mc-stan.org/rstanarm/reference/model.frame.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"model.frame method for stanreg objects — model.frame.stanreg","text":"","code":"# S3 method for class 'stanreg' model.frame(formula, fixed.only = FALSE, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/model.frame.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"model.frame method for stanreg objects — model.frame.stanreg","text":"formula, ... See model.frame. fixed.See model.frame.merMod.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/model.matrix.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"model.matrix method for stanreg objects — model.matrix.stanreg","title":"model.matrix method for stanreg objects — model.matrix.stanreg","text":"model.matrix method stanreg objects","code":""},{"path":"https://mc-stan.org/rstanarm/reference/model.matrix.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"model.matrix method for stanreg objects — model.matrix.stanreg","text":"","code":"# S3 method for class 'stanreg' model.matrix(object, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/model.matrix.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"model.matrix method for stanreg objects — model.matrix.stanreg","text":"object, ... See model.matrix.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/neg_binomial_2.html","id":null,"dir":"Reference","previous_headings":"","what":"Family function for negative binomial GLMs — neg_binomial_2","title":"Family function for negative binomial GLMs — neg_binomial_2","text":"Specifies information required fit Negative Binomial GLM similar way negative.binomial. However, overdispersion parameter theta specified user always estimated (really reciprocal dispersion parameter estimated). call function can passed family argument stan_glm stan_glmer estimate Negative Binomial model. Alternatively, stan_glm.nb stan_glmer.nb wrapper functions may used, call neg_binomial_2 internally.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/neg_binomial_2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Family function for negative binomial GLMs — neg_binomial_2","text":"","code":"neg_binomial_2(link = \"log\")"},{"path":"https://mc-stan.org/rstanarm/reference/neg_binomial_2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Family function for negative binomial GLMs — neg_binomial_2","text":"link poisson, typically character vector length one among \"log\", \"identity\", \"sqrt\".","code":""},{"path":"https://mc-stan.org/rstanarm/reference/neg_binomial_2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Family function for negative binomial GLMs — neg_binomial_2","text":"object class family similar   poisson different family name.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/neg_binomial_2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Family function for negative binomial GLMs — neg_binomial_2","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") stan_glm(Days ~ Sex/(Age + Eth*Lrn), data = MASS::quine, seed = 123,          family = neg_binomial_2, QR = TRUE, algorithm = \"optimizing\")  #> stan_glm #>  family:       neg_binomial_2 [log] #>  formula:      Days ~ Sex/(Age + Eth * Lrn) #>  observations: 146 #>  predictors:   14 #> ------ #>                 Median MAD_SD #> (Intercept)      3.1    0.3   #> SexM            -0.5    0.4   #> SexF:AgeF1      -0.8    0.3   #> SexM:AgeF1      -0.7    0.3   #> SexF:AgeF2      -0.6    0.4   #> SexM:AgeF2       0.6    0.3   #> SexF:AgeF3      -0.4    0.4   #> SexM:AgeF3       1.1    0.4   #> SexF:EthN       -0.1    0.3   #> SexM:EthN       -0.7    0.3   #> SexF:LrnSL       1.0    0.3   #> SexM:LrnSL       0.2    0.4   #> SexF:EthN:LrnSL -1.4    0.4   #> SexM:EthN:LrnSL  0.8    0.5   #>  #> Auxiliary parameter(s): #>                       Median MAD_SD #> reciprocal_dispersion 1.4    0.2    #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg                  # or, equivalently, call stan_glm.nb() without specifying the family"},{"path":"https://mc-stan.org/rstanarm/reference/pairs.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairs method for stanreg objects — pairs.stanreg","title":"Pairs method for stanreg objects — pairs.stanreg","text":"Interface bayesplot's mcmc_pairs function use rstanarm models. careful specify many parameters include plot hard read slow render.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pairs.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairs method for stanreg objects — pairs.stanreg","text":"","code":"# S3 method for class 'stanreg' pairs(   x,   pars = NULL,   regex_pars = NULL,   condition = pairs_condition(nuts = \"accept_stat__\"),   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/pairs.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairs method for stanreg objects — pairs.stanreg","text":"x fitted model object returned one rstanarm modeling functions. See stanreg-objects. pars optional character vector parameter names. parameters included default, models just parameters may far many visualize small computer screen also may require substantial computing time. regex_pars optional character vector regular expressions use parameter selection. regex_pars can used place pars addition pars. Currently, functions accept regex_pars argument ignore models fit using optimization. condition condition argument mcmc_pairs except default different rstanarm models. default, mcmc_pairs function bayesplot package plots Markov chains (half, case even number chains) panels diagonal half panels diagonal. However since know rstanarm models fit using Stan (bayesplot assume) can make default useful splitting draws according accept_stat__ diagnostic. plots diagonal contain realizations median accept_stat__ plots diagonal contain realizations median accept_stat__. change behavior see documentation condition argument mcmc_pairs. ... Optional arguments passed mcmc_pairs. np, lp, max_treedepth arguments mcmc_pairs handled automatically rstanarm need specified user .... arguments can specified ... include transformations, diag_fun, off_diag_fun, diag_args, off_diag_args, np_style. arguments documented thoroughly help page mcmc_pairs.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pairs.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pairs method for stanreg objects — pairs.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{ if (!exists(\"example_model\")) example(example_model)  bayesplot::color_scheme_set(\"purple\")  # see 'condition' argument above for details on the plots below and  # above the diagonal. default is to split by accept_stat__. pairs(example_model, pars = c(\"(Intercept)\", \"log-posterior\"))  # for demonstration purposes, intentionally fit a model that # will (almost certainly) have some divergences fit <- stan_glm(   mpg ~ ., data = mtcars,   iter = 1000,   # this combo of prior and adapt_delta should lead to some divergences   prior = hs(),   adapt_delta = 0.9,   refresh = 0 )  pairs(fit, pars = c(\"wt\", \"sigma\", \"log-posterior\"))  # requires hexbin package # pairs( # fit,  #   pars = c(\"wt\", \"sigma\", \"log-posterior\"),  #   transformations = list(sigma = \"log\"), # show log(sigma) instead of sigma #  off_diag_fun = \"hex\" # use hexagonal heatmaps instead of scatterplots # )  bayesplot::color_scheme_set(\"brightblue\") pairs(   fit,    pars = c(\"(Intercept)\", \"wt\", \"sigma\", \"log-posterior\"),    transformations = list(sigma = \"log\"),    off_diag_args = list(size = 3/4, alpha = 1/3), # size and transparency of scatterplot points   np_style = pairs_style_np(div_color = \"black\", div_shape = 2) # color and shape of the divergences )  # Using the condition argument to show divergences above the diagonal  pairs(   fit,    pars = c(\"(Intercept)\", \"wt\", \"log-posterior\"),    condition = pairs_condition(nuts = \"divergent__\") )  # } } #> Warning: There were 67 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess"},{"path":"https://mc-stan.org/rstanarm/reference/plot.predict.stanjm.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the estimated subject-specific or marginal longitudinal trajectory — plot.predict.stanjm","title":"Plot the estimated subject-specific or marginal longitudinal trajectory — plot.predict.stanjm","text":"generic plot method predict.stanjm objects plot estimated subject-specific marginal longitudinal trajectory using data frame returned call posterior_traj. ensure enough data points available plot longitudinal trajectory, assumed call posterior_traj used default interpolate = TRUE, perhaps also extrapolate = TRUE (latter optional, depending whether user wants see extrapolation longitudinal trajectory beyond last observation time).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/plot.predict.stanjm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the estimated subject-specific or marginal longitudinal trajectory — plot.predict.stanjm","text":"","code":"# S3 method for class 'predict.stanjm' plot(   x,   ids = NULL,   limits = c(\"ci\", \"pi\", \"none\"),   xlab = NULL,   ylab = NULL,   vline = FALSE,   plot_observed = FALSE,   facet_scales = \"free_x\",   ci_geom_args = NULL,   grp_overlay = FALSE,   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/plot.predict.stanjm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the estimated subject-specific or marginal longitudinal trajectory — plot.predict.stanjm","text":"x data frame object class predict.stanjm returned call function posterior_traj. object contains point estimates uncertainty interval limits fitted values longitudinal response. ids optional vector providing subset subject IDs predicted curves plotted. limits quoted character string specifying type limits include plot. Can one : \"ci\" Bayesian posterior uncertainty interval estimated mean longitudinal response (often known credible interval); \"pi\" prediction interval estimated (raw) longitudinal response; \"none\" interval limits. xlab, ylab optional axis label passed labs. vline logical. TRUE vertical dashed line added plot indicating event censoring time individual. Can used plot within figure single individual. plot_observed logical. TRUE observed longitudinal measurements overlaid plot. facet_scales character string passed scales argument facet_wrap plotting longitudinal trajectory one individual. ci_geom_args Optional arguments passed geom_ribbon used control features plotted interval limits. supplied named list. grp_overlay relevant model lower level units clustered within individual. TRUE, fitted trajectories lower level units overlaid plot region (, lower level units single individual shown within single facet). FALSE, fitted trajectories lower level unit shown separate facet. ... Optional arguments passed geom_smooth used control features plotted longitudinal trajectory.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/plot.predict.stanjm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the estimated subject-specific or marginal longitudinal trajectory — plot.predict.stanjm","text":"ggplot object, also class plot.predict.stanjm.   object can customised using ggplot2 package.   can also passed function plot_stack_jm.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/plot.predict.stanjm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the estimated subject-specific or marginal longitudinal trajectory — plot.predict.stanjm","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{   # Run example model if not already loaded   if (!exists(\"example_jm\")) example(example_jm)      # For a subset of individuals in the estimation dataset we will   # obtain subject-specific predictions for the longitudinal submodel    # at evenly spaced times between 0 and their event or censoring time.   pt1 <- posterior_traj(example_jm, ids = c(7,13,15), interpolate = TRUE)   plot(pt1)                  # credible interval for mean response   plot(pt1, limits = \"pi\")   # prediction interval for raw response   plot(pt1, limits = \"none\") # no uncertainty interval      # We can also extrapolate the longitudinal trajectories.   pt2 <- posterior_traj(example_jm, ids = c(7,13,15), interpolate = TRUE,                         extrapolate = TRUE)   plot(pt2)   plot(pt2, vline = TRUE)    # add line indicating event or censoring time   plot(pt2, vline = TRUE, plot_observed = TRUE)  # overlay observed longitudinal data     # We can change or add attributes to the plot   plot1 <- plot(pt2, ids = c(7,13,15), xlab = \"Follow up time\",                      vline = TRUE, plot_observed = TRUE,                       facet_scales = \"fixed\", color = \"blue\", linetype = 2,                      ci_geom_args = list(fill = \"red\"))   plot1           # Since the returned plot is also a ggplot object, we can   # modify some of its attributes after it has been returned   plot1 +      ggplot2::theme(strip.background = ggplot2::element_blank()) +     ggplot2::labs(title = \"Some plotted longitudinal trajectories\") # } } #>  #> exmpl_>   # set.seed(123) #> exmpl_>   if (.Platform$OS.type != \"windows\" || .Platform$r_arch !=\"i386\") #> exmpl_+   example_jm <-  #> exmpl_+      stan_jm(formulaLong = logBili ~ year + (1 | id),  #> exmpl_+              dataLong = pbcLong[1:101,], #> exmpl_+              formulaEvent = survival::Surv(futimeYears, death) ~ sex + trt,  #> exmpl_+              dataEvent = pbcSurv[1:15,], #> exmpl_+              time_var = \"year\", #> exmpl_+              # this next line is only to keep the example small in size! #> exmpl_+              chains = 1, seed = 12345, iter = 100, refresh = 0) #> Fitting a univariate joint model. #>  #> Please note the warmup may be much slower than later iterations! #> Warning: The largest R-hat is 1.07, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> Warning: `aes_string()` was deprecated in ggplot2 3.0.0. #> ℹ Please use tidy evaluation idioms with `aes()`. #> ℹ See also `vignette(\"ggplot2-in-packages\")` for more information. #> ℹ The deprecated feature was likely used in the rstanarm package. #>   Please report the issue at <https://github.com/stan-dev/rstanarm/issues>. #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://mc-stan.org/rstanarm/reference/plot.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot method for stanreg objects — plot.stanreg","title":"Plot method for stanreg objects — plot.stanreg","text":"plot method stanreg-objects provides convenient interface MCMC module bayesplot package plotting MCMC draws diagnostics. also straightforward use functions bayesplot package directly rather via plot method. Examples methods plotting given .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/plot.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot method for stanreg objects — plot.stanreg","text":"","code":"# S3 method for class 'stanreg' plot(x, plotfun = \"intervals\", pars = NULL, regex_pars = NULL, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/plot.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot method for stanreg objects — plot.stanreg","text":"x fitted model object returned one rstanarm modeling functions. See stanreg-objects. plotfun character string naming bayesplot MCMC function use. default call mcmc_intervals. plotfun can specified either full name bayesplot plotting function (e.g. \"mcmc_hist\") can abbreviated part name following \"mcmc_\" prefix (e.g. \"hist\"). get names available MCMC functions see available_mcmc. pars optional character vector parameter names. regex_pars optional character vector regular expressions use parameter selection. regex_pars can used place pars addition pars. Currently, functions accept regex_pars argument ignore models fit using optimization. ... Additional arguments pass plotfun customizing plot. described help pages individual plotting functions. example, arguments accepted default plotfun=\"intervals\" can found mcmc_intervals.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/plot.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot method for stanreg objects — plot.stanreg","text":"Either ggplot object can customized using   ggplot2 package, object created multiple ggplot objects   (e.g. gtable object created arrangeGrob).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/plot.stanreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot method for stanreg objects — plot.stanreg","text":"Gabry, J. , Simpson, D. , Vehtari, . , Betancourt, M.   Gelman, . (2019), Visualization Bayesian workflow. J. R. Stat.   Soc. , 182: 389-402. doi:10.1111/rssa.12378,   arXiv preprint,   code GitHub)","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/plot.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot method for stanreg objects — plot.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{ # Use rstanarm example model if (!exists(\"example_model\")) example(example_model) fit <- example_model  ##################################### ### Intervals and point estimates ### ##################################### plot(fit) # same as plot(fit, \"intervals\"), plot(fit, \"mcmc_intervals\")  p <- plot(fit, pars = \"size\", regex_pars = \"period\",           prob = 0.5, prob_outer = 0.9) p + ggplot2::ggtitle(\"Posterior medians \\n with 50% and 90% intervals\")  # Shaded areas under densities bayesplot::color_scheme_set(\"brightblue\") plot(fit, \"areas\", regex_pars = \"period\",      prob = 0.5, prob_outer = 0.9)  # Make the same plot by extracting posterior draws and calling # bayesplot::mcmc_areas directly x <- as.array(fit, regex_pars = \"period\") bayesplot::mcmc_areas(x, prob = 0.5, prob_outer = 0.9)  # Ridgelines version of the areas plot bayesplot::mcmc_areas_ridges(x, regex_pars = \"period\", prob = 0.9)   ################################## ### Histograms & density plots ### ################################## plot_title <- ggplot2::ggtitle(\"Posterior Distributions\") plot(fit, \"hist\", regex_pars = \"period\") + plot_title plot(fit, \"dens_overlay\", pars = \"(Intercept)\",      regex_pars = \"period\") + plot_title  #################### ### Scatterplots ### #################### bayesplot::color_scheme_set(\"teal\") plot(fit, \"scatter\", pars = paste0(\"period\", 2:3)) plot(fit, \"scatter\", pars = c(\"(Intercept)\", \"size\"),      size = 3, alpha = 0.5) +      ggplot2::stat_ellipse(level = 0.9)   #################################################### ### Rhat, effective sample size, autocorrelation ### #################################################### bayesplot::color_scheme_set(\"red\")  # rhat plot(fit, \"rhat\") plot(fit, \"rhat_hist\")  # ratio of effective sample size to total posterior sample size plot(fit, \"neff\") plot(fit, \"neff_hist\")  # autocorrelation by chain plot(fit, \"acf\", pars = \"(Intercept)\", regex_pars = \"period\") plot(fit, \"acf_bar\", pars = \"(Intercept)\", regex_pars = \"period\")   ################## ### Traceplots ### ################## # NOTE: rstanarm doesn't store the warmup draws (to save space because they # are not so essential for diagnosing the particular models implemented in # rstanarm) so the iterations in the traceplot are post-warmup iterations  bayesplot::color_scheme_set(\"pink\") (trace <- plot(fit, \"trace\", pars = \"(Intercept)\"))  # change traceplot colors to ggplot defaults or custom values trace + ggplot2::scale_color_discrete() trace + ggplot2::scale_color_manual(values = c(\"maroon\", \"skyblue2\"))  # changing facet layout  plot(fit, \"trace\", pars = c(\"(Intercept)\", \"period2\"),      facet_args = list(nrow = 2)) # same plot by calling bayesplot::mcmc_trace directly x <- as.array(fit, pars = c(\"(Intercept)\", \"period2\")) bayesplot::mcmc_trace(x, facet_args = list(nrow = 2))   ############ ### More ### ############  # regex_pars examples plot(fit, regex_pars = \"herd:1\\\\]\") plot(fit, regex_pars = \"herd:[279]\") plot(fit, regex_pars = \"herd:[279]|period2\") plot(fit, regex_pars = c(\"herd:[279]\", \"period2\")) # }  # For graphical posterior predictive checks see # help(\"pp_check.stanreg\") } #> Scale for colour is already present. #> Adding another scale for colour, which will replace the existing scale. #> Scale for colour is already present. #> Adding another scale for colour, which will replace the existing scale."},{"path":"https://mc-stan.org/rstanarm/reference/plot.survfit.stanjm.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the estimated subject-specific or marginal survival function — plot.survfit.stanjm","title":"Plot the estimated subject-specific or marginal survival function — plot.survfit.stanjm","text":"generic plot method survfit.stanjm objects plot estimated subject-specific marginal survival function using data frame returned call posterior_survfit. call posterior_survfit ideally included \"extrapolation\" survival function, obtained setting extrapolate argument TRUE. plot_stack_jm function takes arguments containing plots estimated subject-specific longitudinal trajectory (trajectories multivariate joint model estimated) plot estimated subject-specific survival function combines single figure. easily understood running Examples .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/plot.survfit.stanjm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the estimated subject-specific or marginal survival function — plot.survfit.stanjm","text":"","code":"# S3 method for class 'survfit.stanjm' plot(   x,   ids = NULL,   limits = c(\"ci\", \"none\"),   xlab = NULL,   ylab = NULL,   facet_scales = \"free\",   ci_geom_args = NULL,   ... )  plot_stack_jm(yplot, survplot)"},{"path":"https://mc-stan.org/rstanarm/reference/plot.survfit.stanjm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the estimated subject-specific or marginal survival function — plot.survfit.stanjm","text":"x data frame object class survfit.stanjm returned call function posterior_survfit. object contains point estimates uncertainty interval limits estimated values survival function. ids optional vector providing subset subject IDs predicted curves plotted. limits quoted character string specifying type limits include plot. Can one : \"ci\" Bayesian posterior uncertainty interval estimated survival probability (often known credible interval); \"none\" interval limits. xlab, ylab optional axis label passed labs. facet_scales character string passed scales argument facet_wrap plotting longitudinal trajectory one individual. ci_geom_args Optional arguments passed geom_ribbon used control features plotted interval limits. supplied named list. ... Optional arguments passed geom_line used control features plotted survival function. yplot object class plot.predict.stanjm, returned call generic plot method objects class predict.stanjm. one longitudinal outcome, list objects can provided. survplot object class plot.survfit.stanjm, returned call generic plot method objects class survfit.stanjm.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/plot.survfit.stanjm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the estimated subject-specific or marginal survival function — plot.survfit.stanjm","text":"plot method returns ggplot object, also class   plot.survfit.stanjm. object can customised using   ggplot2 package. can also passed function   plot_stack_jm. plot_stack_jm returns object class   bayesplot_grid includes plots   estimated subject-specific longitudinal trajectories stacked top   associated subject-specific survival curve.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/plot.survfit.stanjm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the estimated subject-specific or marginal survival function — plot.survfit.stanjm","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{   # Run example model if not already loaded   if (!exists(\"example_jm\")) example(example_jm)    # Obtain subject-specific conditional survival probabilities   # for all individuals in the estimation dataset.   ps1 <- posterior_survfit(example_jm, extrapolate = TRUE)    # We then plot the conditional survival probabilities for   # a subset of individuals   plot(ps1, ids = c(7,13,15))   # We can change or add attributes to the plot   plot(ps1, ids = c(7,13,15), limits = \"none\")   plot(ps1, ids = c(7,13,15), xlab = \"Follow up time\")   plot(ps1, ids = c(7,13,15), ci_geom_args = list(fill = \"red\"),        color = \"blue\", linetype = 2)   plot(ps1, ids = c(7,13,15), facet_scales = \"fixed\")    # Since the returned plot is also a ggplot object, we can   # modify some of its attributes after it has been returned   plot1 <- plot(ps1, ids = c(7,13,15))   plot1 +     ggplot2::theme(strip.background = ggplot2::element_blank()) +     ggplot2::coord_cartesian(xlim = c(0, 15)) +     ggplot2::labs(title = \"Some plotted survival functions\")    # We can also combine the plot(s) of the estimated   # subject-specific survival functions, with plot(s)   # of the estimated longitudinal trajectories for the   # same individuals   ps1 <- posterior_survfit(example_jm, ids = c(7,13,15))   pt1 <- posterior_traj(example_jm, , ids = c(7,13,15))   plot_surv <- plot(ps1)   plot_traj <- plot(pt1, vline = TRUE, plot_observed = TRUE)   plot_stack_jm(plot_traj, plot_surv)    # Lastly, let us plot the standardised survival function   # based on all individuals in our estimation dataset   ps2 <- posterior_survfit(example_jm, standardise = TRUE, times = 0,                           control = list(epoints = 20))   plot(ps2) # } } #> Coordinate system already present. #> ℹ Adding new coordinate system, which will replace the existing one. #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x'  if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{   if (!exists(\"example_jm\")) example(example_jm)   ps1 <- posterior_survfit(example_jm, ids = c(7,13,15))   pt1 <- posterior_traj(example_jm, ids = c(7,13,15), extrapolate = TRUE)   plot_surv <- plot(ps1)   plot_traj <- plot(pt1, vline = TRUE, plot_observed = TRUE)   plot_stack_jm(plot_traj, plot_surv) # } } #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior uncertainty intervals — posterior_interval.stanreg","title":"Posterior uncertainty intervals — posterior_interval.stanreg","text":"models fit using MCMC (algorithm=\"sampling\") one variational approximations (\"meanfield\" \"fullrank\"), posterior_interval function computes Bayesian posterior uncertainty intervals. intervals often referred credible intervals, use term uncertainty intervals highlight fact wider intervals correspond greater uncertainty.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior uncertainty intervals — posterior_interval.stanreg","text":"","code":"# S3 method for class 'stanreg' posterior_interval(   object,   prob = 0.9,   type = \"central\",   pars = NULL,   regex_pars = NULL,   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior uncertainty intervals — posterior_interval.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. prob number \\(p \\(0,1)\\) indicating desired probability mass include intervals. default report \\(90\\)% intervals (prob=0.9) rather traditionally used \\(95\\)% (see Details). type type interval compute. Currently option \"central\" (see Details). central \\(100p\\)% interval defined \\(\\alpha/2\\) \\(1 - \\alpha/2\\) quantiles, \\(\\alpha = 1 - p\\). pars optional character vector parameter names. regex_pars optional character vector regular expressions use parameter selection. regex_pars can used place pars addition pars. Currently, functions accept regex_pars argument ignore models fit using optimization. ... Currently ignored.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior uncertainty intervals — posterior_interval.stanreg","text":"matrix two columns many rows model parameters (  subset parameters specified pars /  regex_pars). given value prob, \\(p\\), columns   correspond lower upper \\(100p\\)% interval limits   names \\(100\\alpha/2\\)% \\(100(1 - \\alpha/2)\\)%, \\(\\alpha   = 1-p\\). example, prob=0.9 specified (\\(90\\)%   interval), column names \"5%\" \"95%\",   respectively.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html","id":"interpretation","dir":"Reference","previous_headings":"","what":"Interpretation","title":"Posterior uncertainty intervals — posterior_interval.stanreg","text":"Unlike frenquentist confidence interval, valid say , conditional data model, believe probability \\(p\\) value parameter \\(100p\\)% posterior interval. intuitive interpretation Bayesian intervals often erroneously applied frequentist confidence intervals. See Morey et al. (2015) details issue advantages using Bayesian posterior uncertainty intervals (also known credible intervals).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html","id":"default-intervals","dir":"Reference","previous_headings":"","what":"Default 90% intervals","title":"Posterior uncertainty intervals — posterior_interval.stanreg","text":"default reporting \\(90\\)% intervals rather \\(95\\)% intervals several reasons: Computational stability: \\(90\\)% intervals stable  \\(95\\)% intervals (end relies \\(2.5\\)%  posterior draws). Relation Type-S errors (Gelman Carlin, 2014):  \\(95\\)% mass \\(90\\)% central interval lower  value (\\(95\\)% upper value). parameter  \\(\\theta\\), therefore easy see posterior probability  \\(\\theta > 0\\) (\\(\\theta < 0\\)) larger smaller \\(95\\)%. course, \\(95\\)% intervals desired can computed specifying prob=0.95.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html","id":"types-of-intervals","dir":"Reference","previous_headings":"","what":"Types of intervals","title":"Posterior uncertainty intervals — posterior_interval.stanreg","text":"Currently posterior_interval computes central intervals types intervals rarely useful models rstanarm can estimate. Additional possibilities may provided future releases models become available.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Posterior uncertainty intervals — posterior_interval.stanreg","text":"Gelman, . Carlin, J. (2014). Beyond power calculations: assessing Type S (sign) Type M (magnitude) errors. Perspectives Psychological Science. 9(6), 641–51. Morey, R. D., Hoekstra, R., Rouder, J., Lee, M. D., Wagenmakers, E. (2016). fallacy placing confidence confidence intervals. Psychonomic Bulletin & Review. 23(1), 103–123.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/posterior_interval.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior uncertainty intervals — posterior_interval.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { if (!exists(\"example_model\")) example(example_model) posterior_interval(example_model) posterior_interval(example_model, regex_pars = \"herd\") posterior_interval(example_model, pars = \"period2\", prob = 0.5) } #>               25%        75% #> period2 -1.190268 -0.7887574"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Posterior distribution of the (possibly transformed) linear predictor — posterior_linpred.stanreg","title":"Posterior distribution of the (possibly transformed) linear predictor — posterior_linpred.stanreg","text":"Extract posterior draws linear predictor, possibly transformed inverse-link function. function occasionally useful, used sparingly: inference model checking generally carried using posterior predictive distribution (.e., using posterior_predict).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Posterior distribution of the (possibly transformed) linear predictor — posterior_linpred.stanreg","text":"","code":"# S3 method for class 'stanreg' posterior_linpred(   object,   transform = FALSE,   newdata = NULL,   draws = NULL,   re.form = NULL,   offset = NULL,   XZ = FALSE,   ... )  # S3 method for class 'stanreg' posterior_epred(   object,   newdata = NULL,   draws = NULL,   re.form = NULL,   offset = NULL,   XZ = FALSE,   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Posterior distribution of the (possibly transformed) linear predictor — posterior_linpred.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. transform linear predictor transformed using inverse-link function? default FALSE. argument still allowed recommended posterior_epred function now provides equivalent posterior_linpred(..., transform=TRUE). See Examples. newdata, draws, re.form, offset posterior_predict. XZ TRUE instead computing linear predictor design matrix X (cbind(X,Z) models group-specific terms) constructed newdata returned. default FALSE. ... Currently ignored.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Posterior distribution of the (possibly transformed) linear predictor — posterior_linpred.stanreg","text":"default return draws nrow(newdata)   matrix simulations posterior distribution (possibly   transformed) linear predictor. exception argument XZ   set TRUE (see XZ argument description ).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Posterior distribution of the (possibly transformed) linear predictor — posterior_linpred.stanreg","text":"posterior_linpred function returns posterior   distribution linear predictor, posterior_epred   function returns posterior distribution conditional expectation.   special case Gaussian likelihood identity link   function, two concepts . posterior_epred   function less noisy way obtain expectations output   posterior_predict.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Posterior distribution of the (possibly transformed) linear predictor — posterior_linpred.stanreg","text":"models estimated stan_clogit, number   successes per stratum ostensibly fixed research design. Thus,   calling posterior_linpred new data transform =   TRUE, data.frame passed newdata argument must   contain outcome variable stratifying factor,   name original data.frame. , probabilities   condition outcome new data.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/posterior_linpred.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Posterior distribution of the (possibly transformed) linear predictor — posterior_linpred.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { if (!exists(\"example_model\")) example(example_model) print(family(example_model))  # linear predictor on log-odds scale linpred <- posterior_linpred(example_model) colMeans(linpred)  # probabilities # same as posterior_linpred(example_model, transform = TRUE) probs <- posterior_epred(example_model)  colMeans(probs)  # not conditioning on any group-level parameters probs2 <- posterior_epred(example_model, re.form = NA) apply(probs2, 2, median) } #>  #> Family: binomial  #> Link function: logit  #>  #>          1          2          3          4          5          6          7  #> 0.19321385 0.07963232 0.07058646 0.04248258 0.20038371 0.08293944 0.07416584  #>          8          9         10         11         12         13         14  #> 0.20038371 0.08184582 0.07185831 0.04623685 0.19090399 0.07887589 0.07058646  #>         15         16         17         18         19         20         21  #> 0.04277052 0.19618560 0.08564462 0.07561027 0.04226464 0.19533469 0.08247894  #>         22         23         24         25         26         27         28  #> 0.07292688 0.04623685 0.19424230 0.07887589 0.07058646 0.04248258 0.21139640  #>         29         30         31         32         33         34         35  #> 0.19034663 0.07727663 0.07032113 0.04277052 0.20038371 0.08387899 0.07292688  #>         36         37         38         39         40         41         42  #> 0.04711961 0.20205369 0.08630690 0.07462140 0.04711961 0.19090399 0.07843710  #>         43         44         45         46         47         48         49  #> 0.06977302 0.04248258 0.19933598 0.08501582 0.07355331 0.04754166 0.19751916  #>         50         51         52         53         54         55         56  #> 0.07599325 0.06856146 0.04164939 0.19751916 0.08096430 0.07165066 0.04567692"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw from posterior predictive distribution — posterior_predict.stanreg","title":"Draw from posterior predictive distribution — posterior_predict.stanreg","text":"posterior predictive distribution distribution outcome implied model using observed data update beliefs unknown parameters model. Simulating data posterior predictive distribution using observed predictors useful checking fit model. Drawing posterior predictive distribution interesting values predictors also lets us visualize manipulation predictor affects (function ) outcome(s). new observations predictor variables can use posterior predictive distribution generate predicted outcomes.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw from posterior predictive distribution — posterior_predict.stanreg","text":"","code":"# S3 method for class 'stanreg' posterior_predict(   object,   newdata = NULL,   draws = NULL,   re.form = NULL,   fun = NULL,   seed = NULL,   offset = NULL,   ... )  # S3 method for class 'stanmvreg' posterior_predict(   object,   m = 1,   newdata = NULL,   draws = NULL,   re.form = NULL,   fun = NULL,   seed = NULL,   offset = NULL,   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw from posterior predictive distribution — posterior_predict.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. newdata Optionally, data frame look variables predict. omitted, model matrix used. newdata provided variables transformed (e.g. rescaled) data used fit model, variables must also transformed newdata. applies variables transformed passing data one modeling functions transformations specified inside model formula. Also see Note section note using newdata argument binomial models. draws integer indicating number draws return. default maximum number draws size posterior sample. re.form object contains group-level parameters, formula indicating group-level parameters condition making predictions. re.form specified form predict.merMod. default, NULL, indicates estimated group-level parameters conditioned . refrain conditioning group-level parameters, specify NA ~0. newdata argument may include new levels grouping factors specified model estimated, case resulting posterior predictions marginalize relevant variables. fun optional function apply results. fun found call match.fun can specified function object, string naming function, etc. seed optional seed use. offset vector offsets. required newdata specified offset argument specified fitting model. ... stanmvreg objects, argument m can specified indicating submodel wish obtain predictions. m Integer specifying number name submodel","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw from posterior predictive distribution — posterior_predict.stanreg","text":"draws nrow(newdata) matrix simulations   posterior predictive distribution. row matrix vector   predictions generated using single draw model parameters   posterior distribution.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Draw from posterior predictive distribution — posterior_predict.stanreg","text":"binomial models number trials greater one (.e.,   Bernoulli models), newdata specified must include   variables needed computing number binomial trials use   predictions. example left-hand side model formula   cbind(successes, failures) successes   failures must newdata. particular values   successes failures newdata matter   long sum desired number trials. left-hand side   model formula cbind(successes, trials - successes)   trials successes need newdata,   probably successes set 0 trials specifying   number trials. See Examples section   Use rstanarm Package examples. models estimated stan_clogit, number   successes per stratum ostensibly fixed research design. Thus,   posterior prediction new data, data.frame passed   newdata argument must contain outcome variable stratifying   factor, name original data.frame. ,   posterior predictions condition outcome new data.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw from posterior predictive distribution — posterior_predict.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { if (!exists(\"example_model\")) example(example_model) yrep <- posterior_predict(example_model) table(yrep)  # \\donttest{ # Using newdata counts <- c(18,17,15,20,10,20,25,13,12) outcome <- gl(3,1,9) treatment <- gl(3,3) dat <- data.frame(counts, treatment, outcome) fit3 <- stan_glm(   counts ~ outcome + treatment,    data = dat,   family = poisson(link=\"log\"),   prior = normal(0, 1, autoscale = FALSE),    prior_intercept = normal(0, 5, autoscale = FALSE),   refresh = 0 ) nd <- data.frame(treatment = factor(rep(1,3)), outcome = factor(1:3)) ytilde <- posterior_predict(fit3, nd, draws = 500) print(dim(ytilde))  # 500 by 3 matrix (draws by nrow(nd))  ytilde <- data.frame(   count = c(ytilde),   outcome = rep(nd$outcome, each = 500) ) ggplot2::ggplot(ytilde, ggplot2::aes(x=outcome, y=count)) +   ggplot2::geom_boxplot() +   ggplot2::ylab(\"predicted count\")   # Using newdata with a binomial model. # example_model is binomial so we need to set # the number of trials to use for prediction. # This could be a different number for each # row of newdata or the same for all rows. # Here we'll use the same value for all. nd <- lme4::cbpp print(formula(example_model))  # cbind(incidence, size - incidence) ~ ... nd$size <- max(nd$size) + 1L   # number of trials nd$incidence <- 0  # set to 0 so size - incidence = number of trials ytilde <- posterior_predict(example_model, newdata = nd)   # Using fun argument to transform predictions mtcars2 <- mtcars mtcars2$log_mpg <- log(mtcars2$mpg) fit <- stan_glm(log_mpg ~ wt, data = mtcars2, refresh = 0) ytilde <- posterior_predict(fit, fun = exp) # } } #> [1] 500   3 #> cbind(incidence, size - incidence) ~ size + period + (1 | herd)"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_survfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate subject-specific or standardised survival probabilities — posterior_survfit","title":"Estimate subject-specific or standardised survival probabilities — posterior_survfit","text":"function allows us generate estimated survival probabilities based draws posterior predictive distribution. default survival probabilities conditional individual's group-specific coefficients (.e. individual-level random effects). prediction data provided via newdataLong newdataEvent arguments, default behaviour sample new group-specific coefficients individuals new data using Monte Carlo scheme conditions longitudinal outcome data provided newdataLong (sometimes referred \"dynamic predictions\", see Rizopoulos (2011)). default behaviour can stopped specifying dynamic = FALSE, case predicted survival probabilities marginalised distribution group-specific coefficients. benefit user need provide longitudinal outcome measurements new individuals, however, mean predictions incorporate uncertainty associated -individual variation, since predictions conditional observed data individual. addition, default, predicted subject-specific survival probabilities conditional observed values fixed effect covariates (ie, predictions obtained using either design matrices used original stan_jm model call, using covariate values provided newdataLong newdataEvent arguments). However, wish average observed distribution fixed effect covariates possible – predictions sometimes referred standardised survival probabilties – see standardise argument .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_survfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate subject-specific or standardised survival probabilities — posterior_survfit","text":"","code":"posterior_survfit(   object,   newdataLong = NULL,   newdataEvent = NULL,   extrapolate = TRUE,   control = list(),   condition = NULL,   last_time = NULL,   prob = 0.95,   ids,   times = NULL,   standardise = FALSE,   dynamic = TRUE,   scale = 1.5,   draws = NULL,   seed = NULL,   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_survfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate subject-specific or standardised survival probabilities — posterior_survfit","text":"object fitted model object returned stan_jm modelling function. See stanreg-objects. newdataLong, newdataEvent Optionally, data frame (case newdataLong can list data frames) look variables predict. omitted, model matrices used. new data provided, also contain longitudinal outcome data condition drawing new group-specific coefficients individuals new data. Note allowed one row data individual newdataEvent, , time-varying covariates allowed prediction data event submodel. Also, newdataEvent can optionally include variable information last known survival time new individuals – see description last_time argument – however also note generating survival probabilities course assumed individuals newdataEvent yet experienced event (, variable newdataEvent corresponds event indicator ignored). extrapolate logical specifying whether extrapolate estimated survival probabilities beyond times specified times argument. TRUE extrapolation can controlled using control argument. control named list parameters controlling extrapolation   estimated survival function extrapolate = TRUE. list   can contain one following named elements: epoints positive integer specifying number     discrete time points calculate forecasted survival     probabilities. default 10. edist positive scalar specifying amount time     across forecast estimated survival function, represented     units time variable time_var (fitting model).     default extrapolate times specified     times argument maximum event censoring time     original data. edist leads times beyond     maximum event censoring time original data     estimated survival probabilities truncated point, since     estimate baseline hazard available beyond time. condition logical specifying whether estimated subject-specific survival probabilities time t conditioned survival fixed time point u. default condition set TRUE, unless standardised survival probabilities requested (specifying standardise = TRUE), case condition must () set FALSE. conditional survival probabilities requested, fixed time point u either: () value specified via last_time argument; last_time argument NULL latest observation time individual (taken value times argument newdataEvent specified, observed event censoring time newdataEvent NULL. last_time scalar, character string, NULL. argument specifies last known survival time individual conditional predictions obtained. newdataEvent provided conditional survival predictions obtained, last_time argument can one following: () scalar, use last time individual newdataEvent; (ii) character string, naming column newdataEvent look last time individual; (iii) NULL, case default use time latest longitudinal observation newdataLong. newdataEvent NULL last_time argument specified directly; instead set equal event censoring time individual dataset used estimate model. standardised survival probabilities requested (.e. standardise = TRUE) conditional survival probabilities allowed therefore last_time argument ignored. prob scalar 0 1 specifying width use uncertainty interval (sometimes called credible interval) predictions. example prob = 0.95 (default) means 2.5th 97.5th percentiles provided. ids optional vector specifying subset IDs predictions obtained. default predict individuals used estimating model , newdataLong newdataEvent specified, individuals contained new data. times scalar, character string, NULL. Specifies times estimated survival probabilities calculated. can either: () NULL, case default last known survival time individual, determined last_time argument; (ii) scalar, specifying time estimate survival probability individuals; (iii) newdataEvent provided, can name variable newdataEvent indicates time survival probabilities calculated individual. standardise logical specifying whether estimated subject-specific survival probabilities averaged across individuals subject-specific predictions obtained. can used average covariate random effects distributions individuals used estimating model, individuals included newdata arguments. approach averaging across observed distribution covariates sometimes referred \"standardised\" survival curve. standardise = TRUE, times argument must specified must constant across individuals, , survival probabilities must calculated time individuals. dynamic logical relevant new data provided via newdataLong newdataEvent arguments. dynamic = TRUE, new group-specific parameters drawn individuals new data, conditional longitudinal biomarker data contained newdataLong. group-specific parameters used generate individual-specific survival probabilities individuals. often referred \"dynamic predictions\" joint modelling context, predictions can updated time additional longitudinal biomarker data collected individual. hand, dynamic = FALSE survival probabilities just marginalised distribution group-specific coefficients; mean predictions incorporate uncertainty due -individual variation likely wide credible intervals predicted survival probabilities. scale scalar, specifying much multiply asymptotic variance-covariance matrix random effects , used \"width\" (ie. variance-covariance matrix) multivariate Student-t proposal distribution Metropolis-Hastings algorithm. relevant newdataEvent supplied dynamic = TRUE, case new random effects simulated individuals new data using Metropolis-Hastings algorithm. draws integer indicating number MCMC draws return. default set number draws equal 200, equal size posterior sample less 200. seed optional seed use. ... Currently unused.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_survfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate subject-specific or standardised survival probabilities — posterior_survfit","text":"data frame class survfit.stanjm. data frame includes   columns following:   () median posterior predictions estimated survival   probabilities (survpred);   (ii) lower upper limits corresponding uncertainty   interval estimated survival probabilities (ci_lb   ci_ub);   (iii) subject identifier (id_var), unless standardised survival   probabilities estimated;   (iv) time estimated survival probability calculated   (time_var).   returned object also includes number additional attributes.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_survfit.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Estimate subject-specific or standardised survival probabilities — posterior_survfit","text":"Note variables transformed (e.g. rescaled) data   used fit model, variables must also transformed   newdataLong newdataEvent. applies variables   transformed passing data one modeling functions   transformations specified inside model formula.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_survfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate subject-specific or standardised survival probabilities — posterior_survfit","text":"Rizopoulos, D. (2011). Dynamic predictions prospective accuracy   joint models longitudinal time--event data. Biometrics   67, 819.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/posterior_survfit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate subject-specific or standardised survival probabilities — posterior_survfit","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{   # Run example model if not already loaded   if (!exists(\"example_jm\")) example(example_jm)    # Obtain subject-specific survival probabilities for a few   # selected individuals in the estimation dataset who were   # known to survive up until their censoring time. By default   # the posterior_survfit function will estimate the conditional   # survival probabilities, that is, conditional on having survived   # until the event or censoring time, and then by default will   # extrapolate the survival predictions forward from there.   ps1 <- posterior_survfit(example_jm, ids = c(7,13,15))   # We can plot the estimated survival probabilities using the   # associated plot function   plot(ps1)    # If we wanted to estimate the survival probabilities for the   # same three individuals as the previous example, but this time   # we won't condition on them having survived up until their   # censoring time. Instead, we will estimate their probability   # of having survived between 0 and 5 years given their covariates   # and their estimated random effects.   # The easiest way to achieve the time scale we want (ie, 0 to 5 years)   # is to specify that we want the survival time estimated at time 0   # and then extrapolated forward 5 years. We also specify that we   # do not want to condition on their last known survival time.   ps2 <- posterior_survfit(example_jm, ids = c(7,13,15), times = 0,     extrapolate = TRUE, condition = FALSE, control = list(edist = 5))    # Instead we may want to estimate subject-specific survival probabilities   # for a set of new individuals. To demonstrate this, we will simply take   # the first two individuals in the estimation dataset, but pass their data   # via the newdata arguments so that posterior_survfit will assume we are   # predicting survival for new individuals and draw new random effects   # under a Monte Carlo scheme (see Rizopoulos (2011)).   ndL <- pbcLong[pbcLong$id %in% c(1,2),]   ndE <- pbcSurv[pbcSurv$id %in% c(1,2),]   ps3 <- posterior_survfit(example_jm,     newdataLong = ndL, newdataEvent = ndE,     last_time = \"futimeYears\", seed = 12345)   head(ps3)   # We can then compare the estimated random effects for these   # individuals based on the fitted model and the Monte Carlo scheme   ranef(example_jm)$Long1$id[1:2,,drop=FALSE] # from fitted model   colMeans(attr(ps3, \"b_new\"))                # from Monte Carlo scheme    # Lastly, if we wanted to obtain \"standardised\" survival probabilities,   # (by averaging over the observed distribution of the fixed effect   # covariates, as well as averaging over the estimated random effects   # for individuals in our estimation sample or new data) then we can   # specify 'standardise = TRUE'. We can then plot the resulting   # standardised survival curve.   ps4 <- posterior_survfit(example_jm, standardise = TRUE,                            times = 0, extrapolate = TRUE)   plot(ps4) # } } #> Drawing new random effects for 2 individuals. Monitoring progress: #>    |                                                                               |                                                                      |   0%   |                                                                               |===================================                                   |  50%   |                                                                               |======================================================================| 100%"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_traj.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the subject-specific or marginal longitudinal trajectory — posterior_traj","title":"Estimate the subject-specific or marginal longitudinal trajectory — posterior_traj","text":"function allows us generate estimated longitudinal trajectory (either subject-specific, marginalising distribution group-specific parameters) based draws posterior predictive distribution.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_traj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the subject-specific or marginal longitudinal trajectory — posterior_traj","text":"","code":"posterior_traj(   object,   m = 1,   newdata = NULL,   newdataLong = NULL,   newdataEvent = NULL,   interpolate = TRUE,   extrapolate = FALSE,   control = list(),   last_time = NULL,   prob = 0.95,   ids,   dynamic = TRUE,   scale = 1.5,   draws = NULL,   seed = NULL,   return_matrix = FALSE,   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_traj.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the subject-specific or marginal longitudinal trajectory — posterior_traj","text":"object fitted model object returned stan_jm modelling function. See stanreg-objects. m Integer specifying number name submodel newdata Deprecated: please use newdataLong instead. Optionally, data frame look variables predict. omitted, model matrix used. newdata provided variables transformed (e.g. rescaled) data used fit model, variables must also transformed newdata. applies variables transformed passing data one modeling functions transformations specified inside model formula. newdataLong, newdataEvent Optionally, data frame (case newdataLong can list data frames) look variables predict. omitted, model matrices used. new data provided, two options available. Either one can provide observed covariate outcome data, collected time t, use data draw new individual-specific coefficients (.e. individual-level random effects). default behaviour new data provided, determined argument dynamic = TRUE, requiring newdataLong newdataEvent specified. Alternatively, one can specify dynamic = FALSE, predict using just covariate data, marginalising distribution group-specific coefficients; case, newdataLong needs specified needs single data frame covariate data predictions one longitudinal submodel. interpolate logical specifying whether interpolate estimated longitudinal trajectory observation times. can used achieve smooth estimate longitudinal trajectory across entire follow time. TRUE interpolation can controlled using control argument. extrapolate logical specifying whether extrapolate estimated longitudinal trajectory beyond time last known observation time. TRUE extrapolation can controlled using control argument. control named list parameters controlling interpolation extrapolation estimated longitudinal trajectory either interpolate = TRUE extrapolate = TRUE. list can contain one following named elements: ipoints positive integer specifying number discrete   time points calculate estimated longitudinal response   interpolate = TRUE. time points evenly spaced starting   0 ending last known observation time individual.   last observation time individual taken either:   event censoring time new data provided; time specified   \"last_time\" column provided new data (see Details   section ); time last longitudinal measurement new   data provided \"last_time\" column included. default 15. epoints positive integer specifying number discrete   time points calculate estimated longitudinal response   extrapolate = TRUE. time points evenly spaced   last known observation time individual extrapolation   distance specifed using either edist eprop.   default 15. eprop positive scalar 0 1 specifying   amount time across extrapolate longitudinal trajectory,   represented proportion total observed follow time   individual. example specifying eprop = 0.2 means   individual latest measurement, event censoring times   10 years, estimated longitudinal trajectory extrapolated   12 years (.e. 10 + (0.2 * 10)). default value 0.2. edist positive scalar specifying amount time   across extrapolate longitudinal trajectory individual,   represented units time variable time_var (fitting   model). specified eprop specified. last_time scalar, character string, NULL. argument specifies last known survival time individual conditional predictions obtained. newdataEvent provided conditional survival predictions obtained, last_time argument can one following: () scalar, use last time individual newdataEvent; (ii) character string, naming column newdataEvent look last time individual; (iii) NULL, case default use time latest longitudinal observation newdataLong. newdataEvent NULL last_time argument specified directly; instead set equal event censoring time individual dataset used estimate model. standardised survival probabilities requested (.e. standardise = TRUE) conditional survival probabilities allowed therefore last_time argument ignored. prob scalar 0 1 specifying width use uncertainty interval (sometimes called credible interval) predicted mean response prediction interval predicted (raw) response. example prob = 0.95 (default) means 2.5th 97.5th percentiles provided. relevant return_matrix FALSE. ids optional vector specifying subset subject IDs predictions obtained. default predict individuals used estimating model , newdata specified, individuals contained newdata. dynamic logical relevant new data provided via newdata argument. dynamic = TRUE, new group-specific parameters drawn individuals new data, conditional longitudinal biomarker data contained newdata. group-specific parameters used generate individual-specific survival probabilities individuals. often referred \"dynamic predictions\" joint modelling context, predictions can updated time additional longitudinal biomarker data collected individual. hand, dynamic = FALSE survival probabilities just marginalised distribution group-specific coefficients; mean predictions incorporate uncertainty due -individual variation likely wide credible intervals predicted survival probabilities. scale scalar, specifying much multiply asymptotic variance-covariance matrix random effects , used \"width\" (ie. variance-covariance matrix) multivariate Student-t proposal distribution Metropolis-Hastings algorithm. relevant newdataEvent supplied dynamic = TRUE, case new random effects simulated individuals new data using Metropolis-Hastings algorithm. draws integer indicating number MCMC draws return. default set number draws equal 200, equal size posterior sample less 200. seed optional seed use. return_matrix logical. TRUE draws nrow(newdata) matrix returned contains actual simulations draws posterior predictive distribution. Otherwise return_matrix set FALSE (default) data frame returned, described Value section . ... arguments passed posterior_predict, example draws, re.form, seed, etc.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_traj.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the subject-specific or marginal longitudinal trajectory — posterior_traj","text":"return_matrix = FALSE, data frame   class predict.stanjm. data frame includes column median   posterior predictions mean longitudinal response (yfit),   column lower upper limits uncertainty interval   corresponding posterior predictions mean longitudinal response   (ci_lb ci_ub), column lower upper   limits prediction interval corresponding posterior predictions   (raw) longitudinal response. data frame also includes columns   subject ID variable, predictor variables. returned   object also includes number attributes. return_matrix = TRUE, returned object   described posterior_predict.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_traj.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate the subject-specific or marginal longitudinal trajectory — posterior_traj","text":"posterior_traj function acts wrapper posterior_predict function, allows predictions easily generated time points interpolated /extrapolated time zero (baseline) last known survival time individual, thereby providing predictions correspond smooth estimate longitudinal trajectory (useful plotting via associated plot.predict.stanjm method). addition returns data frame default, whereas posterior_predict function returns matrix; see Value section details. Also, posterior_traj allows predictions generated subset individuals, via ids argument.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/posterior_traj.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate the subject-specific or marginal longitudinal trajectory — posterior_traj","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{   # Run example model if not already loaded   if (!exists(\"example_jm\")) example(example_jm)      # Obtain subject-specific predictions for all individuals    # in the estimation dataset   pt1 <- posterior_traj(example_jm, interpolate = FALSE, extrapolate = FALSE)   head(pt1)      # Obtain subject-specific predictions only for a few selected individuals   pt2 <- posterior_traj(example_jm, ids = c(1,3,8))      # If we wanted to obtain subject-specific predictions in order to plot the    # longitudinal trajectories, then we might want to ensure a full trajectory    # is obtained by interpolating and extrapolating time. We can then use the    # generic plot function to plot the subject-specific predicted trajectories   # for the first three individuals. Interpolation and extrapolation is    # carried out by default.   pt3 <- posterior_traj(example_jm)   head(pt3) # predictions at additional time points compared with pt1    plot(pt3, ids = 1:3)      # If we wanted to extrapolate further in time, but decrease the number of    # discrete time points at which we obtain predictions for each individual,    # then we could specify a named list in the 'control' argument   pt4 <- posterior_traj(example_jm, control = list(ipoints = 10, epoints = 10, eprop = 0.5))      # If we have prediction data for a new individual, and we want to   # estimate the longitudinal trajectory for that individual conditional   # on this new data (perhaps extrapolating forward from our last   # longitudinal measurement) then we can do that. It requires drawing   # new individual-specific parameters, based on the full likelihood,   # so we must supply new data for both the longitudinal and event    # submodels. These are sometimes known as dynamic predictions.   ndL <- pbcLong[pbcLong$id == 8, , drop = FALSE]   ndE <- pbcSurv[pbcSurv$id == 8, , drop = FALSE]   ndL$id <- \"new_subject\" # new id can't match one used in training data   ndE$id <- \"new_subject\"   pt5 <- posterior_traj(example_jm,                          newdataLong = ndL,                         newdataEvent = ndE)                            # By default it is assumed that the last known survival time for    # the individual is the time of their last biomarker measurement,   # but if we know they survived to some later time then we can   # condition on that information using the last_time argument   pt6 <- posterior_traj(example_jm,                          newdataLong = ndL,                         newdataEvent = ndE,                          last_time = \"futimeYears\")      # Alternatively we may want to estimate the marginal longitudinal   # trajectory for a given set of covariates. To do this, we can pass   # the desired covariate values in a new data frame (however the only   # covariate in our fitted model was the time variable, year). To make sure     # that we marginalise over the random effects, we need to specify an ID value   # which does not correspond to any of the individuals who were used in the   # model estimation and specify the argument dynamic=FALSE.   # The marginal prediction is obtained by generating subject-specific    # predictions using a series of random draws from the random    # effects distribution, and then integrating (ie, averaging) over these.    # Our marginal prediction will therefore capture the between-individual    # variation associated with the random effects.      nd <- data.frame(id = rep(\"new1\", 11), year = (0:10 / 2))   pt7 <- posterior_traj(example_jm, newdataLong = nd, dynamic = FALSE)   head(pt7)  # note the greater width of the uncertainty interval compared               # with the subject-specific predictions in pt1, pt2, etc      # Alternatively, we could have estimated the \"marginal\" trajectory by    # ignoring the random effects (ie, assuming the random effects were set    # to zero). This will generate a predicted longitudinal trajectory only   # based on the fixed effect component of the model. In essence, for a    # linear mixed effects model (ie, a model that uses an identity link    # function), we should obtain a similar point estimate (\"yfit\") to the   # estimates obtained in pt5 (since the mean of the estimated random effects   # distribution will be approximately 0). However, it is important to note that   # the uncertainty interval will be much more narrow, since it completely   # ignores the between-individual variability captured by the random effects.   # Further, if the model uses a non-identity link function, then the point   # estimate (\"yfit\") obtained only using the fixed effect component of the   # model will actually provide a biased estimate of the marginal prediction.   # Nonetheless, to demonstrate how we can obtain the predictions only using    # the fixed effect component of the model, we simply specify 're.form = NA'.    # (We will use the same covariate values as used in the prediction for    # example for pt5).      pt8 <- posterior_traj(example_jm, newdataLong = nd, dynamic = FALSE,                          re.form = NA)   head(pt8)  # note the much narrower ci, compared with pt5 # } } #> `geom_smooth()` using formula = 'y ~ x' #> `geom_smooth()` using formula = 'y ~ x' #> Drawing new random effects for 1 individuals. Monitoring progress: #>    |                                                                               |                                                                      |   0%   |                                                                               |======================================================================| 100% #> Drawing new random effects for 1 individuals. Monitoring progress: #>    |                                                                               |                                                                      |   0%   |                                                                               |======================================================================| 100% #>     id      year      yfit      ci_lb     ci_ub      pi_lb    pi_ub #> 1 new1 0.0000000 0.4916872 -0.4241185 0.8481504 -1.2898612 1.439933 #> 2 new1 0.3571429 0.5504692 -0.3639245 0.9054757 -0.4663548 1.641273 #> 3 new1 0.7142857 0.6128161 -0.3037304 0.9653442 -0.4979441 1.371600 #> 4 new1 1.0714286 0.6751630 -0.2435363 1.0255971 -0.5529147 1.420842 #> 5 new1 1.4285714 0.7358875 -0.1833423 1.0858500 -0.3959071 1.359410 #> 6 new1 1.7857143 0.7955649 -0.1231482 1.1461029 -0.4307864 1.614048"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_vs_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Juxtapose prior and posterior — posterior_vs_prior","title":"Juxtapose prior and posterior — posterior_vs_prior","text":"Plot medians central intervals comparing parameter draws prior posterior distributions. plotted priors look different priors think specified likely either internal rescaling use QR argument (see documentation prior_summary method details special cases).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_vs_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Juxtapose prior and posterior — posterior_vs_prior","text":"","code":"posterior_vs_prior(object, ...)  # S3 method for class 'stanreg' posterior_vs_prior(   object,   pars = NULL,   regex_pars = NULL,   prob = 0.9,   color_by = c(\"parameter\", \"vs\", \"none\"),   group_by_parameter = FALSE,   facet_args = list(),   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/posterior_vs_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Juxtapose prior and posterior — posterior_vs_prior","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. ... S3 generic uses ... pass arguments defined methods. method stanreg objects, ... arguments (color) passed geom_pointrange ggplot2 package control appearance plotted intervals. pars optional character vector specifying subset parameters display. Parameters can specified name several shortcuts can used. Using pars=\"beta\" restrict displayed parameters regression coefficients (without intercept). \"alpha\" can also used shortcut \"(Intercept)\". model varying intercepts /slopes can selected using pars = \"varying\". addition, stanmvreg objects additional shortcuts available. Using pars = \"long\" display parameter estimates longitudinal submodels (excluding group-specific pparameters, including auxiliary parameters). Using pars = \"event\" display parameter estimates event submodel , including association parameters. Using pars = \"assoc\" display association parameters. Using pars = \"fixef\" display fixed effects, random effects auxiliary parameters.  pars regex_pars set NULL fixed effect regression coefficients selected, well auxiliary parameters log posterior. pars NULL parameters selected stanreg object, stanmvreg object fixed effect regression coefficients selected well auxiliary parameters log posterior. See Examples. regex_pars optional character vector regular expressions use parameter selection. regex_pars can used place pars addition pars. Currently, functions accept regex_pars argument ignore models fit using optimization. prob number \\(p \\(0,1)\\) indicating desired posterior probability mass include (central posterior) interval estimates displayed plot. default \\(0.9\\). color_by estimates colored? Use \"parameter\" color parameter name, \"vs\" color prior one color posterior another, \"none\" use color. Except color_by=\"none\", variable mapped color aesthetic therefore also possible change default colors adding one various discrete color scales available ggplot2 (scale_color_manual, scale_colour_brewer, etc.). See Examples. group_by_parameter estimates grouped together parameter (TRUE) posterior prior (FALSE, default)? facet_args named list arguments passed facet_wrap (facets argument), e.g., nrow ncol change layout, scales allow axis scales vary across facets, etc. See Examples.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_vs_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Juxtapose prior and posterior — posterior_vs_prior","text":"ggplot object can customized using   ggplot2 package.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_vs_prior.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Juxtapose prior and posterior — posterior_vs_prior","text":"Gabry, J. , Simpson, D. , Vehtari, . , Betancourt, M.   Gelman, . (2019), Visualization Bayesian workflow. J. R. Stat.   Soc. , 182: 389-402. doi:10.1111/rssa.12378,   arXiv preprint,   code GitHub)","code":""},{"path":"https://mc-stan.org/rstanarm/reference/posterior_vs_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Juxtapose prior and posterior — posterior_vs_prior","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\dontrun{ if (!exists(\"example_model\")) example(example_model) # display non-varying (i.e. not group-level) coefficients posterior_vs_prior(example_model, pars = \"beta\")  # show group-level (varying) parameters and group by parameter posterior_vs_prior(example_model, pars = \"varying\",                    group_by_parameter = TRUE, color_by = \"vs\")  # group by parameter and allow axis scales to vary across facets posterior_vs_prior(example_model, regex_pars = \"period\",                    group_by_parameter = TRUE, color_by = \"none\",                    facet_args = list(scales = \"free\"))  # assign to object and customize with functions from ggplot2 (gg <- posterior_vs_prior(example_model, pars = c(\"beta\", \"varying\"), prob = 0.8))  gg +   ggplot2::geom_hline(yintercept = 0, size = 0.3, linetype = 3) +   ggplot2::coord_flip() +   ggplot2::ggtitle(\"Comparing the prior and posterior\")   # compare very wide and very narrow priors using roaches example # (see help(roaches, \"rstanarm\") for info on the dataset) roaches$roach100 <- roaches$roach1 / 100 wide_prior <- normal(0, 10) narrow_prior <- normal(0, 0.1) fit_pois_wide_prior <- stan_glm(y ~ treatment + roach100 + senior,                                  offset = log(exposure2),                                  family = \"poisson\", data = roaches,                                  prior = wide_prior) posterior_vs_prior(fit_pois_wide_prior, pars = \"beta\", prob = 0.5,                     group_by_parameter = TRUE, color_by = \"vs\",                     facet_args = list(scales = \"free\"))                     fit_pois_narrow_prior <- update(fit_pois_wide_prior, prior = narrow_prior) posterior_vs_prior(fit_pois_narrow_prior, pars = \"beta\", prob = 0.5,                     group_by_parameter = TRUE, color_by = \"vs\",                     facet_args = list(scales = \"free\"))                      # look at cutpoints for ordinal model fit_polr <- stan_polr(tobgp ~ agegp, data = esoph, method = \"probit\",                       prior = R2(0.2, \"mean\"), init_r = 0.1) (gg_polr <- posterior_vs_prior(fit_polr, regex_pars = \"\\\\|\", color_by = \"vs\",                                group_by_parameter = TRUE)) # flip the x and y axes gg_polr + ggplot2::coord_flip() # } } #>  #> Drawing from prior... #>  #> Drawing from prior... #>  #> Drawing from prior... #>  #> Drawing from prior... #> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. #> ℹ Please use `linewidth` instead. #>  #> SAMPLING FOR MODEL 'count' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 3e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.173 seconds (Warm-up) #> Chain 1:                0.172 seconds (Sampling) #> Chain 1:                0.345 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'count' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.8e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.198 seconds (Warm-up) #> Chain 2:                0.232 seconds (Sampling) #> Chain 2:                0.43 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'count' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.177 seconds (Warm-up) #> Chain 3:                0.179 seconds (Sampling) #> Chain 3:                0.356 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'count' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.7e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.181 seconds (Warm-up) #> Chain 4:                0.162 seconds (Sampling) #> Chain 4:                0.343 seconds (Total) #> Chain 4:  #>  #> Drawing from prior... #>  #> SAMPLING FOR MODEL 'count' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.7e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.136 seconds (Warm-up) #> Chain 1:                0.118 seconds (Sampling) #> Chain 1:                0.254 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'count' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.7e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.12 seconds (Warm-up) #> Chain 2:                0.119 seconds (Sampling) #> Chain 2:                0.239 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'count' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.136 seconds (Warm-up) #> Chain 3:                0.116 seconds (Sampling) #> Chain 3:                0.252 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'count' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1.7e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.131 seconds (Warm-up) #> Chain 4:                0.106 seconds (Sampling) #> Chain 4:                0.237 seconds (Total) #> Chain 4:  #>  #> Drawing from prior... #>  #> SAMPLING FOR MODEL 'polr' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 4.6e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.46 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.587 seconds (Warm-up) #> Chain 1:                0.525 seconds (Sampling) #> Chain 1:                1.112 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'polr' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 3.5e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.547 seconds (Warm-up) #> Chain 2:                0.452 seconds (Sampling) #> Chain 2:                0.999 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'polr' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 3.7e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.552 seconds (Warm-up) #> Chain 3:                0.477 seconds (Sampling) #> Chain 3:                1.029 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'polr' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 3.6e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.562 seconds (Warm-up) #> Chain 4:                0.462 seconds (Sampling) #> Chain 4:                1.024 seconds (Total) #> Chain 4:  #>  #> Drawing from prior..."},{"path":"https://mc-stan.org/rstanarm/reference/pp_check.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Graphical posterior predictive checks — pp_check.stanreg","title":"Graphical posterior predictive checks — pp_check.stanreg","text":"Interface PPC (posterior predictive checking) module bayesplot package, providing various plots comparing observed outcome variable \\(y\\) simulated datasets \\(y^{rep}\\) posterior predictive distribution. pp_check method stanreg-objects prepares arguments required specified bayesplot PPC plotting function calls function. also straightforward use functions bayesplot package directly rather via pp_check method. Examples given .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pp_check.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graphical posterior predictive checks — pp_check.stanreg","text":"","code":"# S3 method for class 'stanreg' pp_check(object, plotfun = \"dens_overlay\", nreps = NULL, seed = NULL, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/pp_check.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graphical posterior predictive checks — pp_check.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. plotfun character string naming bayesplot PPC function use. default call ppc_dens_overlay. plotfun can specified either full name bayesplot plotting function (e.g. \"ppc_hist\") can abbreviated part name following \"ppc_\" prefix (e.g. \"hist\"). get names available PPC functions see available_ppc. nreps number \\(y^{rep}\\) datasets generate posterior predictive distribution show plots. default depends plotfun. functions plot yrep dataset separately (e.g. ppc_hist), nreps defaults small value make plots readable. functions overlay many yrep datasets (e.g., ppc_dens_overlay) larger number used default, functions (e.g. ppc_stat) default set nreps equal posterior sample size. seed optional seed pass posterior_predict. ... Additonal arguments passed bayesplot function called. many plotting functions ... optional, however functions require group x argument, arguments specified .... specifying group /x, can provided either strings naming variables (case searched model frame) vectors containing actual values variables. See Examples section, .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pp_check.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graphical posterior predictive checks — pp_check.stanreg","text":"pp_check returns ggplot object can   customized using ggplot2 package.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pp_check.stanreg.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Graphical posterior predictive checks — pp_check.stanreg","text":"binomial data, plots \\(y\\) \\(y^{rep}\\) show   proportion 'successes' rather raw count. Also binomial   models see ppc_error_binned binned residual   plots.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pp_check.stanreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Graphical posterior predictive checks — pp_check.stanreg","text":"Gelman, ., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari,   ., Rubin, D. B. (2013). Bayesian Data Analysis. Chapman & Hall/CRC   Press, London, third edition. (Ch. 6) Gabry, J. , Simpson, D. , Vehtari, . , Betancourt, M.   Gelman, . (2019), Visualization Bayesian workflow. J. R. Stat.   Soc. , 182: 389-402. doi:10.1111/rssa.12378,   arXiv preprint,   code GitHub)","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/pp_check.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graphical posterior predictive checks — pp_check.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { fit <- stan_glmer(   mpg ~ wt + am + (1|cyl),   data = mtcars,   iter = 400, # iter and chains small just to keep example quick   chains = 2,   refresh = 0 )  # Compare distribution of y to distributions of multiple yrep datasets pp_check(fit) pp_check(fit, plotfun = \"boxplot\", nreps = 10, notch = FALSE) pp_check(fit, plotfun = \"hist\", nreps = 3)  # \\donttest{ # Same plot (up to RNG noise) using bayesplot package directly bayesplot::ppc_hist(y = mtcars$mpg, yrep = posterior_predict(fit, draws = 3))  # Check histograms of test statistics by level of grouping variable 'cyl' pp_check(fit, plotfun = \"stat_grouped\", stat = \"median\", group = \"cyl\")  # Defining a custom test statistic q25 <- function(y) quantile(y, probs = 0.25) pp_check(fit, plotfun = \"stat_grouped\", stat = \"q25\", group = \"cyl\")  # Scatterplot of two test statistics pp_check(fit, plotfun = \"stat_2d\", stat = c(\"mean\", \"sd\"))  # Scatterplot of y vs. average yrep pp_check(fit, plotfun = \"scatter_avg\") # y vs. average yrep # Same plot (up to RNG noise) using bayesplot package directly bayesplot::ppc_scatter_avg(y = mtcars$mpg, yrep = posterior_predict(fit))  # Scatterplots of y vs. several individual yrep datasets pp_check(fit, plotfun = \"scatter\", nreps = 3)  # Same plot (up to RNG noise) using bayesplot package directly bayesplot::ppc_scatter(y = mtcars$mpg, yrep = posterior_predict(fit, draws = 3))  # yrep intervals with y points overlaid # by default 1:length(y) used on x-axis but can also specify an x variable pp_check(fit, plotfun = \"intervals\") pp_check(fit, plotfun = \"intervals\", x = \"wt\") + ggplot2::xlab(\"wt\")  # Same plot (up to RNG noise) using bayesplot package directly bayesplot::ppc_intervals(y = mtcars$mpg, yrep = posterior_predict(fit),                          x = mtcars$wt) + ggplot2::xlab(\"wt\")  # predictive errors pp_check(fit, plotfun = \"error_hist\", nreps = 6) pp_check(fit, plotfun = \"error_scatter_avg_vs_x\", x = \"wt\") +   ggplot2::xlab(\"wt\")  # Example of a PPC for ordinal models (stan_polr) fit2 <- stan_polr(tobgp ~ agegp, data = esoph, method = \"probit\",                   prior = R2(0.2, \"mean\"), init_r = 0.1,                   refresh = 0) pp_check(fit2, plotfun = \"bars\", nreps = 500, prob = 0.5) pp_check(fit2, plotfun = \"bars_grouped\", group = esoph$agegp,          nreps = 500, prob = 0.5) # } } #> Warning: There were 3 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is 1.07, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> Warning: Markov chains did not converge! Do not analyze results! #> Error in get(as.character(FUN), mode = \"function\", envir = envir): object 'q25' of mode 'function' was not found"},{"path":"https://mc-stan.org/rstanarm/reference/pp_validate.html","id":null,"dir":"Reference","previous_headings":"","what":"Model validation via simulation — pp_validate","title":"Model validation via simulation — pp_validate","text":"pp_validate function based methods described Cook, Gelman, Rubin (2006) validating software developed fit particular Bayesian models. take perspective models software thus useful apply validation approach individual models.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pp_validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model validation via simulation — pp_validate","text":"","code":"pp_validate(object, nreps = 20, seed = 12345, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/pp_validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model validation via simulation — pp_validate","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. nreps number replications performed. nreps must sufficiently large statistics described Details meaningful. Depending model size data, running pp_validate may slow. See also Note section advice avoiding numerical issues. seed seed passed Stan use refitting model. ... Currently ignored.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pp_validate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model validation via simulation — pp_validate","text":"ggplot object can customized using   ggplot2 package.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pp_validate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model validation via simulation — pp_validate","text":"repeat nreps times process simulating parameters data model refitting model simulated data. nreps replications following: Refit model without conditioning data (setting prior_PD=TRUE), obtaining draws \\(\\theta^{true}\\) prior distribution model parameters. Given \\(\\theta^{true}\\), simulate data \\(y^\\ast\\) prior predictive distribution (calling posterior_predict fitted model object obtained step 1). Fit model simulated outcome \\(y^\\ast\\), obtaining parameters \\(\\theta^{post}\\). individual parameter, quantile \"true\" parameter value respect posterior distribution uniformly distributed. validation procedure entails looking deviations uniformity computing statistics test quantiles uniformly distributed. absolute values computed  test statistics plotted batches parameters (e.g., non-varying coefficients grouped batch called \"beta\", parameters vary group level batches named grouping variable, etc.). See Cook, Gelman, Rubin (2006) details validation procedure.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pp_validate.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Model validation via simulation — pp_validate","text":"order make nreps replications without running   numerical difficulties may restrict range randomly   generating initial values parameters fit original   model. rstanarm's modeling functions can done   specifying optional argument init_r number less   default \\(2\\).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/pp_validate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model validation via simulation — pp_validate","text":"Cook, S., Gelman, ., Rubin, D. (2006). Validation software Bayesian models using posterior quantiles. Journal Computational Graphical Statistics. 15(3), 675–692.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/pp_validate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model validation via simulation — pp_validate","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\dontrun{ if (!exists(\"example_model\")) example(example_model) try(pp_validate(example_model)) # fails with default seed / priors # } } #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess"},{"path":"https://mc-stan.org/rstanarm/reference/predict.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for stanreg objects — predict.stanreg","title":"Predict method for stanreg objects — predict.stanreg","text":"method primarily intended used models fit using optimization. models fit using MCMC one variational approximations, see posterior_predict.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/predict.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for stanreg objects — predict.stanreg","text":"","code":"# S3 method for class 'stanreg' predict(   object,   ...,   newdata = NULL,   type = c(\"link\", \"response\"),   se.fit = FALSE )"},{"path":"https://mc-stan.org/rstanarm/reference/predict.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for stanreg objects — predict.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. ... Ignored. newdata Optionally, data frame look variables predict. omitted, model matrix used. type type prediction. default 'link' scale linear predictors; alternative 'response' scale response variable. se.fit logical scalar indicating standard errors returned. default FALSE.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/predict.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for stanreg objects — predict.stanreg","text":"vector se.fit FALSE list se.fit   TRUE.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/predictive_error.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"In-sample or out-of-sample predictive errors — predictive_error.stanreg","title":"In-sample or out-of-sample predictive errors — predictive_error.stanreg","text":"convenience function computing \\(y - y^{rep}\\) (-sample, observed \\(y\\)) \\(y - \\tilde{y}\\) (--sample, new held-\\(y\\)). method stanreg objects calls posterior_predict internally, whereas method matrices accepts matrix returned posterior_predict input can used avoid multiple calls posterior_predict.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/predictive_error.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"In-sample or out-of-sample predictive errors — predictive_error.stanreg","text":"","code":"# S3 method for class 'stanreg' predictive_error(   object,   newdata = NULL,   draws = NULL,   re.form = NULL,   seed = NULL,   offset = NULL,   ... )  # S3 method for class 'matrix' predictive_error(object, y, ...)  # S3 method for class 'ppd' predictive_error(object, y, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/predictive_error.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"In-sample or out-of-sample predictive errors — predictive_error.stanreg","text":"object Either fitted model object returned one rstanarm modeling functions (stanreg object) , matrix method, matrix draws posterior predictive distribution returned posterior_predict. newdata, draws, seed, offset, re.form Optional arguments passed posterior_predict. binomial models, please see Note section newdata specified. ... Currently ignored. y matrix method , vector \\(y\\) values length number columns matrix used object. method stanreg objects takes y directly fitted model object.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/predictive_error.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"In-sample or out-of-sample predictive errors — predictive_error.stanreg","text":"draws nrow(newdata) matrix. newdata   specified draws nobs(object).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/predictive_error.stanreg.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"In-sample or out-of-sample predictive errors — predictive_error.stanreg","text":"Note section posterior_predict   newdata binomial models also applies   predictive_error, one important difference.   posterior_predict left-hand side model formula   cbind(successes, failures) particular values   successes failures newdata matter,   add desired number trials. case   predictive_error. predictive_error particular   value successes matters used \\(y\\)   computing error.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/predictive_error.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"In-sample or out-of-sample predictive errors — predictive_error.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { if (!exists(\"example_model\")) example(example_model) err1 <- predictive_error(example_model, draws = 50) hist(err1)  # Using newdata with a binomial model formula(example_model) nd <- data.frame(  size = c(10, 20),   incidence = c(5, 10),   period = factor(c(1,2)),   herd = c(1, 15) ) err2 <- predictive_error(example_model, newdata = nd, draws = 10, seed = 1234)  # stanreg vs matrix methods fit <- stan_glm(mpg ~ wt, data = mtcars, iter = 300) preds <- posterior_predict(fit, seed = 123) all.equal(   predictive_error(fit, seed = 123),   predictive_error(preds, y = fit$y) ) }  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 300 [  0%]  (Warmup) #> Chain 1: Iteration:  30 / 300 [ 10%]  (Warmup) #> Chain 1: Iteration:  60 / 300 [ 20%]  (Warmup) #> Chain 1: Iteration:  90 / 300 [ 30%]  (Warmup) #> Chain 1: Iteration: 120 / 300 [ 40%]  (Warmup) #> Chain 1: Iteration: 150 / 300 [ 50%]  (Warmup) #> Chain 1: Iteration: 151 / 300 [ 50%]  (Sampling) #> Chain 1: Iteration: 180 / 300 [ 60%]  (Sampling) #> Chain 1: Iteration: 210 / 300 [ 70%]  (Sampling) #> Chain 1: Iteration: 240 / 300 [ 80%]  (Sampling) #> Chain 1: Iteration: 270 / 300 [ 90%]  (Sampling) #> Chain 1: Iteration: 300 / 300 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.009 seconds (Warm-up) #> Chain 1:                0.004 seconds (Sampling) #> Chain 1:                0.013 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 9e-06 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:   1 / 300 [  0%]  (Warmup) #> Chain 2: Iteration:  30 / 300 [ 10%]  (Warmup) #> Chain 2: Iteration:  60 / 300 [ 20%]  (Warmup) #> Chain 2: Iteration:  90 / 300 [ 30%]  (Warmup) #> Chain 2: Iteration: 120 / 300 [ 40%]  (Warmup) #> Chain 2: Iteration: 150 / 300 [ 50%]  (Warmup) #> Chain 2: Iteration: 151 / 300 [ 50%]  (Sampling) #> Chain 2: Iteration: 180 / 300 [ 60%]  (Sampling) #> Chain 2: Iteration: 210 / 300 [ 70%]  (Sampling) #> Chain 2: Iteration: 240 / 300 [ 80%]  (Sampling) #> Chain 2: Iteration: 270 / 300 [ 90%]  (Sampling) #> Chain 2: Iteration: 300 / 300 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.009 seconds (Warm-up) #> Chain 2:                0.004 seconds (Sampling) #> Chain 2:                0.013 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 9e-06 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:   1 / 300 [  0%]  (Warmup) #> Chain 3: Iteration:  30 / 300 [ 10%]  (Warmup) #> Chain 3: Iteration:  60 / 300 [ 20%]  (Warmup) #> Chain 3: Iteration:  90 / 300 [ 30%]  (Warmup) #> Chain 3: Iteration: 120 / 300 [ 40%]  (Warmup) #> Chain 3: Iteration: 150 / 300 [ 50%]  (Warmup) #> Chain 3: Iteration: 151 / 300 [ 50%]  (Sampling) #> Chain 3: Iteration: 180 / 300 [ 60%]  (Sampling) #> Chain 3: Iteration: 210 / 300 [ 70%]  (Sampling) #> Chain 3: Iteration: 240 / 300 [ 80%]  (Sampling) #> Chain 3: Iteration: 270 / 300 [ 90%]  (Sampling) #> Chain 3: Iteration: 300 / 300 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.009 seconds (Warm-up) #> Chain 3:                0.004 seconds (Sampling) #> Chain 3:                0.013 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 9e-06 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:   1 / 300 [  0%]  (Warmup) #> Chain 4: Iteration:  30 / 300 [ 10%]  (Warmup) #> Chain 4: Iteration:  60 / 300 [ 20%]  (Warmup) #> Chain 4: Iteration:  90 / 300 [ 30%]  (Warmup) #> Chain 4: Iteration: 120 / 300 [ 40%]  (Warmup) #> Chain 4: Iteration: 150 / 300 [ 50%]  (Warmup) #> Chain 4: Iteration: 151 / 300 [ 50%]  (Sampling) #> Chain 4: Iteration: 180 / 300 [ 60%]  (Sampling) #> Chain 4: Iteration: 210 / 300 [ 70%]  (Sampling) #> Chain 4: Iteration: 240 / 300 [ 80%]  (Sampling) #> Chain 4: Iteration: 270 / 300 [ 90%]  (Sampling) #> Chain 4: Iteration: 300 / 300 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.006 seconds (Warm-up) #> Chain 4:                0.004 seconds (Sampling) #> Chain 4:                0.01 seconds (Total) #> Chain 4:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> [1] TRUE"},{"path":"https://mc-stan.org/rstanarm/reference/predictive_interval.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictive intervals — predictive_interval.stanreg","title":"Predictive intervals — predictive_interval.stanreg","text":"models fit using MCMC (algorithm=\"sampling\") one variational approximations (\"meanfield\" \"fullrank\"), predictive_interval function computes Bayesian predictive intervals. method stanreg objects calls posterior_predict internally, whereas method matrices accepts matrix returned posterior_predict input can used avoid multiple calls posterior_predict.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/predictive_interval.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictive intervals — predictive_interval.stanreg","text":"","code":"# S3 method for class 'stanreg' predictive_interval(   object,   prob = 0.9,   newdata = NULL,   draws = NULL,   re.form = NULL,   fun = NULL,   seed = NULL,   offset = NULL,   ... )  # S3 method for class 'matrix' predictive_interval(object, prob = 0.9, ...)  # S3 method for class 'ppd' predictive_interval(object, prob = 0.9, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/predictive_interval.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictive intervals — predictive_interval.stanreg","text":"object Either fitted model object returned one rstanarm modeling functions (stanreg object) , matrix method, matrix draws posterior predictive distribution returned posterior_predict. prob number \\(p \\(0,1)\\) indicating desired probability mass include intervals. default report \\(90\\)% intervals (prob=0.9) rather traditionally used \\(95\\)% (see Details). newdata, draws, fun, offset, re.form, seed Passed posterior_predict. ... Currently ignored.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/predictive_interval.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictive intervals — predictive_interval.stanreg","text":"matrix two columns many rows newdata.   newdata provided matrix many rows   data used fit model. given value prob, \\(p\\),   columns correspond lower upper \\(100p\\)% central interval   limits names \\(100\\alpha/2\\)% \\(100(1 -   \\alpha/2)\\)%, \\(\\alpha = 1-p\\). example, prob=0.9   specified (\\(90\\)% interval), column names   \"5%\" \"95%\", respectively.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/predictive_interval.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictive intervals — predictive_interval.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { fit <- stan_glm(mpg ~ wt, data = mtcars, iter = 300) predictive_interval(fit) predictive_interval(fit, newdata = data.frame(wt = range(mtcars$wt)),                      prob = 0.5)  # stanreg vs matrix methods preds <- posterior_predict(fit, seed = 123) all.equal(   predictive_interval(fit, seed = 123),   predictive_interval(preds) ) } #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 3.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 300 [  0%]  (Warmup) #> Chain 1: Iteration:  30 / 300 [ 10%]  (Warmup) #> Chain 1: Iteration:  60 / 300 [ 20%]  (Warmup) #> Chain 1: Iteration:  90 / 300 [ 30%]  (Warmup) #> Chain 1: Iteration: 120 / 300 [ 40%]  (Warmup) #> Chain 1: Iteration: 150 / 300 [ 50%]  (Warmup) #> Chain 1: Iteration: 151 / 300 [ 50%]  (Sampling) #> Chain 1: Iteration: 180 / 300 [ 60%]  (Sampling) #> Chain 1: Iteration: 210 / 300 [ 70%]  (Sampling) #> Chain 1: Iteration: 240 / 300 [ 80%]  (Sampling) #> Chain 1: Iteration: 270 / 300 [ 90%]  (Sampling) #> Chain 1: Iteration: 300 / 300 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.009 seconds (Warm-up) #> Chain 1:                0.005 seconds (Sampling) #> Chain 1:                0.014 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 9e-06 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:   1 / 300 [  0%]  (Warmup) #> Chain 2: Iteration:  30 / 300 [ 10%]  (Warmup) #> Chain 2: Iteration:  60 / 300 [ 20%]  (Warmup) #> Chain 2: Iteration:  90 / 300 [ 30%]  (Warmup) #> Chain 2: Iteration: 120 / 300 [ 40%]  (Warmup) #> Chain 2: Iteration: 150 / 300 [ 50%]  (Warmup) #> Chain 2: Iteration: 151 / 300 [ 50%]  (Sampling) #> Chain 2: Iteration: 180 / 300 [ 60%]  (Sampling) #> Chain 2: Iteration: 210 / 300 [ 70%]  (Sampling) #> Chain 2: Iteration: 240 / 300 [ 80%]  (Sampling) #> Chain 2: Iteration: 270 / 300 [ 90%]  (Sampling) #> Chain 2: Iteration: 300 / 300 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.009 seconds (Warm-up) #> Chain 2:                0.004 seconds (Sampling) #> Chain 2:                0.013 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 9e-06 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:   1 / 300 [  0%]  (Warmup) #> Chain 3: Iteration:  30 / 300 [ 10%]  (Warmup) #> Chain 3: Iteration:  60 / 300 [ 20%]  (Warmup) #> Chain 3: Iteration:  90 / 300 [ 30%]  (Warmup) #> Chain 3: Iteration: 120 / 300 [ 40%]  (Warmup) #> Chain 3: Iteration: 150 / 300 [ 50%]  (Warmup) #> Chain 3: Iteration: 151 / 300 [ 50%]  (Sampling) #> Chain 3: Iteration: 180 / 300 [ 60%]  (Sampling) #> Chain 3: Iteration: 210 / 300 [ 70%]  (Sampling) #> Chain 3: Iteration: 240 / 300 [ 80%]  (Sampling) #> Chain 3: Iteration: 270 / 300 [ 90%]  (Sampling) #> Chain 3: Iteration: 300 / 300 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.008 seconds (Warm-up) #> Chain 3:                0.004 seconds (Sampling) #> Chain 3:                0.012 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 9e-06 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:   1 / 300 [  0%]  (Warmup) #> Chain 4: Iteration:  30 / 300 [ 10%]  (Warmup) #> Chain 4: Iteration:  60 / 300 [ 20%]  (Warmup) #> Chain 4: Iteration:  90 / 300 [ 30%]  (Warmup) #> Chain 4: Iteration: 120 / 300 [ 40%]  (Warmup) #> Chain 4: Iteration: 150 / 300 [ 50%]  (Warmup) #> Chain 4: Iteration: 151 / 300 [ 50%]  (Sampling) #> Chain 4: Iteration: 180 / 300 [ 60%]  (Sampling) #> Chain 4: Iteration: 210 / 300 [ 70%]  (Sampling) #> Chain 4: Iteration: 240 / 300 [ 80%]  (Sampling) #> Chain 4: Iteration: 270 / 300 [ 90%]  (Sampling) #> Chain 4: Iteration: 300 / 300 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.007 seconds (Warm-up) #> Chain 4:                0.004 seconds (Sampling) #> Chain 4:                0.011 seconds (Total) #> Chain 4:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> [1] TRUE"},{"path":"https://mc-stan.org/rstanarm/reference/print.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for stanreg objects — print.stanreg","title":"Print method for stanreg objects — print.stanreg","text":"print method stanreg objects displays compact summary fitted model. See Details section descriptions different components printed output. additional summary statistics diagnostics use summary method.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/print.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for stanreg objects — print.stanreg","text":"","code":"# S3 method for class 'stanreg' print(x, digits = 1, detail = TRUE, ...)  # S3 method for class 'stanmvreg' print(x, digits = 3, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/print.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for stanreg objects — print.stanreg","text":"x fitted model object returned one rstanarm modeling functions. See stanreg-objects. digits Number digits use formatting numbers. detail Logical, defaulting TRUE. FALSE minimal summary printed consisting parameter estimates. ... Ignored.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/print.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for stanreg objects — print.stanreg","text":"Returns x, invisibly.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/print.stanreg.html","id":"point-estimates","dir":"Reference","previous_headings":"","what":"Point estimates","title":"Print method for stanreg objects — print.stanreg","text":"Regardless estimation algorithm, point estimates medians computed simulations. models fit using MCMC (\"sampling\") posterior sample used. optimization (\"optimizing\"), simulations generated asymptotic Gaussian sampling distribution parameters. \"meanfield\" \"fullrank\" variational approximations, draws variational approximation posterior used. cases, point estimates reported values returned coef.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/print.stanreg.html","id":"uncertainty-estimates-mad-sd-","dir":"Reference","previous_headings":"","what":"Uncertainty estimates (MAD_SD)","title":"Print method for stanreg objects — print.stanreg","text":"standard deviations reported (labeled MAD_SD print output) computed set draws described proportional median absolute deviation (mad) median. Compared raw posterior standard deviation, MAD_SD robust long-tailed distributions. values returned se.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/print.stanreg.html","id":"additional-output","dir":"Reference","previous_headings":"","what":"Additional output","title":"Print method for stanreg objects — print.stanreg","text":"GLMs group-specific terms (see stan_glmer) printed output also shows point estimates standard deviations group effects (correlations intercept slopes vary group). analysis variance models (see stan_aov) models, ANOVA-like table also displayed. joint longitudinal time--event (see stan_jm) models estimates presented separately distinct submodels.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/print.survfit.stanjm.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic print method for survfit.stanjm objects — print.survfit.stanjm","title":"Generic print method for survfit.stanjm objects — print.survfit.stanjm","text":"Generic print method survfit.stanjm objects","code":""},{"path":"https://mc-stan.org/rstanarm/reference/print.survfit.stanjm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic print method for survfit.stanjm objects — print.survfit.stanjm","text":"","code":"# S3 method for class 'survfit.stanjm' print(x, digits = 4, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/print.survfit.stanjm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic print method for survfit.stanjm objects — print.survfit.stanjm","text":"x object class survfit.stanjm, returned call posterior_survfit. digits Number digits use formatting time variable survival probabilities. ... Ignored.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/prior_summary.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize the priors used for an rstanarm model — prior_summary.stanreg","title":"Summarize the priors used for an rstanarm model — prior_summary.stanreg","text":"prior_summary method provides summary prior distributions used parameters given model. cases user-specified prior correspond exactly prior used internally rstanarm (see sections ). Especially cases, also general, can much useful visualize priors. Visualizing priors can done using posterior_vs_prior function, alternatively fitting model prior_PD argument set TRUE (draw prior predictive distribution instead conditioning outcome) plotting parameters.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/prior_summary.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize the priors used for an rstanarm model — prior_summary.stanreg","text":"","code":"# S3 method for class 'stanreg' prior_summary(object, digits = 2, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/prior_summary.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize the priors used for an rstanarm model — prior_summary.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. digits Number digits use rounding. ... Currently ignored method stanreg objects.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/prior_summary.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize the priors used for an rstanarm model — prior_summary.stanreg","text":"list class \"prior_summary.stanreg\", print   method.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/prior_summary.stanreg.html","id":"intercept-after-predictors-centered-","dir":"Reference","previous_headings":"","what":"Intercept (after predictors centered)","title":"Summarize the priors used for an rstanarm model — prior_summary.stanreg","text":"rstanarm modeling functions accept prior_intercept   argument, specified prior intercept term applies   intercept rstanarm internally centers predictors   mean zero. estimate intercept returned user   correspond intercept predictors specified user   (unmodified rstanarm), specifying prior   intercept can thought expected outcome predictors   set means. exception models fit   sparse argument set TRUE (possible   subset modeling functions never default).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/prior_summary.stanreg.html","id":"adjusted-scales","dir":"Reference","previous_headings":"","what":"Adjusted scales","title":"Summarize the priors used for an rstanarm model — prior_summary.stanreg","text":"models may see \"adjusted scale\"   printed output adjusted scales included object returned   prior_summary. adjusted scale values prior scales   actually used rstanarm computed adjusting prior   scales specified user account scales predictors   (described documentation autoscale   argument). disable internal prior scale adjustments set   autoscale argument FALSE setting prior using one   distributions accepts autoscale argument. example,   normal(0, 5, autoscale=FALSE) instead just normal(0, 5).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/prior_summary.stanreg.html","id":"coefficients-in-q-space","dir":"Reference","previous_headings":"","what":"Coefficients in Q-space","title":"Summarize the priors used for an rstanarm model — prior_summary.stanreg","text":"models fit rstanarm modeling function supports   QR argument (see e.g, stan_glm), QR   set TRUE prior distributions regression   coefficients specified using prior argument relative   original predictor variables \\(X\\) rather variables   matrix \\(Q\\) obtained \\(QR\\) decomposition \\(X\\). particular, prior = normal(location,scale), prior   coefficients \\(Q\\)-space can easily translated joint   multivariate normal (MVN) prior coefficients original   predictors \\(X\\). Letting \\(\\theta\\) denote coefficients   \\(Q\\) \\(\\beta\\) coefficients \\(X\\) \\(\\theta   \\sim N(\\mu, \\sigma)\\) corresponding prior   \\(\\beta\\) \\(\\beta \\sim MVN(R\\mu, R'R\\sigma^2)\\), \\(\\mu\\) \\(\\sigma\\) vectors   appropriate length. Technically, rstanarm uses scaled \\(QR\\)   decomposition ensure columns predictor matrix used   fit model unit scale, autoscale argument   function passed prior argument TRUE (  default), case matrices actually used   \\(Q^\\ast = Q \\sqrt{n-1}\\) \\(R^\\ast =   \\frac{1}{\\sqrt{n-1}} R\\). autoscale = FALSE   instead scale lower-right element \\(R^\\ast\\)   \\(1\\), useful want specify prior coefficient   last predictor original units (see documentation   QR argument). interested prior \\(\\beta\\) implied prior   \\(\\theta\\), strongly recommend visualizing described   Description section, simpler working   analytically.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/prior_summary.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize the priors used for an rstanarm model — prior_summary.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { if (!exists(\"example_model\")) example(example_model)  prior_summary(example_model)  priors <- prior_summary(example_model) names(priors) priors$prior$scale priors$prior$adjusted_scale  # for a glm with adjusted scales (see Details, above), compare  # the default (rstanarm adjusting the scales) to setting  # autoscale=FALSE for prior on coefficients fit <- stan_glm(mpg ~ wt + am, data = mtcars,                  prior = normal(0, c(2.5, 4)),                  prior_intercept = normal(0, 5),                  iter = 10, chains = 1) # only for demonstration  prior_summary(fit)  fit2 <- update(fit, prior = normal(0, c(2.5, 4), autoscale=FALSE),                 prior_intercept = normal(0, 5, autoscale=FALSE)) prior_summary(fit2) } #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.2e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: WARNING: No variance estimation is #> Chain 1:          performed for num_warmup < 20 #> Chain 1:  #> Chain 1: Iteration: 1 / 10 [ 10%]  (Warmup) #> Chain 1: Iteration: 2 / 10 [ 20%]  (Warmup) #> Chain 1: Iteration: 3 / 10 [ 30%]  (Warmup) #> Chain 1: Iteration: 4 / 10 [ 40%]  (Warmup) #> Chain 1: Iteration: 5 / 10 [ 50%]  (Warmup) #> Chain 1: Iteration: 6 / 10 [ 60%]  (Sampling) #> Chain 1: Iteration: 7 / 10 [ 70%]  (Sampling) #> Chain 1: Iteration: 8 / 10 [ 80%]  (Sampling) #> Chain 1: Iteration: 9 / 10 [ 90%]  (Sampling) #> Chain 1: Iteration: 10 / 10 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0 seconds (Warm-up) #> Chain 1:                0 seconds (Sampling) #> Chain 1:                0 seconds (Total) #> Chain 1:  #> Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See #> https://mc-stan.org/misc/warnings.html#bfmi-low #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is 1.9, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Markov chains did not converge! Do not analyze results! #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.6e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: WARNING: No variance estimation is #> Chain 1:          performed for num_warmup < 20 #> Chain 1:  #> Chain 1: Iteration: 1 / 10 [ 10%]  (Warmup) #> Chain 1: Iteration: 2 / 10 [ 20%]  (Warmup) #> Chain 1: Iteration: 3 / 10 [ 30%]  (Warmup) #> Chain 1: Iteration: 4 / 10 [ 40%]  (Warmup) #> Chain 1: Iteration: 5 / 10 [ 50%]  (Warmup) #> Chain 1: Iteration: 6 / 10 [ 60%]  (Sampling) #> Chain 1: Iteration: 7 / 10 [ 70%]  (Sampling) #> Chain 1: Iteration: 8 / 10 [ 80%]  (Sampling) #> Chain 1: Iteration: 9 / 10 [ 90%]  (Sampling) #> Chain 1: Iteration: 10 / 10 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0 seconds (Warm-up) #> Chain 1:                0 seconds (Sampling) #> Chain 1:                0 seconds (Total) #> Chain 1:  #> Warning: The largest R-hat is 1.9, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Markov chains did not converge! Do not analyze results! #> Priors for model 'fit2'  #> ------ #> Intercept (after predictors centered) #>  ~ normal(location = 0, scale = 5) #>  #> Coefficients #>  ~ normal(location = [0,0], scale = [2.5,4.0]) #>  #> Auxiliary (sigma) #>   Specified prior: #>     ~ exponential(rate = 1) #>   Adjusted prior: #>     ~ exponential(rate = 0.17) #> ------ #> See help('prior_summary.stanreg') for more details"},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Prior distributions and options — priors","title":"Prior distributions and options — priors","text":"functions described page used specify   prior-related arguments various modeling functions   rstanarm package (view priors used existing model see   prior_summary). default priors used various rstanarm modeling functions   intended weakly informative provide moderate   regularization help stabilize computation. many applications   defaults perform well, prudent use informative priors   encouraged. Uniform prior distributions possible (e.g. setting   stan_glm's prior argument NULL) , unless   data strong, recommended   non-informative, giving probability mass implausible values   plausible ones. information priors available vignette   Prior   Distributions rstanarm Models well vignettes   various modeling functions. details   priors used multilevel models particular see vignette   Estimating   Generalized (Non-)Linear Models Group-Specific Terms rstanarm   also Covariance matrices section lower page.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prior distributions and options — priors","text":"","code":"normal(location = 0, scale = NULL, autoscale = FALSE)  student_t(df = 1, location = 0, scale = NULL, autoscale = FALSE)  cauchy(location = 0, scale = NULL, autoscale = FALSE)  hs(df = 1, global_df = 1, global_scale = 0.01, slab_df = 4, slab_scale = 2.5)  hs_plus(   df1 = 1,   df2 = 1,   global_df = 1,   global_scale = 0.01,   slab_df = 4,   slab_scale = 2.5 )  laplace(location = 0, scale = NULL, autoscale = FALSE)  lasso(df = 1, location = 0, scale = NULL, autoscale = FALSE)  product_normal(df = 2, location = 0, scale = 1)  exponential(rate = 1, autoscale = FALSE)  decov(regularization = 1, concentration = 1, shape = 1, scale = 1)  lkj(regularization = 1, scale = 10, df = 1, autoscale = TRUE)  dirichlet(concentration = 1)  R2(location = NULL, what = c(\"mode\", \"mean\", \"median\", \"log\"))  default_prior_intercept(family)  default_prior_coef(family)"},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prior distributions and options — priors","text":"location Prior location. cases, prior mean, cauchy (equivalent student_t df=1), mean exist location prior median. default value \\(0\\), except R2 default value location. R2, location pertains prior location \\(R^2\\) Beta distribution, interpretation location parameter depends specified value argument (see R2 family section Details). scale Prior scale. default depends family (see Details). autoscale TRUE scales priors intercept regression coefficients may additionally modified internally rstanarm following cases. First, Gaussian models , prior scales intercept, coefficients, auxiliary parameter sigma (error standard deviation) multiplied sd(y). Additionally — Gaussian models — QR argument model fitting function (e.g. stan_glm) FALSE also divide prior scale(s) sd(x). Prior autoscaling also discussed vignette Prior Distributions rstanarm Models df, df1, df2 Prior degrees freedom. default \\(1\\) student_t, case equivalent cauchy. hierarchical shrinkage priors (hs hs_plus) degrees freedom parameter(s) default \\(1\\). product_normal prior, degrees freedom parameter must integer (vector) least \\(2\\) (default). global_df, global_scale, slab_df, slab_scale Optional arguments hierarchical shrinkage priors. See Hierarchical shrinkage family section . rate Prior rate exponential distribution. Defaults 1. exponential distribution, rate parameter reciprocal mean. regularization Exponent LKJ prior correlation matrix decov lkj prior. default \\(1\\), implying joint uniform prior. concentration Concentration parameter symmetric Dirichlet distribution. default \\(1\\), implying joint uniform prior. shape Shape parameter gamma prior scale parameter decov prior. shape scale \\(1\\) (default) gamma prior simplifies unit-exponential distribution. character string among 'mode' (default), 'mean', 'median', 'log' indicating location parameter interpreted LKJ case. 'log', location interpreted expected logarithm \\(R^2\\) Beta distribution. Otherwise, location interpreted \\(R^2\\) Beta distribution. number predictors less equal two, mode Beta distribution exist error prompt user specify another choice . family currently used.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prior distributions and options — priors","text":"named list used internally rstanarm model   fitting functions.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prior distributions and options — priors","text":"details depend family prior used:","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"student-t-family","dir":"Reference","previous_headings":"","what":"Student t family","title":"Prior distributions and options — priors","text":"Family members: normal(location, scale) student_t(df, location, scale) cauchy(location, scale) functions also takes argument autoscale. prior distribution intercept, location,   scale, df scalars. prior   coefficients can either vectors length equal number   coefficients (including intercept), can scalars,   case recycled appropriate length.   degrees freedom approaches infinity, Student t distribution   approaches normal distribution degrees freedom one,   Student t distribution Cauchy distribution. scale specified default \\(2.5\\), unless   probit link function used, case defaults scaled   factor dnorm(0)/dlogis(0), roughly \\(1.6\\). autoscale argument TRUE,   scales adjusted described documentation   autoscale argument Arguments section.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"hierarchical-shrinkage-family","dir":"Reference","previous_headings":"","what":"Hierarchical shrinkage family","title":"Prior distributions and options — priors","text":"Family members: hs(df, global_df, global_scale, slab_df, slab_scale) hs_plus(df1, df2, global_df, global_scale, slab_df, slab_scale) hierarchical shrinkage priors normal mean zero   standard deviation also random variable. traditional   hierarchical shrinkage prior utilizes standard deviation   distributed half Cauchy median zero scale parameter   also half Cauchy. called \"horseshoe prior\". hierarchical   shrinkage (hs) prior rstanarm package instead utilizes   regularized horseshoe prior, described Piironen Vehtari (2017),   recommends setting global_scale argument equal ratio   expected number non-zero coefficients expected number   zero coefficients, divided square root number observations. hierarhical shrinkpage plus (hs_plus) prior similar except   standard deviation distributed product two   independent half Cauchy parameters scaled similar way   hs prior. hierarchical shrinkage priors tall modes fat tails.   Consequently, tend produce posterior distributions   concentrated near zero, unless predictor strong influence   outcome, case prior little influence. Hierarchical   shrinkage priors often require increase   adapt_delta tuning parameter order diminish number   divergent transitions. details tuning parameters   divergent transitions see Troubleshooting section   Use rstanarm Package vignette.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"laplace-family","dir":"Reference","previous_headings":"","what":"Laplace family","title":"Prior distributions and options — priors","text":"Family members: laplace(location, scale) lasso(df, location, scale) functions also takes argument autoscale. Laplace distribution also known double-exponential   distribution. symmetric distribution sharp peak mean   / median / mode fairly long tails. distribution can motivated   scale mixture normal distributions remarks   normal distribution apply well. lasso approach supervised learning can expressed finding   posterior mode likelihood Gaussian priors   coefficients independent Laplace distributions. commonplace   supervised learning choose tuning parameter cross-validation,   whereas Bayesian approach place prior “”,   rather reciprocal case (.e. smaller values correspond   shrinkage toward prior location vector). use chi-square   prior degrees freedom equal specified call   lasso , default, 1. expectation chi-square random   variable equal degrees freedom mode equal   degrees freedom minus 2, difference positive. also common supervised learning standardize predictors   training model. recommend . Instead,   better specify autoscale = TRUE,   adjust scales priors according dispersion   variables. See documentation autoscale argument   also prior_summary page information.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"product-normal-family","dir":"Reference","previous_headings":"","what":"Product-normal family","title":"Prior distributions and options — priors","text":"Family members: product_normal(df, location, scale) product-normal distribution product least two independent   normal variates mean zero, shifted location   parameter. can shown density product-normal variate   symmetric infinite location, prior resembles   “spike--slab” prior sufficiently large values   scale parameter. better worse, prior may   appropriate strongly believed (someone) regression   coefficient “” equal location, parameter even though   true Bayesian specify prior. element df must integer least \\(2\\)   “degrees freedom” interpreted number normal   variates multiplied shifted location yield   regression coefficient. Higher degrees freedom produce sharper   spike location. element scale must non-negative real number   interpreted standard deviation normal variates   multiplied shifted location yield regression   coefficient. words, elements scale may differ,   k-th standard deviation presumed hold normal deviates   multiplied together shifted k-th element   location yield k-th regression coefficient. elements   scale prior standard deviations regression   coefficients. prior variance regression coefficients equal   scale raised power \\(2\\) times corresponding element   df. Thus, larger values scale put prior volume   values regression coefficient far zero.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"dirichlet-family","dir":"Reference","previous_headings":"","what":"Dirichlet family","title":"Prior distributions and options — priors","text":"Family members: dirichlet(concentration) Dirichlet distribution multivariate generalization beta   distribution. perhaps easiest prior distribution specify   concentration parameters can interpreted prior counts   (although need integers) multinomial random variable. Dirichlet distribution used stan_polr   implicit prior cutpoints ordinal regression model.   specifically, Dirichlet prior pertains prior probability   observing category ordinal outcome predictors   sample means. Given prior probabilities, straightforward   add form cumulative probabilities use inverse CDF   transformation cumulative probabilities define cutpoints. scalar passed concentration argument   dirichlet function, replicated appropriate length   Dirichlet distribution symmetric. concentration   vector elements \\(1\\), Dirichlet distribution   jointly uniform. concentration parameters equal greater   \\(1\\) prior mode categories equiprobable,   larger value identical concentration parameters,   sharply peaked distribution mode. elements   concentration can also given different values represent   outcome categories priori equiprobable.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"covariance-matrices","dir":"Reference","previous_headings":"","what":"Covariance matrices","title":"Prior distributions and options — priors","text":"Family members: decov(regularization, concentration, shape, scale) lkj(regularization, scale, df) (Also see vignette stan_glmer,   Estimating   Generalized (Non-)Linear Models Group-Specific Terms rstanarm) Covariance matrices decomposed correlation matrices   variances. variances turn decomposed product   simplex vector trace matrix. Finally, trace   product order matrix square scale parameter.   prior covariance matrix represented decov   function. prior correlation matrix called LKJ whose density   proportional determinant correlation matrix raised   power positive regularization parameter minus one.   regularization = 1 (default), prior jointly   uniform correlation matrices size.   regularization > 1, identity matrix mode   unlikely case regularization < 1, identity matrix   trough. trace covariance matrix equal sum variances.   set trace equal product order covariance matrix   square positive scale parameter. particular   variances set equal product simplex vector —   non-negative sums \\(1\\) — scalar trace. words,   element simplex vector represents proportion trace   attributable corresponding variable. symmetric Dirichlet prior used simplex vector,   single (positive) concentration parameter, defaults   \\(1\\) implies prior jointly uniform space   simplex vectors size. concentration > 1, prior   mode corresponds variables (proportion total)   variance, can used ensure posterior variances   zero. concentration parameter approaches infinity,   mode becomes pronounced. unlikely case   concentration < 1, variances polarized. variables multiplied number, trace   covariance matrix increase number squared. Thus,   reasonable use scale-invariant prior distribution positive   scale parameter, case utilize Gamma distribution, whose   shape scale \\(1\\) default, implying   unit-exponential distribution. Set shape hyperparameter   value greater \\(1\\) ensure posterior trace zero. regularization, concentration, shape /   scale positive scalars, recycled   appropriate length. Otherwise, can positive vector   appropriate length, appropriate length depends number   covariance matrices model sizes. one--one covariance   matrix just variance thus regularization   concentration parameters, shape   scale parameters prior standard deviation   variable. Note stan_mvmer stan_jm models   additional prior distribution provided lkj function.   prior fact currently used default modelling   functions (although decov still available option user   wishes specify prior_covariance argument).   lkj prior uses decomposition covariance matrices   correlation matrices variances, however, variances   decomposed simplex vector trace; instead   standard deviations (square root variances) group   specific parameters given half Student t distribution   scale df parameters specified scale df   arguments lkj function. scale parameter default 10   autoscaled, whilst df parameter default 1   (therefore equivalent half Cauchy prior distribution   standard deviation group specific parameter). prior generally   leads similar results decov prior, also likely   **less** diffuse compared decov prior; therefore   sometimes seems lead faster estimation times, hence   chosen default prior stan_mvmer   stan_jm estimation times can long.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"r-family","dir":"Reference","previous_headings":"","what":"R2 family","title":"Prior distributions and options — priors","text":"Family members: R2(location, ) stan_lm, stan_aov,   stan_polr functions allow user utilize function   called R2 convey prior information parameters.   prior hinges prior beliefs location \\(R^2\\),   proportion variance outcome attributable predictors,   Beta prior first shape   hyperparameter equal half number predictors second shape   hyperparameter free. specifying prior mode (  default), mean, median, expected log \\(R^2\\), second shape   parameter Beta distribution determined internally.   = 'log', location negative scalar; otherwise   scalar \\((0,1)\\) interval. example, \\(R^2 = 0.5\\), mode, mean, median   Beta distribution thus   second shape parameter also equal half number predictors.   second shape parameter Beta distribution   actually shape parameter LKJ prior   correlation matrix described previous subsection. Thus, smaller   \\(R^2\\), larger shape parameter, smaller   prior correlations among outcome predictor variables,   concentrated near zero prior density regression   coefficients. Hence, prior coefficients regularizing   yield posterior distribution good --sample predictions   prior location \\(R^2\\) specified reasonable   fashion.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Prior distributions and options — priors","text":"Gelman, ., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari,   ., Rubin, D. B. (2013). Bayesian Data Analysis. Chapman & Hall/CRC   Press, London, third edition. https://stat.columbia.edu/~gelman/book/ Gelman, ., Jakulin, ., Pittau, M. G., Su, Y. (2008). weakly informative default prior distribution logistic regression models. Annals Applied Statistics. 2(4), 1360–1383. Piironen, J., Vehtari, . (2017). Sparsity information regularization horseshoe shrinkage priors. https://arxiv.org/abs/1707.01694 Stan Development Team. Stan Modeling Language Users Guide Reference Manual. https://mc-stan.org/users/documentation/.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/priors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prior distributions and options — priors","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { fmla <- mpg ~ wt + qsec + drat + am  # Draw from prior predictive distribution (by setting prior_PD = TRUE) prior_pred_fit <- stan_glm(fmla, data = mtcars, prior_PD = TRUE,                            chains = 1, seed = 12345, iter = 250, # for speed only                            prior = student_t(df = 4, 0, 2.5),                             prior_intercept = cauchy(0,10),                             prior_aux = exponential(1/2)) plot(prior_pred_fit, \"hist\")  # \\donttest{ # Can assign priors to names N05 <- normal(0, 5) fit <- stan_glm(fmla, data = mtcars, prior = N05, prior_intercept = N05) # }  # Visually compare normal, student_t, cauchy, laplace, and product_normal compare_priors <- function(scale = 1, df_t = 2, xlim = c(-10, 10)) {   dt_loc_scale <- function(x, df, location, scale) {      1/scale * dt((x - location)/scale, df)     }   dlaplace <- function(x, location, scale) {     0.5 / scale * exp(-abs(x - location) / scale)   }   dproduct_normal <- function(x, scale) {     besselK(abs(x) / scale ^ 2, nu = 0) / (scale ^ 2 * pi)   }   stat_dist <- function(dist, ...) {     ggplot2::stat_function(ggplot2::aes_(color = dist), ...)   }   ggplot2::ggplot(data.frame(x = xlim), ggplot2::aes(x)) +      stat_dist(\"normal\", size = .75, fun = dnorm,                args = list(mean = 0, sd = scale)) +     stat_dist(\"student_t\", size = .75, fun = dt_loc_scale,                args = list(df = df_t, location = 0, scale = scale)) +     stat_dist(\"cauchy\", size = .75, linetype = 2, fun = dcauchy,                args = list(location = 0, scale = scale)) +      stat_dist(\"laplace\", size = .75, linetype = 2, fun = dlaplace,               args = list(location = 0, scale = scale)) +     stat_dist(\"product_normal\", size = .75, linetype = 2, fun = dproduct_normal,               args = list(scale = 1))             } # Cauchy has fattest tails, followed by student_t, laplace, and normal compare_priors()  # The student_t with df = 1 is the same as the cauchy compare_priors(df_t = 1)   # Even a scale of 5 is somewhat large. It gives plausibility to rather  # extreme values compare_priors(scale = 5, xlim = c(-20,20))   # If you use a prior like normal(0, 1000) to be \"non-informative\" you are  # actually saying that a coefficient value of e.g. -500 is quite plausible compare_priors(scale = 1000, xlim = c(-1000,1000)) } #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: WARNING: There aren't enough warmup iterations to fit the #> Chain 1:          three stages of adaptation as currently configured. #> Chain 1:          Reducing each adaptation stage to 15%/75%/10% of #> Chain 1:          the given number of warmup iterations: #> Chain 1:            init_buffer = 18 #> Chain 1:            adapt_window = 95 #> Chain 1:            term_buffer = 12 #> Chain 1:  #> Chain 1: Iteration:   1 / 250 [  0%]  (Warmup) #> Chain 1: Iteration:  25 / 250 [ 10%]  (Warmup) #> Chain 1: Iteration:  50 / 250 [ 20%]  (Warmup) #> Chain 1: Iteration:  75 / 250 [ 30%]  (Warmup) #> Chain 1: Iteration: 100 / 250 [ 40%]  (Warmup) #> Chain 1: Iteration: 125 / 250 [ 50%]  (Warmup) #> Chain 1: Iteration: 126 / 250 [ 50%]  (Sampling) #> Chain 1: Iteration: 150 / 250 [ 60%]  (Sampling) #> Chain 1: Iteration: 175 / 250 [ 70%]  (Sampling) #> Chain 1: Iteration: 200 / 250 [ 80%]  (Sampling) #> Chain 1: Iteration: 225 / 250 [ 90%]  (Sampling) #> Chain 1: Iteration: 250 / 250 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.023 seconds (Warm-up) #> Chain 1:                0.024 seconds (Sampling) #> Chain 1:                0.047 seconds (Total) #> Chain 1:  #> Warning: The largest R-hat is 1.14, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.3e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.054 seconds (Warm-up) #> Chain 1:                0.05 seconds (Sampling) #> Chain 1:                0.104 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.055 seconds (Warm-up) #> Chain 2:                0.055 seconds (Sampling) #> Chain 2:                0.11 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.2e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.055 seconds (Warm-up) #> Chain 3:                0.068 seconds (Sampling) #> Chain 3:                0.123 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 9e-06 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.057 seconds (Warm-up) #> Chain 4:                0.056 seconds (Sampling) #> Chain 4:                0.113 seconds (Total) #> Chain 4:  #> Warning: `aes_()` was deprecated in ggplot2 3.0.0. #> ℹ Please use tidy evaluation idioms with `aes()`"},{"path":"https://mc-stan.org/rstanarm/reference/ps_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Graphical checks of the estimated survival function — ps_check","title":"Graphical checks of the estimated survival function — ps_check","text":"function plots estimated marginal survival function based draws posterior predictive distribution fitted joint model, overlays Kaplan-Meier curve based observed data.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/ps_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graphical checks of the estimated survival function — ps_check","text":"","code":"ps_check(   object,   check = \"survival\",   limits = c(\"ci\", \"none\"),   draws = NULL,   seed = NULL,   xlab = NULL,   ylab = NULL,   ci_geom_args = NULL,   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/ps_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graphical checks of the estimated survival function — ps_check","text":"object fitted model object returned stan_jm modelling function. See stanreg-objects. check type plot show. Currently \"survival\" allowed, compares estimated marginal survival function joint model estimated Kaplan-Meier curve based observed data. limits quoted character string specifying type limits include plot. Can one : \"ci\" Bayesian posterior uncertainty interval (often known credible interval); \"none\" interval limits. draws integer indicating number MCMC draws use estimate survival function. default maximum number draws size posterior sample. seed optional seed use. xlab, ylab optional axis label passed labs. ci_geom_args Optional arguments passed geom_ribbon used control features plotted interval limits. supplied named list. ... Optional arguments passed geom_line used control features plotted trajectory.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/ps_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graphical checks of the estimated survival function — ps_check","text":"ggplot object can customized using   ggplot2 package.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/ps_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graphical checks of the estimated survival function — ps_check","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{ if (!exists(\"example_jm\")) example(example_jm) # Compare estimated survival function to Kaplan-Meier curve ps <- ps_check(example_jm) ps +   ggplot2::scale_color_manual(values = c(\"red\", \"black\")) + # change colors  ggplot2::scale_size_manual(values = c(0.5, 3)) + # change line sizes   ggplot2::scale_fill_manual(values = c(NA, NA)) # remove fill # } }"},{"path":"https://mc-stan.org/rstanarm/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. survival Surv","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Datasets for rstanarm examples — rstanarm-datasets","title":"Datasets for rstanarm examples — rstanarm-datasets","text":"Small datasets use rstanarm examples vignettes.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-datasets.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Datasets for rstanarm examples — rstanarm-datasets","text":"bball1970 Data hits -bats 1970 Major League Baseball season 18 players. Source: Efron Morris (1975). 18 obs. 5 variables Player Player's last name Hits Number hits first 45 -bats season AB Number -bats (45 players) RemainingAB Number remaining -bats (different players) RemainingHits Number remaining hits bball2006 Hits -bats entire 2006 American League season Major League Baseball. Source: Carpenter (2009) 302 obs. 2 variables y Number hits K Number -bats kidiq Data survey adult American women children (subsample National Longitudinal Survey Youth). Source: Gelman Hill (2007) 434 obs. 4 variables kid_score Child's IQ score mom_hs Indicator whether mother high school degree mom_iq Mother's IQ score mom_age Mother's age mortality Surgical mortality rates 12 hospitals performing cardiac surgery babies. Source: Spiegelhalter et al. (1996). 12 obs. 2 variables y Number deaths K Number surgeries pbcLong,pbcSurv Longitudinal biomarker time--event survival data 40 patients primary biliary cirrhosis participated randomised placebo controlled trial D-penicillamine conducted Mayo Clinic 1974 1984. Source: Therneau Grambsch (2000) 304 obs. 8 variables (pbcLong) 40 obs. 7 variables (pbcSurv) age years albumin serum albumin (g/dl) logBili logarithm serum bilirubin death indicator death endpoint futimeYears time (years) baseline     earliest death, transplantion censoring id numeric ID unique individual platelet platelet count sex gender (m = male, f = female) status status endpoint (0 = censored,     1 = transplant, 2 = dead) trt binary treatment code (0 = placebo, 1 =     D-penicillamine) year time (years) longitudinal measurements,     taken time since baseline) radon Data radon levels houses state Minnesota. Source: Gelman Hill (2007) 919 obs. 4 variables log_radon Radon measurement house (log scale) log_uranium Uranium level county (log scale) floor Indicator radon measurement made first floor house (0 = basement, 1 = first floor) county County name (factor) roaches Data efficacy pest management system reducing number roaches urban apartments. Source: Gelman Hill (2007) 262 obs. 6 variables y Number roaches caught roach1 Pretreatment number roaches treatment Treatment indicator senior Indicator elderly residents building exposure2 Number days roach traps used tumors Tarone (1982) provides data set tumor incidence historical control groups rats; specifically endometrial stromal polyps female lab rats type F344. Source: Gelman Hill (2007) 71 obs. 2 variables y Number rats tumors K Number rats wells survey 3200 residents small area Bangladesh suffering arsenic contamination groundwater. Respondents elevated arsenic levels wells encouraged switch water source safe public private well nearby area survey conducted several years later learn affected residents switched wells. Souce: Gelman Hill (2007) 3020 obs. 5 variables switch Indicator well-switching arsenic Arsenic level respondent's well dist Distance (meters) respondent's house nearest well safe drinking water. assoc Indicator member(s) household participate community organizations educ Years education (head household)","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-datasets.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Datasets for rstanarm examples — rstanarm-datasets","text":"Carpenter, B. (2009) Bayesian estimators beta-binomial model batting ability. https://web.archive.org/web/20220618114439/https://lingpipe-blog.com/2009/09/23/ Efron, B. Morris, C. (1975) Data analysis using Stein's estimator generalizations. Journal American Statistical Association 70(350), 311–319. Gelman, . Hill, J. (2007). Data Analysis Using   Regression Multilevel/Hierarchical Models. Cambridge University Press,   Cambridge, UK. https://sites.stat.columbia.edu/gelman/arm/ Spiegelhalter, D., Thomas, ., Best, N., & Gilks, W. (1996) BUGS 0.5 Examples. MRC Biostatistics Unit, Institute Public health, Cambridge, UK. Tarone, R. E. (1982) use historical control information testing trend proportions. Biometrics 38(1):215–220. Therneau, T. Grambsch, P. (2000) Modeling Survival Data: Extending Cox Model. Springer-Verlag, New York, US.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-datasets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Datasets for rstanarm examples — rstanarm-datasets","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # Using 'kidiq' dataset  fit <- stan_lm(kid_score ~ mom_hs * mom_iq, data = kidiq,                 prior = R2(location = 0.30, what = \"mean\"),                # the next line is only to make the example go fast enough                chains = 1, iter = 500, seed = 12345) pp_check(fit, nreps = 20) # \\donttest{ bayesplot::color_scheme_set(\"brightblue\") pp_check(fit, plotfun = \"stat_grouped\", stat = \"median\",           group = factor(kidiq$mom_hs, labels = c(\"No HS\", \"HS\"))) # } } #>  #> SAMPLING FOR MODEL 'lm' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.5e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.767 seconds (Warm-up) #> Chain 1:                0.259 seconds (Sampling) #> Chain 1:                1.026 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> `stat_bin()` using `bins = 30`. Pick better value `binwidth`."},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated functions — rstanarm-deprecated","title":"Deprecated functions — rstanarm-deprecated","text":"functions deprecated removed future release. Arguments section provides details functionality obtained via arguments replaced.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated functions — rstanarm-deprecated","text":"","code":"prior_options(   prior_scale_for_dispersion = 5,   min_prior_scale = 1e-12,   scaled = TRUE )"},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deprecated functions — rstanarm-deprecated","text":"prior_scale_for_dispersion, min_prior_scale, scaled Arguments deprecated prior_options function. functionality provided now deprecated prior_options function replaced follows: prior_scale_for_dispersion Instead using prior_scale_for_dispersion argument  prior_options, priors parameters can now  specified directly calling stan_glm ( stan_glmer, etc.) using new prior_aux  argument. scaled Instead setting prior_options(scaled=FALSE), internal rescaling  now toggled using new autoscale arguments  normal, student_t, cauchy  (prior distributions support 'autoscale'). min_prior_scale replacement. min_prior_scale (minimum possible scale  parameter value used priors) now fixed 1e-12.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Applied Regression Modeling via RStan — rstanarm-package","title":"Applied Regression Modeling via RStan — rstanarm-package","text":"Stan Development Team rstanarm package appendage rstan package enables many common applied regression models estimated using Markov Chain Monte Carlo, variational approximations posterior distribution, optimization. rstanarm package allows models specified using customary R modeling syntax (e.g., like glm formula data.frame). sections provide overview modeling functions estimation algorithms used rstanarm.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applied Regression Modeling via RStan — rstanarm-package","text":"set models supported rstanarm large (continue grow), also limited enough possible integrate tightly pp_check function graphical posterior predictive checks bayesplot posterior_predict function easily estimate effect specific manipulations predictor variables predict outcome training set. objects returned rstanarm modeling functions called stanreg objects. addition typical methods defined fitted model objects, stanreg objects can passed loo function loo package model comparison launch_shinystan function shinystan package order visualize posterior distribution using ShinyStan graphical user interface. See rstanarm vignettes details entire process.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-package.html","id":"prior-distributions","dir":"Reference","previous_headings":"","what":"Prior distributions","title":"Applied Regression Modeling via RStan — rstanarm-package","text":"See priors help page vignette Prior Distributions rstanarm Models overview various choices user can make prior distributions. package vignettes modeling functions also provide examples using many available priors well detailed descriptions novel priors used rstanarm.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-package.html","id":"modeling-functions","dir":"Reference","previous_headings":"","what":"Modeling functions","title":"Applied Regression Modeling via RStan — rstanarm-package","text":"model estimating functions described greater detail individual help pages vignettes. provide brief overview: stan_lm, stan_aov, stan_biglm Similar lm aov   novel regularizing priors model parameters driven prior   beliefs \\(R^2\\), proportion variance outcome   attributable predictors linear model. stan_glm, stan_glm.nb Similar glm various possible prior  distributions coefficients , applicable, prior distribution  auxiliary parameter Generalized Linear Model (GLM)  characterized family object (e.g. shape  parameter Gamma models). also possible estimate negative  binomial model similar way glm.nb function  MASS package. stan_glmer, stan_glmer.nb, stan_lmer Similar glmer, glmer.nb   lmer functions lme4 package GLMs   augmented group-specific terms deviate common   coefficients according mean-zero multivariate normal distribution   highly-structured unknown covariance matrix (rstanarm   introduces innovative prior distribution). MCMC provides   appropriate estimates uncertainty models consist mix   common group-specific parameters. stan_nlmer Similar nlmer lme4 package   nonlinear \"mixed-effects\" models, group-specific coefficients   flexible priors unknown covariance matrices. stan_gamm4 Similar gamm4 gamm4 package,   augments GLM (possibly group-specific terms) nonlinear smooth   functions predictors form Generalized Additive Mixed Model   (GAMM). Rather calling glmer like   gamm4 , stan_gamm4 essentially calls   stan_glmer, avoids optimization issues often   crop GAMMs provides better estimates uncertainty   parameter estimates. stan_polr Similar polr MASS package   models ordinal response, Bayesian model also implies prior   distribution unknown cutpoints. Can also used model binary   outcomes, possibly estimating unknown exponent governing   probability success. stan_betareg Similar betareg models outcome   rate (proportion) , rather performing maximum likelihood   estimation, full Bayesian estimation performed default,   customizable prior distributions parameters. stan_clogit Similar clogit models binary outcome    number successes failures fixed within stratum    research design. minor syntactical differences relative    clogit allow stan_clogit accept    group-specific terms stan_glmer. stan_mvmer multivariate form stan_glmer, whereby user can    specify one submodels consisting GLM group-specific    terms. one submodel specified (.e. one    outcome variable) dependence induced assuming    group-specific terms grouping factor correlated across submodels. stan_jm Estimates shared parameter joint models longitudinal time--event    (.e. survival) data. joint model can univariate (.e. one longitudinal    outcome) multivariate (.e. one longitudinal outcome). variety    parameterisations available linking longitudinal event    processes (.e. variety association structures).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-package.html","id":"estimation-algorithms","dir":"Reference","previous_headings":"","what":"Estimation algorithms","title":"Applied Regression Modeling via RStan — rstanarm-package","text":"modeling functions rstanarm package take algorithm argument can one following: Sampling (algorithm=\"sampling\") Uses Markov Chain Monte Carlo (MCMC) — particular, Hamiltonian Monte  Carlo (HMC) tuned diagonal mass matrix — draw  posterior distribution parameters. See sampling  (rstan) details. slowest reliable  available estimation algorithms default  recommended algorithm statistical inference. Mean-field (algorithm=\"meanfield\") Uses mean-field variational inference draw approximation  posterior distribution. particular, algorithm finds set  independent normal distributions unconstrained space —  transformed constrained space — closely approximate  posterior distribution. draws repeatedly independent  normal distributions transforms constrained space.  entire process much faster HMC yields independent draws  recommended final statistical inference. can  useful narrow set candidate models large problems, particularly  specifying QR=TRUE stan_glm,  stan_glmer, stan_gamm4,  approximation posterior distribution. Full-rank (algorithm=\"fullrank\") Uses full-rank variational inference draw approximation  posterior distribution finding multivariate normal distribution  unconstrained space — transformed constrained space  — closely approximates posterior distribution. draws  repeatedly multivariate normal distribution transforms  draws constrained space. process slower meanfield  variational inference faster HMC. Although still  approximation posterior distribution thus recommended  final statistical inference, approximation realistic  mean-field variational inference parameters  assumed independent unconstrained space. Nevertheless, fullrank  variational inference difficult optimization problem  algorithm prone non-convergence convergence local  optimum. Optimizing (algorithm=\"optimizing\") Finds posterior mode using C++ implementation LBGFS algorithm.  See optimizing details. prior  information, equivalent maximum likelihood, case  great reason use functions rstanarm package  emulated functions packages. However, priors  specified, estimates penalized maximum likelihood estimates,  may redeeming value. Currently, optimization  supported stan_glm.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Applied Regression Modeling via RStan — rstanarm-package","text":"Bates, D., Maechler, M., Bolker, B., Walker, S. (2015). Fitting linear mixed-Effects models using lme4. Journal Statistical Software. 67(1), 1–48. Gelman, ., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari,   ., Rubin, D. B. (2013). Bayesian Data Analysis. Chapman & Hall/CRC   Press, London, third edition. https://sites.stat.columbia.edu/gelman/book/ Gelman, . Hill, J. (2007). Data Analysis Using   Regression Multilevel/Hierarchical Models. Cambridge University Press,   Cambridge, UK. https://sites.stat.columbia.edu/gelman/arm/ Stan Development Team. Stan Modeling Language Users Guide Reference Manual. https://mc-stan.org/users/documentation/. Vehtari, ., Gelman, ., Gabry, J. (2017). Practical   Bayesian model evaluation using leave-one-cross-validation WAIC.   Statistics Computing. 27(5), 1413–1432.   doi:10.1007/s11222-016-9696-4. arXiv preprint:   https://arxiv.org/abs/1507.04544 Yao, Y., Vehtari, ., Simpson, D., Gelman, . (2018) Using   stacking average Bayesian predictive distributions. Bayesian   Analysis, advance publication,  doi:10.1214/17-BA1091 . Gabry, J. , Simpson, D. , Vehtari, . , Betancourt, M.   Gelman, . (2019), Visualization Bayesian workflow. J. R. Stat.   Soc. , 182: 389-402. doi:10.1111/rssa.12378,   arXiv preprint,   code GitHub) Muth, C., Oravecz, Z., Gabry, J. (2018) User-friendly Bayesian regression modeling: tutorial rstanarm shinystan. Quantitative Methods Psychology. 14(2), 99–119. https://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/rstanarm-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Applied Regression Modeling via RStan — rstanarm-package","text":"Maintainer: Ben Goodrich benjamin.goodrich@columbia.edu Authors: Jonah Gabry jgabry@gmail.com contributors: Imad Ali [contributor] Sam Brilleman [contributor] Jacqueline Buros Novik (R/stan_jm.R) [contributor] AstraZeneca (R/stan_jm.R) [contributor] Trustees Columbia University [copyright holder] Simon Wood (R/stan_gamm4.R) [copyright holder] R Core Deveopment Team (R/stan_aov.R) [copyright holder] Douglas Bates (R/pp_data.R) [copyright holder] Martin Maechler (R/pp_data.R) [copyright holder] Ben Bolker (R/pp_data.R) [copyright holder] Steve Walker (R/pp_data.R) [copyright holder] Brian Ripley (R/stan_aov.R, R/stan_polr.R) [copyright holder] William Venables (R/stan_polr.R) [copyright holder] Paul-Christian Burkner paul.buerkner@gmail.com (R/misc.R) [copyright holder]","code":""},{"path":"https://mc-stan.org/rstanarm/reference/se.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract standard errors — se","title":"Extract standard errors — se","text":"Generic function extracting standard errors fitted models.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/se.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract standard errors — se","text":"","code":"se(object, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/se.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract standard errors — se","text":"object fitted model object. ... Arguments methods.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/se.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract standard errors — se","text":"Standard errors model parameters.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_betareg.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian beta regression models via Stan — stan_betareg","title":"Bayesian beta regression models via Stan — stan_betareg","text":"Beta regression modeling optional prior distributions coefficients, intercept, auxiliary parameter phi (applicable).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_betareg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian beta regression models via Stan — stan_betareg","text":"","code":"stan_betareg(   formula,   data,   subset,   na.action,   weights,   offset,   link = c(\"logit\", \"probit\", \"cloglog\", \"cauchit\", \"log\", \"loglog\"),   link.phi = NULL,   model = TRUE,   y = TRUE,   x = FALSE,   ...,   prior = normal(autoscale = TRUE),   prior_intercept = normal(autoscale = TRUE),   prior_z = normal(autoscale = TRUE),   prior_intercept_z = normal(autoscale = TRUE),   prior_phi = exponential(autoscale = TRUE),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"optimizing\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   QR = FALSE )  stan_betareg.fit(   x,   y,   z = NULL,   weights = rep(1, NROW(x)),   offset = rep(0, NROW(x)),   link = c(\"logit\", \"probit\", \"cloglog\", \"cauchit\", \"log\", \"loglog\"),   link.phi = NULL,   ...,   prior = normal(autoscale = TRUE),   prior_intercept = normal(autoscale = TRUE),   prior_z = normal(autoscale = TRUE),   prior_intercept_z = normal(autoscale = TRUE),   prior_phi = exponential(autoscale = TRUE),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"optimizing\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   QR = FALSE )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_betareg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian beta regression models via Stan — stan_betareg","text":"formula, data, subset betareg, strongly advise omitting data argument. Unless data specified (data frame) many post-estimation functions (including update, loo, kfold) guaranteed work properly. na.action betareg, rarely specified. link Character specification link function used model mu (specified x). Currently, \"logit\", \"probit\", \"cloglog\", \"cauchit\", \"log\", \"loglog\" supported. link.phi applicable, character specification link function used model phi (specified z). Currently, \"identity\", \"log\" (default), \"sqrt\" supported. Since \"sqrt\" link function known unstable, advisable specify different link function (model phi scalar parameter instead via linear predictor excluding z formula excluding link.phi). model, offset, weights betareg. x, y stan_betareg, logical scalars indicating whether return design matrix response vector. stan_betareg.fit, design matrix response vector. ... arguments passed function rstan package (sampling, vb, optimizing), corresponding estimation method named algorithm. example, algorithm \"sampling\" possible specify iter, chains, cores, MCMC controls. Another useful argument can passed rstan via ... refresh, specifies often print updates sampling (.e., show progress every refresh iterations). refresh=0 turns iteration updates. prior prior distribution (non-hierarchical) regression coefficients. default priors described vignette Prior Distributions rstanarm Models. using default, prior call one various functions provided rstanarm specifying priors. subset functions can used prior coefficients can grouped several \"families\": See priors help page details families specify arguments functions table . omit prior —.e., use flat (improper) uniform prior— prior can set NULL, although rarely good idea. Note: Unless QR=TRUE, prior Student t family Laplace family, autoscale argument function used specify prior (e.g. normal) left default recommended value TRUE, default user-specified prior scale(s) may adjusted internally based scales predictors. See priors help page Prior Distributions vignette details rescaling prior_summary function summary priors used particular model. prior_intercept prior distribution intercept (  centering predictors, see note ). default prior described vignette   Prior   Distributions rstanarm Models.   using default, prior_intercept can call   normal, student_t cauchy. See   priors help page details functions. omit   prior intercept —.e., use flat (improper) uniform prior—   prior_intercept can set NULL. Note: using dense representation design matrix   —.e., sparse argument left default value   FALSE— prior distribution intercept set   applies value predictors centered (  need manually center ). explained   [Prior Distributions rstanarm Models](https://mc-stan.org/rstanarm/articles/priors.html)   prefer specify prior intercept without predictors   auto-centered, omit intercept   formula include column ones predictor,   case element prior specifies prior ,   rather prior_intercept. Regardless   prior_intercept specified, reported estimates   intercept always correspond parameterization without centered   predictors (.e., glm). prior_z Prior distribution coefficients model phi (applicable). options prior. prior_intercept_z Prior distribution intercept model phi (applicable). options prior_intercept. prior_phi prior distribution phi modeled function predictors. z variables specified prior_phi ignored prior_intercept_z prior_z used specify priors intercept coefficients model phi. applicable, prior_phi can call exponential use exponential distribution, one normal, student_t cauchy use half-normal, half-t, half-Cauchy prior. See priors details functions. omit prior —.e., use flat (improper) uniform prior— set prior_phi NULL. prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. QR logical scalar defaulting FALSE, TRUE applies scaled qr decomposition design matrix. transformation change likelihood data recommended computational reasons multiple predictors. See QR-argument documentation page details rstanarm transformation important information interpret prior distributions model parameters using QR=TRUE. z stan_betareg.fit, regressor matrix phi. Defaults intercept .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_betareg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian beta regression models via Stan — stan_betareg","text":"stanreg object returned stan_betareg. stanfit object (slightly modified   stanfit object) returned stan_betareg.fit called directly.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_betareg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian beta regression models via Stan — stan_betareg","text":"stan_betareg function similar syntax   betareg rather performing maximum   likelihood estimation, full Bayesian estimation performed (  algorithm \"sampling\") via MCMC. Bayesian model adds   priors (independent default) coefficients beta regression   model. stan_betareg function calls workhorse   stan_betareg.fit function, also possible call   latter directly.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_betareg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian beta regression models via Stan — stan_betareg","text":"Ferrari, SLP Cribari-Neto, F (2004). Beta regression   modeling rates proportions. Journal Applied Statistics.   31(7), 799–815.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_betareg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian beta regression models via Stan — stan_betareg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { ### Simulated data N <- 200 x <- rnorm(N, 2, 1) z <- rnorm(N, 2, 1) mu <- binomial(link = \"logit\")$linkinv(1 + 0.2*x) phi <- exp(1.5 + 0.4*z) y <- rbeta(N, mu * phi, (1 - mu) * phi) hist(y, col = \"dark grey\", border = FALSE, xlim = c(0,1)) fake_dat <- data.frame(y, x, z)  fit <- stan_betareg(   y ~ x | z, data = fake_dat,    link = \"logit\",    link.phi = \"log\",    algorithm = \"optimizing\" # just for speed of example  )  print(fit, digits = 2) }  #> stan_betareg #>  family:       beta [logit, link.phi=log] #>  formula:      y ~ x | z #>  observations: 200 #> ------ #>                   Median MAD_SD #> (Intercept)       1.02   0.11   #> x                 0.17   0.05   #> (phi)_(Intercept) 1.35   0.24   #> (phi)_z           0.45   0.12   #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg"},{"path":"https://mc-stan.org/rstanarm/reference/stan_biglm.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian regularized linear but big models via Stan — stan_biglm","title":"Bayesian regularized linear but big models via Stan — stan_biglm","text":"model stan_lm utilizes output biglm biglm package order proceed data large fit memory.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_biglm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian regularized linear but big models via Stan — stan_biglm","text":"","code":"stan_biglm(   biglm,   xbar,   ybar,   s_y,   ...,   prior = R2(stop(\"'location' must be specified\")),   prior_intercept = NULL,   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL )  stan_biglm.fit(   b,   R,   SSR,   N,   xbar,   ybar,   s_y,   has_intercept = TRUE,   ...,   prior = R2(stop(\"'location' must be specified\")),   prior_intercept = NULL,   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\", \"optimizing\"),   adapt_delta = NULL,   importance_resampling = TRUE,   keep_every = 1 )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_biglm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian regularized linear but big models via Stan — stan_biglm","text":"biglm list output biglm biglm package. xbar numeric vector column means implicit design matrix excluding intercept observations included model. ybar numeric scalar indicating mean outcome observations included model. s_y numeric scalar indicating unbiased sample standard deviation outcome observations included model. ... arguments passed function rstan package (sampling, vb, optimizing), corresponding estimation method named algorithm. example, algorithm \"sampling\" possible specify iter, chains, cores, MCMC controls. Another useful argument can passed rstan via ... refresh, specifies often print updates sampling (.e., show progress every refresh iterations). refresh=0 turns iteration updates. prior Must call R2 location argument specified NULL, indicate standard uniform prior \\(R^2\\). prior_intercept Either NULL (default) call normal. normal prior specified without scale, standard deviation taken marginal standard deviation outcome divided square root sample size, legitimate marginal standard deviation outcome primitive parameter estimated. Note: using dense representation design matrix —.e., sparse argument left default value FALSE— prior distribution intercept set applies value predictors centered. prefer specify prior intercept without predictors auto-centered, omit intercept formula include column ones predictor, case element prior specifies prior , rather prior_intercept. Regardless prior_intercept specified, reported estimates intercept always correspond parameterization without centered predictors (.e., glm). prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. b numeric vector OLS coefficients, excluding intercept R square upper-triangular matrix QR decomposition design matrix, excluding intercept SSR numeric scalar indicating sum--squared residuals OLS N integer scalar indicating number included observations has_intercept logical scalar indicating whether add intercept model estimating . importance_resampling Logical scalar indicating whether use importance resampling approximating posterior distribution multivariate normal around posterior mode, applies algorithm \"optimizing\" defaults TRUE case keep_every Positive integer, defaults 1, can higher order thin importance sampling realizations also apples algorithm \"optimizing\" defaults TRUE case","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_biglm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian regularized linear but big models via Stan — stan_biglm","text":"output stan_biglm stan_biglm.fit   object stanfit-class rather   stanreg-objects, limited less convenient   necessitated fact stan_biglm bring full   design matrix memory. Without full design matrix,  elements stanreg-objects object calculated,   residuals. Thus, functions rstanarm package   input stanreg-objects,   posterior_predict used.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_biglm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian regularized linear but big models via Stan — stan_biglm","text":"stan_biglm function intended used   circumstances biglm function biglm   package informative prior \\(R^2\\) regression.   Like biglm, memory required estimate model   depends largely number predictors rather number   observations. However, stan_biglm stan_biglm.fit   additional required arguments necessary   biglm, namely xbar, ybar, s_y.   observations missing values predictors   outcome, observations contribute statistics.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_biglm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian regularized linear but big models via Stan — stan_biglm","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # create inputs ols <- lm(mpg ~ wt + qsec + am, data = mtcars, # all row are complete so ...           na.action = na.exclude)              # not necessary in this case b <- coef(ols)[-1] R <- qr.R(ols$qr)[-1,-1] SSR <- crossprod(ols$residuals)[1] not_NA <- !is.na(fitted(ols)) N <- sum(not_NA) xbar <- colMeans(mtcars[not_NA,c(\"wt\", \"qsec\", \"am\")]) y <- mtcars$mpg[not_NA] ybar <- mean(y) s_y <- sd(y) post <- stan_biglm.fit(b, R, SSR, N, xbar, ybar, s_y, prior = R2(.75),                        # the next line is only to make the example go fast                        chains = 1, iter = 500, seed = 12345) cbind(lm = b, stan_lm = rstan::get_posterior_mean(post)[13:15,]) # shrunk } #>  #> SAMPLING FOR MODEL 'lm' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.6e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.52 seconds (Warm-up) #> Chain 1:                0.268 seconds (Sampling) #> Chain 1:                0.788 seconds (Total) #> Chain 1:  #> Warning: There were 1 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #>             lm   stan_lm #> wt   -3.916504 -3.694667 #> qsec  1.225886  1.190556 #> am    2.935837  2.984365"},{"path":"https://mc-stan.org/rstanarm/reference/stan_clogit.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional logistic (clogit) regression models via Stan — stan_clogit","title":"Conditional logistic (clogit) regression models via Stan — stan_clogit","text":"model case-control studies optional prior distributions coefficients, intercept, auxiliary parameters.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_clogit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional logistic (clogit) regression models via Stan — stan_clogit","text":"","code":"stan_clogit(   formula,   data,   subset,   na.action = NULL,   contrasts = NULL,   ...,   strata,   prior = normal(autoscale = TRUE),   prior_covariance = decov(),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"optimizing\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   QR = FALSE,   sparse = FALSE )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_clogit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional logistic (clogit) regression models via Stan — stan_clogit","text":"formula, data, subset, na.action, contrasts glmer, except global intercept included formula dropped. strongly advise omitting data argument. Unless data specified (data frame) many post-estimation functions (including update, loo, kfold) guaranteed work properly. ... arguments passed function rstan package (sampling, vb, optimizing), corresponding estimation method named algorithm. example, algorithm \"sampling\" possible specify iter, chains, cores, MCMC controls. Another useful argument can passed rstan via ... refresh, specifies often print updates sampling (.e., show progress every refresh iterations). refresh=0 turns iteration updates. strata factor indicating groups data number successes (possibly one) fixed research design. may useful use interaction strata create factor. However, strata argument must rely object besides data data.frame. prior prior distribution (non-hierarchical) regression coefficients. default priors described vignette Prior Distributions rstanarm Models. using default, prior call one various functions provided rstanarm specifying priors. subset functions can used prior coefficients can grouped several \"families\": See priors help page details families specify arguments functions table . omit prior —.e., use flat (improper) uniform prior— prior can set NULL, although rarely good idea. Note: Unless QR=TRUE, prior Student t family Laplace family, autoscale argument function used specify prior (e.g. normal) left default recommended value TRUE, default user-specified prior scale(s) may adjusted internally based scales predictors. See priors help page Prior Distributions vignette details rescaling prior_summary function summary priors used particular model. prior_covariance NULL lme4-style group-specific terms included formula. See decov information default arguments. Ignored group-specific terms. prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. QR logical scalar defaulting FALSE, TRUE applies scaled qr decomposition design matrix. transformation change likelihood data recommended computational reasons multiple predictors. See QR-argument documentation page details rstanarm transformation important information interpret prior distributions model parameters using QR=TRUE. sparse logical scalar (defaulting FALSE) indicating whether use sparse representation design (X) matrix. TRUE, design matrix centered (since destroy sparsity) likewise possible specify QR = TRUE sparse = TRUE. Depending many zeros design matrix, setting sparse = TRUE may make code run faster can consume much less RAM.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_clogit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional logistic (clogit) regression models via Stan — stan_clogit","text":"stanreg object returned stan_clogit.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_clogit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conditional logistic (clogit) regression models via Stan — stan_clogit","text":"stan_clogit function mostly similar syntax   clogit rather performing maximum   likelihood estimation generalized linear models, full Bayesian   estimation performed (algorithm \"sampling\") via   MCMC. Bayesian model adds priors (independent default)   coefficients GLM. data.frame passed data argument must sorted   variable passed strata argument. formula may group-specific terms like   stan_glmer allow intercept vary   stratifying variable, since information data   estimate deviations intercept.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_clogit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional logistic (clogit) regression models via Stan — stan_clogit","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { dat <- infert[order(infert$stratum), ] # order by strata post <- stan_clogit(case ~ spontaneous + induced + (1 | education),                      strata = stratum,                     data = dat,                     subset = parity <= 2,                     QR = TRUE,                     chains = 2, iter = 500) # for speed only  nd <- dat[dat$parity > 2, c(\"case\", \"spontaneous\", \"induced\", \"education\", \"stratum\")] # next line would fail without case and stratum variables                                  pr <- posterior_epred(post, newdata = nd) # get predicted probabilities  # not a random variable b/c probabilities add to 1 within strata all.equal(rep(sum(nd$case), nrow(pr)), rowSums(pr))  } #>  #> SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 4.8e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.48 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.218 seconds (Warm-up) #> Chain 1:                0.075 seconds (Sampling) #> Chain 1:                0.293 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'bernoulli' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 3.4e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.34 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 2: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 2: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 2: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 2: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 2: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 2: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 2: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 2: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 2: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 2: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 2: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.22 seconds (Warm-up) #> Chain 2:                0.082 seconds (Sampling) #> Chain 2:                0.302 seconds (Total) #> Chain 2:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> [1] TRUE"},{"path":"https://mc-stan.org/rstanarm/reference/stan_gamm4.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian generalized linear additive models with optional group-specific terms via Stan — stan_gamm4","title":"Bayesian generalized linear additive models with optional group-specific terms via Stan — stan_gamm4","text":"Bayesian inference GAMMs flexible priors.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_gamm4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian generalized linear additive models with optional group-specific terms via Stan — stan_gamm4","text":"","code":"stan_gamm4(   formula,   random = NULL,   family = gaussian(),   data,   weights = NULL,   subset = NULL,   na.action,   knots = NULL,   drop.unused.levels = TRUE,   ...,   prior = default_prior_coef(family),   prior_intercept = default_prior_intercept(family),   prior_smooth = exponential(autoscale = FALSE),   prior_aux = exponential(autoscale = TRUE),   prior_covariance = decov(),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   QR = FALSE,   sparse = FALSE )  plot_nonlinear(   x,   smooths,   ...,   prob = 0.9,   facet_args = list(),   alpha = 1,   size = 0.75 )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_gamm4.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian generalized linear additive models with optional group-specific terms via Stan — stan_gamm4","text":"formula, random, family, data, knots, drop.unused.levels gamm4. strongly advise omitting data argument. Unless data specified (data frame) many post-estimation functions (including update, loo, kfold) guaranteed work properly. subset, weights, na.action glm, rarely specified. ... arguments passed sampling (e.g. iter, chains, cores, etc.) vb (algorithm \"meanfield\" \"fullrank\"). prior prior distribution (non-hierarchical) regression coefficients. default priors described vignette Prior Distributions rstanarm Models. using default, prior call one various functions provided rstanarm specifying priors. subset functions can used prior coefficients can grouped several \"families\": See priors help page details families specify arguments functions table . omit prior —.e., use flat (improper) uniform prior— prior can set NULL, although rarely good idea. Note: Unless QR=TRUE, prior Student t family Laplace family, autoscale argument function used specify prior (e.g. normal) left default recommended value TRUE, default user-specified prior scale(s) may adjusted internally based scales predictors. See priors help page Prior Distributions vignette details rescaling prior_summary function summary priors used particular model. prior_intercept prior distribution intercept (  centering predictors, see note ). default prior described vignette   Prior   Distributions rstanarm Models.   using default, prior_intercept can call   normal, student_t cauchy. See   priors help page details functions. omit   prior intercept —.e., use flat (improper) uniform prior—   prior_intercept can set NULL. Note: using dense representation design matrix   —.e., sparse argument left default value   FALSE— prior distribution intercept set   applies value predictors centered (  need manually center ). explained   [Prior Distributions rstanarm Models](https://mc-stan.org/rstanarm/articles/priors.html)   prefer specify prior intercept without predictors   auto-centered, omit intercept   formula include column ones predictor,   case element prior specifies prior ,   rather prior_intercept. Regardless   prior_intercept specified, reported estimates   intercept always correspond parameterization without centered   predictors (.e., glm). prior_smooth prior distribution hyperparameters GAMs, lower values yielding less flexible smooth functions. prior_smooth can call exponential use exponential distribution, normal, student_t cauchy, results half-normal, half-t, half-Cauchy prior. See priors details functions. omit prior —.e., use flat (improper) uniform prior— set prior_smooth NULL. number hyperparameters depends model specification scalar prior recylced necessary appropriate length. prior_aux prior distribution \"auxiliary\" parameter (applicable). \"auxiliary\" parameter refers different parameter depending family. Gaussian models prior_aux controls \"sigma\", error standard deviation. negative binomial models prior_aux controls \"reciprocal_dispersion\", similar \"size\" parameter rnbinom: smaller values \"reciprocal_dispersion\" correspond greater dispersion. gamma models prior_aux sets prior \"shape\" parameter (see e.g., rgamma), inverse-Gaussian models -called \"lambda\" parameter (essentially reciprocal scale parameter). Binomial Poisson models auxiliary parameters. default prior described vignette Prior Distributions rstanarm Models. using default, prior_aux can call exponential use exponential distribution, normal, student_t cauchy, results half-normal, half-t, half-Cauchy prior. See priors details functions. omit prior —.e., use flat (improper) uniform prior— set prior_aux NULL. prior_covariance NULL; see decov information default arguments. prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. QR logical scalar defaulting FALSE, TRUE applies scaled qr decomposition design matrix. transformation change likelihood data recommended computational reasons multiple predictors. See QR-argument documentation page details rstanarm transformation important information interpret prior distributions model parameters using QR=TRUE. sparse logical scalar (defaulting FALSE) indicating whether use sparse representation design (X) matrix. TRUE, design matrix centered (since destroy sparsity) likewise possible specify QR = TRUE sparse = TRUE. Depending many zeros design matrix, setting sparse = TRUE may make code run faster can consume much less RAM. x object produced stan_gamm4. smooths optional character vector specifying subset smooth functions specified call stan_gamm4. default include smooth terms. prob univarite smooths, scalar 0 1 governing width uncertainty interval. facet_args optional named list arguments passed facet_wrap (facets argument). alpha, size univariate smooths, passed geom_ribbon. bivariate smooths, size/2 passed geom_contour.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_gamm4.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian generalized linear additive models with optional group-specific terms via Stan — stan_gamm4","text":"stanreg object returned stan_gamm4. plot_nonlinear returns ggplot object.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_gamm4.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian generalized linear additive models with optional group-specific terms via Stan — stan_gamm4","text":"stan_gamm4 function similar syntax   gamm4 gamm4 package. rather performing   (restricted) maximum likelihood estimation lme4 package,   stan_gamm4 function utilizes MCMC perform Bayesian   estimation. Bayesian model adds priors common regression   coefficients (way stan_glm), priors   standard deviations smooth terms, prior decomposition   covariance matrices group-specific parameters (  stan_glmer). Estimating models via MCMC avoids   optimization issues often crop GAMMs provides better   estimates uncertainty parameter estimates. See gamm4 information model   specicification priors information   priors main coefficients. formula include least   one smooth term, can specified way supported   jagam function mgcv package.   prior_smooth argument used specify prior unknown   standard deviations govern smooth smooth function .   prior_covariance argument can used specify prior   components covariance matrix (optional) group-specific terms.   gamm4 function gamm4 package uses   group-specific terms implement departure linearity smooth   terms, case stan_gamm4 group-specific   terms exactly stan_glmer. plot_nonlinear function creates ggplot object one facet   smooth function specified call stan_gamm4 case   smooths univariate. subset smooth functions can   specified using smooths argument, necessary plot   bivariate smooth exclude bivariate smooth plot univariate   ones. bivariate case, plot produced using   geom_contour. univariate case, resulting   plot conceptually similar plot.gam except   outer lines demark edges posterior uncertainty intervals   (credible intervals) rather confidence intervals inner line   posterior median function rather function implied   point estimate. change colors used plot see   color_scheme_set.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_gamm4.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian generalized linear additive models with optional group-specific terms via Stan — stan_gamm4","text":"Crainiceanu, C., Ruppert D., Wand, M. (2005). Bayesian analysis penalized spline regression using WinBUGS. Journal Statistical Software. 14(14), 1–22. https://www.jstatsoft.org/article/view/v014i14","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_gamm4.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian generalized linear additive models with optional group-specific terms via Stan — stan_gamm4","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # from example(gamm4, package = \"gamm4\"), prefixing gamm4() call with stan_ # \\donttest{ dat <- mgcv::gamSim(1, n = 400, scale = 2) ## simulate 4 term additive truth ## Now add 20 level random effect `fac'... dat$fac <- fac <- as.factor(sample(1:20, 400, replace = TRUE)) dat$y <- dat$y + model.matrix(~ fac - 1) %*% rnorm(20) * .5  br <- stan_gamm4(y ~ s(x0) + x1 + s(x2), data = dat, random = ~ (1 | fac),                   chains = 1, iter = 500) # for example speed print(br) plot_nonlinear(br) plot_nonlinear(br, smooths = \"s(x0)\", alpha = 2/3) # } } #> Gu & Wahba 4 term additive model #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 9.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.99 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 500 [  0%]  (Warmup) #> Chain 1: Iteration:  50 / 500 [ 10%]  (Warmup) #> Chain 1: Iteration: 100 / 500 [ 20%]  (Warmup) #> Chain 1: Iteration: 150 / 500 [ 30%]  (Warmup) #> Chain 1: Iteration: 200 / 500 [ 40%]  (Warmup) #> Chain 1: Iteration: 250 / 500 [ 50%]  (Warmup) #> Chain 1: Iteration: 251 / 500 [ 50%]  (Sampling) #> Chain 1: Iteration: 300 / 500 [ 60%]  (Sampling) #> Chain 1: Iteration: 350 / 500 [ 70%]  (Sampling) #> Chain 1: Iteration: 400 / 500 [ 80%]  (Sampling) #> Chain 1: Iteration: 450 / 500 [ 90%]  (Sampling) #> Chain 1: Iteration: 500 / 500 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 2.482 seconds (Warm-up) #> Chain 1:                1.248 seconds (Sampling) #> Chain 1:                3.73 seconds (Total) #> Chain 1:  #> Warning: There were 6 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is 1.05, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> stan_gamm4 #>  family:       gaussian [identity] #>  formula:      y ~ s(x0) + x1 + s(x2) #>  observations: 400 #> ------ #>             Median MAD_SD #> (Intercept)   5.2    0.2  #> x1            5.6    0.4  #> s(x0).1      -0.2    1.6  #> s(x0).2      -0.1    2.1  #> s(x0).3       0.1    2.0  #> s(x0).4       0.2    1.6  #> s(x0).5      -0.1    1.7  #> s(x0).6      -2.6    1.4  #> s(x0).7       0.2    0.8  #> s(x0).8      -1.8    1.6  #> s(x0).9       0.0    0.8  #> s(x2).1     -31.8   13.3  #> s(x2).2     -21.1    9.9  #> s(x2).3      23.3    8.1  #> s(x2).4      18.1    5.2  #> s(x2).5     -29.0    4.3  #> s(x2).6      13.1    2.1  #> s(x2).7      12.4    2.1  #> s(x2).8     -11.0    4.9  #> s(x2).9       6.1    9.0  #>  #> Auxiliary parameter(s): #>       Median MAD_SD #> sigma 2.1    0.1    #>  #> Smoothing terms: #>                   Median MAD_SD #> smooth_sd[s(x0)1]  2.1    0.8   #> smooth_sd[s(x0)2]  1.2    1.2   #> smooth_sd[s(x2)1] 16.7    3.1   #> smooth_sd[s(x2)2]  5.2    4.9   #>  #> Error terms: #>  Groups   Name        Std.Dev. #>  fac      (Intercept) 0.75     #>  Residual             2.15     #> Num. levels: fac 20  #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg"},{"path":"https://mc-stan.org/rstanarm/reference/stan_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian generalized linear models via Stan — stan_glm","title":"Bayesian generalized linear models via Stan — stan_glm","text":"Generalized linear modeling optional prior distributions coefficients, intercept, auxiliary parameters.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian generalized linear models via Stan — stan_glm","text":"","code":"stan_glm(   formula,   family = gaussian(),   data,   weights,   subset,   na.action = NULL,   offset = NULL,   model = TRUE,   x = FALSE,   y = TRUE,   contrasts = NULL,   ...,   prior = default_prior_coef(family),   prior_intercept = default_prior_intercept(family),   prior_aux = exponential(autoscale = TRUE),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"optimizing\", \"meanfield\", \"fullrank\"),   mean_PPD = algorithm != \"optimizing\" && !prior_PD,   adapt_delta = NULL,   QR = FALSE,   sparse = FALSE )  stan_glm.nb(   formula,   data,   weights,   subset,   na.action = NULL,   offset = NULL,   model = TRUE,   x = FALSE,   y = TRUE,   contrasts = NULL,   link = \"log\",   ...,   prior = default_prior_coef(family),   prior_intercept = default_prior_intercept(family),   prior_aux = exponential(autoscale = TRUE),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"optimizing\", \"meanfield\", \"fullrank\"),   mean_PPD = algorithm != \"optimizing\",   adapt_delta = NULL,   QR = FALSE )  stan_glm.fit(   x,   y,   weights = rep(1, NROW(y)),   offset = rep(0, NROW(y)),   family = gaussian(),   ...,   prior = default_prior_coef(family),   prior_intercept = default_prior_intercept(family),   prior_aux = exponential(autoscale = TRUE),   prior_smooth = exponential(autoscale = FALSE),   prior_ops = NULL,   group = list(),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"optimizing\", \"meanfield\", \"fullrank\"),   mean_PPD = algorithm != \"optimizing\" && !prior_PD,   adapt_delta = NULL,   QR = FALSE,   sparse = FALSE,   importance_resampling = algorithm != \"sampling\",   keep_every = algorithm != \"sampling\" )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian generalized linear models via Stan — stan_glm","text":"formula, data, subset glm, strongly advise omitting data argument. Unless data specified (data frame) many post-estimation functions (including update, loo, kfold) guaranteed work properly. family glm, except negative binomial GLMs also possible using neg_binomial_2 family object. na.action, contrasts glm, rarely specified. model, offset, weights glm. x stan_glm, logical scalar indicating whether return design matrix. stan_glm.fit, usually design matrix can also list design matrices number rows, case first element list interpreted primary design matrix remaining list elements collectively constitute basis smooth nonlinear function predictors indicated formula argument stan_gamm4. y stan_glm, logical scalar indicating whether return response vector. stan_glm.fit, response vector. ... arguments passed function rstan package (sampling, vb, optimizing), corresponding estimation method named algorithm. example, algorithm \"sampling\" possible specify iter, chains, cores, MCMC controls. Another useful argument can passed rstan via ... refresh, specifies often print updates sampling (.e., show progress every refresh iterations). refresh=0 turns iteration updates. prior prior distribution (non-hierarchical) regression coefficients. default priors described vignette Prior Distributions rstanarm Models. using default, prior call one various functions provided rstanarm specifying priors. subset functions can used prior coefficients can grouped several \"families\": See priors help page details families specify arguments functions table . omit prior —.e., use flat (improper) uniform prior— prior can set NULL, although rarely good idea. Note: Unless QR=TRUE, prior Student t family Laplace family, autoscale argument function used specify prior (e.g. normal) left default recommended value TRUE, default user-specified prior scale(s) may adjusted internally based scales predictors. See priors help page Prior Distributions vignette details rescaling prior_summary function summary priors used particular model. prior_intercept prior distribution intercept (  centering predictors, see note ). default prior described vignette   Prior   Distributions rstanarm Models.   using default, prior_intercept can call   normal, student_t cauchy. See   priors help page details functions. omit   prior intercept —.e., use flat (improper) uniform prior—   prior_intercept can set NULL. Note: using dense representation design matrix   —.e., sparse argument left default value   FALSE— prior distribution intercept set   applies value predictors centered (  need manually center ). explained   [Prior Distributions rstanarm Models](https://mc-stan.org/rstanarm/articles/priors.html)   prefer specify prior intercept without predictors   auto-centered, omit intercept   formula include column ones predictor,   case element prior specifies prior ,   rather prior_intercept. Regardless   prior_intercept specified, reported estimates   intercept always correspond parameterization without centered   predictors (.e., glm). prior_aux prior distribution \"auxiliary\" parameter (applicable). \"auxiliary\" parameter refers different parameter depending family. Gaussian models prior_aux controls \"sigma\", error standard deviation. negative binomial models prior_aux controls \"reciprocal_dispersion\", similar \"size\" parameter rnbinom: smaller values \"reciprocal_dispersion\" correspond greater dispersion. gamma models prior_aux sets prior \"shape\" parameter (see e.g., rgamma), inverse-Gaussian models -called \"lambda\" parameter (essentially reciprocal scale parameter). Binomial Poisson models auxiliary parameters. default prior described vignette Prior Distributions rstanarm Models. using default, prior_aux can call exponential use exponential distribution, normal, student_t cauchy, results half-normal, half-t, half-Cauchy prior. See priors details functions. omit prior —.e., use flat (improper) uniform prior— set prior_aux NULL. prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. mean_PPD logical value indicating whether sample mean posterior predictive distribution outcome calculated generated quantities block. TRUE mean_PPD computed displayed diagnostic printed output. default TRUE except algorithm==\"optimizing\". useful heuristic check mean_PPD plausible compared mean(y). plausible mean model good general (can reproduce sample mean), mean_PPD implausible may something wrong, e.g., severe model misspecification, problems data /priors, computational issues, etc. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. QR logical scalar defaulting FALSE, TRUE applies scaled qr decomposition design matrix. transformation change likelihood data recommended computational reasons multiple predictors. See QR-argument documentation page details rstanarm transformation important information interpret prior distributions model parameters using QR=TRUE. sparse logical scalar (defaulting FALSE) indicating whether use sparse representation design (X) matrix. TRUE, design matrix centered (since destroy sparsity) likewise possible specify QR = TRUE sparse = TRUE. Depending many zeros design matrix, setting sparse = TRUE may make code run faster can consume much less RAM. link stan_glm.nb , link function use. See neg_binomial_2. prior_smooth prior distribution hyperparameters GAMs, lower values yielding less flexible smooth functions. prior_smooth can call exponential use exponential distribution, normal, student_t cauchy, results half-normal, half-t, half-Cauchy prior. See priors details functions. omit prior —.e., use flat (improper) uniform prior— set prior_smooth NULL. number hyperparameters depends model specification scalar prior recylced necessary appropriate length. prior_ops Deprecated. See rstanarm-deprecated details. group list, possibly length zero (default), otherwise structure produced mkReTrms indicate group-specific part model. addition, list must elements regularization, concentration shape, scale components decov prior covariance matrices among group-specific coefficients. importance_resampling Logical scalar indicating whether use importance resampling approximating posterior distribution multivariate normal around posterior mode, applies algorithm \"optimizing\" defaults TRUE case keep_every Positive integer, defaults 1, can higher order \"thin\" importance sampling realizations. Applies importance_resampling=TRUE.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian generalized linear models via Stan — stan_glm","text":"stanreg object returned stan_glm, stan_glm.nb. stanfit object (slightly modified   stanfit object) returned stan_glm.fit called directly.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_glm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian generalized linear models via Stan — stan_glm","text":"stan_glm function similar syntax   glm rather performing maximum likelihood   estimation generalized linear models, full Bayesian estimation   performed (algorithm \"sampling\") via MCMC. Bayesian   model adds priors (independent default) coefficients GLM.   stan_glm function calls workhorse stan_glm.fit   function, also possible call latter directly. stan_glm.nb function, takes extra argument   link, wrapper stan_glm family =   neg_binomial_2(link).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_glm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian generalized linear models via Stan — stan_glm","text":"Gelman, . Hill, J. (2007). Data Analysis Using   Regression Multilevel/Hierarchical Models. Cambridge University Press,   Cambridge, UK. (Ch. 3-6) Muth, C., Oravecz, Z., Gabry, J. (2018) User-friendly Bayesian regression modeling: tutorial rstanarm shinystan. Quantitative Methods Psychology. 14(2), 99–119. https://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian generalized linear models via Stan — stan_glm","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { ### Linear regression mtcars$mpg10 <- mtcars$mpg / 10 fit <- stan_glm(   mpg10 ~ wt + cyl + am,               data = mtcars,    QR = TRUE,   # for speed of example only (default is \"sampling\")   algorithm = \"fullrank\",   refresh = 0   )                   plot(fit, prob = 0.5) plot(fit, prob = 0.5, pars = \"beta\") plot(fit, \"hist\", pars = \"sigma\") # \\donttest{ ### Logistic regression head(wells) wells$dist100 <- wells$dist / 100 fit2 <- stan_glm(   switch ~ dist100 + arsenic,    data = wells,    family = binomial(link = \"logit\"),    prior_intercept = normal(0, 10),   QR = TRUE,   refresh = 0,   # for speed of example only   chains = 2, iter = 200  ) print(fit2) prior_summary(fit2)  # ?bayesplot::mcmc_areas plot(fit2, plotfun = \"areas\", prob = 0.9,      pars = c(\"(Intercept)\", \"arsenic\"))  # ?bayesplot::ppc_error_binned pp_check(fit2, plotfun = \"error_binned\")    ### Poisson regression (example from help(\"glm\"))  count_data <- data.frame(  counts = c(18,17,15,20,10,20,25,13,12),  outcome = gl(3,1,9),  treatment = gl(3,3) ) fit3 <- stan_glm(   counts ~ outcome + treatment,    data = count_data,    family = poisson(link=\"log\"),   prior = normal(0, 2),   refresh = 0,   # for speed of example only   chains = 2, iter = 250  )  print(fit3)  bayesplot::color_scheme_set(\"viridis\") plot(fit3) plot(fit3, regex_pars = c(\"outcome\", \"treatment\")) plot(fit3, plotfun = \"combo\", regex_pars = \"treatment\") # ?bayesplot::mcmc_combo posterior_vs_prior(fit3, regex_pars = c(\"outcome\", \"treatment\"))  ### Gamma regression (example from help(\"glm\")) clotting <- data.frame(log_u = log(c(5,10,15,20,30,40,60,80,100)),                        lot1 = c(118,58,42,35,27,25,21,19,18),                        lot2 = c(69,35,26,21,18,16,13,12,12)) fit4 <- stan_glm(   lot1 ~ log_u,    data = clotting,    family = Gamma(link=\"log\"),   iter = 500, # for speed of example only   refresh = 0  )  print(fit4, digits = 2)  fit5 <- update(fit4, formula = lot2 ~ log_u)  # ?bayesplot::ppc_dens_overlay bayesplot::bayesplot_grid(   pp_check(fit4, seed = 123),    pp_check(fit5, seed = 123),   titles = c(\"lot1\", \"lot2\") )    ### Negative binomial regression fit6 <- stan_glm.nb(   Days ~ Sex/(Age + Eth*Lrn),    data = MASS::quine,    link = \"log\",    prior_aux = exponential(1.5, autoscale=TRUE),   chains = 2, iter = 200, # for speed of example only   refresh = 0 )   prior_summary(fit6) bayesplot::color_scheme_set(\"brightblue\") plot(fit6) pp_check(fit6, plotfun = \"hist\", nreps = 5) # ?bayesplot::ppc_hist  # 80% interval of estimated reciprocal_dispersion parameter posterior_interval(fit6, pars = \"reciprocal_dispersion\", prob = 0.8) plot(fit6, \"areas\", pars = \"reciprocal_dispersion\", prob = 0.8) # } } #> Warning: The largest R-hat is 1.06, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> stan_glm #>  family:       binomial [logit] #>  formula:      switch ~ dist100 + arsenic #>  observations: 3020 #>  predictors:   3 #> ------ #>             Median MAD_SD #> (Intercept)  0.0    0.1   #> dist100     -0.9    0.1   #> arsenic      0.5    0.0   #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg #> 'x' not specified in '...'. Using x=1:length(y). #> Warning: The largest R-hat is 1.07, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> stan_glm #>  family:       poisson [log] #>  formula:      counts ~ outcome + treatment #>  observations: 9 #>  predictors:   5 #> ------ #>             Median MAD_SD #> (Intercept)  3.0    0.2   #> outcome2    -0.4    0.2   #> outcome3    -0.3    0.2   #> treatment2   0.0    0.2   #> treatment3   0.0    0.2   #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg #>  #> Drawing from prior... #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> stan_glm #>  family:       Gamma [log] #>  formula:      lot1 ~ log_u #>  observations: 9 #>  predictors:   2 #> ------ #>             Median MAD_SD #> (Intercept)  5.53   0.63  #> log_u       -0.61   0.18  #>  #> Auxiliary parameter(s): #>       Median MAD_SD #> shape 3.93   1.82   #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess"},{"path":"https://mc-stan.org/rstanarm/reference/stan_glmer.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian generalized linear models with group-specific terms via Stan — stan_glmer","title":"Bayesian generalized linear models with group-specific terms via Stan — stan_glmer","text":"Bayesian inference GLMs group-specific coefficients unknown covariance matrices flexible priors.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_glmer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian generalized linear models with group-specific terms via Stan — stan_glmer","text":"","code":"stan_glmer(   formula,   data = NULL,   family = gaussian,   subset,   weights,   na.action = getOption(\"na.action\", \"na.omit\"),   offset,   contrasts = NULL,   ...,   prior = default_prior_coef(family),   prior_intercept = default_prior_intercept(family),   prior_aux = exponential(autoscale = TRUE),   prior_covariance = decov(),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   QR = FALSE,   sparse = FALSE )  stan_lmer(   formula,   data = NULL,   subset,   weights,   na.action = getOption(\"na.action\", \"na.omit\"),   offset,   contrasts = NULL,   ...,   prior = default_prior_coef(family),   prior_intercept = default_prior_intercept(family),   prior_aux = exponential(autoscale = TRUE),   prior_covariance = decov(),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   QR = FALSE )  stan_glmer.nb(   formula,   data = NULL,   subset,   weights,   na.action = getOption(\"na.action\", \"na.omit\"),   offset,   contrasts = NULL,   link = \"log\",   ...,   prior = default_prior_coef(family),   prior_intercept = default_prior_intercept(family),   prior_aux = exponential(autoscale = TRUE),   prior_covariance = decov(),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   QR = FALSE )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_glmer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian generalized linear models with group-specific terms via Stan — stan_glmer","text":"formula, data glmer. strongly advise omitting data argument. Unless data specified (data frame) many post-estimation functions (including update, loo, kfold) guaranteed work properly. family glmer except also possible use family=mgcv::betar estimate Beta regression stan_glmer. subset, weights, offset glm. na.action, contrasts glm, rarely specified. ... stan_glmer, arguments passed sampling (e.g. iter, chains, cores, etc.) vb (algorithm \"meanfield\" \"fullrank\"). stan_lmer stan_glmer.nb, ... also contain relevant arguments pass stan_glmer (except family). prior prior distribution (non-hierarchical) regression coefficients. default priors described vignette Prior Distributions rstanarm Models. using default, prior call one various functions provided rstanarm specifying priors. subset functions can used prior coefficients can grouped several \"families\": See priors help page details families specify arguments functions table . omit prior —.e., use flat (improper) uniform prior— prior can set NULL, although rarely good idea. Note: Unless QR=TRUE, prior Student t family Laplace family, autoscale argument function used specify prior (e.g. normal) left default recommended value TRUE, default user-specified prior scale(s) may adjusted internally based scales predictors. See priors help page Prior Distributions vignette details rescaling prior_summary function summary priors used particular model. prior_intercept prior distribution intercept (  centering predictors, see note ). default prior described vignette   Prior   Distributions rstanarm Models.   using default, prior_intercept can call   normal, student_t cauchy. See   priors help page details functions. omit   prior intercept —.e., use flat (improper) uniform prior—   prior_intercept can set NULL. Note: using dense representation design matrix   —.e., sparse argument left default value   FALSE— prior distribution intercept set   applies value predictors centered (  need manually center ). explained   [Prior Distributions rstanarm Models](https://mc-stan.org/rstanarm/articles/priors.html)   prefer specify prior intercept without predictors   auto-centered, omit intercept   formula include column ones predictor,   case element prior specifies prior ,   rather prior_intercept. Regardless   prior_intercept specified, reported estimates   intercept always correspond parameterization without centered   predictors (.e., glm). prior_aux prior distribution \"auxiliary\" parameter (applicable). \"auxiliary\" parameter refers different parameter depending family. Gaussian models prior_aux controls \"sigma\", error standard deviation. negative binomial models prior_aux controls \"reciprocal_dispersion\", similar \"size\" parameter rnbinom: smaller values \"reciprocal_dispersion\" correspond greater dispersion. gamma models prior_aux sets prior \"shape\" parameter (see e.g., rgamma), inverse-Gaussian models -called \"lambda\" parameter (essentially reciprocal scale parameter). Binomial Poisson models auxiliary parameters. default prior described vignette Prior Distributions rstanarm Models. using default, prior_aux can call exponential use exponential distribution, normal, student_t cauchy, results half-normal, half-t, half-Cauchy prior. See priors details functions. omit prior —.e., use flat (improper) uniform prior— set prior_aux NULL. prior_covariance NULL; see decov information default arguments. prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. QR logical scalar defaulting FALSE, TRUE applies scaled qr decomposition design matrix. transformation change likelihood data recommended computational reasons multiple predictors. See QR-argument documentation page details rstanarm transformation important information interpret prior distributions model parameters using QR=TRUE. sparse logical scalar (defaulting FALSE) indicating whether use sparse representation design (X) matrix. TRUE, design matrix centered (since destroy sparsity) likewise possible specify QR = TRUE sparse = TRUE. Depending many zeros design matrix, setting sparse = TRUE may make code run faster can consume much less RAM. link stan_glmer.nb , link function use. See neg_binomial_2.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_glmer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian generalized linear models with group-specific terms via Stan — stan_glmer","text":"stanreg object returned stan_glmer, stan_lmer, stan_glmer.nb. list classes stanreg, glm, lm,   lmerMod. conventions parameter names   lme4 package addition standard   deviation errors called sigma variance-covariance   matrix group-specific deviations common parameters   called Sigma, even variance-covariance matrix   one row one column (case just group-level variance).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_glmer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian generalized linear models with group-specific terms via Stan — stan_glmer","text":"stan_glmer function similar syntax   glmer rather performing (restricted) maximum   likelihood estimation generalized linear models, Bayesian estimation   performed via MCMC. Bayesian model adds priors   regression coefficients (way stan_glm)   priors terms decomposition covariance matrices   group-specific parameters. See priors information   priors. stan_lmer function equivalent stan_glmer   family = gaussian(link = \"identity\"). stan_glmer.nb function, takes extra argument   link, wrapper stan_glmer family =   neg_binomial_2(link).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_glmer.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian generalized linear models with group-specific terms via Stan — stan_glmer","text":"Gelman, . Hill, J. (2007). Data Analysis Using   Regression Multilevel/Hierarchical Models. Cambridge University Press,   Cambridge, UK. (Ch. 11-15) Muth, C., Oravecz, Z., Gabry, J. (2018) User-friendly Bayesian regression modeling: tutorial rstanarm shinystan. Quantitative Methods Psychology. 14(2), 99–119. https://www.tqmp.org/RegularArticles/vol14-2/p099/p099.pdf","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_glmer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian generalized linear models with group-specific terms via Stan — stan_glmer","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # see help(example_model) for details on the model below if (!exists(\"example_model\")) example(example_model)  print(example_model, digits = 1) } #> stan_glmer #>  family:       binomial [logit] #>  formula:      cbind(incidence, size - incidence) ~ size + period + (1 | herd) #>  observations: 56 #> ------ #>             Median MAD_SD #> (Intercept) -1.5    0.6   #> size         0.0    0.0   #> period2     -1.0    0.3   #> period3     -1.1    0.4   #> period4     -1.6    0.5   #>  #> Error terms: #>  Groups Name        Std.Dev. #>  herd   (Intercept) 0.76     #> Num. levels: herd 15  #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg"},{"path":"https://mc-stan.org/rstanarm/reference/stan_jm.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian joint longitudinal and time-to-event models via Stan — stan_jm","title":"Bayesian joint longitudinal and time-to-event models via Stan — stan_jm","text":"Fits shared parameter joint model longitudinal time--event (e.g. survival) data Bayesian framework using Stan.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_jm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian joint longitudinal and time-to-event models via Stan — stan_jm","text":"","code":"stan_jm(   formulaLong,   dataLong,   formulaEvent,   dataEvent,   time_var,   id_var,   family = gaussian,   assoc = \"etavalue\",   lag_assoc = 0,   grp_assoc,   scale_assoc = NULL,   epsilon = 1e-05,   basehaz = c(\"bs\", \"weibull\", \"piecewise\"),   basehaz_ops,   qnodes = 15,   init = \"prefit\",   weights,   priorLong = normal(autoscale = TRUE),   priorLong_intercept = normal(autoscale = TRUE),   priorLong_aux = cauchy(0, 5, autoscale = TRUE),   priorEvent = normal(autoscale = TRUE),   priorEvent_intercept = normal(autoscale = TRUE),   priorEvent_aux = cauchy(autoscale = TRUE),   priorEvent_assoc = normal(autoscale = TRUE),   prior_covariance = lkj(autoscale = TRUE),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   max_treedepth = 10L,   QR = FALSE,   sparse = FALSE,   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_jm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian joint longitudinal and time-to-event models via Stan — stan_jm","text":"formulaLong two-sided linear formula object describing fixed-effects random-effects parts longitudinal submodel, similar vein formula specification lme4 package (see glmer lme4 vignette details). Note however double bar (||) notation allowed specifying random-effects parts formula, neither nested grouping factors (e.g. (1 | g1/g2)) (1 | g1:g2), g1, g2 grouping factors. Offset terms can also included model formula. multivariate joint model (.e. one longitudinal marker) list formula objects, element list providing formula one longitudinal submodels. dataLong data frame containing variables specified formulaLong. fitting multivariate joint model, can either single data frame contains data longitudinal submodels, can list data frames element list provides data one longitudinal submodels. formulaEvent two-sided formula object describing event submodel. left hand side formula Surv() object. See Surv. dataEvent data frame containing variables specified formulaEvent. time_var character string specifying name variable dataLong represents time. id_var character string specifying name variable dataLong distinguishes individuals. can left unspecified one grouping factor (assumed individual). one grouping factor (.e. clustering beyond level individual) id_var argument must specified. family family (possibly also link function) longitudinal submodel(s). See glmer details. fitting multivariate joint model, can optionally list families, case element list specifies family one longitudinal submodels. assoc character string character vector specifying joint model association structure. Possible association structures can used include: \"etavalue\" (default); \"etaslope\"; \"etaauc\"; \"muvalue\"; \"muslope\"; \"muauc\"; \"shared_b\"; \"shared_coef\"; \"null\". described Details section . multivariate joint model, different association structures can optionally used longitudinal submodel specifying list character vectors, element list specifying desired association structure one longitudinal submodels. Specifying assoc = NULL fit joint model association structure (equivalent fitting separate longitudinal time--event models). also possible include interaction terms association term (\"etavalue\", \"etaslope\", \"muvalue\", \"muslope\") observed data/covariates. also possible, fitting multivariate joint model, include interaction terms association terms (\"etavalue\" \"muvalue\") corresponding different longitudinal outcomes. See Details section well Examples . lag_assoc non-negative scalar specifying time lag used association structure. , hazard event time t assumed associated value/slope/auc longitudinal marker time t-u, u time lag. fitting multivariate joint model, different time lag can used longitudinal marker providing numeric vector lags, otherwise scalar provided specified time lag used longitudinal markers. Note however one time lag  can specified linking longitudinal marker event, time lag used association structure types (e.g. \"etavalue\", \"etaslope\", \"etaauc\", \"muvalue\", etc) specified longitudinal marker assoc argument. grp_assoc Character string specifying method combining information across lower level units clustered within individual forming association structure. relevant grouping factor specified formulaLong corresponds clustering within individuals. can specified either \"sum\", mean, \"min\" \"max\". example, specifying grp_assoc = \"sum\" indicates association structure based summation across lower level units clustered within individual, specifying grp_assoc = \"mean\"  indicates association structure based mean (.e. average) taken across lower level units clustered within individual. , example, specifying assoc = \"muvalue\" grp_assoc = \"sum\" mean log hazard time t individual linearly related sum expected values time t lower level units (may example tumor lesions) clustered within individual. scale_assoc non-zero numeric value specifying optional scaling parameter association structure. multiplicatively scales value/slope/auc longitudinal marker scale_assoc within event submodel. fitting multivariate joint model, scaling parameter must specified longitudinal submodel using vector numeric values. Note one scaling parameter can specified longitudinal submodel, used association structure types (e.g. \"etavalue\", \"etaslope\", \"etaauc\", \"muvalue\", etc) specified longitudinal marker assoc argument. epsilon half-width central difference used numerically calculate derivate \"etaslope\" association structure used. basehaz character string indicating baseline hazard use event submodel. Options B-splines approximation estimated log baseline hazard (\"bs\", default), Weibull baseline hazard (\"weibull\"), piecewise constant baseline hazard (\"piecewise\"). (Note however currently limited post-estimation functionality available models estimated using piecewise constant baseline hazard). basehaz_ops named list specifying options related baseline hazard. Currently can include: df positive integer specifying degrees freedom   B-splines basehaz = \"bs\", number   intervals used piecewise constant baseline hazard   basehaz = \"piecewise\". default 6. knots optional numeric vector specifying internal knot   locations B-splines basehaz = \"bs\",   internal cut-points defining intervals piecewise constant   baseline hazard basehaz = \"piecewise\". Knots   specified df specified. specified,   default use df - 4 knots basehaz = \"bs\",   df - 1 knots basehaz = \"piecewise\",   placed equally spaced percentiles distribution   observed event times. qnodes number nodes use Gauss-Kronrod quadrature used evaluate cumulative hazard likelihood function. Options 15 (default), 11 7. init method generating initial values MCMC. default \"prefit\", uses obtained fitting separate longitudinal time--event models prior fitting joint model. separate longitudinal model (possibly multivariate) generalised linear mixed model estimated using variational bayes. achieved via stan_mvmer function algorithm = \"meanfield\". separate Cox model estimated using coxph. achieved using time--event models prior fitting joint model. separate models estimated using glmer coxph functions. provide reasonable initial values aid MCMC sampler. Parameters obtained fitting separate longitudinal time--event models initialised using \"random\" method stan. However recommended final analysis ideally performed several MCMC chains initiated different set initial values; can obtained setting init = \"random\". addition, possibilities specifying init described stan. weights Experimental used caution. user can optionally supply 2-column data frame containing set 'prior weights' used estimation process. data frame contain two columns: first containing IDs individual, second containing corresponding weights. data frame one row individual; , weights constant within individuals. priorLong, priorEvent, priorEvent_assoc prior distributions regression coefficients longitudinal submodel(s), event submodel, association parameter(s). Can call one various functions provided rstanarm specifying priors. subset functions can used prior coefficients can grouped several \"families\": See priors help page details families specify arguments functions table . omit prior —.e., use flat (improper) uniform prior— prior can set NULL, although rarely good idea. Note: Unless QR=TRUE, prior Student t family Laplace family, autoscale argument function used specify prior (e.g. normal) left default recommended value TRUE, default user-specified prior scale(s) may adjusted internally based scales predictors. See priors help page details rescaling prior_summary function summary priors used particular model. priorLong_intercept, priorEvent_intercept prior distributions intercepts longitudinal submodel(s) event submodel. Can call normal, student_t cauchy. See priors help page details functions. omit prior intercept —.e., use flat (improper) uniform prior— prior_intercept can set NULL. Note: prior distribution intercept set applies value predictors centered. Moreover, note prior placed intercept event submodel Weibull baseline hazard specified. B-splines piecewise constant baseline hazards intercept parameter given prior distribution; intercept parameter shown output fitted model, just corresponds necessary post-estimation adjustment linear predictor due centering predictiors event submodel. priorLong_aux prior distribution \"auxiliary\" parameters longitudinal submodels (applicable). \"auxiliary\" parameter refers different parameter depending family. Gaussian models priorLong_aux controls \"sigma\", error standard deviation. negative binomial models priorLong_aux controls \"reciprocal_dispersion\", similar \"size\" parameter rnbinom: smaller values \"reciprocal_dispersion\" correspond greater dispersion. gamma models priorLong_aux sets prior \"shape\" parameter (see e.g., rgamma), inverse-Gaussian models -called \"lambda\" parameter (essentially reciprocal scale parameter). Binomial Poisson models auxiliary parameters. priorLong_aux can call exponential use exponential distribution, normal, student_t cauchy, results half-normal, half-t, half-Cauchy prior. See priors details functions. omit prior —.e., use flat (improper) uniform prior— set priorLong_aux NULL. fitting multivariate joint model, option specify list prior distributions, however elements list correspond longitudinal submodel auxiliary parameter ignored. priorEvent_aux prior distribution \"auxiliary\" parameters event submodel. \"auxiliary\" parameters refers different parameters depending baseline hazard. basehaz = \"weibull\" auxiliary parameter Weibull shape parameter. basehaz = \"bs\" auxiliary parameters coefficients B-spline approximation log baseline hazard. basehaz = \"piecewise\" auxiliary parameters piecewise estimates log baseline hazard. prior_covariance NULL; see priors information prior distributions covariance matrices. Note however default prior covariance matrices stan_jm slightly different stan_glmer (details described priors page). prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. max_treedepth positive integer specifying maximum treedepth non-U-turn sampler. See control argument stan. QR logical scalar defaulting FALSE, TRUE applies scaled qr decomposition design matrix. transformation change likelihood data recommended computational reasons multiple predictors. See QR-argument documentation page details rstanarm transformation important information interpret prior distributions model parameters using QR=TRUE. sparse logical scalar (defaulting FALSE) indicating whether use sparse representation design (X) matrix. TRUE, design matrix centered (since destroy sparsity) likewise possible specify QR = TRUE sparse = TRUE. Depending many zeros design matrix, setting sparse = TRUE may make code run faster can consume much less RAM. ... arguments passed function rstan package (sampling, vb, optimizing), corresponding estimation method named algorithm. example, algorithm \"sampling\" possible specify iter, chains, cores, MCMC controls. Another useful argument can passed rstan via ... refresh, specifies often print updates sampling (.e., show progress every refresh iterations). refresh=0 turns iteration updates.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_jm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian joint longitudinal and time-to-event models via Stan — stan_jm","text":"stanjm object returned.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_jm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian joint longitudinal and time-to-event models via Stan — stan_jm","text":"stan_jm function can used fit joint model (also   known shared parameter model) longitudinal time--event data   Bayesian framework. underlying   estimation carried using Bayesian C++ package Stan   (https://mc-stan.org/).    joint model may univariate (one longitudinal submodel)   multivariate (one longitudinal submodel).   longitudinal submodel (possibly multivariate) generalised linear   mixed model assumed family choices   allowed glmer. multivariate joint model specified   (providing list formulas formulaLong argument),   multivariate longitudinal submodel consists multivariate generalized   linear model (GLM) group-specific terms assumed correlated   across different GLM submodels. , within   grouping factor (example, patient ID) group-specific terms   assumed correlated across different GLM submodels.   possible specify different outcome type (example different   family /link function) GLM submodels, providing   list family objects family   argument. Multi-level   clustered data allowed, additional clustering can occur   level higher individual-level (e.g. patients clustered within   clinics), level lower individual-level (e.g. tumor lesions   clustered within patients). clustering occurs level lower   individual, user needs indicate lower level   clusters handled forming association structure   longitudinal event submodels (see grp_assoc argument   described ).    event submodel parametric   proportional hazards model assumed. baseline hazard can estimated   using either cubic B-splines approximation (basehaz = \"bs\",   default), Weibull distribution (basehaz = \"weibull\"),   piecewise constant baseline hazard (basehaz = \"piecewise\").   B-spline piecewise constant baseline hazards used,   degrees freedom internal knot locations can   (optionally) specified.   degrees freedom specified (df argument)   knot locations automatically generated based   distribution observed event times (including censoring times).   Otherwise internal knot locations can specified   directly knots argument. neither df   knots specified, default set df equal 6.   possible specify df knots.    Time-varying covariates allowed   longitudinal event submodels. specified data   way normally fitting separate   longitudinal model using lmer separate   time--event model using coxph. time-varying   covariates exogenous nature, otherwise perhaps   better specified additional outcome (.e. including   additional longitudinal outcome joint model).    Bayesian estimation joint model performed via MCMC. Bayesian   model includes independent priors   regression coefficients longitudinal event submodels,   including association parameter(s) (much way   regression parameters stan_glm)   priors terms decomposition covariance matrices   group-specific parameters.   See priors information priors distributions   available.    Gauss-Kronrod quadrature used numerically evaluate integral   cumulative hazard likelihood function event submodel.   accuracy numerical approximation can controlled using   number quadrature nodes, specified qnodes   argument. Using higher number quadrature nodes result   accurate approximation.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_jm.html","id":"association-structures","dir":"Reference","previous_headings":"","what":"Association structures","title":"Bayesian joint longitudinal and time-to-event models via Stan — stan_jm","text":"association structure joint model can based   following parameterisations: current value linear predictor         longitudinal submodel (\"etavalue\") first derivative (slope) linear predictor         longitudinal submodel (\"etaslope\") area curve linear predictor         longitudinal submodel (\"etaauc\") current expected value longitudinal submodel         (\"muvalue\") area curve expected value         longitudinal submodel (\"muauc\") shared individual-level random effects (\"shared_b\") shared individual-level random effects also incorporate         corresponding fixed effect well corresponding         random effects clustering levels higher individual)         (\"shared_coef\") interactions association terms observed data/covariates         (\"etavalue_data\", \"etaslope_data\", \"muvalue_data\",         \"muslope_data\"). described . interactions association terms corresponding different         longitudinal outcomes multivariate joint model         (\"etavalue_etavalue(#)\", \"etavalue_muvalue(#)\",         \"muvalue_etavalue(#)\", \"muvalue_muvalue(#)\").         described . association structure (equivalent fitting separate         longitudinal event models) (\"null\" NULL) one association structure can specified, however,   possible combinations allowed.   Note lagged association structures baseline values (time = 0)   used instances   time lag results time prior baseline. using   \"etaauc\" \"muauc\" association structures, area   curve evaluated using Gauss-Kronrod quadrature 15 quadrature   nodes. default, \"shared_b\" \"shared_coef\" contribute   random effects association structure; however, subset   random effects can chosen specifying indices parentheses   suffix, example, \"shared_b(1)\" \"shared_b(1:3)\"   \"shared_b(1,2,4)\", .    addition, several association terms (\"etavalue\", \"etaslope\",   \"muvalue\", \"muslope\") can interacted observed   data/covariates. , use association term's main handle plus   suffix \"_data\" followed model matrix formula   parentheses. example variable dataset gender   named sex might want obtain different estimates   association current slope marker risk   event gender. specify   assoc = c(\"etaslope\", \"etaslope_data(~ sex)\").    also possible, fitting  multivariate joint model, include   interaction terms association terms (  applies interacting \"etavalue\" \"muvalue\"). example,   joint model two longitudinal markers, specify   assoc = list(c(\"etavalue\", \"etavalue_etavalue(2)\"), \"etavalue\").   first element list says want use value linear   predictor first marker, well interaction   value linear predictor second marker. second element   list says want also include expected value second marker   (.e. \"main effect\"). Therefore, linear predictor event   submodel include \"main effects\" marker well   interaction.    additional examples Examples section .","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_jm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian joint longitudinal and time-to-event models via Stan — stan_jm","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch !=\"i386\") { # \\donttest{  ##### # Univariate joint model, with association structure based on the  # current value of the linear predictor f1 <- stan_jm(formulaLong = logBili ~ year + (1 | id),                dataLong = pbcLong,               formulaEvent = Surv(futimeYears, death) ~ sex + trt,                dataEvent = pbcSurv,               time_var = \"year\",               # this next line is only to keep the example small in size!               chains = 1, cores = 1, seed = 12345, iter = 1000) print(f1)  summary(f1)           ##### # Univariate joint model, with association structure based on the  # current value and slope of the linear predictor f2 <- stan_jm(formulaLong = logBili ~ year + (year | id),                dataLong = pbcLong,               formulaEvent = Surv(futimeYears, death) ~ sex + trt,                dataEvent = pbcSurv,               assoc = c(\"etavalue\", \"etaslope\"),               time_var = \"year\",               chains = 1, cores = 1, seed = 12345, iter = 1000) print(f2)    ##### # Univariate joint model, with association structure based on the  # lagged value of the linear predictor, where the lag is 2 time  # units (i.e. 2 years in this example) f3 <- stan_jm(formulaLong = logBili ~ year + (1 | id),                dataLong = pbcLong,               formulaEvent = Surv(futimeYears, death) ~ sex + trt,                dataEvent = pbcSurv,               time_var = \"year\",               assoc = \"etavalue\", lag_assoc = 2,               chains = 1, cores = 1, seed = 12345, iter = 1000) print(f3)   ##### # Univariate joint model, where the association structure includes  # interactions with observed data. Here we specify that we want to use  # an association structure based on the current value of the linear  # predictor from the longitudinal submodel (i.e. \"etavalue\"), but we  # also want to interact this with the treatment covariate (trt) from # pbcLong data frame, so that we can estimate a different association  # parameter (i.e. estimated effect of log serum bilirubin on the log  # hazard of death) for each treatment group f4 <- stan_jm(formulaLong = logBili ~ year + (1 | id),                dataLong = pbcLong,               formulaEvent = Surv(futimeYears, death) ~ sex + trt,                dataEvent = pbcSurv,               time_var = \"year\",               assoc = c(\"etavalue\", \"etavalue_data(~ trt)\"),               chains = 1, cores = 1, seed = 12345, iter = 1000) print(f4)  ###### # Multivariate joint model, with association structure based  # on the current value and slope of the linear predictor in the  # first longitudinal submodel and the area under the marker  # trajectory for the second longitudinal submodel mv1 <- stan_jm(         formulaLong = list(           logBili ~ year + (1 | id),            albumin ~ sex + year + (year | id)),         dataLong = pbcLong,         formulaEvent = Surv(futimeYears, death) ~ sex + trt,          dataEvent = pbcSurv,         assoc = list(c(\"etavalue\", \"etaslope\"), \"etaauc\"),          time_var = \"year\",         chains = 1, cores = 1, seed = 12345, iter = 100) print(mv1)  ##### # Multivariate joint model, where the association structure is formed by  # including the expected value of each longitudinal marker (logBili and  # albumin) in the linear predictor of the event submodel, as well as their  # interaction effect (i.e. the interaction between the two \"etavalue\" terms).  # Note that whether such an association structure based on a marker by  # marker interaction term makes sense will depend on the context of your  # application -- here we just show it for demostration purposes). mv2 <- stan_jm(         formulaLong = list(           logBili ~ year + (1 | id),            albumin ~ sex + year + (year | id)),         dataLong = pbcLong,         formulaEvent = Surv(futimeYears, death) ~ sex + trt,          dataEvent = pbcSurv,         assoc = list(c(\"etavalue\", \"etavalue_etavalue(2)\"), \"etavalue\"),         time_var = \"year\",          chains = 1, cores = 1, seed = 12345, iter = 100)          ##### # Multivariate joint model, with one bernoulli marker and one # Gaussian marker. We will artificially create the bernoulli # marker by dichotomising log serum bilirubin pbcLong$ybern <- as.integer(pbcLong$logBili >= mean(pbcLong$logBili)) mv3 <- stan_jm(         formulaLong = list(           ybern ~ year + (1 | id),            albumin ~ sex + year + (year | id)),         dataLong = pbcLong,         formulaEvent = Surv(futimeYears, death) ~ sex + trt,          dataEvent = pbcSurv,         family = list(binomial, gaussian),         time_var = \"year\",          chains = 1, cores = 1, seed = 12345, iter = 1000) # } } #> Fitting a univariate joint model. #>  #> Please note the warmup may be much slower than later iterations! #>  #> SAMPLING FOR MODEL 'jm' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000163 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.63 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 3.219 seconds (Warm-up) #> Chain 1:                2.192 seconds (Sampling) #> Chain 1:                5.411 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> stan_jm #>  formula (Long1): logBili ~ year + (1 | id) #>  family  (Long1): gaussian [identity] #>  formula (Event): Surv(futimeYears, death) ~ sex + trt #>  baseline hazard: bs #>  assoc:           etavalue (Long1) #> ------ #>  #> Longitudinal submodel: logBili #>             Median MAD_SD #> (Intercept) 0.802  0.203  #> year        0.092  0.010  #> sigma       0.509  0.026  #>  #> Event submodel: #>                 Median MAD_SD exp(Median) #> (Intercept)     -3.068  0.569  0.046      #> sexf            -0.376  0.538  0.687      #> trt             -0.719  0.506  0.487      #> Long1|etavalue   1.449  0.281  4.257      #> b-splines-coef1 -1.418  1.106     NA      #> b-splines-coef2  0.222  0.859     NA      #> b-splines-coef3 -1.768  1.192     NA      #> b-splines-coef4  1.058  1.450     NA      #> b-splines-coef5 -0.460  1.602     NA      #> b-splines-coef6 -0.369  1.558     NA      #>  #> Group-level error terms: #>  Groups Name              Std.Dev. #>  id     Long1|(Intercept) 1.323    #> Num. levels: id 40  #>  #> Sample avg. posterior predictive distribution  #> of longitudinal outcomes: #>                Median MAD_SD #> Long1|mean_PPD 0.586  0.043  #>  #> ------ #> For info on the priors used see help('prior_summary.stanreg').Fitting a univariate joint model. #>  #> Please note the warmup may be much slower than later iterations! #>  #> SAMPLING FOR MODEL 'jm' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000281 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.81 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 21.061 seconds (Warm-up) #> Chain 1:                15 seconds (Sampling) #> Chain 1:                36.061 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> stan_jm #>  formula (Long1): logBili ~ year + (year | id) #>  family  (Long1): gaussian [identity] #>  formula (Event): Surv(futimeYears, death) ~ sex + trt #>  baseline hazard: bs #>  assoc:           etavalue (Long1), etaslope (Long1) #> ------ #>  #> Longitudinal submodel: logBili #>             Median MAD_SD #> (Intercept) 0.625  0.229  #> year        0.249  0.063  #> sigma       0.357  0.017  #>  #> Event submodel: #>                 Median    MAD_SD    exp(Median) #> (Intercept)        -3.416     0.757     0.033   #> sexf               -0.440     0.720     0.644   #> trt                -0.987     0.640     0.373   #> Long1|etavalue      0.821     0.427     2.273   #> Long1|etaslope      9.538     5.737 13874.955   #> b-splines-coef1    -5.377     4.425        NA   #> b-splines-coef2    -2.087     2.338        NA   #> b-splines-coef3    -2.848     1.555        NA   #> b-splines-coef4    -0.511     1.833        NA   #> b-splines-coef5     0.326     1.747        NA   #> b-splines-coef6    -0.537     1.694        NA   #>  #> Group-level error terms: #>  Groups Name              Std.Dev. Corr #>  id     Long1|(Intercept) 1.284         #>         Long1|year        0.241    0.67 #> Num. levels: id 40  #>  #> Sample avg. posterior predictive distribution  #> of longitudinal outcomes: #>                Median MAD_SD #> Long1|mean_PPD 0.585  0.027  #>  #> ------ #> For info on the priors used see help('prior_summary.stanreg').Fitting a univariate joint model. #>  #> Please note the warmup may be much slower than later iterations! #>  #> SAMPLING FOR MODEL 'jm' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000145 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.45 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 2.707 seconds (Warm-up) #> Chain 1:                2.172 seconds (Sampling) #> Chain 1:                4.879 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> stan_jm #>  formula (Long1): logBili ~ year + (1 | id) #>  family  (Long1): gaussian [identity] #>  formula (Event): Surv(futimeYears, death) ~ sex + trt #>  baseline hazard: bs #>  assoc:           etavalue (Long1) #> ------ #>  #> Longitudinal submodel: logBili #>             Median MAD_SD #> (Intercept) 0.838  0.188  #> year        0.092  0.010  #> sigma       0.509  0.023  #>  #> Event submodel: #>                 Median MAD_SD exp(Median) #> (Intercept)     -2.910  0.631  0.054      #> sexf            -0.380  0.591  0.684      #> trt             -0.703  0.489  0.495      #> Long1|etavalue   1.454  0.254  4.281      #> b-splines-coef1 -1.600  1.023     NA      #> b-splines-coef2  0.250  0.898     NA      #> b-splines-coef3 -1.518  1.312     NA      #> b-splines-coef4  0.913  1.666     NA      #> b-splines-coef5 -0.029  1.747     NA      #> b-splines-coef6 -0.174  1.602     NA      #>  #> Group-level error terms: #>  Groups Name              Std.Dev. #>  id     Long1|(Intercept) 1.325    #> Num. levels: id 40  #>  #> Sample avg. posterior predictive distribution  #> of longitudinal outcomes: #>                Median MAD_SD #> Long1|mean_PPD 0.585  0.042  #>  #> ------ #> For info on the priors used see help('prior_summary.stanreg').Fitting a univariate joint model. #>  #> Please note the warmup may be much slower than later iterations! #>  #> SAMPLING FOR MODEL 'jm' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000176 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.76 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 3.981 seconds (Warm-up) #> Chain 1:                2.835 seconds (Sampling) #> Chain 1:                6.816 seconds (Total) #> Chain 1:  #> Warning: The largest R-hat is 1.06, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> stan_jm #>  formula (Long1): logBili ~ year + (1 | id) #>  family  (Long1): gaussian [identity] #>  formula (Event): Surv(futimeYears, death) ~ sex + trt #>  baseline hazard: bs #>  assoc:           etavalue (Long1), etavalue_data (Long1) #> ------ #>  #> Longitudinal submodel: logBili #>             Median MAD_SD #> (Intercept) 0.830  0.206  #> year        0.092  0.008  #> sigma       0.508  0.022  #>  #> Event submodel: #>                    Median MAD_SD exp(Median) #> (Intercept)        -3.140  0.690  0.043      #> sexf               -0.366  0.629  0.694      #> trt                -0.184  0.929  0.832      #> Long1|etavalue      1.598  0.323  4.945      #> Long1|etavalue:trt -0.374  0.574  0.688      #> b-splines-coef1    -1.477  1.254     NA      #> b-splines-coef2     0.038  0.856     NA      #> b-splines-coef3    -1.639  1.234     NA      #> b-splines-coef4     0.736  1.674     NA      #> b-splines-coef5    -0.292  1.705     NA      #> b-splines-coef6    -0.227  1.665     NA      #>  #> Group-level error terms: #>  Groups Name              Std.Dev. #>  id     Long1|(Intercept) 1.345    #> Num. levels: id 40  #>  #> Sample avg. posterior predictive distribution  #> of longitudinal outcomes: #>                Median MAD_SD #> Long1|mean_PPD 0.588  0.039  #>  #> ------ #> For info on the priors used see help('prior_summary.stanreg').Fitting a multivariate joint model. #>  #> Please note the warmup may be much slower than later iterations! #>  #> SAMPLING FOR MODEL 'jm' NOW (CHAIN 1). #> Chain 1: Rejecting initial value: #> Chain 1:   Log probability evaluates to log(0), i.e. negative infinity. #> Chain 1:   Stan can't start sampling from this initial value. #> Chain 1:  #> Chain 1: Gradient evaluation took 0.001643 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 16.43 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: WARNING: There aren't enough warmup iterations to fit the #> Chain 1:          three stages of adaptation as currently configured. #> Chain 1:          Reducing each adaptation stage to 15%/75%/10% of #> Chain 1:          the given number of warmup iterations: #> Chain 1:            init_buffer = 7 #> Chain 1:            adapt_window = 38 #> Chain 1:            term_buffer = 5 #> Chain 1:  #> Chain 1: Iteration:  1 / 100 [  1%]  (Warmup) #> Chain 1: Iteration: 10 / 100 [ 10%]  (Warmup) #> Chain 1: Iteration: 20 / 100 [ 20%]  (Warmup) #> Chain 1: Iteration: 30 / 100 [ 30%]  (Warmup) #> Chain 1: Iteration: 40 / 100 [ 40%]  (Warmup) #> Chain 1: Iteration: 50 / 100 [ 50%]  (Warmup) #> Chain 1: Iteration: 51 / 100 [ 51%]  (Sampling) #> Chain 1: Iteration: 60 / 100 [ 60%]  (Sampling) #> Chain 1: Iteration: 70 / 100 [ 70%]  (Sampling) #> Chain 1: Iteration: 80 / 100 [ 80%]  (Sampling) #> Chain 1: Iteration: 90 / 100 [ 90%]  (Sampling) #> Chain 1: Iteration: 100 / 100 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 23.534 seconds (Warm-up) #> Chain 1:                0.636 seconds (Sampling) #> Chain 1:                24.17 seconds (Total) #> Chain 1:  #> Warning: There were 50 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: The largest R-hat is 2.15, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> Warning: Markov chains did not converge! Do not analyze results! #> stan_jm #>  formula (Long1): logBili ~ year + (1 | id) #>  family  (Long1): gaussian [identity] #>  formula (Long2): albumin ~ sex + year + (year | id) #>  family  (Long2): gaussian [identity] #>  formula (Event): Surv(futimeYears, death) ~ sex + trt #>  baseline hazard: bs #>  assoc:           etavalue (Long1), etaslope (Long1), etaauc (Long2) #> ------ #>  #> Longitudinal submodel 1: logBili #>             Median MAD_SD #> (Intercept) 0.697  0.000  #> year        0.086  0.000  #> sigma       0.526  0.000  #>  #> Longitudinal submodel 2: albumin #>             Median MAD_SD #> (Intercept)  3.509  0.000 #> sexf         0.081  0.000 #> year        -0.123  0.000 #> sigma        0.334  0.000 #>  #> Event submodel: #>                 Median        MAD_SD        exp(Median)   #> (Intercept)      1.082885e+11  1.330000e-01           Inf #> sexf            -3.470000e-01  0.000000e+00  7.070000e-01 #> trt             -9.600000e-02  0.000000e+00  9.080000e-01 #> Long1|etavalue   3.422000e+00  0.000000e+00  3.064300e+01 #> Long1|etaslope  -1.264015e+12  1.549000e+00  0.000000e+00 #> Long2|etaauc     3.360000e-01  0.000000e+00  1.399000e+00 #> b-splines-coef1  0.000000e+00  0.000000e+00            NA #> b-splines-coef2  0.000000e+00  0.000000e+00            NA #> b-splines-coef3  0.000000e+00  0.000000e+00            NA #> b-splines-coef4  0.000000e+00  0.000000e+00            NA #> b-splines-coef5  0.000000e+00  0.000000e+00            NA #> b-splines-coef6  0.000000e+00  0.000000e+00            NA #>  #> Group-level error terms: #>  Groups Name              Std.Dev. Corr      #>  id     Long1|(Intercept) 1.11688            #>         Long2|(Intercept) 0.36463  0.00      #>         Long2|year        0.03419  0.00 0.00 #> Num. levels: id 40  #>  #> Sample avg. posterior predictive distribution  #> of longitudinal outcomes: #>                Median MAD_SD #> Long1|mean_PPD 0.885  0.036  #> Long2|mean_PPD 3.145  0.021  #>  #> ------ #> For info on the priors used see help('prior_summary.stanreg').Fitting a multivariate joint model. #>  #> Please note the warmup may be much slower than later iterations! #>  #> SAMPLING FOR MODEL 'jm' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000354 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 3.54 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: WARNING: There aren't enough warmup iterations to fit the #> Chain 1:          three stages of adaptation as currently configured. #> Chain 1:          Reducing each adaptation stage to 15%/75%/10% of #> Chain 1:          the given number of warmup iterations: #> Chain 1:            init_buffer = 7 #> Chain 1:            adapt_window = 38 #> Chain 1:            term_buffer = 5 #> Chain 1:  #> Chain 1: Iteration:  1 / 100 [  1%]  (Warmup) #> Chain 1: Iteration: 10 / 100 [ 10%]  (Warmup) #> Chain 1: Iteration: 20 / 100 [ 20%]  (Warmup) #> Chain 1: Iteration: 30 / 100 [ 30%]  (Warmup) #> Chain 1: Iteration: 40 / 100 [ 40%]  (Warmup) #> Chain 1: Iteration: 50 / 100 [ 50%]  (Warmup) #> Chain 1: Iteration: 51 / 100 [ 51%]  (Sampling) #> Chain 1: Iteration: 60 / 100 [ 60%]  (Sampling) #> Chain 1: Iteration: 70 / 100 [ 70%]  (Sampling) #> Chain 1: Iteration: 80 / 100 [ 80%]  (Sampling) #> Chain 1: Iteration: 90 / 100 [ 90%]  (Sampling) #> Chain 1: Iteration: 100 / 100 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 3.45 seconds (Warm-up) #> Chain 1:                8.113 seconds (Sampling) #> Chain 1:                11.563 seconds (Total) #> Chain 1:  #> Warning: The largest R-hat is 1.14, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> Fitting a multivariate joint model. #>  #> Please note the warmup may be much slower than later iterations! #>  #> SAMPLING FOR MODEL 'jm' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.00028 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.8 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 16.231 seconds (Warm-up) #> Chain 1:                7.422 seconds (Sampling) #> Chain 1:                23.653 seconds (Total) #> Chain 1:  #> Warning: The largest R-hat is 1.06, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess"},{"path":"https://mc-stan.org/rstanarm/reference/stan_lm.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian regularized linear models via Stan — stan_aov","title":"Bayesian regularized linear models via Stan — stan_aov","text":"Bayesian inference linear modeling regularizing priors model parameters driven prior beliefs \\(R^2\\), proportion variance outcome attributable predictors. See priors explanation critical point. stan_glm family=\"gaussian\" also estimates linear model normally-distributed errors allows various priors coefficients.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_lm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian regularized linear models via Stan — stan_aov","text":"","code":"stan_aov(   formula,   data,   projections = FALSE,   contrasts = NULL,   ...,   prior = R2(stop(\"'location' must be specified\")),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL )  stan_lm(   formula,   data,   subset,   weights,   na.action,   model = TRUE,   x = FALSE,   y = FALSE,   singular.ok = TRUE,   contrasts = NULL,   offset,   ...,   prior = R2(stop(\"'location' must be specified\")),   prior_intercept = NULL,   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL )  stan_lm.wfit(   x,   y,   w,   offset = NULL,   singular.ok = TRUE,   ...,   prior = R2(stop(\"'location' must be specified\")),   prior_intercept = NULL,   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL )  stan_lm.fit(   x,   y,   offset = NULL,   singular.ok = TRUE,   ...,   prior = R2(stop(\"'location' must be specified\")),   prior_intercept = NULL,   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_lm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian regularized linear models via Stan — stan_aov","text":"formula, data, subset lm, strongly advise omitting data argument. Unless data specified (data frame) many post-estimation functions (including update, loo, kfold) guaranteed work properly. projections stan_aov, logical scalar (defaulting FALSE) indicating whether proj called fit. ... arguments passed function rstan package (sampling, vb, optimizing), corresponding estimation method named algorithm. example, algorithm \"sampling\" possible specify iter, chains, cores, MCMC controls. Another useful argument can passed rstan via ... refresh, specifies often print updates sampling (.e., show progress every refresh iterations). refresh=0 turns iteration updates. prior Must call R2 location argument specified NULL, indicate standard uniform prior \\(R^2\\). prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. na.action, singular.ok, contrasts lm, rarely specified. model, offset, weights lm, rarely specified. x, y stan_lm, stan_aov, logical scalars indicating whether return design matrix response vector. stan_lm.fit stan_lm.wfit, design matrix response vector. prior_intercept Either NULL (default) call normal. normal prior specified without scale, standard deviation taken marginal standard deviation outcome divided square root sample size, legitimate marginal standard deviation outcome primitive parameter estimated. Note: using dense representation design matrix —.e., sparse argument left default value FALSE— prior distribution intercept set applies value predictors centered. prefer specify prior intercept without predictors auto-centered, omit intercept formula include column ones predictor, case element prior specifies prior , rather prior_intercept. Regardless prior_intercept specified, reported estimates intercept always correspond parameterization without centered predictors (.e., glm). w lm.wfit rarely specified.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_lm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian regularized linear models via Stan — stan_aov","text":"stanreg object returned stan_lm, stan_aov. stanfit object (slightly modified   stanfit object) returned stan_lm.fit stan_lm.wfit called directly.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_lm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian regularized linear models via Stan — stan_aov","text":"stan_lm function similar syntax   lm function rather choosing parameters   minimize sum squared residuals, samples posterior   distribution drawn using MCMC (algorithm   \"sampling\"). stan_lm function formula-based   interface usually called users stan_lm.fit   stan_lm.wfit functions might called functions   parse data analogous lm.fit   lm.wfit respectively. addition estimating sigma — standard deviation   normally-distributed errors — model estimates positive parameter   called log-fit_ratio. positive, marginal posterior   variance outcome exceed sample variance outcome   multiplicative factor equal square fit_ratio.   Conversely log-fit_ratio negative, model underfits.   Given regularizing nature priors, slight underfit good. Finally, posterior predictive distribution generated   predictors fixed sample means. quantity useful   checking convergence reasonably normally distributed   function parameters model. stan_aov function similar aov,   Bayesian analysis variance basically equivalent   stan_lm dummy variables. stan_aov somewhat   customized print method prints ANOVA-like table   addition output printed stan_lm models.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_lm.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian regularized linear models via Stan — stan_aov","text":"Lewandowski, D., Kurowicka D., Joe, H. (2009). Generating random correlation matrices based vines extended onion method. Journal Multivariate Analysis. 100(9), 1989–2001.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_lm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian regularized linear models via Stan — stan_aov","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { # \\donttest{ op <- options(contrasts = c(\"contr.helmert\", \"contr.poly\")) fit_aov <- stan_aov(yield ~ block + N*P*K, data = npk,          prior = R2(0.5), seed = 12345) options(op) print(fit_aov) # } } #>  #> SAMPLING FOR MODEL 'lm' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 1.6e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.092 seconds (Warm-up) #> Chain 1:                0.074 seconds (Sampling) #> Chain 1:                0.166 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'lm' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 8e-06 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.105 seconds (Warm-up) #> Chain 2:                0.071 seconds (Sampling) #> Chain 2:                0.176 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'lm' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 8e-06 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.099 seconds (Warm-up) #> Chain 3:                0.1 seconds (Sampling) #> Chain 3:                0.199 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'lm' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 8e-06 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.104 seconds (Warm-up) #> Chain 4:                0.1 seconds (Sampling) #> Chain 4:                0.204 seconds (Total) #> Chain 4:  #> stan_aov #>  family:       gaussian [identity] #>  formula:      yield ~ block + N * P * K #>  observations: 24 #>  predictors:   12 #> ------ #>             Median MAD_SD #> (Intercept) 54.9    0.8   #> block1       1.2    1.3   #> block2       1.2    0.7   #> block3      -1.3    0.5   #> block4      -0.7    0.4   #> block5       0.2    0.3   #> N1           2.0    0.7   #> P1          -0.4    0.7   #> K1          -1.4    0.7   #> N1:P1       -0.6    0.7   #> N1:K1       -0.8    0.7   #> P1:K1        0.1    0.7   #>  #> Auxiliary parameter(s): #>               Median MAD_SD #> R2            0.5    0.1    #> log-fit_ratio 0.0    0.1    #> sigma         4.2    0.7    #>  #> ANOVA-like table: #>               Median MAD_SD #> Mean Sq block 43.8   20.9   #> Mean Sq N     48.6   26.7   #> Mean Sq P     13.7   11.0   #> Mean Sq K     29.5   19.6   #> Mean Sq N:P   12.0   16.0   #> Mean Sq N:K   17.6   23.0   #> Mean Sq P:K    5.5    7.6   #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg if (.Platform$OS.type != \"windows\" || .Platform$r_arch !=\"i386\") { (fit <- stan_lm(mpg ~ wt + qsec + am, data = mtcars, prior = R2(0.75),                  # the next line is only to make the example go fast enough                 chains = 1, iter = 300, seed = 12345, refresh = 0)) plot(fit, \"hist\", pars = c(\"wt\", \"am\", \"qsec\", \"sigma\"),       transformations = list(sigma = \"log\")) } #> Warning: The largest R-hat is 1.09, indicating chains have not mixed. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#r-hat #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess #> Warning: Markov chains did not converge! Do not analyze results! #> `stat_bin()` using `bins = 30`. Pick better value `binwidth`."},{"path":"https://mc-stan.org/rstanarm/reference/stan_mvmer.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian multivariate generalized linear models with correlated group-specific terms via Stan — stan_mvmer","title":"Bayesian multivariate generalized linear models with correlated group-specific terms via Stan — stan_mvmer","text":"Bayesian inference multivariate GLMs group-specific coefficients assumed correlated across GLM submodels.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_mvmer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian multivariate generalized linear models with correlated group-specific terms via Stan — stan_mvmer","text":"","code":"stan_mvmer(   formula,   data,   family = gaussian,   weights,   prior = normal(autoscale = TRUE),   prior_intercept = normal(autoscale = TRUE),   prior_aux = cauchy(0, 5, autoscale = TRUE),   prior_covariance = lkj(autoscale = TRUE),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   max_treedepth = 10L,   init = \"random\",   QR = FALSE,   sparse = FALSE,   ... )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_mvmer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian multivariate generalized linear models with correlated group-specific terms via Stan — stan_mvmer","text":"formula two-sided linear formula object describing fixed-effects random-effects parts longitudinal submodel similar vein formula specification lme4 package (see glmer lme4 vignette details). Note however double bar (||) notation allowed specifying random-effects parts formula, neither nested grouping factors (e.g. (1 | g1/g2)) (1 | g1:g2), g1, g2 grouping factors. multivariate GLM list formula objects, element list providing formula one GLM submodels. data data frame containing variables specified formula. multivariate GLM, can either single data frame contains data GLM submodels, can list data frames element list provides data one GLM submodels. family family (possibly also link function) GLM submodel(s). See glmer details. fitting multivariate GLM, can optionally list families, case element list specifies family one GLM submodels. words, different family can specified GLM submodel. weights glm, except fitting multivariate GLM list data frames provided data corresponding list weights must provided. weights provided one GLM submodels, must provided GLM submodels. prior, prior_intercept, prior_aux stan_glmer except multivariate GLM list priors can provided prior, prior_intercept prior_aux arguments. , different priors can optionally specified GLM submodels. list provided, prior distributions used GLM submodel. Note \"product_normal\" prior allowed stan_mvmer. prior_covariance NULL; see priors information prior distributions covariance matrices. Note however default prior covariance matrices stan_mvmer slightly different stan_glmer (details described priors page). prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. max_treedepth positive integer specifying maximum treedepth non-U-turn sampler. See control argument stan. init method generating initial values. See stan. QR logical scalar defaulting FALSE, TRUE applies scaled qr decomposition design matrix. transformation change likelihood data recommended computational reasons multiple predictors. See QR-argument documentation page details rstanarm transformation important information interpret prior distributions model parameters using QR=TRUE. sparse logical scalar (defaulting FALSE) indicating whether use sparse representation design (X) matrix. TRUE, design matrix centered (since destroy sparsity) likewise possible specify QR = TRUE sparse = TRUE. Depending many zeros design matrix, setting sparse = TRUE may make code run faster can consume much less RAM. ... arguments passed function rstan package (sampling, vb, optimizing), corresponding estimation method named algorithm. example, algorithm \"sampling\" possible specify iter, chains, cores, MCMC controls. Another useful argument can passed rstan via ... refresh, specifies often print updates sampling (.e., show progress every refresh iterations). refresh=0 turns iteration updates.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_mvmer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian multivariate generalized linear models with correlated group-specific terms via Stan — stan_mvmer","text":"stanmvreg object returned.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_mvmer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian multivariate generalized linear models with correlated group-specific terms via Stan — stan_mvmer","text":"stan_mvmer function can used fit multivariate   generalized linear model (GLM) group-specific terms. model consists   distinct GLM submodels, contains group-specific terms; within   grouping factor (example, patient ID) grouping-specific terms   assumed correlated across different GLM submodels.   possible specify different outcome type (example different   family /link function) GLM submodels.    Bayesian estimation model performed via MCMC, way   stan_glmer. Also, similar stan_glmer,   unstructured covariance matrix used group-specific terms   within given grouping factor, priors terms decomposition   covariance matrix.See priors information   priors distributions available covariance matrices,   regression coefficients intercept auxiliary parameters.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_mvmer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian multivariate generalized linear models with correlated group-specific terms via Stan — stan_mvmer","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch !=\"i386\") { # \\donttest{ ##### # A multivariate GLM with two submodels. For the grouping factor 'id', the  # group-specific intercept from the first submodel (logBili) is assumed to # be correlated with the group-specific intercept and linear slope in the  # second submodel (albumin) f1 <- stan_mvmer(         formula = list(           logBili ~ year + (1 | id),            albumin ~ sex + year + (year | id)),         data = pbcLong,          # this next line is only to keep the example small in size!         chains = 1, cores = 1, seed = 12345, iter = 1000) summary(f1)   ##### # A multivariate GLM with one bernoulli outcome and one # gaussian outcome. We will artificially create the bernoulli # outcome by dichotomising log serum bilirubin pbcLong$ybern <- as.integer(pbcLong$logBili >= mean(pbcLong$logBili)) f2 <- stan_mvmer(         formula = list(           ybern ~ year + (1 | id),            albumin ~ sex + year + (year | id)),         data = pbcLong,         family = list(binomial, gaussian),         chains = 1, cores = 1, seed = 12345, iter = 1000) # } } #> Fitting a multivariate glmer model. #>  #> Please note the warmup may be much slower than later iterations! #>  #> SAMPLING FOR MODEL 'mvmer' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 9.8e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.98 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 3.672 seconds (Warm-up) #> Chain 1:                2.049 seconds (Sampling) #> Chain 1:                5.721 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Fitting a multivariate glmer model. #>  #> Please note the warmup may be much slower than later iterations! #>  #> SAMPLING FOR MODEL 'mvmer' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 0.000102 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.02 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 3.977 seconds (Warm-up) #> Chain 1:                2.119 seconds (Sampling) #> Chain 1:                6.096 seconds (Total) #> Chain 1:  #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess"},{"path":"https://mc-stan.org/rstanarm/reference/stan_nlmer.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian nonlinear models with group-specific terms via Stan — stan_nlmer","title":"Bayesian nonlinear models with group-specific terms via Stan — stan_nlmer","text":"Bayesian inference NLMMs group-specific coefficients unknown covariance matrices flexible priors.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_nlmer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian nonlinear models with group-specific terms via Stan — stan_nlmer","text":"","code":"stan_nlmer(   formula,   data = NULL,   subset,   weights,   na.action,   offset,   contrasts = NULL,   ...,   prior = normal(autoscale = TRUE),   prior_aux = exponential(autoscale = TRUE),   prior_covariance = decov(),   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   QR = FALSE,   sparse = FALSE )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_nlmer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian nonlinear models with group-specific terms via Stan — stan_nlmer","text":"formula, data nlmer. strongly advise omitting data argument. Unless data specified (data frame) many post-estimation functions (including update, loo, kfold) guaranteed work properly. subset, weights, offset glm. na.action, contrasts glm, rarely specified. ... arguments passed function rstan package (sampling, vb, optimizing), corresponding estimation method named algorithm. example, algorithm \"sampling\" possible specify iter, chains, cores, MCMC controls. Another useful argument can passed rstan via ... refresh, specifies often print updates sampling (.e., show progress every refresh iterations). refresh=0 turns iteration updates. prior prior distribution (non-hierarchical) regression coefficients. default priors described vignette Prior Distributions rstanarm Models. using default, prior call one various functions provided rstanarm specifying priors. subset functions can used prior coefficients can grouped several \"families\": See priors help page details families specify arguments functions table . omit prior —.e., use flat (improper) uniform prior— prior can set NULL, although rarely good idea. Note: Unless QR=TRUE, prior Student t family Laplace family, autoscale argument function used specify prior (e.g. normal) left default recommended value TRUE, default user-specified prior scale(s) may adjusted internally based scales predictors. See priors help page Prior Distributions vignette details rescaling prior_summary function summary priors used particular model. prior_aux prior distribution \"auxiliary\" parameter (applicable). \"auxiliary\" parameter refers different parameter depending family. Gaussian models prior_aux controls \"sigma\", error standard deviation. negative binomial models prior_aux controls \"reciprocal_dispersion\", similar \"size\" parameter rnbinom: smaller values \"reciprocal_dispersion\" correspond greater dispersion. gamma models prior_aux sets prior \"shape\" parameter (see e.g., rgamma), inverse-Gaussian models -called \"lambda\" parameter (essentially reciprocal scale parameter). Binomial Poisson models auxiliary parameters. default prior described vignette Prior Distributions rstanarm Models. using default, prior_aux can call exponential use exponential distribution, normal, student_t cauchy, results half-normal, half-t, half-Cauchy prior. See priors details functions. omit prior —.e., use flat (improper) uniform prior— set prior_aux NULL. prior_covariance NULL; see decov information default arguments. prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. QR logical scalar defaulting FALSE, TRUE applies scaled qr decomposition design matrix. transformation change likelihood data recommended computational reasons multiple predictors. See QR-argument documentation page details rstanarm transformation important information interpret prior distributions model parameters using QR=TRUE. sparse logical scalar (defaulting FALSE) indicating whether use sparse representation design (X) matrix. TRUE, design matrix centered (since destroy sparsity) likewise possible specify QR = TRUE sparse = TRUE. Depending many zeros design matrix, setting sparse = TRUE may make code run faster can consume much less RAM.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_nlmer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian nonlinear models with group-specific terms via Stan — stan_nlmer","text":"stanreg object returned stan_nlmer.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_nlmer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian nonlinear models with group-specific terms via Stan — stan_nlmer","text":"stan_nlmer function similar syntax   nlmer rather performing (approximate) maximum   marginal likelihood estimation, Bayesian estimation default performed   via MCMC. Bayesian model adds independent priors \"coefficients\"   — really intercepts — way   stan_nlmer priors terms decomposition   covariance matrices group-specific parameters. See   priors information priors. supported transformation functions limited named   \"self-starting\" functions stats library:   SSasymp, SSasympOff,   SSasympOrig, SSbiexp,   SSfol, SSfpl,   SSgompertz, SSlogis,   SSmicmen, SSweibull.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_nlmer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian nonlinear models with group-specific terms via Stan — stan_nlmer","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch !=\"i386\") { # \\donttest{ data(\"Orange\", package = \"datasets\") Orange$circumference <- Orange$circumference / 100 Orange$age <- Orange$age / 100 fit <- stan_nlmer(   circumference ~ SSlogis(age, Asym, xmid, scal) ~ Asym|Tree,    data = Orange,    # for speed only   chains = 1,    iter = 1000  )  print(fit) posterior_interval(fit) plot(fit, regex_pars = \"b\\\\[\") # } } #> Warning: number of iterations exceeded maximum of 0 #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 3.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup) #> Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup) #> Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup) #> Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup) #> Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup) #> Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup) #> Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling) #> Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling) #> Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling) #> Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling) #> Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling) #> Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.755 seconds (Warm-up) #> Chain 1:                0.379 seconds (Sampling) #> Chain 1:                1.134 seconds (Total) #> Chain 1:  #> stan_nlmer #>  family:       gaussian [inv_SSlogis] #>  formula:      circumference ~ SSlogis(age, Asym, xmid, scal) ~ Asym | Tree #>  observations: 35 #> ------ #>      Median MAD_SD #> Asym 1.9    0.1    #> xmid 7.2    0.3    #> scal 3.4    0.3    #>  #> Auxiliary parameter(s): #>       Median MAD_SD #> sigma 0.1    0.0    #>  #> Error terms: #>  Groups   Name Std.Dev. #>  Tree     Asym 0.313    #>  Residual      0.089    #> Num. levels: Tree 5  #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg"},{"path":"https://mc-stan.org/rstanarm/reference/stan_polr.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian ordinal regression models via Stan — stan_polr","title":"Bayesian ordinal regression models via Stan — stan_polr","text":"Bayesian inference ordinal (binary) regression models proportional odds assumption.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_polr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian ordinal regression models via Stan — stan_polr","text":"","code":"stan_polr(   formula,   data,   weights,   ...,   subset,   na.action = getOption(\"na.action\", \"na.omit\"),   contrasts = NULL,   model = TRUE,   method = c(\"logistic\", \"probit\", \"loglog\", \"cloglog\", \"cauchit\"),   prior = R2(stop(\"'location' must be specified\")),   prior_counts = dirichlet(1),   shape = NULL,   rate = NULL,   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   do_residuals = NULL )  stan_polr.fit(   x,   y,   wt = NULL,   offset = NULL,   method = c(\"logistic\", \"probit\", \"loglog\", \"cloglog\", \"cauchit\"),   ...,   prior = R2(stop(\"'location' must be specified\")),   prior_counts = dirichlet(1),   shape = NULL,   rate = NULL,   prior_PD = FALSE,   algorithm = c(\"sampling\", \"meanfield\", \"fullrank\"),   adapt_delta = NULL,   do_residuals = algorithm == \"sampling\" )"},{"path":"https://mc-stan.org/rstanarm/reference/stan_polr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian ordinal regression models via Stan — stan_polr","text":"formula, data, subset polr, strongly advise omitting data argument. Unless data specified (data frame) many post-estimation functions (including update, loo, kfold) guaranteed work properly. weights, na.action, contrasts, model polr, rarely specified. ... arguments passed function rstan package (sampling, vb, optimizing), corresponding estimation method named algorithm. example, algorithm \"sampling\" possible specify iter, chains, cores, MCMC controls. Another useful argument can passed rstan via ... refresh, specifies often print updates sampling (.e., show progress every refresh iterations). refresh=0 turns iteration updates. method One 'logistic', 'probit', 'loglog', 'cloglog' 'cauchit', can abbreviated. See polr details. prior Prior coefficients. call R2 specify prior location \\(R^2\\) can NULL indicate standard uniform prior. See priors. prior_counts call dirichlet specify prior counts outcome predictors sample means. shape Either NULL positive scalar interpreted shape parameter GammaDistribution exponent applied probability success two outcome categories. NULL, default, exponent taken fixed \\(1\\). rate Either NULL positive scalar interpreted rate parameter GammaDistribution exponent applied probability success two outcome categories. NULL, default, exponent taken fixed \\(1\\). prior_PD logical scalar (defaulting FALSE) indicating whether draw prior predictive distribution instead conditioning outcome. algorithm string (possibly abbreviated) indicating estimation approach use. Can \"sampling\" MCMC (default), \"optimizing\" optimization, \"meanfield\" variational inference independent normal distributions, \"fullrank\" variational inference multivariate normal distribution. See rstanarm-package details estimation algorithms. NOTE: fitting functions support four algorithms. adapt_delta relevant algorithm=\"sampling\". See adapt_delta help page details. do_residuals logical scalar indicating whether automatically calculate fit residuals sampling completes. Defaults TRUE algorithm=\"sampling\". Setting do_residuals=FALSE useful somewhat rare case stan_polr appears finish sampling hangs instead returning fitted model object. x design matrix. y response variable, must (preferably ordered) factor. wt numeric vector (possibly NULL) observation weights. offset numeric vector (possibly NULL) offsets.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_polr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bayesian ordinal regression models via Stan — stan_polr","text":"stanreg object returned stan_polr. stanfit object (slightly modified   stanfit object) returned stan_polr.fit called directly.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_polr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian ordinal regression models via Stan — stan_polr","text":"stan_polr function similar syntax   polr rather performing maximum likelihood   estimation proportional odds model, Bayesian estimation performed   (algorithm = \"sampling\") via MCMC. stan_polr   function calls workhorse stan_polr.fit function,   possible call latter directly. stan_lm, necessary specify prior   location \\(R^2\\). case, \\(R^2\\) pertains   proportion variance latent variable (discretized   cutpoints) attributable predictors model. Prior beliefs cutpoints governed prior beliefs   outcome predictors sample means.   explained help page priors   rstanarm vignettes. Unlike polr, stan_polr also allows \"ordinal\"   outcome contain two levels, case likelihood   default stan_glm family = binomial   prior coefficients different. However, stan_polr   allows user specify shape rate hyperparameters,   case probability success defined logistic CDF   linear predictor, raised power alpha alpha   gamma prior specified shape rate.   likelihood called “scobit” Nagler (1994) alpha   equal \\(1\\), relationship linear predictor   probability success skewed. shape rate   NULL, alpha assumed fixed \\(1\\). Otherwise, usually advisible set shape rate   number expected value alpha \\(1\\)   leaving open possibility alpha may depart \\(1\\)   little bit. often necessary lot data order estimate   alpha much precision always necessary inspect   Pareto shape parameters calculated loo see   results particularly sensitive individual observations. Users think carefully outcome coded using   scobit-type model. alpha \\(1\\), asymmetry   implies probability success sensitive predictors   probability success less \\(0.63\\). Reversing   coding successes failures allows predictors   greatest impact probability failure less \\(0.63\\).   Also, gamma prior alpha positively skewed,   can reverse coding successes failures circumvent   property.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stan_polr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Bayesian ordinal regression models via Stan — stan_polr","text":"Nagler, J., (1994). Scobit: Alternative Estimator Logit Probit. American Journal Political Science. 230 – 255.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stan_polr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bayesian ordinal regression models via Stan — stan_polr","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch !=\"i386\") {  fit <- stan_polr(tobgp ~ agegp, data = esoph, method = \"probit\",           prior = R2(0.2, \"mean\"), init_r = 0.1, seed = 12345,           algorithm = \"fullrank\") # for speed only  print(fit)  plot(fit) } #> Chain 1: ------------------------------------------------------------ #> Chain 1: EXPERIMENTAL ALGORITHM: #> Chain 1:   This procedure has not been thoroughly tested and may be unstable #> Chain 1:   or buggy. The interface is subject to change. #> Chain 1: ------------------------------------------------------------ #> Chain 1:  #> Chain 1:  #> Chain 1:  #> Chain 1: Gradient evaluation took 4.7e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.47 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Begin eta adaptation. #> Chain 1: Iteration:   1 / 250 [  0%]  (Adaptation) #> Chain 1: Iteration:  50 / 250 [ 20%]  (Adaptation) #> Chain 1: Iteration: 100 / 250 [ 40%]  (Adaptation) #> Chain 1: Iteration: 150 / 250 [ 60%]  (Adaptation) #> Chain 1: Iteration: 200 / 250 [ 80%]  (Adaptation) #> Chain 1: Success! Found best value [eta = 1] earlier than expected. #> Chain 1:  #> Chain 1: Begin stochastic gradient ascent. #> Chain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  #> Chain 1:    100         -135.991             1.000            1.000 #> Chain 1:    200         -131.110             0.519            1.000 #> Chain 1:    300         -128.295             0.353            0.037 #> Chain 1:    400         -127.636             0.266            0.037 #> Chain 1:    500         -127.828             0.213            0.022 #> Chain 1:    600         -127.903             0.178            0.022 #> Chain 1:    700         -127.740             0.153            0.005   MEDIAN ELBO CONVERGED #> Chain 1:  #> Chain 1: Drawing a sample of size 1000 from the approximate posterior...  #> Chain 1: COMPLETED. #> stan_polr #>  family:       ordered [probit] #>  formula:      tobgp ~ agegp #>  observations: 88 #> ------ #>         Median MAD_SD #> agegp.L -0.1    0.3   #> agegp.Q -0.2    0.2   #> agegp.C  0.0    0.3   #> agegp^4  0.0    0.2   #> agegp^5  0.0    0.2   #>  #> Cutpoints: #>                Median MAD_SD #> 0-9g/day|10-19 -0.6    0.1   #> 10-19|20-29     0.1    0.1   #> 20-29|30+       0.8    0.2   #>  #> ------ #> * For help interpreting the printed output see ?print.stanreg #> * For info on the priors used see ?prior_summary.stanreg"},{"path":"https://mc-stan.org/rstanarm/reference/stanmvreg-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for stanmvreg objects — stanmvreg-methods","title":"Methods for stanmvreg objects — stanmvreg-methods","text":"S3 methods stanmvreg objects. also several methods (listed See Also, ) individual help pages. main difference methods stanreg methods methods described generally include additional argument m allows user specify submodel wish return result . argument m set NULL result generally named list element list containing result one submodels.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanmvreg-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for stanmvreg objects — stanmvreg-methods","text":"","code":"# S3 method for class 'stanmvreg' coef(object, m = NULL, ...)  # S3 method for class 'stanmvreg' fitted(object, m = NULL, ...)  # S3 method for class 'stanmvreg' residuals(object, m = NULL, ...)  # S3 method for class 'stanmvreg' se(object, m = NULL, ...)  # S3 method for class 'stanmvreg' formula(x, fixed.only = FALSE, random.only = FALSE, m = NULL, ...)  # S3 method for class 'stanmvreg' update(object, formula., ..., evaluate = TRUE)  # S3 method for class 'stanjm' update(object, formulaLong., formulaEvent., ..., evaluate = TRUE)  # S3 method for class 'stanmvreg' fixef(object, m = NULL, remove_stub = TRUE, ...)  # S3 method for class 'stanmvreg' ngrps(object, ...)  # S3 method for class 'stanmvreg' ranef(object, m = NULL, ...)  # S3 method for class 'stanmvreg' sigma(object, m = NULL, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/stanmvreg-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for stanmvreg objects — stanmvreg-methods","text":"object, x fitted model object returned one multivariate rstanarm modelling functions. See stanreg-objects. m Integer specifying number name submodel ... Ignored, except update method. See update. fixed.logical specifying whether retain fixed effect part longitudinal submodel formulas random.logical specifying whether retain random effect part longitudinal submodel formulas formula. updated formula model. multivariate model formula. list formulas, described formula argument stan_mvmer. evaluate See update. formulaLong., formulaEvent. updated formula longitudinal event submodel, object estimated using stan_jm. multivariate joint model formulaLong. list formulas, described formulaLong argument stan_jm. remove_stub Logical specifying whether remove string identifying submodel (e.g. y1|, y2|, Long1|, Long2|, Event|) parameter names.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanmvreg-methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods for stanmvreg objects — stanmvreg-methods","text":"methods similar methods defined objects   class 'lm', 'glm', 'glmer', etc. However exceptions: coef Medians used point estimates. See Point estimates section print.stanmvreg details. coef returns list equal length number submodels. first elements list coefficients fitted longitudinal submodels layout returned coef method lme4 package, , sum random fixed effects coefficients explanatory variable level grouping factor. final element returned list vector fixed effect coefficients event submodel. se se function returns standard errors based mad. See Uncertainty estimates section print.stanmvreg details. confint supplied, since posterior_interval function used instead compute Bayesian uncertainty intervals. residuals Residuals always type \"response\" (\"deviance\" residuals type).","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-draws-formats.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a draws object from a stanreg object — stanreg-draws-formats","title":"Create a draws object from a stanreg object — stanreg-draws-formats","text":"Convert stanreg object format supported posterior package.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-draws-formats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a draws object from a stanreg object — stanreg-draws-formats","text":"","code":"# S3 method for class 'stanreg' as_draws(x, ...)  # S3 method for class 'stanreg' as_draws_matrix(x, ...)  # S3 method for class 'stanreg' as_draws_array(x, ...)  # S3 method for class 'stanreg' as_draws_df(x, ...)  # S3 method for class 'stanreg' as_draws_list(x, ...)  # S3 method for class 'stanreg' as_draws_rvars(x, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-draws-formats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a draws object from a stanreg object — stanreg-draws-formats","text":"x stanreg object returned one rstanarm modeling functions. ... Arguments (e.g., pars, regex_pars) passed internally .matrix.stanreg .array.stanreg.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-draws-formats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a draws object from a stanreg object — stanreg-draws-formats","text":"draws object   posterior package. See   posterior package documentation vignettes details working   objects.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-draws-formats.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a draws object from a stanreg object — stanreg-draws-formats","text":"subset iterations, chains, draws, use   subset_draws making   draws object. subset variables use ... pass pars   /regex_pars arguments .matrix.stanreg   .array.stanreg (called internally   as_draws.stanreg), use   subset_draws making   draws object.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-draws-formats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a draws object from a stanreg object — stanreg-draws-formats","text":"","code":"fit <- stan_glm(mpg ~ wt + as.factor(cyl), data = mtcars) #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 2.1e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.051 seconds (Warm-up) #> Chain 1:                0.046 seconds (Sampling) #> Chain 1:                0.097 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 3.1e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.049 seconds (Warm-up) #> Chain 2:                0.046 seconds (Sampling) #> Chain 2:                0.095 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 9e-06 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.051 seconds (Warm-up) #> Chain 3:                0.05 seconds (Sampling) #> Chain 3:                0.101 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 9e-06 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.049 seconds (Warm-up) #> Chain 4:                0.042 seconds (Sampling) #> Chain 4:                0.091 seconds (Total) #> Chain 4:  as_draws_matrix(fit) # matrix format combines all chains  #> # A draws_matrix: 4000 iterations, 1 chains, and 5 variables #>     variable #> draw (Intercept)   wt as.factor(cyl)6 as.factor(cyl)8 sigma #>   1           35 -3.1            -7.4            -7.2   2.5 #>   2           32 -2.5            -4.4            -6.8   2.4 #>   3           33 -2.8            -3.4            -6.5   2.6 #>   4           36 -3.6            -5.1            -5.9   2.8 #>   5           37 -3.8            -5.2            -6.5   2.9 #>   6           31 -2.6            -4.0            -5.7   2.3 #>   7           37 -4.5            -3.3            -4.5   2.8 #>   8           33 -2.8            -3.5            -4.9   2.8 #>   9           34 -3.7            -1.6            -5.3   2.3 #>   10          36 -3.5            -4.8            -6.7   3.2 #> # ... with 3990 more draws as_draws_df(fit, regex_pars = \"cyl\") #> # A draws_df: 1000 iterations, 4 chains, and 2 variables #>    as.factor(cyl)6 as.factor(cyl)8 #> 1             -7.4            -7.2 #> 2             -4.4            -6.8 #> 3             -3.4            -6.5 #> 4             -5.1            -5.9 #> 5             -5.2            -6.5 #> 6             -4.0            -5.7 #> 7             -3.3            -4.5 #> 8             -3.5            -4.9 #> 9             -1.6            -5.3 #> 10            -4.8            -6.7 #> # ... with 3990 more draws #> # ... hidden reserved variables {'.chain', '.iteration', '.draw'} posterior::summarize_draws(as_draws_array(fit)) #> # A tibble: 5 × 10 #>   variable         mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail #>   <chr>           <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl> #> 1 (Intercept)     34.0   33.9  1.96  1.93  30.8  37.2   1.00    2819.    3016. #> 2 wt              -3.21  -3.20 0.776 0.749 -4.51 -1.96  1.00    2018.    2385. #> 3 as.factor(cyl)6 -4.24  -4.25 1.48  1.46  -6.65 -1.82  1.00    1924.    2547. #> 4 as.factor(cyl)8 -6.04  -6.05 1.72  1.68  -8.88 -3.18  1.00    1767.    2050. #> 5 sigma            2.65   2.61 0.374 0.360  2.12  3.34  1.00    2744.    2655."},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for stanreg objects — nobs.stanmvreg","title":"Methods for stanreg objects — nobs.stanmvreg","text":"methods documented page actually least important methods defined stanreg objects. important methods documented separately, page. Links pages provided See Also section, .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for stanreg objects — nobs.stanmvreg","text":"","code":"# S3 method for class 'stanmvreg' nobs(object, ...)  # S3 method for class 'stanreg' coef(object, ...)  # S3 method for class 'stanreg' confint(object, parm, level = 0.95, ...)  # S3 method for class 'stanreg' fitted(object, ...)  # S3 method for class 'stanreg' nobs(object, ...)  # S3 method for class 'stanreg' residuals(object, ...)  # S3 method for class 'stanreg' se(object, ...)  # S3 method for class 'stanreg' update(object, formula., ..., evaluate = TRUE)  # S3 method for class 'stanreg' vcov(object, correlation = FALSE, ...)  # S3 method for class 'stanreg' fixef(object, ...)  # S3 method for class 'stanreg' ngrps(object, ...)  # S3 method for class 'stanreg' nsamples(object, ...)  # S3 method for class 'stanreg' ranef(object, ...)  # S3 method for class 'stanreg' sigma(object, ...)  # S3 method for class 'stanreg' VarCorr(x, sigma = 1, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for stanreg objects — nobs.stanmvreg","text":"object, x fitted model object returned one rstanarm modeling functions. See stanreg-objects. ... Ignored, except update method. See update. parm confint, optional character vector parameter names. level confint, scalar \\(0\\) \\(1\\) indicating confidence level use. formula., evaluate See update. correlation vcov, FALSE (default) covariance matrix returned. TRUE, correlation matrix returned instead. sigma Ignored (included compatibility VarCorr).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods for stanreg objects — nobs.stanmvreg","text":"methods documented page similar methods   defined objects class 'lm', 'glm', 'glmer', etc. However   key differences: residuals Residuals always type \"response\" (\"deviance\" residuals type). However, case stan_polr two response categories, residuals difference latent utility linear predictor. coef Medians used point estimates. See Point estimates section print.stanreg details. se se function returns standard errors based mad. See Uncertainty estimates section print.stanreg details. confint models fit using optimization, confidence intervals returned via call confint.default. algorithm \"sampling\", \"meanfield\", \"fullrank\", confint throw error posterior_interval function used compute Bayesian uncertainty intervals. nsamples number draws posterior distribution obtained","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-objects.html","id":null,"dir":"Reference","previous_headings":"","what":"Fitted model objects — stanreg-objects","title":"Fitted model objects — stanreg-objects","text":"rstanarm model-fitting functions return object class 'stanreg', list containing minimum components listed . stanreg object also additional classes (e.g. 'aov', 'betareg', 'glm', 'polr', etc.) several additional components depending model estimation algorithm.  additional details apply models estimated using stan_mvmer stan_jm modelling functions. stan_mvmer modelling function returns object class 'stanmvreg', inherits 'stanreg' class, number additional elements described subsection . stan_jm modelling function returns object class 'stanjm', inherits 'stanmvreg' 'stanreg' classes, number additional elements described subsection . 'stanjm' 'stanmvreg' classes several methods situations default 'stanreg' methods suitable; see See Also section .","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-objects.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fitted model objects — stanreg-objects","text":"stan_biglm function exception. returns   stanfit object rather stanreg object.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-objects.html","id":"elements-for-stanreg-objects","dir":"Reference","previous_headings":"","what":"Elements for stanreg objects","title":"Fitted model objects — stanreg-objects","text":"coefficients Point estimates, described print.stanreg. ses Standard errors based mad, described   print.stanreg. residuals Residuals type 'response'. fitted.values Fitted mean values. GLMs linear predictors transformed   inverse link function. linear.predictors Linear fit link scale. linear models   fitted.values. covmat Variance-covariance matrix coefficients based draws   posterior distribution, variational approximation, asymptotic   sampling distribution, depending estimation algorithm. model,x,y requested, model frame, model matrix response variable used,   respectively. family family object used. call matched call. formula model formula. data,offset,weights data, offset, weights arguments. algorithm estimation method used. prior.info list information prior distributions used. stanfit,stan_summary object stanfit-class returned RStan   matrix various summary statistics stanfit object. rstan_version version rstan package used fit model.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-objects.html","id":"elements-for-stanmvreg-objects","dir":"Reference","previous_headings":"","what":"Elements for stanmvreg objects","title":"Fitted model objects — stanreg-objects","text":"cnms names grouping factors group specific parameters, collapsed   across longitudinal glmer submodels. flevels unique factor levels grouping factor, collapsed across   longitudinal glmer submodels. n_markers number longitudinal glmer submodels. n_yobs number observations longitudinal glmer submodel. n_grps number levels grouping factor (models estimated using   stan_jm, equal n_subjects   individual grouping factor). runtime time taken fit model (minutes).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg-objects.html","id":"additional-elements-for-stanjm-objects","dir":"Reference","previous_headings":"","what":"Additional elements for stanjm objects","title":"Fitted model objects — stanreg-objects","text":"id_var,time_var names variables distinguishing individuals,   representing time longitudinal submodel. n_subjects number individuals. n_events number non-censored events. eventtime,status event (censoring) time status indicator individual. basehaz list containing information baseline hazard. assoc array containing information association structure. epsilon width one-sided difference used numerically evaluate   slope longitudinal trajectory; relevant slope-based   association structure specified (e.g. etaslope, muslope, etc). qnodes number Gauss-Kronrod quadrature nodes used evaluate   cumulative hazard joint likelihood function.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/stanreg_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Create lists of fitted model objects, combine them, or append new models to existing lists of models. — stanreg_list","title":"Create lists of fitted model objects, combine them, or append new models to existing lists of models. — stanreg_list","text":"Create lists fitted model objects, combine , append new models existing lists models.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create lists of fitted model objects, combine them, or append new models to existing lists of models. — stanreg_list","text":"","code":"stanreg_list(..., model_names = NULL)  stanmvreg_list(..., model_names = NULL)  stanjm_list(..., model_names = NULL)  # S3 method for class 'stanreg_list' print(x, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/stanreg_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create lists of fitted model objects, combine them, or append new models to existing lists of models. — stanreg_list","text":"... Objects combine \"stanreg_list\", \"stanmvreg_list\", \"stanjm_list\". Can fitted model objects, existing \"stan*_list\" objects combine, one existing \"stan*_list\" object followed fitted model objects append list. model_names Optionally, character vector model names. specified names inferred name objects passed via .... model names used, example, printing results loo_compare.stanreg_list loo_model_weights.stanreg_list methods. x object print.","code":""},{"path":"https://mc-stan.org/rstanarm/reference/stanreg_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create lists of fitted model objects, combine them, or append new models to existing lists of models. — stanreg_list","text":"list class \"stanreg_list\", \"stanmvreg_list\",   \"stanjm_list\", containing fitted model objects metadata   stored attributes.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/summary.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for stanreg objects — summary.stanreg","title":"Summary method for stanreg objects — summary.stanreg","text":"Summaries parameter estimates MCMC convergence diagnostics (Monte Carlo error, effective sample size, Rhat).","code":""},{"path":"https://mc-stan.org/rstanarm/reference/summary.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for stanreg objects — summary.stanreg","text":"","code":"# S3 method for class 'stanreg' summary(   object,   pars = NULL,   regex_pars = NULL,   probs = c(0.1, 0.5, 0.9),   ...,   digits = 1 )  # S3 method for class 'summary.stanreg' print(x, digits = max(1, attr(x, \"print.digits\")), ...)  # S3 method for class 'summary.stanreg' as.data.frame(x, ...)  # S3 method for class 'stanmvreg' summary(object, pars = NULL, regex_pars = NULL, probs = NULL, ..., digits = 3)  # S3 method for class 'summary.stanmvreg' print(x, digits = max(1, attr(x, \"print.digits\")), ...)"},{"path":"https://mc-stan.org/rstanarm/reference/summary.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for stanreg objects — summary.stanreg","text":"object fitted model object returned one rstanarm modeling functions. See stanreg-objects. pars optional character vector specifying subset parameters display. Parameters can specified name several shortcuts can used. Using pars=\"beta\" restrict displayed parameters regression coefficients (without intercept). \"alpha\" can also used shortcut \"(Intercept)\". model varying intercepts /slopes can selected using pars = \"varying\". addition, stanmvreg objects additional shortcuts available. Using pars = \"long\" display parameter estimates longitudinal submodels (excluding group-specific pparameters, including auxiliary parameters). Using pars = \"event\" display parameter estimates event submodel , including association parameters. Using pars = \"assoc\" display association parameters. Using pars = \"fixef\" display fixed effects, random effects auxiliary parameters.  pars regex_pars set NULL fixed effect regression coefficients selected, well auxiliary parameters log posterior. pars NULL parameters selected stanreg object, stanmvreg object fixed effect regression coefficients selected well auxiliary parameters log posterior. See Examples. regex_pars optional character vector regular expressions use parameter selection. regex_pars can used place pars addition pars. Currently, functions accept regex_pars argument ignore models fit using optimization. probs models fit using MCMC one variational algorithms, optional numeric vector probabilities passed quantile. ... Currently ignored. digits Number digits use formatting numbers printing. calling summary, value digits stored \"print.digits\" attribute returned object. x object class \"summary.stanreg\".","code":""},{"path":"https://mc-stan.org/rstanarm/reference/summary.stanreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for stanreg objects — summary.stanreg","text":"summary method returns object class   \"summary.stanreg\" (\"summary.stanmvreg\", inheriting   \"summary.stanreg\"), matrix   summary statistics   diagnostics, attributes storing information use   print method. print method summary.stanreg   summary.stanmvreg objects called side effect just returns   input. .data.frame method summary.stanreg   objects converts matrix data.frame, preserving row column   names dropping print-related attributes.","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/summary.stanreg.html","id":"mean-ppd-diagnostic","dir":"Reference","previous_headings":"","what":"mean_PPD diagnostic","title":"Summary method for stanreg objects — summary.stanreg","text":"Summary statistics also reported mean_PPD, sample average posterior predictive distribution outcome. useful quick diagnostic. useful heuristic check mean_PPD plausible compared mean(y). plausible mean model good general (can reproduce sample mean), however mean_PPD implausible sign something wrong (severe model misspecification, problems data, computational issues, etc.).","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/reference/summary.stanreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for stanreg objects — summary.stanreg","text":"","code":"if (.Platform$OS.type != \"windows\" || .Platform$r_arch != \"i386\") { if (!exists(\"example_model\")) example(example_model)  summary(example_model, probs = c(0.1, 0.9))  # These produce the same output for this example,  # but the second method can be used for any model summary(example_model, pars = c(\"(Intercept)\", \"size\",                                  paste0(\"period\", 2:4))) summary(example_model, pars = c(\"alpha\", \"beta\"))  # Only show parameters varying by group summary(example_model, pars = \"varying\") as.data.frame(summary(example_model, pars = \"varying\")) } #>                               mean       mcse        sd         10%         50% #> b[(Intercept) herd:1]   0.62722341 0.01608742 0.4415459  0.07595455  0.62715031 #> b[(Intercept) herd:2]  -0.36427769 0.01525883 0.4424714 -0.94483006 -0.33901142 #> b[(Intercept) herd:3]   0.38045628 0.01263177 0.3766349 -0.07852149  0.37502550 #> b[(Intercept) herd:4]   0.03841076 0.01803683 0.4905975 -0.58000948  0.04103359 #> b[(Intercept) herd:5]  -0.26015881 0.01415271 0.4160125 -0.80240461 -0.23959978 #> b[(Intercept) herd:6]  -0.45988461 0.01559916 0.4388333 -1.02158661 -0.43434658 #> b[(Intercept) herd:7]   0.92618148 0.01426487 0.4360411  0.40131569  0.89970975 #> b[(Intercept) herd:8]   0.51032101 0.01925821 0.5221492 -0.13943996  0.52135539 #> b[(Intercept) herd:9]  -0.25893282 0.01666986 0.5406258 -0.90647896 -0.24139284 #> b[(Intercept) herd:10] -0.62914073 0.01481049 0.4468560 -1.22576496 -0.60609808 #> b[(Intercept) herd:11] -0.14637179 0.01431972 0.4129541 -0.71249718 -0.11485555 #> b[(Intercept) herd:12] -0.04363117 0.01846334 0.5122429 -0.69627174 -0.02758330 #> b[(Intercept) herd:13] -0.78627355 0.01656960 0.4573965 -1.36763552 -0.75501245 #> b[(Intercept) herd:14]  1.00700584 0.01707785 0.4423126  0.43654877  0.98415992 #> b[(Intercept) herd:15] -0.60198255 0.01381385 0.4725656 -1.22122313 -0.57879172 #>                                90% n_eff      Rhat #> b[(Intercept) herd:1]   1.18994683   753 1.0005647 #> b[(Intercept) herd:2]   0.18168238   841 0.9992947 #> b[(Intercept) herd:3]   0.86572288   889 0.9996979 #> b[(Intercept) herd:4]   0.64919383   740 0.9988455 #> b[(Intercept) herd:5]   0.24399929   864 0.9985012 #> b[(Intercept) herd:6]   0.06249890   791 1.0008678 #> b[(Intercept) herd:7]   1.52063980   934 0.9988557 #> b[(Intercept) herd:8]   1.15757378   735 1.0005324 #> b[(Intercept) herd:9]   0.41947464  1052 0.9983954 #> b[(Intercept) herd:10] -0.09920854   910 0.9994387 #> b[(Intercept) herd:11]  0.35927443   832 0.9998923 #> b[(Intercept) herd:12]  0.59755834   770 1.0019334 #> b[(Intercept) herd:13] -0.25753682   762 1.0027890 #> b[(Intercept) herd:14]  1.59355623   671 1.0003160 #> b[(Intercept) herd:15] -0.01508412  1170 0.9985240"},{"path":"https://mc-stan.org/rstanarm/reference/terms.stanmvreg.html","id":null,"dir":"Reference","previous_headings":"","what":"terms method for stanmvreg objects — terms.stanmvreg","title":"terms method for stanmvreg objects — terms.stanmvreg","text":"terms method stanmvreg objects","code":""},{"path":"https://mc-stan.org/rstanarm/reference/terms.stanmvreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"terms method for stanmvreg objects — terms.stanmvreg","text":"","code":"# S3 method for class 'stanmvreg' terms(x, fixed.only = TRUE, random.only = FALSE, m = NULL, ...)"},{"path":"https://mc-stan.org/rstanarm/reference/terms.stanmvreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"terms method for stanmvreg objects — terms.stanmvreg","text":"x, fixed., random., ... See lme4:::terms.merMod. m Integer specifying number name submodel","code":""},{"path":"https://mc-stan.org/rstanarm/reference/terms.stanreg.html","id":null,"dir":"Reference","previous_headings":"","what":"terms method for stanreg objects — terms.stanreg","title":"terms method for stanreg objects — terms.stanreg","text":"terms method stanreg objects","code":""},{"path":"https://mc-stan.org/rstanarm/reference/terms.stanreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"terms method for stanreg objects — terms.stanreg","text":"","code":"# S3 method for class 'stanreg' terms(x, ..., fixed.only = TRUE, random.only = FALSE)"},{"path":"https://mc-stan.org/rstanarm/reference/terms.stanreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"terms method for stanreg objects — terms.stanreg","text":"x, fixed., random., ... See lme4:::terms.merMod.","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2213","dir":"Changelog","previous_headings":"","what":"rstanarm 2.21.3","title":"rstanarm 2.21.3","text":"CRAN release: 2022-04-08","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-21-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.21.3","text":"Fix bug loo() k_threshold argument specified error model formula string instead formula object. (#454) Fix bug loo() k_threshold argument specified error models fit stan_polr(). (#450) Fix bug stan_aov() use wrong singular.ok logic. (#448) Fix bug contrasts info dropped subsetting model matrix stan_glm(). (#459) Fix bug stan_glmer() error prior_aux=NULL. (#482) posterior_predict() posterior_epred() don’t error newdata intercept models allowing data frames 0 columns multiple rows. (#492)","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-2-21-3","dir":"Changelog","previous_headings":"","what":"New features","title":"rstanarm 2.21.3","text":"New vignette AB testing. (#409) stan_jm() gains offset term longitudinal submodel. (#415, @pamelanluna) Effective number parameters computed K-fold CV just LOO CV. (#462) stan_clogit() now allows outcome variable factor. (#520)","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2211","dir":"Changelog","previous_headings":"","what":"rstanarm 2.21.1","title":"rstanarm 2.21.1","text":"CRAN release: 2020-07-20 Compatible rstan v2.21.1 Consistent new book Regression Stories","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"backwards-incompatible-changes-2-21-1","dir":"Changelog","previous_headings":"","what":"Backwards incompatible changes","title":"rstanarm 2.21.1","text":"stan_jm() available 32bit Windows improvements prior distributions, described detail vignette Prior Distributions rstanarm Models book Regression Stories. changes shouldn’t cause existing code error, default priors changed cases: default prior intercept still Gaussian way location scale determined updated (#432) autoscale argument functions like normal(), student_t(), etc., now defaults FALSE except used default priors (default priors still autoscalinng). makes simpler specify non-default priors. (#432)","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-21-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.21.1","text":"Fixed error kfold() stan_gamm4() models used random argument (#435) Fixed error posterior_predict() posterior_linpred() using newdata family = mgcv::betar (#406, #407) singular.ok now rules singular design matrices stan_lm() (#402) Fix potential error data data.table object (#434, @danschrage)","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-functions-2-21-1","dir":"Changelog","previous_headings":"","what":"New functions","title":"rstanarm 2.21.1","text":"New method posterior_epred() returns posterior distribution conditional expectation, equivalent (may eventually entirely replace) setting argument transform=TRUE posterior_linpred(). (#432) Added convenience functions logit() invlogit() just wrappers qlogis() plogis(). previously provided arm package. (#432)","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2193","dir":"Changelog","previous_headings":"","what":"rstanarm 2.19.3","title":"rstanarm 2.19.3","text":"CRAN release: 2020-02-11","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-19-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.19.3","text":"Allow vignettes knit platforms support version 2 RMarkdown","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2192","dir":"Changelog","previous_headings":"","what":"rstanarm 2.19.2","title":"rstanarm 2.19.2","text":"CRAN release: 2019-10-03","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-19-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.19.2","text":"src/Makevars{.win} now uses robust way find StanHeaders Fixed bug ranef() coef() methods glmer-style models printed wrong output certain combinations varying intercepts slopes. Fixed bug posterior_predict() failed stan_glmer() models estimated family = mgcv::betar. Fixed bug bayes_R2() bernoulli models. (Thanks @mcol) loo_R2() can now called fitted model object multiple times identical (just rng noise) results. (Thanks @mcol)","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-and-improvements-2-19-2","dir":"Changelog","previous_headings":"","what":"New features and improvements","title":"rstanarm 2.19.2","text":"New vignette MRP using rstanarm. (Thanks @lauken13) 4x speedup GLMs (stan_glm()) GAMs (stan_gamm4() without random argument). comes using Stan’s new compound _glm functions (normal_id_glm, bernoulli_logit_glm, poisson_log_glm, neg_binomial_2_log_glm) hood whenever possible. (Thanks @avehtari @VMatthijs) compare_models() deprecated favor loo_compare() keep loo package (loo::loo_compare()) kfold() method now cores argument parallelizes fold rather Markov chain (unless otherwise specified), much efficient many cores available. stan_glm() algorithm='optimizing', Pareto smoothed importance sampling (arxiv.org/abs/1507.02646, mc-stan.org/loo/reference/psis.html) now used diagnose improve inference (see https://avehtari.github.io/RAOS-Examples/BigData/bigdata.html). also now means can use PSIS-LOO also algorithm='optimizing'. (Thanks @avehtari) stan_glm() \"meanfield\" \"fullrank\" ADVI algorithms also include PSIS diagnostics adjustments, far seen example better optimzation MCMC.","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2181","dir":"Changelog","previous_headings":"","what":"rstanarm 2.18.1","title":"rstanarm 2.18.1","text":"CRAN release: 2018-10-21","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-18-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.18.1","text":"stan_clogit() now works even common predictors prior.info() works better models produced stan_jm() stan_mvmer()","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-and-improvements-2-18-1","dir":"Changelog","previous_headings":"","what":"New features and improvements","title":"rstanarm 2.18.1","text":"stan_glm() () gets mean_PPD argument FALSE avoids drawing posterior predictive distribution Stan code posterior_linpred() now works even model estimated algorithm = \"optimizing\"","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2174","dir":"Changelog","previous_headings":"","what":"rstanarm 2.17.4","title":"rstanarm 2.17.4","text":"CRAN release: 2018-04-13","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-17-4","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.17.4","text":"stan_jm() stan_mvmer() now correctly include intercept longitudinal submodel","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-and-improvements-2-17-4","dir":"Changelog","previous_headings":"","what":"New features and improvements","title":"rstanarm 2.17.4","text":"Compatible loo package version >= 2.0 QR = TRUE longer ignores autoscale argument better behavior autoscale = FALSE posterior_linpred() now draws argument like posterior_predict() Dynamic predictions now supported posterior_traj() stan_jm models. options K-fold CV, including manually specifying folds using helper functions create particular model/data combinations.","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2173","dir":"Changelog","previous_headings":"","what":"rstanarm 2.17.3","title":"rstanarm 2.17.3","text":"CRAN release: 2018-02-18 Minor release build fixes Solaris avoiding test failure","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2172","dir":"Changelog","previous_headings":"","what":"rstanarm 2.17.2","title":"rstanarm 2.17.2","text":"CRAN release: 2017-12-21 Lots good stuff release.","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-17-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.17.2","text":"stan_polr() stan_lm() handle K = 1 case better","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"important-user-facing-improvements-2-17-2","dir":"Changelog","previous_headings":"","what":"Important user-facing improvements","title":"rstanarm 2.17.2","text":"prior_aux arguments now defaults exponential rather Cauchy. safer default. Stan programs drop constants now safe use bridgesampling package hs() hs_plus() priors new defaults based new paper Aki Vehtari Juho Piironen stan_gamm4() now closely based mgcv::jagam(), may affect estimates options remain largely product_normal() prior permits df = 1, product … one normal variate build system conventional now. require less RAM build source slower unless utilize parallel make LTO","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"big-new-features-2-17-2","dir":"Changelog","previous_headings":"","what":"Big new features","title":"rstanarm 2.17.2","text":"stan_jm() stan_mvmer() contributed Sam Brilleman bayes_R2() method calculate quantity similar \\(R^2\\) stan_nlmer(), similar lme4::nlmer watch multimodal posterior distributions stan_clogit(), similar survival::clogit accepts lme4-style group-specific terms mgcv::betar family supported lme4-like modeling functions, allowing beta regressions lme4-style group terms / smooth nonlinear functions predictors","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2153","dir":"Changelog","previous_headings":"","what":"rstanarm 2.15.3","title":"rstanarm 2.15.3","text":"CRAN release: 2017-04-29","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-15-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.15.3","text":"Fix stan_glmer() Bernoulli models multiple group-specific intercept terms result draws wrong posterior distribution Fix bug contrasts stan_aov() (thanks Henrik Singmann) Fix bug na.action stan_glmer() (thanks Henrik Singmann)","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2151","dir":"Changelog","previous_headings":"","what":"rstanarm 2.15.1","title":"rstanarm 2.15.1","text":"Minor release changes allow tests pass CRAN","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2141","dir":"Changelog","previous_headings":"","what":"rstanarm 2.14.1","title":"rstanarm 2.14.1","text":"CRAN release: 2017-01-17","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-14-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.14.1","text":"VarCorr() return duplicates cases stan_{g}lmer model used grouping factor level names spaces pairs() function now works group-specific parameters stan_gamm4() function works better now Fix problem factor levels estimating model via stan_lm()","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-2-14-1","dir":"Changelog","previous_headings":"","what":"New features","title":"rstanarm 2.14.1","text":"New model-fitting function(s) stan_betareg() (stan_betareg.fit()) uses likelihoods supported betareg() function betareg package (Thanks Imad Ali) New choices priors coefficients: laplace(), lasso(), product_normal() hs() hs_plus() priors now new global_df global_scale arguments stan_{g}lmer() models group-specific intercept shifts considerably faster now Models Student t priors low degrees freedom (1, 2, 4) may work better now due Cornish-Fisher transformations Many functions priors gained autoscale argument defaults TRUE indicates rstanarm make internal changes prior based scales variables default priors weakly informative new compare_models() function extensive checking models compared compatible","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"deprecated-arguments-2-14-1","dir":"Changelog","previous_headings":"","what":"Deprecated arguments","title":"rstanarm 2.14.1","text":"prior_ops argument various model fitting functions deprecated replaced prior_aux argument prior auxiliary parameter various GLM-like models","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2131","dir":"Changelog","previous_headings":"","what":"rstanarm 2.13.1","title":"rstanarm 2.13.1","text":"CRAN release: 2016-11-20","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-13-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.13.1","text":"Fix bug reloo() data specified Fix bug pp_validate() introduced GitHub","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-2-13-1","dir":"Changelog","previous_headings":"","what":"New features","title":"rstanarm 2.13.1","text":"Uses new bayesplot rstantools R packages new prior_summary() function can used figure priors actually used stan_gamm4() better implemented, can followed plot_nonlinear(), posterior_predict() (newdata), etc. Hyperparameters (.e. covariance matrices general) lme4 style models now returned .matrix() .data.frame() pp_validate() can now used optimization variational Bayesian inference used estimate original model","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2121","dir":"Changelog","previous_headings":"","what":"rstanarm 2.12.1","title":"rstanarm 2.12.1","text":"CRAN release: 2016-09-13","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-12-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.12.1","text":"Fix bad bug posterior_predict() factor labels spaces lme4-style models Fix weights used Poisson models","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-2-12-1","dir":"Changelog","previous_headings":"","what":"New features","title":"rstanarm 2.12.1","text":"posterior_linpred() gains XZ argument output design matrix","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2111","dir":"Changelog","previous_headings":"","what":"rstanarm 2.11.1","title":"rstanarm 2.11.1","text":"CRAN release: 2016-07-29","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-11-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.11.1","text":"Requiring manually specifying offsets model offset newdata NULL","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-2-11-1","dir":"Changelog","previous_headings":"","what":"New features","title":"rstanarm 2.11.1","text":"stan_biglm() function somewhat supports biglm::biglm .array() method stanreg objects","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-2101","dir":"Changelog","previous_headings":"","what":"rstanarm 2.10.1","title":"rstanarm 2.10.1","text":"CRAN release: 2016-06-25","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-10-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.10.1","text":"Works devtools now","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-2-10-1","dir":"Changelog","previous_headings":"","what":"New features","title":"rstanarm 2.10.1","text":"k_threshold argument loo() PSIS-LOO+ kfold() K-fold CV Ability use sparse X matrices (slowly) many models memory issue","code":""},{"path":[]},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-10-1-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.10.1","text":"posterior_predict() newdata now works correctly ordinal models stan_lm() now works intercept omitted stan_glmer.fit() longer permit models duplicative group-specific terms since don’t make sense usually mistake user’s part posterior_predict() lme4-style models longer fails spaces colons levels grouping variables posterior_predict() ordinal models outputs character matrix now","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-2-10-1-1","dir":"Changelog","previous_headings":"","what":"New features","title":"rstanarm 2.10.1","text":"pp_validate() function based BayesValidate package Sam Cook posterior_vs_prior() function visualize effect conditioning data Works () R versions back 3.0.2 (untested though)","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-290-3","dir":"Changelog","previous_headings":"","what":"rstanarm 2.9.0-3","title":"rstanarm 2.9.0-3","text":"CRAN release: 2016-02-13","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"bug-fixes-2-9-0-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"rstanarm 2.9.0-3","text":"Fix problem models group-specific coefficients, mislabled. Although parameters estimated correctly, users previous versions rstanarm run models obtain correct summaries posterior predictions. Thanks someone named Luke pointing problem stan-users. Vignettes now view correctly CRAN webiste thanks Yihui Xie Fix problem models without intercepts thanks Paul-Christian Buerkner Fix problem specifying binomial ‘size’ posterior_predict using newdata Fix problem lme4-style formulas use grouping factor multiple times Fix conclusion rstanarm vignette thanks someone named Michael","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"new-features-2-9-0-3","dir":"Changelog","previous_headings":"","what":"New features","title":"rstanarm 2.9.0-3","text":"Group-specific design matrices kept sparse throughout reduce memory consumption log_lik() function now newdata argument New vignette hierarchical partial pooling","code":""},{"path":"https://mc-stan.org/rstanarm/news/index.html","id":"rstanarm-290-1","dir":"Changelog","previous_headings":"","what":"rstanarm 2.9.0-1","title":"rstanarm 2.9.0-1","text":"CRAN release: 2016-01-09 Initial CRAN release","code":""}]
