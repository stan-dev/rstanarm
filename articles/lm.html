<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- upstream: inst/BS5/templates/head.html; pkgdown-version: 2.1.3, fe04924 --><!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 --><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Estimating Regularized Linear Models with rstanarm • rstanarm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<!-- mathjax math --><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script><script>
  window.MathJax = {
    chtml: {
      fontURL: "https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2"
    }
  };
</script><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Source_Sans_3-0.4.10/font.css" rel="stylesheet">
<link href="../deps/Source_Code_Pro-0.4.10/font.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- Font Awesome 7.0.1 for Bluesky icon --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css" referrerpolicy="no-referrer">
<!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Estimating Regularized Linear Models with rstanarm">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <!-- upstream: inst/BS5/templates/navbar.html; pkgdown-version: 2.1.3, fe04924 -->
<!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 -->
<nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">


    <a class="navbar-brand me-2" href="../index.html">
      <!-- Add Stan logo -->
      <picture><source type="image/svg+xml" srcset="../logo.svg"><img src="../logo.png" class="stan-logo" alt="Stan blue hex logo"></source></picture>
      rstanarm
    </a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.32.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../index.html" aria-label="Go to homepage"><span class="fa fa-home fa-lg"></span></a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html">Vignettes</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Functions</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-other-packages" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Other Packages</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-other-packages">
<li><a class="external-link dropdown-item" href="https://mc-stan.org/bayesplot">bayesplot</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/cmdstanr">cmdstanr</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/loo">loo</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/posterior">posterior</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/projpred">projpred</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstan">rstan</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstantools">rstantools</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/shinystan">shinystan</a></li>
  </ul>
</li>
<li class="nav-item"><a class="external-link nav-link" href="https://mc-stan.org/about/">About Stan</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://bsky.app/profile/did:plc:qznndgdnkem2yryu7ipqbpv7" aria-label="Visit our Bluesky profile"><span class="fa fa-brands fa-bluesky"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://discourse.mc-stan.org/" aria-label="Visit our forums"><span class="fa fa-users"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/stan-dev/rstanarm/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Estimating Regularized Linear Models with rstanarm</h1>
                        <h4 data-toc-skip class="author">Jonah Gabry and
Ben Goodrich</h4>
            
            <h4 data-toc-skip class="date">2025-12-03</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/stan-dev/rstanarm/blob/New-pkgdown-theme/vignettes/lm.Rmd" class="external-link"><code>vignettes/lm.Rmd</code></a></small>
      <div class="d-none name"><code>lm.Rmd</code></div>
    </div>

    
    
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{stan_lm: Regularized Linear Models}
-->
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/bayesplot/" class="external-link">bayesplot</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/get_theme.html" class="external-link">theme_set</a></span><span class="op">(</span><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/theme_default.html" class="external-link">theme_default</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This vignette explains how to estimate linear models using the
<code>stan_lm</code> function in the <strong>rstanarm</strong>
package.</p>
<p>The four steps of a Bayesian analysis are</p>
<ol style="list-style-type: decimal">
<li>Specify a joint distribution for the outcome(s) and all the
unknowns, which typically takes the form of a marginal prior
distribution for the unknowns multiplied by a likelihood for the
outcome(s) conditional on the unknowns. This joint distribution is
proportional to a posterior distribution of the unknowns conditional on
the observed data</li>
<li>Draw from posterior distribution using Markov Chain Monte Carlo
(MCMC).</li>
<li>Evaluate how well the model fits the data and possibly revise the
model.</li>
<li>Draw from the posterior predictive distribution of the outcome(s)
given interesting values of the predictors in order to visualize how a
manipulation of a predictor affects (a function of) the outcome(s).</li>
</ol>
<p>Steps 3 and 4 are covered in more depth by the vignette entitled <a href="rstanarm.html">“How to Use the <strong>rstanarm</strong>
Package”</a>. This vignette focuses on Step 1 when the likelihood is the
product of independent normal distributions.</p>
<p>The goal of the <strong>rstanarm</strong> package is to make Bayesian
estimation of common regression models routine. That goal can be
partially accomplished by providing interfaces that are similar to the
popular formula-based interfaces to frequentist estimators of those
regression models. But fully accomplishing that goal sometimes entails
utilizing priors that applied researchers are unaware that they prefer.
These priors are intended to work well for any data that a user might
pass to the interface that was generated according to the assumptions of
the likelihood function.</p>
<p>It is important to distinguish between priors that are easy for
applied researchers to <em>specify</em> and priors that are easy for
applied researchers to <em>conceptualize</em>. The prior described below
emphasizes the former but we outline its derivation so that applied
researchers may feel more comfortable utilizing it.</p>
</div>
<div class="section level2">
<h2 id="likelihood">Likelihood<a class="anchor" aria-label="anchor" href="#likelihood"></a>
</h2>
<p>The likelihood for one observation under a linear model can be
written as a conditionally normal PDF <span class="math display">\[\frac{1}{\sigma_{\epsilon} \sqrt{2 \pi}}
  e^{-\frac{1}{2} \left(\frac{y -
\mu}{\sigma_{\epsilon}}\right)^2},\]</span> where <span class="math inline">\(\mu = \alpha + \mathbf{x}^\top
\boldsymbol{\beta}\)</span> is a linear predictor and <span class="math inline">\(\sigma_{\epsilon}\)</span> is the standard
deviation of the error in predicting the outcome, <span class="math inline">\(y\)</span>. The likelihood of the entire sample is
the product of <span class="math inline">\(N\)</span> individual
likelihood contributions.</p>
<p>It is well-known that the likelihood of the sample is maximized when
the sum-of-squared residuals is minimized, which occurs when <span class="math display">\[ \widehat{\boldsymbol{\beta}} =
\left(\mathbf{X}^\top \mathbf{X}\right)^{-1}
                                   \mathbf{X}^\top \mathbf{y}, \]</span>
<span class="math display">\[ \widehat{\alpha} = \overline{y} -
\overline{\mathbf{x}}^\top
                                     \widehat{\boldsymbol{\beta}},
\]</span> <span class="math display">\[ \widehat{\sigma}_{\epsilon}^2 =
  \frac{\left(\mathbf{y} - \widehat{\alpha} - \mathbf{X} \widehat{
                                              \boldsymbol{\beta}}\right)^\top
        \left(\mathbf{y} - \widehat{\alpha} - \mathbf{X} \widehat{
                                              \boldsymbol{\beta}}\right)}{N},\]</span>
where <span class="math inline">\(\overline{\mathbf{x}}\)</span> is a
vector that contains the sample means of the <span class="math inline">\(K\)</span> predictors, <span class="math inline">\(\mathbf{X}\)</span> is a <span class="math inline">\(N \times K\)</span> matrix of <em>centered</em>
predictors, <span class="math inline">\(\mathbf{y}\)</span> is a <span class="math inline">\(N\)</span>-vector of outcomes and <span class="math inline">\(\overline{y}\)</span> is the sample mean of the
outcome.</p>
</div>
<div class="section level2">
<h2 id="qr-decomposition">QR Decomposition<a class="anchor" aria-label="anchor" href="#qr-decomposition"></a>
</h2>
<p>The <code>lm</code> function in R actually performs a QR
decomposition of the design matrix, <span class="math inline">\(\mathbf{X} = \mathbf{Q}\mathbf{R}\)</span>, where
<span class="math inline">\(\mathbf{Q}^\top \mathbf{Q} =
\mathbf{I}\)</span> and <span class="math inline">\(\mathbf{R}\)</span>
is upper triangular. Thus, the OLS solution for the coefficients can be
written as <span class="math inline">\(\left(\mathbf{X}^\top
\mathbf{X}\right)^{-1} \mathbf{X}^\top \mathbf{y} =
  \mathbf{R}^{-1} \mathbf{Q}^\top \mathbf{y}\)</span>. The
<code>lm</code> function utilizes the QR decomposition for numeric
stability reasons, but the QR decomposition is also useful for thinking
about priors in a Bayesian version of the linear model. In addition,
writing the likelihood in terms of <span class="math inline">\(\mathbf{Q}\)</span> allows it to be evaluated in a
very efficient manner in Stan.</p>
</div>
<div class="section level2">
<h2 id="priors">Priors<a class="anchor" aria-label="anchor" href="#priors"></a>
</h2>
<p>The key innovation in the <code>stan_lm</code> function in the
<strong>rstanarm</strong> package is the prior for the parameters in the
QR-reparameterized model. To understand this prior, think about the
equations that characterize the maximum likelihood solutions before
observing the data on <span class="math inline">\(\mathbf{X}\)</span>
and especially <span class="math inline">\(\mathbf{y}\)</span>.</p>
<p>What would the prior distribution of <span class="math inline">\(\boldsymbol{\theta} = \mathbf{Q}^\top
\mathbf{y}\)</span> be? We can write its <span class="math inline">\(k\)</span>-th element as <span class="math inline">\(\theta_k = \rho_k \sigma_Y \sqrt{N - 1}\)</span>
where <span class="math inline">\(\rho_k\)</span> is the correlation
between the <span class="math inline">\(k\)</span>th column of <span class="math inline">\(\mathbf{Q}\)</span> and the outcome, <span class="math inline">\(\sigma_Y\)</span> is the standard deviation of the
outcome, and <span class="math inline">\(\frac{1}{\sqrt{N-1}}\)</span>
is the standard deviation of the <span class="math inline">\(k\)</span>
column of <span class="math inline">\(\mathbf{Q}\)</span>. Then let
<span class="math inline">\(\boldsymbol{\rho} =
\sqrt{R^2}\mathbf{u}\)</span> where <span class="math inline">\(\mathbf{u}\)</span> is a unit vector that is
uniformly distributed on the surface of a hypersphere. Consequently,
<span class="math inline">\(R^2 = \boldsymbol{\rho}^\top
\boldsymbol{\rho}\)</span> is the familiar coefficient of determination
for the linear model.</p>
<p>An uninformative prior on <span class="math inline">\(R^2\)</span>
would be standard uniform, which is a special case of a Beta
distribution with both shape parameters equal to <span class="math inline">\(1\)</span>. A non-uniform prior on <span class="math inline">\(R^2\)</span> is somewhat analogous to ridge
regression, which is popular in data mining and produces better
out-of-sample predictions than least squares because it penalizes <span class="math inline">\(\boldsymbol{\beta}^\top
\boldsymbol{\beta}\)</span>, usually after standardizing the predictors.
An informative prior on <span class="math inline">\(R^2\)</span>
effectively penalizes <span class="math inline">\(\boldsymbol{\rho}\top
\boldsymbol{\rho}\)</span>, which encourages <span class="math inline">\(\boldsymbol{\beta} = \mathbf{R}^{-1}
\boldsymbol{\theta}\)</span> to be closer to the origin.</p>
<p>Lewandowski, Kurowicka, and Joe (2009) derives a distribution for a
correlation matrix that depends on a single shape parameter <span class="math inline">\(\eta &gt; 0\)</span>, which implies the variance
of one variable given the remaining <span class="math inline">\(K\)</span> variables is <span class="math inline">\(\mathrm{Beta}\left(\eta,\frac{K}{2}\right)\)</span>.
Thus, the <span class="math inline">\(R^2\)</span> is distributed <span class="math inline">\(\mathrm{Beta}\left(\frac{K}{2},\eta\right)\)</span>
and any prior information about the location of <span class="math inline">\(R^2\)</span> can be used to choose a value of the
hyperparameter <span class="math inline">\(\eta\)</span>. The
<code>R2(location, what)</code> function in the
<strong>rstanarm</strong> package supports four ways of choosing <span class="math inline">\(\eta\)</span>:</p>
<ol style="list-style-type: decimal">
<li>
<code>what = "mode"</code> and <code>location</code> is some prior
mode on the <span class="math inline">\(\left(0,1\right)\)</span>
interval. This is the default but since the mode of a <span class="math inline">\(\mathrm{Beta}\left(\frac{K}{2},\eta\right)\)</span>
distribution is <span class="math inline">\(\frac{\frac{K}{2} -
1}{\frac{K}{2} + \eta - 2}\)</span> the mode only exists if <span class="math inline">\(K &gt; 2\)</span>. If <span class="math inline">\(K \leq 2\)</span>, then the user must specify
something else for <code>what</code>.</li>
<li>
<code>what = "mean"</code> and <code>location</code> is some prior
mean on the <span class="math inline">\(\left(0,1\right)\)</span>
interval, where the mean of a <span class="math inline">\(\mathrm{Beta}\left(\frac{K}{2},\eta\right)\)</span>
distribution is <span class="math inline">\(\frac{\frac{K}{2}}{\frac{K}{2} +
\eta}\)</span>.</li>
<li>
<code>what = "median"</code> and <code>location</code> is some prior
median on the <span class="math inline">\(\left(0,1\right)\)</span>
interval. The median of a <span class="math inline">\(\mathrm{Beta}\left(\frac{K}{2},\eta\right)\)</span>
distribution is not available in closed form but if <span class="math inline">\(K &gt; 2\)</span> it is approximately equal to
<span class="math inline">\(\frac{\frac{K}{2} - \frac{1}{3}}{\frac{K}{2}
+ \eta - \frac{2}{3}}\)</span>. Regardless of whether <span class="math inline">\(K &gt; 2\)</span>, the <code>R2</code> function
can numerically solve for the value of <span class="math inline">\(\eta\)</span> that is consistent with a given
prior median utilizing the quantile function.</li>
<li>
<code>what = "log"</code> and <code>location</code> is some
(negative) prior value for <span class="math inline">\(\mathbb{E} \ln
R^2 = \psi\left(\frac{K}{2}\right)-
  \psi\left(\frac{K}{2}+\eta\right)\)</span>, where <span class="math inline">\(\psi\left(\cdot\right)\)</span> is the
<code>digamma</code> function. Again, given a prior value for the
left-hand side it is easy to numerically solve for the corresponding
value of <span class="math inline">\(\eta\)</span>.</li>
</ol>
<p>There is no default value for the <code>location</code> argument of
the <code>R2</code> function. This is an <em>informative</em> prior on
<span class="math inline">\(R^2\)</span>, which must be chosen by the
user in light of the research project. However, specifying
<code>location = 0.5</code> is often safe, in which case <span class="math inline">\(\eta = \frac{K}{2}\)</span> regardless of whether
<code>what</code> is <code>"mode"</code>, <code>"mean"</code>, or
<code>"median"</code>. In addition, it is possible to specify
<code>NULL</code>, in which case a standard uniform on <span class="math inline">\(R^2\)</span> is utilized.</p>
<p>We set <span class="math inline">\(\sigma_y = \omega s_y\)</span>
where <span class="math inline">\(s_y\)</span> is the sample standard
deviation of the outcome and <span class="math inline">\(\omega &gt;
0\)</span> is an unknown scale parameter to be estimated. The only prior
for <span class="math inline">\(\omega\)</span> that does not contravene
Bayes’ theorem in this situation is Jeffreys prior, <span class="math inline">\(f\left(\omega\right) \propto
\frac{1}{\omega}\)</span>, which is proportional to a Jeffreys prior on
the unknown <span class="math inline">\(\sigma_y\)</span>, <span class="math inline">\(f\left(\sigma_y\right) \propto \frac{1}{\sigma_y}
=
\frac{1}{\omega \widehat{\sigma}_y} \propto \frac{1}{\omega}\)</span>.
This parameterization and prior makes it easy for Stan to work with any
continuous outcome variable, no matter what its units of measurement
are.</p>
<p>It would seem that we need a prior for <span class="math inline">\(\sigma_{\epsilon}\)</span>, but our prior beliefs
about <span class="math inline">\(\sigma_{\epsilon} = \omega s_y \sqrt{1
- R^2}\)</span> are already implied by our prior beliefs about <span class="math inline">\(\omega\)</span> and <span class="math inline">\(R^2\)</span>. That only leaves a prior for <span class="math inline">\(\alpha = \overline{y} - \overline{\mathbf{x}}^\top
\mathbf{R}^{-1} \boldsymbol{\theta}\)</span>. The default choice is an
improper uniform prior, but a normal prior can also be specified such as
one with mean zero and standard deviation <span class="math inline">\(\frac{\sigma_y}{\sqrt{N}}\)</span>.</p>
</div>
<div class="section level2">
<h2 id="posterior">Posterior<a class="anchor" aria-label="anchor" href="#posterior"></a>
</h2>
<p>The previous sections imply a posterior distribution for <span class="math inline">\(\omega\)</span>, <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\mathbf{u}\)</span>, and <span class="math inline">\(R^2\)</span>. The parameters of interest can then
be recovered as generated quantities:</p>
<ul>
<li><span class="math inline">\(\sigma_y = \omega s_y\)</span></li>
<li><span class="math inline">\(\sigma_{\epsilon} = \sigma_y \sqrt{1 -
R^2}\)</span></li>
<li><span class="math inline">\(\boldsymbol{\beta} = \mathbf{R}^{-1}
\mathbf{u} \sigma_y
\sqrt{R^2 \left(N-1\right)}\)</span></li>
</ul>
<p>The implementation actually utilizes an improper uniform prior on
<span class="math inline">\(\ln \omega\)</span>. Consequently, if <span class="math inline">\(\ln \omega = 0\)</span>, then the marginal
standard deviation of the outcome <em>implied by the model</em> is the
same as the sample standard deviation of the outcome. If <span class="math inline">\(\ln \omega &gt; 0\)</span>, then the marginal
standard deviation of the outcome implied by the model exceeds the
sample standard deviation, so the model overfits the data. If <span class="math inline">\(\ln \omega &lt; 0\)</span>, then the marginal
standard deviation of the outcome implied by the model is less than the
sample standard deviation, so the model <em>underfits</em> the data or
that the data-generating process is nonlinear. Given the regularizing
nature of the prior on <span class="math inline">\(R^2\)</span>, a minor
underfit would be considered ideal if the goal is to obtain good
out-of-sample predictions. If the model badly underfits or overfits the
data, then you may want to reconsider the model.</p>
</div>
<div class="section level2">
<h2 id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h2>
<p>We will utilize an example from the <strong>HSAUR3</strong> package
by Brian S. Everitt and Torsten Hothorn, which is used in their 2014
book <em>A Handbook of Statistical Analyses Using R (3rd Edition)</em>
(Chapman &amp; Hall / CRC). This book is frequentist in nature and we
will show how to obtain the corresponding Bayesian results.</p>
<p>The model in section 5.3.1 analyzes an experiment where clouds were
seeded with different amounts of silver iodide to see if there was
increased rainfall. This effect could vary according to covariates,
which (except for <code>time</code>) are interacted with the treatment
variable. Most people would probably be skeptical that cloud hacking
could explain very much of the variation in rainfall and thus the prior
mode of the <span class="math inline">\(R^2\)</span> would probably be
fairly small.</p>
<p>The frequentist estimator of this model can be replicated by
executing</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"clouds"</span>, package <span class="op">=</span> <span class="st">"HSAUR3"</span><span class="op">)</span></span>
<span><span class="va">ols</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">rainfall</span> <span class="op">~</span> <span class="va">seeding</span> <span class="op">*</span> <span class="op">(</span><span class="va">sne</span> <span class="op">+</span> <span class="va">cloudcover</span> <span class="op">+</span> <span class="va">prewetness</span> <span class="op">+</span> <span class="va">echomotion</span><span class="op">)</span> <span class="op">+</span></span>
<span>            <span class="va">time</span>, data <span class="op">=</span> <span class="va">clouds</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">ols</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<pre><code>                    (Intercept)                      seedingyes 
                         -0.346                          15.683 
                            sne                      cloudcover 
                          0.420                           0.388 
                     prewetness            echomotionstationary 
                          4.108                           3.153 
                           time                  seedingyes:sne 
                         -0.045                          -3.197 
          seedingyes:cloudcover           seedingyes:prewetness 
                         -0.486                          -2.557 
seedingyes:echomotionstationary 
                         -0.562 </code></pre>
<p>Note that we have <em>not</em> looked at the estimated <span class="math inline">\(R^2\)</span> or <span class="math inline">\(\sigma\)</span> for the ordinary least squares
model. We can estimate a Bayesian version of this model by prepending
<code>stan_</code> to the <code>lm</code> call, specifying a prior mode
for <span class="math inline">\(R^2\)</span>, and optionally specifying
how many cores the computer may utilize:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/rstanarm/">rstanarm</a></span><span class="op">)</span></span>
<span><span class="va">post</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="../reference/stan_lm.html">stan_lm</a></span><span class="op">(</span></span>
<span>    <span class="va">rainfall</span> <span class="op">~</span> <span class="va">seeding</span> <span class="op">*</span> <span class="op">(</span><span class="va">sne</span> <span class="op">+</span> <span class="va">cloudcover</span> <span class="op">+</span> <span class="va">prewetness</span> <span class="op">+</span> <span class="va">echomotion</span><span class="op">)</span> <span class="op">+</span> <span class="va">time</span>,</span>
<span>    data <span class="op">=</span> <span class="va">clouds</span>,</span>
<span>    prior <span class="op">=</span> <span class="fu"><a href="../reference/priors.html">R2</a></span><span class="op">(</span>location <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span>,</span>
<span>    seed <span class="op">=</span> <span class="fl">12345</span></span>
<span>  <span class="op">)</span></span>
<span><span class="va">post</span></span></code></pre></div>
<pre><code>stan_lm
 family:       gaussian [identity]
 formula:      rainfall ~ seeding * (sne + cloudcover + prewetness + echomotion) + 
       time
 observations: 24
 predictors:   11
------
                                Median MAD_SD
(Intercept)                      2.4    2.3  
seedingyes                       6.8    3.8  
sne                              0.2    0.7  
cloudcover                       0.2    0.2  
prewetness                       1.7    2.8  
echomotionstationary             1.4    1.5  
time                             0.0    0.0  
seedingyes:sne                  -1.4    1.0  
seedingyes:cloudcover           -0.2    0.2  
seedingyes:prewetness           -1.1    3.5  
seedingyes:echomotionstationary -0.2    2.0  

Auxiliary parameter(s):
              Median MAD_SD
R2            0.3    0.1   
log-fit_ratio 0.0    0.1   
sigma         2.6    0.4   

------
* For help interpreting the printed output see ?print.stanreg
* For info on the priors used see ?prior_summary.stanreg</code></pre>
<p>In this case, the “Bayesian point estimates”, which are represented
by the posterior medians, appear quite different from the ordinary least
squares estimates. However, the <code>log-fit_ratio</code> (i.e. <span class="math inline">\(\ln \omega\)</span>) is quite small, indicating
that the model only slightly overfits the data when the prior derived
above is utilized. Thus, it would be safe to conclude that the ordinary
least squares estimator considerably overfits the data since there are
only <span class="math inline">\(24\)</span> observations to estimate
<span class="math inline">\(12\)</span> parameters with and no prior
information on the parameters.</p>
<p>Also, it is not obvious what the estimated average treatment effect
is since the treatment variable, <code>seeding</code>, is interacted
with four other correlated predictors. However, it is easy to estimate
or visualize the average treatment effect (ATE) using
<strong>rstanarm</strong>’s <code>posterior_predict</code> function.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">clouds_cf</span> <span class="op">&lt;-</span> <span class="va">clouds</span></span>
<span><span class="va">clouds_cf</span><span class="op">$</span><span class="va">seeding</span><span class="op">[</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"yes"</span></span>
<span><span class="va">y1_rep</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/posterior_predict.stanreg.html">posterior_predict</a></span><span class="op">(</span><span class="va">post</span>, newdata <span class="op">=</span> <span class="va">clouds_cf</span><span class="op">)</span></span>
<span><span class="va">clouds_cf</span><span class="op">$</span><span class="va">seeding</span><span class="op">[</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">"no"</span></span>
<span><span class="va">y0_rep</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/posterior_predict.stanreg.html">posterior_predict</a></span><span class="op">(</span><span class="va">post</span>, newdata <span class="op">=</span> <span class="va">clouds_cf</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/qplot.html" class="external-link">qplot</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">y1_rep</span> <span class="op">-</span> <span class="va">y0_rep</span><span class="op">)</span>, geom <span class="op">=</span> <span class="st">"histogram"</span>, xlab <span class="op">=</span> <span class="st">"Estimated ATE"</span><span class="op">)</span></span></code></pre></div>
<p><img src="lm_files/figure-html/lm-clouds-ate-plot-1.png" class="r-plt" width="60%" style="display: block; margin: auto;"></p>
<p>As can be seen, the treatment effect is not estimated precisely and
is as almost as likely to be negative as it is to be positive.</p>
</div>
<div class="section level2">
<h2 id="alternative-approach">Alternative Approach<a class="anchor" aria-label="anchor" href="#alternative-approach"></a>
</h2>
<p>The prior derived above works well in many situations and is quite
simple to <em>use</em> since it only requires the user to specify the
prior location of the <span class="math inline">\(R^2\)</span>.
Nevertheless, the implications of the prior are somewhat difficult to
<em>conceptualize</em>. Thus, it is perhaps worthwhile to compare to
another estimator of a linear model that simply puts independent Cauchy
priors on the regression coefficients. This simpler approach can be
executed by calling the <code>stan_glm</code> function with
<code>family = gaussian()</code> and specifying the priors:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">simple</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="../reference/stan_glm.html">stan_glm</a></span><span class="op">(</span></span>
<span>    <span class="va">rainfall</span> <span class="op">~</span> <span class="va">seeding</span> <span class="op">*</span> <span class="op">(</span><span class="va">sne</span> <span class="op">+</span> <span class="va">cloudcover</span> <span class="op">+</span> <span class="va">prewetness</span> <span class="op">+</span> <span class="va">echomotion</span><span class="op">)</span> <span class="op">+</span> <span class="va">time</span>,</span>
<span>    data <span class="op">=</span> <span class="va">clouds</span>,</span>
<span>    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">gaussian</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    prior <span class="op">=</span> <span class="fu"><a href="../reference/priors.html">cauchy</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    prior_intercept <span class="op">=</span> <span class="fu"><a href="../reference/priors.html">cauchy</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    seed <span class="op">=</span> <span class="fl">12345</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>We can compare the two approaches using an approximation to
Leave-One-Out (LOO) cross-validation, which is implemented by the
<code>loo</code> function in the <strong>loo</strong> package.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">loo_post</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/loo.stanreg.html">loo</a></span><span class="op">(</span><span class="va">post</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>
Computed from 4000 by 24 log-likelihood matrix.

         Estimate   SE
elpd_loo    -60.3  5.3
p_loo         5.9  2.4
looic       120.5 10.6
------
MCSE of elpd_loo is 0.1.
MCSE and ESS estimates assume independent draws (r_eff=1).

All Pareto k estimates are good (k &lt; 0.7).
See help('pareto-k-diagnostic') for details.</code></pre>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/loo.stanreg.html">loo_compare</a></span><span class="op">(</span><span class="va">loo_post</span>, <span class="fu"><a href="../reference/loo.stanreg.html">loo</a></span><span class="op">(</span><span class="va">simple</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>Warning: Found 3 observation(s) with a pareto_k &gt; 0.7. We recommend calling 'loo' again with argument 'k_threshold = 0.7' in order to calculate the ELPD without the assumption that these observations are negligible. This will refit the model 3 times to compute the ELPDs for the problematic observations directly.</code></pre>
<pre><code>       elpd_diff se_diff
post    0.0       0.0   
simple -0.9       3.0   </code></pre>
<p>The results indicate that the first approach is expected to produce
better out-of-sample predictions but the Warning messages are at least
as important. Many of the estimated shape parameters for the Generalized
Pareto distribution are above <span class="math inline">\(0.5\)</span>
in the model with Cauchy priors, which indicates that these estimates
are only going to converge slowly to the true out-of-sample deviance
measures. Thus, with only <span class="math inline">\(24\)</span>
observations, they should not be considered reliable. The more
complicated prior derived above is stronger — as evidenced by the fact
that the effective number of parameters is about half of that in the
simpler approach and <span class="math inline">\(12\)</span> for the
maximum likelihood estimator — and only has a few of the <span class="math inline">\(24\)</span> Pareto shape estimates in the “danger
zone”. We might want to reexamine these observations</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">loo_post</span>, label_points <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="lm_files/figure-html/lm-clouds-plot-loo-1.png" class="r-plt" width="60%" style="display: block; margin: auto;"></p>
<p>because the posterior is sensitive to them but, overall, the results
seem tolerable.</p>
<p>In general, we would expect the joint prior derived here to work
better when there are many predictors relative to the number of
observations. Placing independent, heavy-tailed priors on the
coefficients neither reflects the beliefs of the researcher nor conveys
enough information to stabilize all the computations.</p>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>This vignette has discussed the prior distribution utilized in the
<code>stan_lm</code> function, which has the same likelihood and a
similar syntax as the <code>lm</code> function in R but adds the ability
to expression prior beliefs about the location of the <span class="math inline">\(R^2\)</span>, which is the familiar proportion of
variance in the outcome variable that is attributable to the predictors
under a linear model. Since the <span class="math inline">\(R^2\)</span>
is a well-understood bounded scalar, it is easy to specify prior
information about it, whereas other Bayesian approaches require the
researcher to specify a joint prior distribution for the regression
coefficients (and the intercept and error variance).</p>
<p>However, most researchers have little inclination to specify all
these prior distributions thoughtfully and take a short-cut by
specifying one prior distribution that is taken to apply to all the
regression coefficients as if they were independent of each other (and
the intercept and error variance). This short-cut is available in the
<code>stan_glm</code> function and is described in more detail in other
<strong>rstanarm</strong> vignettes for Generalized Linear Models
(GLMs), which can be found by navigating up one level.</p>
<p>We are optimistic that this prior on the <span class="math inline">\(R^2\)</span> will greatly help in accomplishing
our goal for <strong>rstanarm</strong> of making Bayesian estimation of
regression models routine. The same approach is used to specify a prior
in ANOVA models (see <code>stan_aov</code>) and proportional-odds models
for ordinal outcomes (see <code>stan_polr</code>).</p>
<p>Finally, the <code>stan_biglm</code> function can be used when the
design matrix is too large for the <code>qr</code> function to process.
The <code>stan_biglm</code> function inputs the output of the
<code>biglm</code> function in the <strong>biglm</strong> package, which
utilizes an incremental QR decomposition that does not require the
entire dataset to be loaded into memory simultaneously. However, the
<code>biglm</code> function needs to be called in a particular way in
order to work with <code>stan_biglm</code>. In particular, The means of
the columns of the design matrix, the sample mean of the outcome, and
the sample standard deviation of the outcome all need to be passed to
the <code>stan_biglm</code> function, as well as a flag indicating
whether the model really does include an intercept. Also, the number of
columns of the design matrix currently cannot exceed the number of rows.
Although <code>stan_biglm</code> should run fairly quickly and without
much memory, the resulting object is a fairly plain <code>stanfit</code>
object rather than an enhanced <code>stanreg</code> object like that
produced by <code>stan_lm</code>. Many of the enhanced capabilities of a
<code>stanreg</code> object depend on being able to access the full
design matrix, so doing posterior predictions, posterior checks, etc.
with the output of <code>stan_biglm</code> would require some custom R
code.</p>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>Lewandowski, D., Kurowicka D., and Joe, H. (2009). Generating random
correlation matrices based on vines and extended onion method.
<em>Journal of Multivariate Analysis</em>. <strong>100</strong>(9),
1989–2001.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Jonah Gabry, Ben Goodrich.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
