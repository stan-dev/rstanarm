<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- upstream: inst/BS5/templates/head.html; pkgdown-version: 2.1.3, fe04924 --><!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 --><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Hierarchical Partial Pooling for Repeated Binary Trials • rstanarm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<!-- mathjax math --><script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@4.0.0/tex-mml-chtml.js" integrity="sha256-qoRlVrS5NAnXSSSiMfFXwK8C9obG11Iybe4h2+bQYR4=" crossorigin="anonymous">
  </script><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Source_Sans_3-0.4.10/font.css" rel="stylesheet">
<link href="../deps/Source_Code_Pro-0.4.10/font.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- Font Awesome 7.0.1 for Bluesky icon --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css" referrerpolicy="no-referrer">
<!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Hierarchical Partial Pooling for Repeated Binary Trials">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <!-- upstream: inst/BS5/templates/navbar.html; pkgdown-version: 2.1.3, fe04924 -->
<!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 -->
<nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">


    <a class="navbar-brand me-2" href="../index.html">
      <!-- Add Stan logo -->
      <picture><source type="image/svg+xml" srcset="../logo.svg"><img src="../logo.png" class="stan-logo" alt="Stan blue hex logo"></source></picture>
      rstanarm
    </a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">2.32.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../index.html" aria-label="Go to homepage"><span class="fa fa-home fa-lg"></span></a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html">Vignettes</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Functions</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-other-packages" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Other Packages</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-other-packages">
<li><a class="external-link dropdown-item" href="https://mc-stan.org/bayesplot">bayesplot</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/cmdstanr">cmdstanr</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/loo">loo</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/posterior">posterior</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/projpred">projpred</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstan">rstan</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstantools">rstantools</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/shinystan">shinystan</a></li>
  </ul>
</li>
<li class="nav-item"><a class="external-link nav-link" href="https://mc-stan.org/about/">About Stan</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://bsky.app/profile/did:plc:qznndgdnkem2yryu7ipqbpv7" aria-label="Visit our Bluesky profile"><span class="fa fa-brands fa-bluesky"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://discourse.mc-stan.org/" aria-label="Visit our forums"><span class="fa fa-users"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/stan-dev/rstanarm/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Hierarchical Partial Pooling for Repeated Binary Trials</h1>
                        <h4 data-toc-skip class="author">Bob Carpenter,
Jonah Gabry and Ben Goodrich</h4>
            
            <h4 data-toc-skip class="date">2025-12-09</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/stan-dev/rstanarm/blob/New-pkgdown-theme/vignettes/pooling.Rmd" class="external-link"><code>vignettes/pooling.Rmd</code></a></small>
      <div class="d-none name"><code>pooling.Rmd</code></div>
    </div>

    
    
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Hierarchical Partial Pooling}
-->
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/bayesplot/" class="external-link">bayesplot</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/get_theme.html" class="external-link">theme_set</a></span><span class="op">(</span><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/theme_default.html" class="external-link">theme_default</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This vignette illustrates the effects on posterior inference of
pooling data (a.k.a sharing strength) across units for repeated binary
trial data. It provides R code to fit and check predictive models for
three situations: (a) complete pooling, which assumes each unit is the
same, (b) no pooling, which assumes the units are unrelated, and (c)
partial pooling, where the similarity among the units is estimated. The
note explains with working examples how to (i) fit the models using
<strong>rstanarm</strong> and plot the results, (ii) estimate event
probabilities, (iii) evaluate posterior predictive densities to evaluate
model predictions on held-out data, (iv) rank units by chance of
success, (v) perform multiple comparisons in several settings, (vi)
replicate new data for posterior <span class="math inline">\(p\)</span>-values, and (vii) perform graphical
posterior predictive checks.</p>
<p>The content of the vignette is based on Bob Carpenter’s Stan tutorial
<em><a href="https://mc-stan.org/users/documentation/case-studies/pool-binary-trials.html" class="external-link">Hierarchical
Partial Pooling for Repeated Binary Trials</a></em>, but here we show
how to fit the models and carry out predictions and model checking and
comparison using <strong>rstanarm</strong>. Most of the text is taken
from the original, with some additions and subtractions to make the
content more useful for <strong>rstanarm</strong> users. The Stan code
from the original tutorial has also been entirely removed, as
<strong>rstanarm</strong> will fit all of the models in Stan without the
user having to write the underlying Stan programs. The Stan code in the
original document is a good reference for anyone interested in how these
models are estimated “under-the-hood”, though the parameterizations used
internally by <strong>rstanarm</strong> differ somewhat from those in
the original.</p>
</div>
<div class="section level2">
<h2 id="repeated-binary-trials">Repeated Binary Trials<a class="anchor" aria-label="anchor" href="#repeated-binary-trials"></a>
</h2>
<p>Suppose that for each of <span class="math inline">\(N\)</span> units
<span class="math inline">\(n \in 1{:}N\)</span>, we observe <span class="math inline">\(y_n\)</span> successes out of <span class="math inline">\(K_n\)</span> trials. For example, the data may
consist of</p>
<ul>
<li><p>rat tumor development, with <span class="math inline">\(y_n\)</span> rats developing tumors of <span class="math inline">\(K_n\)</span> total rats in experimental control
group <span class="math inline">\(n \in 1{:}N\)</span> (Tarone
1982)</p></li>
<li><p>surgical mortality, with <span class="math inline">\(y_n\)</span>
surgical patients dying in <span class="math inline">\(K_n\)</span>
surgeries for hospitals <span class="math inline">\(n \in 1{:}N\)</span>
(Spiegelhalter et al. 1996)</p></li>
<li><p>baseball batting ability, with <span class="math inline">\(y_n\)</span> hits in <span class="math inline">\(K_n\)</span> at bats for baseball players <span class="math inline">\(n \in 1{:}N\)</span> (Efron and Morris 1975;
Carpenter 2009)</p></li>
<li><p>machine learning system accuracy, with <span class="math inline">\(y_n\)</span> correct classifications out of <span class="math inline">\(K_n\)</span> examples for systems <span class="math inline">\(n \in 1{:}N\)</span> (ML conference proceedings;
Kaggle competitions)</p></li>
</ul>
<p>In this vignette we use the small baseball data set of Efron and
Morris (1975), but we also provide the rat control data of Tarone
(1982), the surgical mortality data of Spiegelhalter et al. (1996) and
the extended baseball data set of Carpenter (2009).</p>
<div class="section level4">
<h4 id="baseball-hits-efron-and-morris-1975">Baseball Hits (Efron and Morris 1975)<a class="anchor" aria-label="anchor" href="#baseball-hits-efron-and-morris-1975"></a>
</h4>
<p>As a running example, we will use the data from Table 1 of (Efron and
Morris 1975), which is included in <strong>rstanarm</strong> under the
name <code>bball1970</code> (it was downloaded 24 Dec 2015 from <a href="https://www1.swarthmore.edu/NatSci/peverso1/Sports%20Data/JamesSteinData/Efron-Morris%20Baseball/EfronMorrisBB.txt" class="external-link">here</a>).
It is drawn from the 1970 Major League Baseball season (from both
leagues).</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mc-stan.org/rstanarm/">rstanarm</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">bball1970</span><span class="op">)</span></span>
<span><span class="va">bball</span> <span class="op">&lt;-</span> <span class="va">bball1970</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">bball</span><span class="op">)</span></span></code></pre></div>
<pre><code>       Player AB Hits RemainingAB RemainingHits
1    Clemente 45   18         367           127
2    Robinson 45   17         426           127
3      Howard 45   16         521           144
4   Johnstone 45   15         275            61
5       Berry 45   14         418           114
6     Spencer 45   14         466           126
7   Kessinger 45   13         586           155
8    Alvarado 45   12         138            29
9       Santo 45   11         510           137
10    Swaboda 45   11         200            46
11 Petrocelli 45   10         538           142
12  Rodriguez 45   10         186            42
13      Scott 45   10         435           132
14      Unser 45   10         277            73
15   Williams 45   10         591           195
16 Campaneris 45    9         558           159
17     Munson 45    8         408           129
18      Alvis 45    7          70            14</code></pre>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># A few quantities we'll use throughout</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">bball</span><span class="op">)</span></span>
<span><span class="va">K</span> <span class="op">&lt;-</span> <span class="va">bball</span><span class="op">$</span><span class="va">AB</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">bball</span><span class="op">$</span><span class="va">Hits</span></span>
<span><span class="va">K_new</span> <span class="op">&lt;-</span> <span class="va">bball</span><span class="op">$</span><span class="va">RemainingAB</span></span>
<span><span class="va">y_new</span> <span class="op">&lt;-</span> <span class="va">bball</span><span class="op">$</span><span class="va">RemainingHits</span></span></code></pre></div>
<p>The data separates the outcome from the initial 45 at-bats from the
rest of the season. After running this code, <code>N</code> is the
number of units (players). Then for each unit <code>n</code>,
<code>K[n]</code> is the number of initial trials (at-bats),
<code>y[n]</code> is the number of initial successes (hits),
<code>K_new[n]</code> is the remaining number of trials (remaining
at-bats), and <code>y_new[n]</code> is the number of successes in the
remaining trials (remaining hits).</p>
<p>The remaining data can be used to evaluate the predictive performance
of our models conditioned on the observed data. That is, we will “train”
on the first 45 at bats and see how well our various models do at
predicting the rest of the season.</p>
</div>
</div>
<div class="section level2">
<h2 id="pooling">Pooling<a class="anchor" aria-label="anchor" href="#pooling"></a>
</h2>
<p>With <em>complete pooling</em>, each unit is assumed to have the same
chance of success. With <em>no pooling</em>, each unit is assumed to
have a completely unrelated chance of success. With <em>partial
pooling</em>, each unit is assumed to have a different chance of
success, but the data for all of the observed units informs the
estimates for each unit.</p>
<p>Partial pooling is typically accomplished through hierarchical
models. Hierarchical models directly model the population of units. From
a population model perspective, no pooling corresponds to infinite
population variance, whereas complete pooling corresponds to zero
population variance.</p>
<p>In the following sections, all three types of pooling models will be
fit for the baseball data.</p>
</div>
<div class="section level2">
<h2 id="fitting-the-models">Fitting the Models<a class="anchor" aria-label="anchor" href="#fitting-the-models"></a>
</h2>
<p>First we’ll create some useful objects to use throughout the rest of
this vignette. One of them is a function <code>batting_avg</code>, which
just formats a number to include three decimal places to the right of
zero when printing, as is customary for batting averages.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">batting_avg</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/format.html" class="external-link">format</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">x</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>, nsmall <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>, quote <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">player_avgs</span> <span class="op">&lt;-</span> <span class="va">y</span> <span class="op">/</span> <span class="va">K</span> <span class="co"># player avgs through 45 AB</span></span>
<span><span class="va">tot_avg</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">K</span><span class="op">)</span> <span class="co"># overall avg through 45 AB</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Player averages through 45 at-bats:\n"</span><span class="op">)</span></span>
<span><span class="fu">batting_avg</span><span class="op">(</span><span class="va">player_avgs</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Overall average through 45 at-bats:\n"</span><span class="op">)</span></span>
<span><span class="fu">batting_avg</span><span class="op">(</span><span class="va">tot_avg</span><span class="op">)</span></span></code></pre></div>
<pre><code>Player averages through 45 at-bats:
 [1] 0.400 0.378 0.356 0.333 0.311 0.311 0.289 0.267 0.244 0.244 0.222 0.222
[13] 0.222 0.222 0.222 0.200 0.178 0.156
Overall average through 45 at-bats:
[1] 0.265</code></pre>
<div class="section level3">
<h3 id="complete-pooling">Complete Pooling<a class="anchor" aria-label="anchor" href="#complete-pooling"></a>
</h3>
<p>The complete pooling model assumes a single parameter <span class="math inline">\(\theta\)</span> representing the chance of success
for all units (in this case players).</p>
<p>Assuming each player’s at-bats are independent Bernoulli trials, the
probability distribution for each player’s number of hits <span class="math inline">\(y_n\)</span> is modeled as</p>
<p><span class="math display">\[
p(y_n \, | \, \theta)
\ = \
\mathsf{Binomial}(y_n \, | \, K_n, \theta).
\]</span></p>
<p>When viewed as a function of <span class="math inline">\(\theta\)</span> for fixed <span class="math inline">\(y_n\)</span>, this is called the likelihood
function.</p>
<p>Assuming each player is independent leads to the complete data
likelihood</p>
<p><span class="math display">\[
p(y \, | \, \theta) = \prod_{n=1}^N \mathsf{Binomial}(y_n \, | \, K_n,
\theta).
\]</span></p>
<p>Using <code>family=binomial("logit")</code>, the
<code>stan_glm</code> function in <strong>rstanarm</strong> will
parameterize the model in terms of the log-odds <span class="math inline">\(\alpha\)</span>, which are defined by the logit
transform as</p>
<p><span class="math display">\[
\alpha
= \mathrm{logit}(\theta)
= \log \, \frac{\theta}{1 - \theta}.
\]</span></p>
<p>For example, <span class="math inline">\(\theta = 0.25\)</span>
corresponds to odds of <span class="math inline">\(.25\)</span> to <span class="math inline">\(.75\)</span> (equivalently, <span class="math inline">\(1\)</span> to <span class="math inline">\(3\)</span>), or log-odds of <span class="math inline">\(\log .25 / .75 = -1.1\)</span>.</p>
<p>The model is therefore</p>
<p><span class="math display">\[
p(y_n \, | \, K_n, \alpha)
\ = \ \mathsf{Binomial}(y_n \, | \, K_n, \ \mathrm{logit}^{-1}(\alpha))
\]</span></p>
<p>The inverse logit function is the logistic <a href="https://en.wikipedia.org/wiki/Sigmoid_function" class="external-link">sigmoid</a> from
which logistic regression gets its name because the inverse logit
function is also the standard logistic Cumulative Distribution Function
(CDF),</p>
<p><span class="math display">\[
\mathrm{logit}^{-1}(\alpha) = \frac{1}{1 + \exp(-\alpha)} = \theta.
\]</span></p>
<p>By construction, for any <span class="math inline">\(\alpha \in
(-\infty, \infty)\)</span>, <span class="math inline">\(\mathrm{logit}^{-1}(\alpha) \in (0, 1)\)</span>;
the sigmoid converts arbitrary log odds back to the probability
scale.</p>
<p>We will use a normal distribution with mean <span class="math inline">\(-1\)</span> and standard deviation <span class="math inline">\(1\)</span> as the prior on the log-odds <span class="math inline">\(\alpha\)</span>. This is a weakly informative
prior that places about 95% of the prior probability in the interval
<span class="math inline">\((-3, 1)\)</span>, which inverse-logit
transforms to the interval <span class="math inline">\((0.05,
0.73)\)</span>. The prior median <span class="math inline">\(-1\)</span>
corresponds to a <span class="math inline">\(0.27\)</span> chance of
success. In fact, an even narrower prior is actually motivated here from
substantial baseball knowledge.</p>
<p>The figure below shows both this prior on <span class="math inline">\(\alpha\)</span> as well as the prior it implies on
the probability <span class="math inline">\(\theta\)</span>.</p>
<p><img src="pooling_files/figure-html/unnamed-chunk-2-1.png" class="r-plt" width="70%" style="display: block; margin: auto;"></p>
<p>To fit the model we call <code>stan_glm</code> with the formula
<code>cbind(Hits, AB - Hits) ~ 1</code>. The left-hand side of the
formula specifies the binomial outcome by providing the number of
successes (hits) and failures (at-bats) for each player, and the
right-hand side indicates that we want an intercept-only model.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">SEED</span> <span class="op">&lt;-</span> <span class="fl">101</span></span>
<span><span class="va">wi_prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/priors.html">normal</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>  <span class="co"># weakly informative prior on log-odds</span></span>
<span><span class="va">fit_pool</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/stan_glm.html">stan_glm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">Hits</span>, <span class="va">AB</span> <span class="op">-</span> <span class="va">Hits</span><span class="op">)</span> <span class="op">~</span> <span class="fl">1</span>, data <span class="op">=</span> <span class="va">bball</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">binomial</a></span><span class="op">(</span><span class="st">"logit"</span><span class="op">)</span>,</span>
<span>                     prior_intercept <span class="op">=</span> <span class="va">wi_prior</span>, seed <span class="op">=</span> <span class="va">SEED</span><span class="op">)</span></span></code></pre></div>
<p>The <code>summary</code> function will compute all sorts of summary
statistics from the fitted model, but here we’ll create a small function
that will compute just a few posterior summary statistics that we’ll
want for each of the models we estimate. The <code>summary_stats</code>
function, defined below, will take a matrix of posterior draws as its
input, apply an inverse-logit transformation (to convert from log-odds
to probabilities) and then compute the median and 80% interval.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">invlogit</span> <span class="op">&lt;-</span> <span class="va">plogis</span>  <span class="co"># function(x) 1/(1 + exp(-x))</span></span>
<span><span class="va">summary_stats</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/logit.html">invlogit</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span>  <span class="co"># log-odds -&gt; probabilities</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span>, <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">pool</span> <span class="op">&lt;-</span> <span class="fu">summary_stats</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">fit_pool</span><span class="op">)</span><span class="op">)</span>  <span class="co"># as.matrix extracts the posterior draws</span></span>
<span><span class="va">pool</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">pool</span>,  <span class="co"># replicate to give each player the same estimates</span></span>
<span>               <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">bball</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">pool</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>               dimnames <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">bball</span><span class="op">$</span><span class="va">Player</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"10%"</span>, <span class="st">"50%"</span>, <span class="st">"90%"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">batting_avg</span><span class="op">(</span><span class="va">pool</span><span class="op">)</span></span></code></pre></div>
<pre><code>           10%   50%   90%  
Clemente   0.245 0.265 0.285
Robinson   0.245 0.265 0.285
Howard     0.245 0.265 0.285
Johnstone  0.245 0.265 0.285
Berry      0.245 0.265 0.285
Spencer    0.245 0.265 0.285
Kessinger  0.245 0.265 0.285
Alvarado   0.245 0.265 0.285
Santo      0.245 0.265 0.285
Swaboda    0.245 0.265 0.285
Petrocelli 0.245 0.265 0.285
Rodriguez  0.245 0.265 0.285
Scott      0.245 0.265 0.285
Unser      0.245 0.265 0.285
Williams   0.245 0.265 0.285
Campaneris 0.245 0.265 0.285
Munson     0.245 0.265 0.285
Alvis      0.245 0.265 0.285</code></pre>
<p>With more data, such as from more players or from the rest of the
season, the posterior approaches a delta function around the maximum
likelihood estimate and the posterior interval around the central
posterior intervals will shrink. Nevertheless, even if we know a
player’s chance of success exactly, there is a large amount of
uncertainty in running <span class="math inline">\(K\)</span> binary
trials with that chance of success; using a binomial model fundamentally
bounds our prediction accuracy.</p>
<p>Although this model will be a good baseline for comparison, we have
good reason to believe from a large amount of prior data (players with
as many as 10,000 trials) that it is very unlikely that all baseball
players have the same chance of success.</p>
</div>
<div class="section level3">
<h3 id="no-pooling">No Pooling<a class="anchor" aria-label="anchor" href="#no-pooling"></a>
</h3>
<p>A model with no pooling involves a separate chance-of-success
parameter <span class="math inline">\(\theta_n \in [0,1]\)</span> for
each player <span class="math inline">\(n\)</span>, where the <span class="math inline">\(\theta_n\)</span> are assumed to be
independent.</p>
<p><strong>rstanarm</strong> will again parameterize the model in terms
of the log-odds, <span class="math inline">\(\alpha_n =
\mathrm{logit}(\theta_n)\)</span>, so the likelihood then uses the
log-odds of success <span class="math inline">\(\alpha_n\)</span> for
unit <span class="math inline">\(n\)</span> in modeling the number of
successes <span class="math inline">\(y_n\)</span> as</p>
<p><span class="math display">\[
p(y_n \, | \, \alpha_n) =
\mathsf{Binomial}(y_n \, | \, K_n, \mathrm{logit}^{-1}(\alpha_n)).
\]</span></p>
<p>Assuming the <span class="math inline">\(y_n\)</span> are independent
(conditional on <span class="math inline">\(\theta\)</span>), this leads
to the total data likelihood</p>
<p><span class="math display">\[
p(y \, | \, \alpha) = \prod_{n=1}^N \mathsf{Binomial}(y_n \, | \, K_n,
\mathrm{logit}^{-1}(\alpha_n)).
\]</span></p>
<p>To fit the model we need only tweak the model formula used for the
full pooling model to drop the intercept and instead include as the only
predictor the factor variable <code>Player</code>. This is equivalent to
estimating a separate intercept on the log-odds scale for each player.
We’ll also use the <code>prior</code> (rather than
<code>prior_intercept</code>) argument since <code>Player</code> is
considered a predictor rather than an intercept from R’s perspective.
Using the same weakly informative prior now means that the each <span class="math inline">\(\alpha_n\)</span> gets a <span class="math inline">\(\mathsf{Normal}(-1, 1)\)</span> prior, independent
of the others.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_nopool</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">fit_pool</span>, formula <span class="op">=</span> <span class="va">.</span> <span class="op">~</span> <span class="fl">0</span> <span class="op">+</span> <span class="va">Player</span>, prior <span class="op">=</span> <span class="va">wi_prior</span><span class="op">)</span></span>
<span><span class="va">nopool</span> <span class="op">&lt;-</span> <span class="fu">summary_stats</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">fit_nopool</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">nopool</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html" class="external-link">as.character</a></span><span class="op">(</span><span class="va">bball</span><span class="op">$</span><span class="va">Player</span><span class="op">)</span></span>
<span><span class="fu">batting_avg</span><span class="op">(</span><span class="va">nopool</span><span class="op">)</span></span></code></pre></div>
<pre><code>            
parameters   10%   50%   90%  
  Clemente   0.300 0.386 0.473
  Robinson   0.279 0.366 0.458
  Howard     0.263 0.344 0.435
  Johnstone  0.244 0.326 0.414
  Berry      0.227 0.305 0.393
  Spencer    0.226 0.306 0.389
  Kessinger  0.209 0.284 0.370
  Alvarado   0.190 0.266 0.352
  Santo      0.172 0.244 0.330
  Swaboda    0.172 0.243 0.328
  Petrocelli 0.154 0.223 0.305
  Rodriguez  0.157 0.226 0.305
  Scott      0.156 0.224 0.306
  Unser      0.156 0.225 0.303
  Williams   0.156 0.225 0.305
  Campaneris 0.138 0.204 0.282
  Munson     0.124 0.185 0.258
  Alvis      0.108 0.166 0.241</code></pre>
<p>Each 80% interval is much wider than the estimated interval for the
population in the complete pooling model; this is to be expected—there
are only 45 data units for each parameter here as opposed to 810 in the
complete pooling case. If the units each had different numbers of
trials, the intervals would also vary based on size.</p>
<p>As the estimated chance of success goes up toward 0.5, the 80%
intervals gets wider. This is to be expected for chance of success
parameters, because the variance is maximized when <span class="math inline">\(\theta = 0.5\)</span>.</p>
<p>Based on our existing knowledge of baseball, the no-pooling model is
almost certainly overestimating the high abilities and underestimating
lower abilities (Ted Williams, 30 years prior to the year this data was
collected, was the last player with a 40% observed success rate over a
season, whereas 20% or less is too low for all but a few rare defensive
specialists).</p>
</div>
<div class="section level3">
<h3 id="partial-pooling">Partial Pooling<a class="anchor" aria-label="anchor" href="#partial-pooling"></a>
</h3>
<p>Complete pooling provides estimated abilities that are too narrowly
distributed for the units and removes any chance of modeling population
variation. Estimating each chance of success separately without any
pooling provides estimated abilities that are too broadly distributed
for the units and hence too variable. Clearly some amount of pooling
between these two extremes is called for. But how much?</p>
<p>A hierarchical model treats the players as belonging to a population
of players. The properties of this population will be estimated along
with player abilities, implicitly controlling the amount of pooling that
is applied. The more variable the (estimate of the) population, the less
pooling is applied. Mathematically, the hierarchical model places a
prior on the abilities with parameters that are themselves
estimated.</p>
<p>This model can be estimated using the <code>stan_glmer</code>
function.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_partialpool</span> <span class="op">&lt;-</span> </span>
<span>  <span class="fu"><a href="../reference/stan_glmer.html">stan_glmer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">Hits</span>, <span class="va">AB</span> <span class="op">-</span> <span class="va">Hits</span><span class="op">)</span> <span class="op">~</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">Player</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">bball</span>, </span>
<span>             family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">binomial</a></span><span class="op">(</span><span class="st">"logit"</span><span class="op">)</span>,</span>
<span>             prior_intercept <span class="op">=</span> <span class="va">wi_prior</span>, seed <span class="op">=</span> <span class="va">SEED</span><span class="op">)</span></span></code></pre></div>
<p>Because <code>stan_glmer</code> (like <code>glmer</code>) estimates
the varying intercepts for <code>Player</code> by estimating a single
global intercept <span class="math inline">\(\alpha_0\)</span> and
individual deviations from that intercept for each player <span class="math inline">\(\delta_n = \alpha_n - \alpha_0\)</span>, to get
the posterior distribution for each <span class="math inline">\(\alpha_n\)</span> we need to shift each of the
posterior draws by the corresponding draw for the intercept. We can do
this easily using the <code>sweep</code> function.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># shift each player's estimate by intercept (and then drop intercept)</span></span>
<span><span class="va">shift_draws</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">draws</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/sweep.html" class="external-link">sweep</a></span><span class="op">(</span><span class="va">draws</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>, MARGIN <span class="op">=</span> <span class="fl">1</span>, STATS <span class="op">=</span> <span class="va">draws</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, FUN <span class="op">=</span> <span class="st">"+"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">alphas</span> <span class="op">&lt;-</span> <span class="fu">shift_draws</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">fit_partialpool</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">partialpool</span> <span class="op">&lt;-</span> <span class="fu">summary_stats</span><span class="op">(</span><span class="va">alphas</span><span class="op">)</span></span>
<span><span class="va">partialpool</span> <span class="op">&lt;-</span> <span class="va">partialpool</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">partialpool</span><span class="op">)</span>,<span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">partialpool</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html" class="external-link">as.character</a></span><span class="op">(</span><span class="va">bball</span><span class="op">$</span><span class="va">Player</span><span class="op">)</span></span>
<span><span class="fu">batting_avg</span><span class="op">(</span><span class="va">partialpool</span><span class="op">)</span></span></code></pre></div>
<pre><code>            
parameters   10%   50%   90%  
  Clemente   0.249 0.283 0.349
  Robinson   0.245 0.281 0.341
  Howard     0.243 0.277 0.331
  Johnstone  0.240 0.274 0.323
  Berry      0.238 0.271 0.317
  Spencer    0.235 0.271 0.316
  Kessinger  0.233 0.268 0.310
  Alvarado   0.229 0.265 0.303
  Santo      0.222 0.262 0.299
  Swaboda    0.223 0.262 0.298
  Petrocelli 0.216 0.258 0.294
  Rodriguez  0.218 0.259 0.293
  Scott      0.217 0.259 0.294
  Unser      0.217 0.258 0.293
  Williams   0.215 0.258 0.296
  Campaneris 0.211 0.255 0.290
  Munson     0.205 0.253 0.287
  Alvis      0.198 0.250 0.285</code></pre>
<p>Here the estimates are less extreme than in the no-pooling case,
which we should expect due to the partial pooling. It is also clear from
the wide posteriors for the <span class="math inline">\(\theta_n\)</span> that there is considerable
uncertainty in the estimates of chance-of-success on an unit-by-unit
(player-by-player) basis.</p>
</div>
<div class="section level3">
<h3 id="observed-vs--estimated-chance-of-success">Observed vs. Estimated Chance of Success<a class="anchor" aria-label="anchor" href="#observed-vs--estimated-chance-of-success"></a>
</h3>
<p>Figure 5.4 from (Gelman et al. 2013) plots the observed number of
successes <span class="math inline">\(y_n\)</span> for the first <span class="math inline">\(K_n\)</span> trials versus the median and 80%
intervals for the estimated chance-of-success parameters <span class="math inline">\(\theta_n\)</span> in the posterior. The following
R code reproduces a similar plot for our data.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="va">models</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"complete pooling"</span>, <span class="st">"no pooling"</span>, <span class="st">"partial pooling"</span><span class="op">)</span></span>
<span><span class="va">estimates</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">pool</span>, <span class="va">nopool</span>, <span class="va">partialpool</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">estimates</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"lb"</span>, <span class="st">"median"</span>, <span class="st">"ub"</span><span class="op">)</span></span>
<span><span class="va">plotdata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">estimates</span>, </span>
<span>                       observed <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">player_avgs</span>, times <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">models</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                       model <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">models</span>, each <span class="op">=</span> <span class="va">N</span><span class="op">)</span>, </span>
<span>                       row.names <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">plotdata</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">observed</span>, y <span class="op">=</span> <span class="va">median</span>, ymin <span class="op">=</span> <span class="va">lb</span>, ymax <span class="op">=</span> <span class="va">ub</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="va">tot_avg</span>, color <span class="op">=</span> <span class="st">"lightpink"</span>, size <span class="op">=</span> <span class="fl">0.75</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_abline</a></span><span class="op">(</span>intercept <span class="op">=</span> <span class="fl">0</span>, slope <span class="op">=</span> <span class="fl">1</span>, color <span class="op">=</span> <span class="st">"skyblue"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_linerange.html" class="external-link">geom_linerange</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"gray60"</span>, size <span class="op">=</span> <span class="fl">0.75</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">2.5</span>, shape <span class="op">=</span> <span class="fl">21</span>, fill <span class="op">=</span> <span class="st">"gray30"</span>, color <span class="op">=</span> <span class="st">"white"</span>, stroke <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_grid.html" class="external-link">facet_grid</a></span><span class="op">(</span><span class="va">.</span> <span class="op">~</span> <span class="va">model</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_fixed.html" class="external-link">coord_fixed</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Observed Hits / AB"</span>, y <span class="op">=</span> <span class="st">"Predicted chance of hit"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Posterior Medians and 80% Intervals"</span><span class="op">)</span></span></code></pre></div>
<p><img src="pooling_files/figure-html/plot-observed-vs-estimated-1.png" class="r-plt" width="70%" style="display: block; margin: auto;"></p>
<p>The horizontal axis is the observed rate of success, broken out by
player (the overplotting is from players with the same number of
successes—they all had the same number of trials in this data). The dots
are the posterior medians with bars extending to cover the central 80%
posterior interval. Players with the same observed rates are
indistinguishable, any differences in estimates are due to MCMC
error.</p>
<p>The horizontal red line has an intercept equal to the overall success
rate, The overall success rate is also the posterior mode (i.e., maximum
likelihood estimate) for the complete pooling model. The diagonal blue
line has intercept 0 and slope 1. Estimates falling on this line make up
the maximum likelihood estimates for the no-pooling model. Overall, the
plot makes the amount of pooling toward the prior evident.</p>
</div>
</div>
<div class="section level2">
<h2 id="posterior-predictive-distribution">Posterior Predictive Distribution<a class="anchor" aria-label="anchor" href="#posterior-predictive-distribution"></a>
</h2>
<p>After we have fit a model using some “training” data, we are usually
interested in the predictions of the fitted model for new data, which we
can use to</p>
<ul>
<li><p>make predictions for new data points; e.g., predict how many hits
will Roberto Clemente get in the rest of the season,</p></li>
<li><p>evaluate predictions against observed future data; e.g., how well
did we predict how many hits Roberto Clemente actually got in the rest
of the season, and</p></li>
<li><p>generate new simulated data to validate our model fits.</p></li>
</ul>
<p>With full Bayesian inference, we do not make a point estimate of
parameters and use those prediction—we instead use an average of
predictions weighted by the posterior.</p>
<p>Given data <span class="math inline">\(y\)</span> and a model with
parameters <span class="math inline">\(\theta\)</span>, the posterior
predictive distribution for new data <span class="math inline">\(\tilde{y}\)</span> is defined by</p>
<p><span class="math display">\[
p(\tilde{y} \, | \, y)
\ = \
\int_{\Theta} p(\tilde{y} \, | \, \theta) \ p(\theta \, | \, y) \
\mathrm{d}\theta,
\]</span></p>
<p>where <span class="math inline">\(\Theta\)</span> is the support of
the parameters <span class="math inline">\(\theta\)</span>. What an
integral of this form says is that <span class="math inline">\(p(\tilde{y} \, | \, y)\)</span> is defined as a
weighted average over the legal parameter values <span class="math inline">\(\theta \in
\Theta\)</span> of the likelihood function <span class="math inline">\(p(\tilde{y} \, | \, \theta)\)</span>, with weights
given by the posterior, <span class="math inline">\(p(\theta \, | \,
y)\)</span>. While we do not want to get sidetracked with the notational
and mathematical subtleties of expectations here, the posterior
predictive density reduces to the expectation of <span class="math inline">\(p(\tilde{y} \, | \, \theta)\)</span> conditioned
on <span class="math inline">\(y\)</span>.</p>
<div class="section level4">
<h4 id="evaluating-held-out-data-predictions">Evaluating Held-Out Data Predictions<a class="anchor" aria-label="anchor" href="#evaluating-held-out-data-predictions"></a>
</h4>
<p>Because the posterior predictive density is formulated as an
expectation over the posterior, it is possible to compute via MCMC. With
<span class="math inline">\(M\)</span> draws <span class="math inline">\(\theta^{(m)}\)</span> from the posterior <span class="math inline">\(p(\theta \, | \,
y)\)</span>, the posterior predictive log density for new data <span class="math inline">\(y^{\mathrm{new}}\)</span> is given by the MCMC
approximation</p>
<p><span class="math display">\[
\log \frac{1}{M} \, \sum_{m=1}^M \ p\left( y^{\mathrm{new}} \, | \,
\theta^{(m)} \right).
\]</span></p>
<p>In practice, this requires care to prevent underflow in floating
point calculations; a robust calculation on the log scale is provided
below.</p>
</div>
<div class="section level4">
<h4 id="simulating-replicated-data">Simulating Replicated Data<a class="anchor" aria-label="anchor" href="#simulating-replicated-data"></a>
</h4>
<p>It is also straightforward to use forward simulation from the
probability distribution of the data <span class="math inline">\(p(y \,
| \, \theta)\)</span> to generate replicated data <span class="math inline">\(y^{\mathrm{rep}}\)</span> according to the
posterior predictive distribution. (Recall that <span class="math inline">\(p(y \, | \, \theta)\)</span> is called the
probability distribution when <span class="math inline">\(\theta\)</span> is fixed and the likelihood when
<span class="math inline">\(y\)</span> is fixed.)</p>
<p>With <span class="math inline">\(M\)</span> draws <span class="math inline">\(\theta^{(m)}\)</span> from the posterior <span class="math inline">\(p(\theta \, | \,
y)\)</span>, replicated data can be simulated by drawing a sequence of
<span class="math inline">\(M\)</span> simulations according <span class="math inline">\(y^{\mathrm{rep} \ (m)}\)</span> with each drawn
according to distribution <span class="math inline">\(p(y \, | \,
\theta^{(m)})\)</span>. This latter random variate generation can
usually be done efficiently (both computationally and statistically) by
means of forward simulation from the probability distribution of the
data; we provide an example below.</p>
</div>
<div class="section level3">
<h3 id="prediction-for-new-trials">Prediction for New Trials<a class="anchor" aria-label="anchor" href="#prediction-for-new-trials"></a>
</h3>
<p>Efron and Morris’s (1975) baseball data includes not only the
observed hit rate in the initial 45 at bats, but also includes the data
for how the player did for the rest of the season. The question arises
as to how well these models predict a player’s performance for the rest
of the season based on their initial 45 at bats.</p>
<div class="section level4">
<h4 id="calibration">Calibration<a class="anchor" aria-label="anchor" href="#calibration"></a>
</h4>
<p>A well calibrated statistical model is one in which the uncertainty
in the predictions matches the uncertainty in further data. That is, if
we estimate posterior 50% intervals for predictions on new data (here,
number of hits in the rest of the season for each player), roughly 50%
of the new data should fall in its predicted 50% interval. If the model
is true in the sense of correctly describing the generative process of
the data, then Bayesian inference is guaranteed to be well calibrated.
Given that our models are rarely correct in this deep sense, in practice
we are concerned with testing their calibration on quantities of
interest.</p>
</div>
<div class="section level4">
<h4 id="sharpness">Sharpness<a class="anchor" aria-label="anchor" href="#sharpness"></a>
</h4>
<p>Given two well calibrated models, the one that makes the more precise
predictions in the sense of having narrower intervals is better
predictively (Gneiting et al. 2007). To see this in an example, we would
rather have a well-calibrated prediction that there’s a 90% chance the
number of hits for a player in the rest of the season will fall in <span class="math inline">\((120, 130)\)</span> than a 90% prediction that the
number of hits will fall in <span class="math inline">\((100,
150)\)</span>.</p>
<p>For the models introduced here, a posterior that is a delta function
provides the sharpest predictions. Even so, there is residual
uncertainty due to the repeated trials; with <span class="math inline">\(K^{\mathrm{new}}\)</span> further trials and a a
fixed <span class="math inline">\(\theta_n\)</span> chance of success,
the random variable <span class="math inline">\(Y^{\mathrm{new}}_n\)</span> denoting the number of
further successes for unit <span class="math inline">\(n\)</span> has a
standard deviation from the repeated binary trials of</p>
<p><span class="math display">\[
\mathrm{sd}[Y^{\mathrm{new}}_n] \ = \ \sqrt{K \
\theta \, (1 - \theta)}.
\]</span></p>
</div>
<div class="section level4">
<h4 id="why-evaluate-with-the-predictive-posterior">Why Evaluate with the Predictive Posterior?<a class="anchor" aria-label="anchor" href="#why-evaluate-with-the-predictive-posterior"></a>
</h4>
<p>The predictive posterior density directly measures the probability of
seeing the new data. The higher the probability assigned to the new
data, the better job the model has done at predicting the outcome. In
the limit, an ideal model would perfectly predict the new outcome with
no uncertainty (probability of 1 for a discrete outcome or a delta
function at the true value for the density in a continuous outcome).
This notion is related to the notion of sharpness discussed in the
previous section, because if the new observations have higher predictive
densities, they’re probably within narrower posterior intervals
(Gneiting et al. 2007).</p>
</div>
<div class="section level4">
<h4 id="log-eptildey-theta-vs-elog-ptildey-theta">
<span class="math inline">\(\log E[p(\tilde{y} \, | \,
\theta)]\)</span> vs <span class="math inline">\(E[\log p(\tilde{y} \, |
\, \theta)]\)</span><a class="anchor" aria-label="anchor" href="#log-eptildey-theta-vs-elog-ptildey-theta"></a>
</h4>
<p>The log of posterior predictive density is defined in the obvious way
as</p>
<p><span class="math display">\[
\log p(\tilde{y} \, | \, y)
= \log \int_{\Theta} p(\tilde{y} \, | \, \theta)
                     \ p(\theta \, | \, y)
                     \ \mathrm{d}\theta.
\]</span></p>
<p>This is not a posterior expectation, but rather the log of a
posterior expectation. In particular, it should not be confused with the
posterior expectation of the log predictive density, which is given
by</p>
<p><span class="math display">\[
\int_{\Theta} \left( \log p(\tilde{y} \, | \, \theta) \right)
               \ p(\theta \, | \, y)  
               \ \mathrm{d}\theta.
\]</span></p>
<p>Although this is easy to compute in Stan in a stable fashion, it does
not produce the same answer (as we show below).</p>
<p>Because <span class="math inline">\(-\log(u)\)</span> is convex, a
little wrangling with <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality" class="external-link">Jensen’s
inequality</a> shows that the expectation of the log is less than or
equal to the log of the expectation,</p>
<p><span class="math display">\[
\int_{\Theta} \left( \, \log p(\tilde{y} \, | \, \theta) \, \right) \
p(\theta \, | \, y) \ \mathrm{d}\theta
\ \leq \
\log \int_{\Theta} p(\tilde{y} \, | \, \theta) \ p(\theta \, | \, y) \
\mathrm{d}\theta
\]</span></p>
<p>We’ll compute both expectations and demonstrate Jensen’s inequality
in our running example.</p>
<p>The variables <code>K_new[n]</code> and <code>y_new[n]</code> hold
the number of at bats (trials) and the number of hits (successes) for
player (unit) <code>n</code>. With the held out data we can compute the
log density of each data point using the <code>log_lik</code> function,
which, like <code>posterior_predict</code>, accepts a
<code>newdata</code> argument. The <code>log_lik</code> function will
return an <span class="math inline">\(M \times N\)</span> matrix, where
<span class="math inline">\(M\)</span> is the size of the posterior
sample (the number of draws we obtained from the posterior distribution)
and <span class="math inline">\(N\)</span> is the number of data points
in <code>newdata</code>. We can then take the row sums of this matrix to
sum over the data points.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">newdata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Hits <span class="op">=</span> <span class="va">y_new</span>, AB <span class="op">=</span> <span class="va">K_new</span>, Player <span class="op">=</span> <span class="va">bball</span><span class="op">$</span><span class="va">Player</span><span class="op">)</span></span>
<span><span class="va">fits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>Pooling <span class="op">=</span> <span class="va">fit_pool</span>, </span>
<span>             NoPooling <span class="op">=</span> <span class="va">fit_nopool</span>, </span>
<span>             PartialPooling <span class="op">=</span> <span class="va">fit_partialpool</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># compute log_p_new matrix with each of the models in 'fits'</span></span>
<span><span class="va">log_p_new_mats</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">fits</span>, <span class="va">log_lik</span>, newdata <span class="op">=</span> <span class="va">newdata</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># for each matrix in the list take the row sums</span></span>
<span><span class="va">log_p_new</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="va">log_p_new_mats</span>, <span class="va">rowSums</span><span class="op">)</span></span>
<span><span class="va">M</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">log_p_new</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">log_p_new</span><span class="op">)</span></span></code></pre></div>
<pre><code>       Pooling NoPooling PartialPooling
[1,] -87.50510 -270.1454      -98.24389
[2,] -73.97575 -310.3988     -116.16486
[3,] -80.95743 -250.4451      -93.64268
[4,] -77.54662 -281.8998     -101.46736
[5,] -74.39093 -172.3741     -115.82690
[6,] -88.18157 -171.3092      -74.83273</code></pre>
<p>We now have the distributions of <code>log_p_new</code> in a matrix
with a column for each model.</p>
<p>For each model, the posterior mean for <code>log_p_new</code> will
give us</p>
<p><span class="math display">\[
\int_{\Theta} \left( \log p(\tilde{y} \, | \, \theta) \right)
               \ p(\theta \, | \, y)  
               \ \mathrm{d}\theta
\ \approx \
\frac{1}{M} \, \sum_{m=1}^M \log p(y^{\mathrm{new}} \, | \,
\theta^{(m)}).
\]</span></p>
<p>To compute this for each of the models we only need to take the mean
of the corresponding column of <code>log_p_new</code>.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mean_log_p_new</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">colMeans</a></span><span class="op">(</span><span class="va">log_p_new</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="va">mean_log_p_new</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>       Pooling PartialPooling      NoPooling 
         -81.8          -99.6         -207.8 </code></pre>
<p>From a predictive standpoint, the models are ranked by the amount of
pooling they do, with complete pooling being the best, and no pooling
being the worst predictively. All of these models do predictions by
averaging over their posteriors, with the amount of posterior
uncertainty also being ranked in reverse order of the amount of pooling
they do.</p>
<p>As we will now see, the ranking of the models can change when we
compute the posterior expectation of the log predictive density.</p>
<div class="section level5">
<h5 id="posterior-expectation-of-the-log-predictive-density">Posterior expectation of the log predictive density<a class="anchor" aria-label="anchor" href="#posterior-expectation-of-the-log-predictive-density"></a>
</h5>
<p>The straight path to calculate this would be to define a generated
quantity <span class="math inline">\(p(y^{\mathrm{new}} \, |
y)\)</span>, look at the posterior mean computed by Stan, and takes its
log. That is,</p>
<p><span class="math display">\[
\log p(y^{\mathrm{new}} \, | \, y)
\ \approx \
\log \frac{1}{M} \, \sum_{m=1}^M p(y^{\mathrm{new}} \, | \,
\theta^{(m)}).
\]</span></p>
<p>Unfortunately, this won’t work in most cases because when we try to
compute <span class="math inline">\(p(y^{\mathrm{new}} \, | \,
\theta^{(m)})\)</span> directly, it is prone to underflow. For example,
2000 outcomes <span class="math inline">\(y^{\mathrm{new}}_n\)</span>,
each with likelihood 0.5 for <span class="math inline">\(\theta^{(m)}\)</span>, will underflow, because
<span class="math inline">\(0.5^{2000}\)</span> is smaller than the
smallest positive number that a computer can represent using standard <a href="https://en.wikipedia.org/wiki/IEEE_754-1985" class="external-link">double-precision
floating point</a> (used by Stan, R, etc.).</p>
<p>In contrast, if we work on the log scale, <span class="math inline">\(\log p(y^{\mathrm{new}} \,
| \, y)\)</span> will not underflow. It’s a sum of a bunch of terms of
order 1. But we already saw we can’t just average the log to get the log
of the average.</p>
<p>To avoid underflow, we’re going to use the <a href="https://en.wikipedia.org/wiki/LogSumExp" class="external-link">log-sum-of-exponentials</a>
trick, which begins by noting the obvious,</p>
<p><span class="math display">\[
\log \frac{1}{M} \, \sum_{m=1}^M \ p(y^{\mathrm{new}} \, | \,
\theta^{(m)}).
\ = \
\log \frac{1}{M} \, \sum_{m=1}^M
                     \ \exp \left( \log p(y^{\mathrm{new}} \, | \,
\theta^{(m)}) \right).
\]</span></p>
<p>We’ll then write that last expression as</p>
<p><span class="math display">\[
-\log M
+  \mathrm{log\_sum\_exp \, }
        \ \log p(y^{\mathrm{new}} \, | \, \theta^{(m)})
\]</span></p>
<p>We can compute <span class="math inline">\(\mathrm{log\_sum\_exp}\)</span> stably by
subtracting the max value. Suppose <span class="math inline">\(u = u_1,
\ldots, u_M\)</span>, and <span class="math inline">\(\max(u)\)</span>
is the largest <span class="math inline">\(u_m\)</span>. We can
calculate</p>
<p><span class="math display">\[
\mathrm{log\_sum\_exp \, } \ u_m
\ = \
\log \sum_{m=1}^M \exp(u_m)
\ = \
\max(u) + \log \sum_{m=1}^M \exp(u_m - \max(u)).
\]</span></p>
<p>Because <span class="math inline">\(u_m - \max(u) \leq 0\)</span>,
the exponentiations cannot overflow. They may underflow to zero, but
this will not lose precision because of the leading <span class="math inline">\(\max(u)\)</span> term; the only way underflow can
arise is if <span class="math inline">\(u_m - \max(u)\)</span> is very
small, meaning that it won’t add significant digits to <span class="math inline">\(\max(u)\)</span> if it had not underflowed.</p>
<p>We can implement <span class="math inline">\(\mathrm{log\_sum\_exp}\)</span> in R as
follows:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">log_sum_exp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">u</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">max_u</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">u</span><span class="op">)</span></span>
<span>  <span class="va">a</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">n</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">u</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">a</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">u</span><span class="op">[</span><span class="va">n</span><span class="op">]</span> <span class="op">-</span> <span class="va">max_u</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">max_u</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">a</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Or equivalently using vectorization</span></span>
<span><span class="va">log_sum_exp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">u</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">max_u</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">u</span><span class="op">)</span></span>
<span>  <span class="va">max_u</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">u</span> <span class="op">-</span> <span class="va">max_u</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>and then include the <span class="math inline">\(-\log M\)</span>
term to make it <code>log_mean_exp</code>:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">log_mean_exp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">u</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">M</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">u</span><span class="op">)</span></span>
<span>  <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">M</span><span class="op">)</span> <span class="op">+</span> <span class="fu">log_sum_exp</span><span class="op">(</span><span class="va">u</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>We can then use it to compute the log posterior predictive densities
for each of the models:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">new_lps</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">log_p_new_mats</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span>, <span class="va">log_mean_exp</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># sum over the data points</span></span>
<span><span class="va">new_lps_sums</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="va">new_lps</span>, <span class="va">sum</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="va">new_lps_sums</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code>PartialPooling        Pooling      NoPooling 
         -71.8          -73.1          -81.5 </code></pre>
<p>Now the ranking is different! As expected, the values here are
greater than the expectation of the log density due to Jensen’s
inequality. The partial pooling model appears to be making slightly
better predictions than the full pooling model, which in turn is making
slightly better predictions than the no pooling model.</p>
</div>
<div class="section level5">
<h5 id="approximating-the-expected-log-predictive-density">Approximating the expected log predictive density<a class="anchor" aria-label="anchor" href="#approximating-the-expected-log-predictive-density"></a>
</h5>
<p>Vehtari, Gelman, and Gabry (2016) shows that the expected log
predictive density can be approximated using the <code>loo</code>
function for each model and then compared across models:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/loo.stanreg.html">loo_compare</a></span><span class="op">(</span><span class="fu"><a href="../reference/loo.stanreg.html">loo</a></span><span class="op">(</span><span class="va">fit_partialpool</span><span class="op">)</span>, <span class="fu"><a href="../reference/loo.stanreg.html">loo</a></span><span class="op">(</span><span class="va">fit_pool</span><span class="op">)</span>, <span class="fu"><a href="../reference/loo.stanreg.html">loo</a></span><span class="op">(</span><span class="va">fit_nopool</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>                elpd_diff se_diff
fit_pool         0.0       0.0   
fit_partialpool -0.1       0.5   
fit_nopool      -6.0       2.6   </code></pre>
<p>The third column is the leave-one-out (loo) approximation to the
expected log predictive density. This approximation is only
asymptotically valid and with only 18 observations in this case,
substantially underestimates the expected log predictive densities found
in the previous subsection. Nevertheless, the relative ranking of the
models is essentially the same with the pooled and partially pooled
models being virtually indistinguishable but much better than the no
pooling model.</p>
</div>
</div>
</div>
<div class="section level3">
<h3 id="predicting-new-observations">Predicting New Observations<a class="anchor" aria-label="anchor" href="#predicting-new-observations"></a>
</h3>
<p>With <strong>rstanarm</strong> it is straightforward to generate
draws from the posterior predictive distribution using the
<code>posterior_predict</code> function. With this capability, we can
either generate predictions for new data or we can apply it to the
predictors we already have.</p>
<p>There will be two sources of uncertainty in our predictions, the
first being the uncertainty in <span class="math inline">\(\theta\)</span> in the posterior <span class="math inline">\(p(\theta \, | \, y)\)</span> and the second being
the uncertainty due to the likelihood <span class="math inline">\(p(\tilde{y} \, | \, \theta)\)</span>.</p>
<p>We let <span class="math inline">\(z_n\)</span> be the number of
successes for unit <span class="math inline">\(n\)</span> in <span class="math inline">\(K^{\mathrm{new}}_n\)</span> further trials. It
might seem tempting to eliminate that second source of uncertainty and
set <span class="math inline">\(z_n^{(m)}\)</span> to its expectation,
<span class="math inline">\(\theta_n^{(m)} \,
K^{\mathrm{new}}\)</span>, at each draw <span class="math inline">\(m\)</span> from the posterior rather than
simulating a new value. Or it might seem tempting to remove the first
source of uncertainty and use the posterior mean (or median or mode or
…) rather than draws from the posterior. Either way, the resulting
values would suffice for estimating the posterior mean, but would not
capture the uncertainty in the prediction for <span class="math inline">\(y^{\mathrm{new}}_n\)</span> and would thus not be
useful in estimating predictive standard deviations or quantiles or as
the basis for decision making under uncertainty. In other words, the
predictions would not be properly calibrated (in a sense we define
below).</p>
<p>To predict <span class="math inline">\(z\)</span> for each player we
can use the following code:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">newdata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Hits <span class="op">=</span> <span class="va">y_new</span>, AB <span class="op">=</span> <span class="va">K_new</span>, Player <span class="op">=</span> <span class="va">bball</span><span class="op">$</span><span class="va">Player</span><span class="op">)</span></span>
<span><span class="va">ppd_pool</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/posterior_predict.stanreg.html">posterior_predict</a></span><span class="op">(</span><span class="va">fit_pool</span>, <span class="va">newdata</span><span class="op">)</span></span>
<span><span class="va">ppd_nopool</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/posterior_predict.stanreg.html">posterior_predict</a></span><span class="op">(</span><span class="va">fit_nopool</span>, <span class="va">newdata</span><span class="op">)</span></span>
<span><span class="va">ppd_partialpool</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/posterior_predict.stanreg.html">posterior_predict</a></span><span class="op">(</span><span class="va">fit_partialpool</span>, <span class="va">newdata</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">ppd_pool</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">ppd_nopool</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">ppd_partialpool</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html" class="external-link">as.character</a></span><span class="op">(</span><span class="va">bball</span><span class="op">$</span><span class="va">Player</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">colMeans</a></span><span class="op">(</span><span class="va">ppd_partialpool</span><span class="op">)</span></span></code></pre></div>
<pre><code>  Clemente   Robinson     Howard  Johnstone      Berry    Spencer  Kessinger 
 107.11175  122.81375  147.09175   76.57650  114.83275  127.77175  158.14625 
  Alvarado      Santo    Swaboda Petrocelli  Rodriguez      Scott      Unser 
  36.78775  133.26850   52.09350  137.74925   47.83100  111.74450   71.23400 
  Williams Campaneris     Munson      Alvis 
 151.40900  141.09625  101.63950   17.27250 </code></pre>
<p>Translating the posterior number of hits into a season batting
average, <span class="math inline">\(\frac{y_n + z_n}{K_n +
K^{\mathrm{new}}_n}\)</span>, we get an 80% posterior interval of</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">z_1</span> <span class="op">&lt;-</span> <span class="va">ppd_partialpool</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">clemente_80pct</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile</a></span><span class="op">(</span><span class="va">z_1</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">K</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">K_new</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu">batting_avg</span><span class="op">(</span><span class="va">clemente_80pct</span><span class="op">)</span></span></code></pre></div>
<pre><code>  10%   90% 
0.255 0.359 </code></pre>
<p>for Roberto Clemente from the partial pooling model. Part of our
uncertainty here is due to our uncertainty in Clemente’s underlying
chance of success, and part of our uncertainty is due to there being 367
remaining trials (at bats) modeled as binomial. In the remaining at bats
for the season, Clemente’s success rate (batting average) was <span class="math inline">\(127 / 367 = 0.346\)</span>.</p>
<p>For each model, the following plot shows each player’s posterior
predictive 50% interval for predicted batting average (success rate) in
his remaining at bats (trials); the observed success rate in the
remainder of the season is shown as a blue dot.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ppd_intervals</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span>, <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.25</span>, <span class="fl">0.75</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ppd_summaries</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="va">K_new</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/PPD-intervals.html" class="external-link">ppd_intervals</a></span><span class="op">(</span><span class="va">ppd_pool</span><span class="op">)</span>,</span>
<span>                                     <span class="fu"><a href="https://mc-stan.org/bayesplot/reference/PPD-intervals.html" class="external-link">ppd_intervals</a></span><span class="op">(</span><span class="va">ppd_nopool</span><span class="op">)</span>,</span>
<span>                                     <span class="fu"><a href="https://mc-stan.org/bayesplot/reference/PPD-intervals.html" class="external-link">ppd_intervals</a></span><span class="op">(</span><span class="va">ppd_partialpool</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">df_ppd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>player <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y_new</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>                     y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">y_new</span> <span class="op">/</span> <span class="va">K_new</span>, <span class="fl">3</span><span class="op">)</span>,</span>
<span>                     lb <span class="op">=</span> <span class="va">ppd_summaries</span><span class="op">[</span>, <span class="st">"25%"</span><span class="op">]</span>,</span>
<span>                     ub <span class="op">=</span> <span class="va">ppd_summaries</span><span class="op">[</span>, <span class="st">"75%"</span><span class="op">]</span>,</span>
<span>                     model <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">models</span>, each <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y_new</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">df_ppd</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">player</span>, y<span class="op">=</span><span class="va">y</span>, ymin<span class="op">=</span><span class="va">lb</span>, ymax<span class="op">=</span><span class="va">ub</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_linerange.html" class="external-link">geom_linerange</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"gray60"</span>, size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">2.5</span>, color <span class="op">=</span> <span class="st">"skyblue4"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_grid.html" class="external-link">facet_grid</a></span><span class="op">(</span><span class="va">.</span> <span class="op">~</span> <span class="va">model</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="cn">NULL</span>, y <span class="op">=</span> <span class="st">"batting average"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span></span>
<span>    <span class="fu">atop</span><span class="op">(</span><span class="st">"Posterior Predictions for Batting Average in Remainder of Season"</span>,</span>
<span>         <span class="fu">atop</span><span class="op">(</span><span class="st">"50% posterior predictive intervals (gray bars); observed (blue dots)"</span>, <span class="st">""</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="pooling_files/figure-html/plot-ppd-1.png" class="r-plt" width="70%" style="display: block; margin: auto;"></p>
<p>We choose to plot 50% posterior intervals as they are a good single
point for checking calibration. Rather than plotting the number of hits
on the vertical axis, we have standardized all the predictions and
outcomes to a success rate. Because each unit (player) has a different
number of subsequent trials (at bats), the posterior intervals are
relatively wider or narrower within the plots for each model (more
trials imply narrower intervals for the average). Because each unit had
the same number of initial observed trials, this variation is primarily
due to the uncertainty from the binomial model of outcomes.</p>
<div class="section level4">
<h4 id="calibration-1">Calibration<a class="anchor" aria-label="anchor" href="#calibration-1"></a>
</h4>
<p>With 50% intervals, we expect half of our estimates to lie outside
their intervals in a well-calibrated model. If fewer than the expected
number of outcomes lie in their estimated posterior intervals, we have
reason to believe the model is not well calibrated—its posterior
intervals are too narrow. This is also true if too many outcomes lie in
their estimated posterior intervals—in this case the intervals are too
broad. Of course, there is variation in the tests as the number of units
lying in their intervals is itself a random variable (see the
exercises), so in practice we are only looking for extreme values as
indicators of miscalibration.</p>
<p>Each of the models other than the complete pooling model appears to
be reasonably well calibrated, and even the calibration for the complete
pooling model is not bad (the variation in chance-of-success among
players has low enough variance that the complete pooling model cannot
be rejected as a possibility with only the amount of data we used
here).</p>
</div>
<div class="section level4">
<h4 id="sharpness-1">Sharpness<a class="anchor" aria-label="anchor" href="#sharpness-1"></a>
</h4>
<p>Consider the width of the posterior predictive intervals for the
units across the models. The model with no pooling has the broadest
posterior predictive intervals and the complete pooling model the
narrowest. This is to be expected given the number of observations used
to fit each model; 45 each in the no pooling case and 810 in the
complete pooling case, and relatively something in between for the
partial pooling models. Because the log odds model is doing more
pooling, its intervals are slightly narrower than that of the direct
hierarchical model.</p>
<p>For two well calibrated models, the one with the narrower posterior
intervals is preferable because its predictions are more tighter. The
term introduced for this by Gneiting et al. (2007) is “sharpness.” In
the limit, a perfect model would provide a delta function at the true
answer with a vanishing posterior interval.</p>
</div>
</div>
<div class="section level3">
<h3 id="estimating-event-probabilities">Estimating Event Probabilities<a class="anchor" aria-label="anchor" href="#estimating-event-probabilities"></a>
</h3>
<p>The 80% interval in the partial pooling model coincidentally shows us
that our model estimates a roughly 10% chance of Roberto Clemente
batting 0.400 or better for the season based on batting 0.400 in his
first 45 at bats. Not great, but non-trivial. Rather than fishing for
the right quantile and hoping to get lucky, we can write a model to
directly estimate event probabilities, such as Robert Clemente’s batting
average is 0.400 or better for the season.</p>
<p>Event probabilities are defined as expectations of indicator
functions over parameters and data. For example, the probability of
player <span class="math inline">\(n\)</span>’s batting average being
0.400 or better conditioned on the data <span class="math inline">\(y\)</span> is defined by the conditional event
probability</p>
<p><span class="math display">\[
\mathrm{Pr}\left[
\frac{(y_n + z_n)}{(45 + K^{\mathrm{new}}_n)} \geq 0.400
\, \Big| \,
y
\right]
\ = \
\int_{\Theta}
\mathrm{I}\left[\frac{(y_n + z_n)}{(45 + K^{\mathrm{new}}_n)} \geq
0.400\right]
       \ p(z_n \, | \, \theta_n, K^{\mathrm{new}}_n)
       \ p(\theta \, | \, y, K)
       \ \mathrm{d}\theta.
\]</span></p>
<p>The indicator function <span class="math inline">\(\mathrm{I}[c]\)</span> evaluates to 1 if the
condition <span class="math inline">\(c\)</span> is true and 0 if it is
false. Because it is just another expectation with respect to the
posterior, we can calculate this event probability using MCMC as</p>
<p><span class="math display">\[
\mathrm{Pr}\left[\frac{(y_n + z_n)}{(45 + K^{\mathrm{new}}_n)} \geq
0.400 \, \Big| \, y \right]
\ \approx \
\frac{1}{M} \, \sum_{m=1}^M \mathrm{I}\left[\frac{(y_n + z_n^{(m)})}{(45
+ K^{\mathrm{new}}_n)} \geq 0.400\right].
\]</span></p>
<p>This event is about the season batting average being greater than
0.400. What if we care about ability (chance of success), not batting
average (success rate) for the rest of the season? Then we would ask the
question of whether <span class="math inline">\(\mathrm{Pr}[\theta_n
&gt; 0.4]\)</span>. This is defined as a weighted average over the prior
and computed via MCMC as the previous case.</p>
<p><span class="math display">\[
\mathrm{Pr}\left[\theta_n \geq 0.400 \, | \, y \right]
\ = \
\int_{\Theta}
\mathrm{I}\left[\theta_n \geq 0.400\right]
       \ p(\theta \, | \, y, K)
       \ \mathrm{d}\theta
\ \approx \
\frac{1}{M} \, \sum_{m=1}^M \mathrm{I}[\theta_n^{(m)} \geq 0.400].
\]</span></p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">draws_partialpool</span> <span class="op">&lt;-</span> <span class="fu">shift_draws</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">fit_partialpool</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">thetas_partialpool</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="va">draws_partialpool</span><span class="op">)</span></span>
<span><span class="va">thetas_partialpool</span> <span class="op">&lt;-</span> <span class="va">thetas_partialpool</span><span class="op">[</span>,<span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">thetas_partialpool</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">thetas_partialpool</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html" class="external-link">as.character</a></span><span class="op">(</span><span class="va">bball</span><span class="op">$</span><span class="va">Player</span><span class="op">)</span></span>
<span><span class="va">ability_gt_400</span> <span class="op">&lt;-</span> <span class="va">thetas_partialpool</span> <span class="op">&gt;</span> <span class="fl">0.4</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pr(theta_n &gt;= 0.400 | y)\n"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">colMeans</a></span><span class="op">(</span><span class="va">ability_gt_400</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">10</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">some_gt_350</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">thetas_partialpool</span>, <span class="fl">1</span>, <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0.35</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pr(at least one theta_n &gt;= 0.350 | y)\n"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">some_gt_350</span><span class="op">)</span></span></code></pre></div>
<pre><code>Pr(theta_n &gt;= 0.400 | y)
Clemente    Berry  Swaboda 
 0.02175  0.00325  0.00050 
Pr(at least one theta_n &gt;= 0.350 | y)
[1] 0.22875</code></pre>
<!-- These results show that the probability of batting 0.400 or better for -->
<!-- the season is a different question than asking if the player's ability -->
<!-- is 0.400 or better; for example, with respect to the basic partial -->
<!-- pooling model, there is roughly an estimated 10% chance of Roberto -->
<!-- Clemente ($n = 1$) batting 0.400 or better for the season, but only an -->
<!-- estimated 8% chance that he has ability greater than 0.400.  This is -->
<!-- again due to there being two sources of uncertainty, that from the -->
<!-- estimate of the chance of success in the posterior and that from the -->
<!-- remaining binary trials. -->
</div>
<div class="section level3">
<h3 id="multiple-comparisons">Multiple Comparisons<a class="anchor" aria-label="anchor" href="#multiple-comparisons"></a>
</h3>
<p>We snuck in a “multiple comparison” event in the last section, namely
whether there was some player with an a chance of success for hits of
.350 or greater.</p>
<p>With traditional significance testing over multiple trials, it is
common to adjust for falsely rejecting the null hypothesis (a so-called
<a href="https://en.wikipedia.org/wiki/Type_I_and_type_II_errors#Type_I_error" class="external-link">Type
I error</a>) by inflating the conventional (and arguably far too low) 5%
target for reporting “significance.”</p>
<p>For example, suppose we have our 18 players with ability parameters
<span class="math inline">\(\theta_n\)</span> and we have <span class="math inline">\(N\)</span> null hypotheses of the form <span class="math inline">\(H_0^n:
\theta_n &lt; 0.350\)</span>. Now suppose we evaluate each of these 18
hypotheses independently at the conventional <span class="math inline">\(p = 0.05\)</span> significance level, giving each
a 5% chance of rejecting the null hypothesis in error. When we run all
18 hypothesis tests, the overall chance of falsely rejecting at least
one of the null hypotheses is a whopping <span class="math inline">\(1
- (1 - 0.05)^{18} = 0.60\)</span>.</p>
<p>The traditional solution to this problem is to apply a <a href="https://en.wikipedia.org/wiki/Bonferroni_correction" class="external-link">Bonferroni
adjustment</a> to control the false rejection rate; the typical
adjustment is to divide the <span class="math inline">\(p\)</span>-value
by the number of hypothesis tests in the “family” (that is, the
collective test being done). Here that sets the rate to <span class="math inline">\(p = 0.05/18\)</span>, or approximately <span class="math inline">\(p = 0.003\)</span>, and results in a slightly less
than 5% chance of falsely rejecting a null hypothesis in error.</p>
<p>Although the Bonferroni correction does reduce the overall chance of
falsely rejecting a null hypothesis, it also reduces the statistical
power of the test to the same degree. This means that many null
hypotheses will fail to be rejected in error.</p>
<p>Rather than doing classical multiple comparison adjustments to adjust
for false-discovery rate, such as a Bonferroni correction, Gelman et
al. (2012) suggest using a hierarchical model to perform partial pooling
instead. As already shown, hierarchical models partially pool the data,
which pulls estimates toward the population mean with a strength
determined by the amount of observed variation in the population (see
also Figure 2 of (Gelman et al. 2012)). This automatically reduces the
false-discovery rate, though not in a way that is intrinsically
calibrated to false discovery, which is good, because reducing the
overall false discovery rate in and of itself reduces the true discovery
rate at the same time.</p>
<p>The generated quantity <code>some_ability_gt_350</code> will be set
to 1 if the maximum ability estimate in <span class="math inline">\(\theta\)</span> is greater than 0.35. And thus the
posterior mean of this generated quantity will be the event
probability</p>
<p><span class="math display">\[
\mathrm{Pr}[\mathrm{max}(\theta) &gt; 0.350]
\ = \ \int_{\Theta} \mathrm{I}[\mathrm{max}(\theta) &gt; 0.35] \
p(\theta \, | \, y, K) \ \mathrm{d}\theta
\ \approx \ \frac{1}{M} \, \sum_{m=1}^M \
\mathrm{I}[\mathrm{max}(\theta^{(m)}) &gt; 0.35]
\]</span></p>
<p>where <span class="math inline">\(\theta^{(m)}\)</span> is the
sequence of posterior draws for the ability parameter vector. Stan
reports this value as the posterior mean of the generated quantity
<code>some_ability_gt_350</code>, which takes on the value <span class="math inline">\(\mathrm{I}[\mathrm{max}(\theta^{(m)}) &gt;
0.35]\)</span> in each iteration.</p>
<p>The probability estimate of there being a player with an ability
(chance of success) greater than 0.350 is essentially zero in the
complete and is essentially guaranteed in the no pooling model. The
partially pooled estimates would not be considered significant at
conventional p=0.05 thresholds. One way to get a handle on what’s going
on is to inspect the posterior 80% intervals for chance-of-success
estimates in the first graph above.</p>
</div>
<div class="section level3">
<h3 id="ranking">Ranking<a class="anchor" aria-label="anchor" href="#ranking"></a>
</h3>
<p>In addition to multiple comparisons, we can use the simultaneous
estimation of the ability parameters to rank the units. In this section,
we rank ballplayers by (estimated) chance of success (i.e., batting
ability).</p>
<p>Of course, ranking players by ability makes no sense for the complete
pooling model, where every player is assumed to have the same
ability.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">reverse_rank</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/rank.html" class="external-link">rank</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="co"># so lower rank is better</span></span>
<span><span class="va">rank</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">thetas_partialpool</span>, <span class="fl">1</span>, <span class="va">reverse_rank</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">rank</span>, <span class="fl">1</span>, <span class="va">quantile</span>, prob <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>            
parameters   10% 50% 90%
  Clemente     1   5  14
  Robinson     1   5  14
  Howard       1   6  14
  Johnstone    2   7  15
  Berry        2   8  15
  Spencer      2   8  15
  Kessinger    2   9  16
  Alvarado     3   9  16
  Santo        3  10  17
  Swaboda      3  10  17
  Petrocelli   4  11  17
  Rodriguez    4  11  17
  Scott        4  11  17
  Unser        4  11  17
  Williams     3  11  17
  Campaneris   4  12  17
  Munson       4  13  18
  Alvis        5  14  18</code></pre>
<p>It is again abundantly clear from the posterior intervals that our
uncertainty is very great after only 45 at bats.</p>
<p>In the original Volume I BUGS <a href="https://chjackson.github.io/openbugsdoc/Examples/Surgical.html" class="external-link">example</a>
of surgical mortality, the posterior distribution over ranks was plotted
for each hospital. It is now straightforward to reproduce that figure
here for the baseball data.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df_rank</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>name <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">bball</span><span class="op">$</span><span class="va">Player</span>, each <span class="op">=</span> <span class="va">M</span><span class="op">)</span>, </span>
<span>                      rank <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">rank</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">df_rank</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">rank</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html" class="external-link">stat_count</a></span><span class="op">(</span>width <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html" class="external-link">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">name</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_discrete.html" class="external-link">scale_x_discrete</a></span><span class="op">(</span><span class="st">"Rank"</span>, limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_discrete.html" class="external-link">scale_y_discrete</a></span><span class="op">(</span><span class="st">"Probability"</span>, limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span> <span class="op">*</span> <span class="va">M</span>, <span class="fl">0.2</span> <span class="op">*</span> <span class="va">M</span><span class="op">)</span>,</span>
<span>                   labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"0.0"</span>, <span class="st">"0.1"</span>, <span class="st">"0.2"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Rankings for Partial Pooling Model"</span><span class="op">)</span></span></code></pre></div>
<p><img src="pooling_files/figure-html/plot-ranks-1.png" class="r-plt" width="70%" style="display: block; margin: auto;"></p>
<div class="section level5">
<h5 id="who-has-the-highest-chance-of-success">Who has the Highest Chance of Success?<a class="anchor" aria-label="anchor" href="#who-has-the-highest-chance-of-success"></a>
</h5>
<p>We can use our ranking statistic to calculate the event probability
for unit <span class="math inline">\(n\)</span> that the unit has the
highest chance of success using MCMC as</p>
<p><span class="math display">\[
\mathrm{Pr}[\theta_n = \max(\theta)]
\ = \
\int_{\Theta} \mathrm{I}[\theta_n = \mathrm{max}(\theta)]
              \ p(\theta \, | \, y, K)
              \ \mathrm{d}\theta
\ \approx \
\frac{1}{M} \, \sum_{m=1}^M \mathrm{I}[\theta^{(m)}_n =
\mathrm{max}(\theta^{(m)})].
\]</span></p>
<p>Like our other models, the partial pooling mitigates the implicit
multiple comparisons being done to calculate the probabilities of
rankings. Contrast this with an approach that does a pairwise
significance test and then applies a false-discovery correction.</p>
<p>We can compute this straightforwardly using the rank data we have
already computed or we could compute it directly as above. Because <span class="math inline">\(\mathrm{Pr}[\theta_n = \theta_{n'}] =
0\)</span> for <span class="math inline">\(n \neq n'\)</span>, we
don’t have to worry about ties.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">thetas_nopool</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">fit_nopool</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">thetas_nopool</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html" class="external-link">as.character</a></span><span class="op">(</span><span class="va">bball</span><span class="op">$</span><span class="va">Player</span><span class="op">)</span></span>
<span><span class="va">rank_nopool</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">thetas_nopool</span>, <span class="fl">1</span>, <span class="va">reverse_rank</span><span class="op">)</span></span>
<span><span class="va">is_best_nopool</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowMeans</a></span><span class="op">(</span><span class="va">rank_nopool</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">is_best_partialpool</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowMeans</a></span><span class="op">(</span><span class="va">rank</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df_is_best</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>unit <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">bball</span><span class="op">$</span><span class="va">Player</span>, <span class="fl">2</span><span class="op">)</span>, </span>
<span>                         is_best <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">is_best_partialpool</span>, <span class="va">is_best_nopool</span><span class="op">)</span>, </span>
<span>                         model <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"partial pooling"</span>, <span class="st">"no pooling"</span><span class="op">)</span>, each <span class="op">=</span> <span class="va">N</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">df_is_best</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">unit</span>, y<span class="op">=</span><span class="va">is_best</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html" class="external-link">geom_bar</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"identity"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html" class="external-link">facet_wrap</a></span><span class="op">(</span><span class="op">~</span> <span class="va">model</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html" class="external-link">scale_y_continuous</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"Pr[player is best]"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Who is the Best Player?"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html" class="external-link">element_text</a></span><span class="op">(</span>angle <span class="op">=</span> <span class="op">-</span><span class="fl">45</span>, vjust <span class="op">=</span> <span class="fl">1</span>, hjust <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="pooling_files/figure-html/plot-best-player-1.png" class="r-plt" width="70%" style="display: block; margin: auto;"></p>
<p>This question of which player has the highest chance of success
(batting ability) doesn’t even make sense in the complete pooling model,
because the chance of success parameters are all the same by definition.
In the other models, the amount of pooling directly determines the
probabilities of being the best player. That is, the probability of
being best goes down for high performing players with more pooling,
whereas it goes up for below-average players.</p>
</div>
</div>
<div class="section level3">
<h3 id="graphical-posterior-predictive-checks">Graphical Posterior Predictive Checks<a class="anchor" aria-label="anchor" href="#graphical-posterior-predictive-checks"></a>
</h3>
<p>We can simulate data from the predictive distribution and compare it
to the original data used for fitting the model. If they are not
consistent, then either our model is not capturing the aspects of the
data we are probing with test statistics or the measurement we made is
highly unlikely. That is, extreme <span class="math inline">\(p\)</span>-values lead us to suspect there is
something wrong with our model that deserves further exploration.</p>
<p>In some cases, we are willing to work with models that are wrong in
some measurable aspects, but accurately capture quantities of interest
for an application. That is, it’s possible for a model to capture some,
but not all, aspects of a data set, and still be useful.</p>
<div class="section level4">
<h4 id="test-statistics-and-bayesian-p-values">Test Statistics and Bayesian <span class="math inline">\(p\)</span>-Values<a class="anchor" aria-label="anchor" href="#test-statistics-and-bayesian-p-values"></a>
</h4>
<p>A test statistic <span class="math inline">\(T\)</span> is a function
from data to a real value. Following (Gelman et al. 2013), we will
concentrate on four specific test statistics for repeated binary trial
data (though these choices are fairly general): minimum value, maximum
value, sample mean, and sample standard deviation.</p>
<p>Given a test statistic <span class="math inline">\(T\)</span> and
data <span class="math inline">\(y\)</span>, the Bayesian <span class="math inline">\(p\)</span>-value has a direct definition as a
probability,</p>
<p><span class="math display">\[
p_B = \mathrm{Pr}[T(y^{\mathrm{rep}}) \geq T(y) \, | \, y].
\]</span></p>
<p>Bayesian <span class="math inline">\(p\)</span>-values, like their
traditional counterparts, are probabilities, but not probabilities that
a model is true. They simply measure discrepancies between the observed
data and what we would expect if the model is true.</p>
<p>Values of Bayesian <span class="math inline">\(p\)</span>-values near
0 or 1 indicate that the data <span class="math inline">\(y\)</span>
used to estimate the model is unlikely to have been generated by the
estimated model. As with other forms of full Bayesian inference, our
estimate is the full posterior, not just a point estimate.</p>
<p>As with other Bayesain inferences, we average over the posterior
rather than working from a point estimate of the parameters. Expanding
this as an expectation of an indicator function,</p>
<p><span class="math display">\[
p_B
\ = \
  \int_{\Theta, Y^{\mathrm{rep}}}
    \mathrm{I}[T(y^{\mathrm{rep}}) \geq T(y)]  
    \ p(y^{\mathrm{rep}} \, | \, \theta)
    \ p(\theta \, | \, y)
    \ \mathrm{d}\theta,
\]</span></p>
<p>We treat <span class="math inline">\(y^{\mathrm{rep}}\)</span> as a
parameter in parallel with <span class="math inline">\(\theta\)</span>,
integrating over possible values <span class="math inline">\(y^{\mathrm{rep}} \in
Y^{\mathrm{rep}}\)</span>. As usual, we use the integration sign in a
general way intended to include summation, as with the discrete variable
<span class="math inline">\(y^{\mathrm{rep}}\)</span>.</p>
<p>The formulation as an expectation leads to the obvious MCMC
calculation based on posterior draws <span class="math inline">\(y^{\mathrm{rep} (m)}\)</span> for <span class="math inline">\(m \in 1{:}M\)</span>,</p>
<p><span class="math display">\[
p_B
\approx
\frac{1}{M}
\,
\sum_{m=1}^M
\mathrm{I}[T(y^{\mathrm{rep} \ (m)}) \geq T(y)].
\]</span></p>
<p>Using the <code>pp_check</code> in <strong>rstanarm</strong>, we can
easily reproduce Figure 6.12 from (Gelman et al. 2013), which shows the
posterior predictive distribution for the test statistic, the observed
value as a vertical line, and the <span class="math inline">\(p\)</span>-value for each of the tests. First,
here is just the plot for the no pooling model using the mean as the
test statistic:</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/pp_check.stanreg.html">pp_check</a></span><span class="op">(</span><span class="va">fit_nopool</span>, plotfun <span class="op">=</span> <span class="st">"stat"</span>, stat <span class="op">=</span> <span class="st">"mean"</span><span class="op">)</span></span></code></pre></div>
<p><img src="pooling_files/figure-html/plot-ppc-stats-mean-1.png" class="r-plt" width="70%" style="display: block; margin: auto;"></p>
<p>The <code>stat</code> argument can the be the name of any R function
(including your own functions defined in the Global Environment) that
takes a vector as an input and returns a scalar.</p>
<p>To make plots for each of the models for several test statistics we
can use the following code, which will create a list of ggplot objects
for each model and then arrange everything in a single plot.</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tstat_plots</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">model</span>, <span class="va">stats</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">stats</span>, <span class="kw">function</span><span class="op">(</span><span class="va">stat</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">graph</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pp_check.stanreg.html">pp_check</a></span><span class="op">(</span><span class="va">model</span>, plotfun <span class="op">=</span> <span class="st">"stat"</span>, stat <span class="op">=</span> <span class="va">stat</span>, </span>
<span>                      seed <span class="op">=</span> <span class="va">SEED</span><span class="op">)</span> <span class="co"># optional arguments</span></span>
<span>    <span class="va">graph</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">xlab</a></span><span class="op">(</span><span class="va">stat</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">Tstats</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"mean"</span>, <span class="st">"sd"</span>, <span class="st">"min"</span>, <span class="st">"max"</span><span class="op">)</span></span>
<span><span class="va">ppcs_pool</span> <span class="op">&lt;-</span> <span class="fu">tstat_plots</span><span class="op">(</span><span class="va">fit_pool</span>, <span class="va">Tstats</span><span class="op">)</span></span>
<span><span class="va">ppcs_nopool</span> <span class="op">&lt;-</span> <span class="fu">tstat_plots</span><span class="op">(</span><span class="va">fit_nopool</span>, <span class="va">Tstats</span><span class="op">)</span></span>
<span><span class="va">ppcs_partialpool</span> <span class="op">&lt;-</span> <span class="fu">tstat_plots</span><span class="op">(</span><span class="va">fit_partialpool</span>, <span class="va">Tstats</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va">gridExtra</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/gridExtra/man/arrangeGrob.html" class="external-link">grid.arrange</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/gridExtra/man/arrangeGrob.html" class="external-link">arrangeGrob</a></span><span class="op">(</span>grobs <span class="op">=</span> <span class="va">ppcs_pool</span>, nrow <span class="op">=</span> <span class="fl">1</span>, left <span class="op">=</span> <span class="st">"Pooling"</span><span class="op">)</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/gridExtra/man/arrangeGrob.html" class="external-link">arrangeGrob</a></span><span class="op">(</span>grobs <span class="op">=</span> <span class="va">ppcs_nopool</span>, nrow <span class="op">=</span> <span class="fl">1</span>, left <span class="op">=</span> <span class="st">"No Pooling"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/gridExtra/man/arrangeGrob.html" class="external-link">arrangeGrob</a></span><span class="op">(</span>grobs <span class="op">=</span> <span class="va">ppcs_partialpool</span>, nrow <span class="op">=</span> <span class="fl">1</span>, left <span class="op">=</span> <span class="st">"Partial Pooling"</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p><img src="pooling_files/figure-html/plot-ppc-stats-1.png" class="r-plt" width="70%" style="display: block; margin: auto;"></p>
<p>The only worrisomely extreme value visible in the plots is the <span class="math inline">\(p\)</span>-value for standard deviation in the
no-pooling model, where the vast majority of the simulated data sets
under the model had standard deviations greater than the actual
data.</p>
<p>We didn’t actually compute this <span class="math inline">\(p\)</span>-value because extreme <span class="math inline">\(p\)</span>-values are easy to detect visually and
whether or not the <span class="math inline">\(p\)</span>-value is less
than <span class="math inline">\(0.05\)</span> or some other arbitrary
value is of little use to us beyond what we can already see in the plot.
However, if we did want to actually compute the <span class="math inline">\(p\)</span>-value we can do so easily:</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">yrep</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/posterior_predict.stanreg.html">posterior_predict</a></span><span class="op">(</span><span class="va">fit_nopool</span>, seed <span class="op">=</span> <span class="va">SEED</span><span class="op">)</span> <span class="co"># seed is optional</span></span>
<span><span class="va">Ty</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html" class="external-link">sd</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="va">Tyrep</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">yrep</span>, <span class="fl">1</span>, <span class="va">sd</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># tail-area probability</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">Tyrep</span> <span class="op">&gt;</span> <span class="va">Ty</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] 0.01325</code></pre>
</div>
<div class="section level4">
<h4 id="comparing-observed-and-replicated-data">Comparing Observed and Replicated Data<a class="anchor" aria-label="anchor" href="#comparing-observed-and-replicated-data"></a>
</h4>
<p>Following the advice of Gelman et al. (2013), we will take the fitted
parameters of the data set and generate replicated data sets, then
compare the replicated data sets visually to the observed data we used
to fit the model. In this section we’ll create the plots for the model
using partial pooling, but the same plots can be made for the other
models too.</p>
<p>Again using <strong>rstanarm</strong>’s <code>pp_check</code>
function, we can plot some of the simulated data sets along with the
original data set to do a visual inspection as suggested by Gelman et
al. (2013). For this type of posterior predictive check we set the
<code>check</code> argument to <code>"distributions"</code> and we use
<code>nreps</code> to specify how many replicated sets of data to
generate from the posterior predictive distribution. Because our models
have a binomial outcome, instead of plotting the number of successes
(hits in this case) on the x-axis, <code>pp_check</code> will plot the
proportion of successes.</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/pp_check.stanreg.html">pp_check</a></span><span class="op">(</span><span class="va">fit_partialpool</span>, plotfun <span class="op">=</span> <span class="st">"hist"</span>, nreps <span class="op">=</span> <span class="fl">15</span>, binwidth <span class="op">=</span> <span class="fl">0.025</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ggtitle</a></span><span class="op">(</span><span class="st">"Model: Partial Pooling"</span><span class="op">)</span></span></code></pre></div>
<p><img src="pooling_files/figure-html/plot-ppc-y-vs-yrep-1.png" class="r-plt" width="70%" style="display: block; margin: auto;"></p>
<p>These simulations are not unreasonable for a binomial likelihood, but
they are more spread out than the actual data. In this case, this may
actually have more to do with how the data were selected out of all the
major league baseball players than the actual data distribution. Efron
and Morris (1975, p 312) write</p>
<blockquote>
<p>This sample was chosen because we wanted between 30 and 50 at bats to
assure a satisfactory approximation of the binomial by the normal
distribution while leaving the bulk of at bats to be estimated. We also
wanted to include an unusually good hitter (Clemente) to test the method
with at least one extreme parameter, a situation expected to be less
favorable to Stein’s estimator. Stein’s estimator requires equal
variances, or in this situation, equal at bats, so the remaining 17
players are all whom either the April 26 or May 3 <em>New York
Times</em> reported with 45 at bats.</p>
</blockquote>
</div>
</div>
</div>
<div class="section level2">
<h2 id="discussion">Discussion<a class="anchor" aria-label="anchor" href="#discussion"></a>
</h2>
<p>A hierarchical model introduces an estimation bias toward the
population mean and the stronger the bias, the less variance there is in
the estimates for the units. Exactly how much bias and variance is
warranted can be estimated by further calibrating the model and testing
where its predictions do not bear out.</p>
<p>With very little data, there is very little we can do to gain sharp
inferences other than provide more informative priors, which is well
worth doing when prior information is available.</p>
<p>On the other hand, with more data, the models provide similar results
(see the exercises), and in the limit, all of the models (other than
complete pooling) converge to posteriors that are delta functions around
the empirical chance of success (i.e., the maximum likelihood estimate).
Meanwhile, Bayesian inference is allowing us to make more accurate
predictions with the data available before we hit that asymptotic
regime.</p>
</div>
<div class="section level2">
<h2 id="exercises">Exercises<a class="anchor" aria-label="anchor" href="#exercises"></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Generate fake data according to the pooling, no-pooling, and
partial pooling models. Fit the model and consider the coverage of the
posterior 80% intervals.</p></li>
<li><p>Try generating data where each player has a different number of
at-bats (trials) and then fitting the models. What effect does the
number of initial trials have on the posterior? Is there a way to
quantify the effect?</p></li>
<li><p>In the section where we fit the complete pooling model we show a
plot of the prior distribution on the probability of success <span class="math inline">\(\theta\)</span> implied by the <span class="math inline">\(\mathsf{Normal}(-1,1)\)</span> prior on the
log-odds <span class="math inline">\(\alpha\)</span>. If <span class="math inline">\(\theta = \mathrm{logit}^{-1}(\alpha)\)</span> and
<span class="math inline">\(p(\alpha) = \mathsf{Normal}(\alpha \,|\, -1,
1)\)</span>, what is <span class="math inline">\(p(\theta)\)</span>? For
a hint, see <a href="https://en.wikipedia.org/wiki/Probability_density_function#Dependent_variables_and_change_of_variables" class="external-link">here</a>.</p></li>
<li><p>How sensitive is the basic no-pooling model to the choice of
prior? We used a somewhat informative prior due to our knowledge of
baseball, but the prior could be made more or less informative. How, if
at all, does this affect posterior inference?</p></li>
<li><p>What are some other test statistics that might be used to
evaluate our model fit to data? Try some out using
<code>pp_check(model, plotfun="stat", stat = "my_test")</code>, where
<code>my_test</code> is your function that computes the test statistic.
For example, to check the 25% quantile you could first define a function
<code>q25 &lt;- function(x) quantile(x, 0.25)</code> and then call
<code>pp_check(model, plotfun = "stat", stat = "q25")</code>.</p></li>
<li><p>Discuss the difference between batting average and on-base
percentage as random variables. Consider particularly the denominator
(at-bat versus plate appearance). Is the denominator in these kinds of
problems always a random variable itself? Why might this be important in
inference?</p></li>
</ol>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<ul>
<li><p>Betancourt, M. and Girolami, M. (2015) Hamiltonian Monte Carlo
for hierarchical models. <em>Current Trends in Bayesian Methodology with
Applications</em> <strong>79</strong>.</p></li>
<li><p>Efron, B. and Morris, C. (1975) Data analysis using Stein’s
estimator and its generalizations. <em>Journal of the American
Statistical Association</em> <strong>70</strong>(350), 311–319. [ <a href="https://www.medicine.mcgill.ca/epidemiology/hanley/bios602/MultilevelData/EfronMorrisJASA1975.pdf" class="external-link">pdf</a>]</p></li>
<li><p>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari,
A., and Rubin, D. B. (2013) <em>Bayesian Data Analysis</em>, 3rd
Edition. Chapman &amp; Hall/CRC Press, London.</p></li>
<li><p>Gelman, A. and Hill, J. (2007) <em>Data Analysis Using Regression
and Multilevel-Hierarchical Models</em>. Cambridge University Press,
Cambridge, United Kingdom.</p></li>
<li><p>Gelman, A., Hill, J., and Yajima, M. (2012) Why we (usually)
don’t have to worry about multiple comparisons. <em>Journal of Research
on Educational Effectiveness</em> <strong>5</strong>, 189–211. [ <a href="https://arxiv.org/abs/0907.2478" class="external-link">preprint</a>]</p></li>
<li><p>Gneiting, T., Balabdaoui, F., and Raftery, A. E. (2007)
Probabilistic forecasts, calibration and sharpness. <em>Journal of the
Royal Statistical Society: Series B</em> (Statistical Methodology),
<strong>69</strong>(2), 243–268.</p></li>
<li><p>Lunn, D., Jackson, C., Best, N., Thomas, A., and Spiegelhalter,
D. (2013) <em>The BUGS Book: A Practical Introduction to Bayesian
Analysis</em>. Chapman &amp; Hall/CRC Press.</p></li>
<li><p>Neal, R. M. (2003) Slice sampling. <em>Annals of Statistics</em>
<strong>31</strong>(3):705–767.</p></li>
<li><p>Papaspiliopoulos, O., Roberts, G. O., and Skold, M. (2003)
Non-centered parameterisations for hierarchical models and data
augmentation. In <em>Bayesian Statistics 7: Proceedings of the Seventh
Valencia International Meeting</em>, edited by Bernardo, J. M., Bayarri,
M. J., Berger, J. O., Dawid, A. P., Heckerman, D., Smith, A. F. M., and
West, M. Oxford University Press, Chicago.</p></li>
<li><p>Plummer, M., Best, N., Cowles, K., &amp; Vines, K. (2006). CODA:
Convergence diagnosis and output analysis for MCMC. <em>R News</em>,
<strong>6</strong>(1), 7–11.</p></li>
<li><p>Spiegelhalter, D., Thomas, A., Best, N., &amp; Gilks, W. (1996)
BUGS 0.5 Examples. MRC Biostatistics Unit, Institute of Public health,
Cambridge, UK.</p></li>
<li><p>Stan Development Team (2015) <em>Stan Modeling Language User’s
Guide and Reference Manual</em>. <a href="https://mc-stan.org/docs/" class="external-link">[web page]</a></p></li>
<li><p>Tarone, R. E. (1982) The use of historical control information in
testing for a trend in proportions. <em>Biometrics</em>
<strong>38</strong>(1):215–220.</p></li>
<li><p>Vehtari, A, Gelman, A., &amp; Gabry, J. (2016) Practical Bayesian
model evaluation using leave-one-out cross-validation and WAIC. [ <a href="https://arxiv.org/abs/1507.04544" class="external-link">pdf</a>]</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="additional-data-sets">Additional Data Sets<a class="anchor" aria-label="anchor" href="#additional-data-sets"></a>
</h2>
<p>The following additional data sets have a similar structure to the
baseball data used in this vignette and are included with
<strong>rstanarm</strong>.</p>
<div class="section level5">
<h5 id="rat-tumors-n-71">Rat tumors (N = 71)<a class="anchor" aria-label="anchor" href="#rat-tumors-n-71"></a>
</h5>
<p>Tarone (1982) provides a data set of tumor incidence in historical
control groups of rats; specifically endometrial stromal polyps in
female lab rats of type F344. The data set is taken from the book site
for (Gelman et al. 2013):</p>
<ul>
<li>To load: <code>data(tumors, package = "rstanarm")</code>
</li>
<li>Data source: <a href="https://www.stat.columbia.edu/~gelman/book/data/rats.asc" class="external-link">https://www.stat.columbia.edu/~gelman/book/data/rats.asc</a>
</li>
</ul>
</div>
<div class="section level5">
<h5 id="surgical-mortality-n-12">Surgical mortality (N = 12)<a class="anchor" aria-label="anchor" href="#surgical-mortality-n-12"></a>
</h5>
<p>Spiegelhalter et al. (1996) provide a data set of mortality rates in
12 hospitals performing cardiac surgery in babies. We just manually
entered the data from the paper; it is also available in the Stan
example models repository in R format.</p>
<ul>
<li>To load: <code>data(mortality, package = "rstanarm")</code>
</li>
<li>Data source: Unknown</li>
</ul>
</div>
<div class="section level5">
<h5 id="baseball-hits-1996-al-n-308">Baseball hits 1996 AL (N = 308)<a class="anchor" aria-label="anchor" href="#baseball-hits-1996-al-n-308"></a>
</h5>
<p>Carpenter (2009) updates Efron and Morris’s (1975) data set for the
entire set of players for the entire 2006 American League season of
Major League Baseball. The data was originally downloaded from the
seanlahman.com, which is currently not working.</p>
<ul>
<li>To load: <code>data(bball2006, package = "rstanarm")</code>
</li>
<li>Data Source: <a href="https://web.archive.org/web/20220618114439/https://lingpipe-blog.com/2009/09/23/" class="external-link">https://web.archive.org/web/20220618114439/https://lingpipe-blog.com/2009/09/23/</a>
</li>
</ul>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Jonah Gabry, Ben Goodrich.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
